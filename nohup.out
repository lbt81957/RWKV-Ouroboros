[2023-09-30 14:43:29,895] [WARNING] [runner.py:190:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2023-09-30 14:43:29,915] [INFO] [runner.py:540:main] cmd = /home/neromous/.minicoda3/envs/blackfog/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None app.py --deepspeed
[2023-09-30 14:43:32,381] [INFO] [launch.py:229:main] WORLD INFO DICT: {'localhost': [1]}
[2023-09-30 14:43:32,381] [INFO] [launch.py:235:main] nnodes=1, num_local_procs=1, node_rank=0
[2023-09-30 14:43:32,381] [INFO] [launch.py:246:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2023-09-30 14:43:32,381] [INFO] [launch.py:247:main] dist_world_size=1
[2023-09-30 14:43:32,381] [INFO] [launch.py:249:main] Setting CUDA_VISIBLE_DEVICES=1
RWKV_MY_TESTING 
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/wkv_512/build.ninja...
Building extension module wkv_512...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module wkv_512...
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 4.616151332855225 seconds
Adam Optimizer #0 is created with AVX2 arithmetic capability.
Config: alpha=0.000100, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=0
[2023-09-30 14:44:20,319] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.9.1, git-hash=unknown, git-branch=unknown
[2023-09-30 14:44:20,320] [INFO] [comm.py:586:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2023-09-30 14:44:23,626] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-30 14:44:23,628] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2023-09-30 14:44:23,628] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2023-09-30 14:44:23,667] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam
[2023-09-30 14:44:23,667] [INFO] [utils.py:51:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>
[2023-09-30 14:44:23,667] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float32 ZeRO stage 2 optimizer
[2023-09-30 14:44:23,667] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 2000000
[2023-09-30 14:44:23,667] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 2000000
[2023-09-30 14:44:23,668] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: True
[2023-09-30 14:44:23,668] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.23317265510559082 seconds
Rank: 0 partition count [1, 1, 1] and sizes[(3062589440, False), (81920, False), (81920, False)] 
[2023-09-30 14:44:50,011] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[2023-09-30 14:44:50,012] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 14:44:50,012] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 22.04 GB, percent = 17.5%
[2023-09-30 14:45:09,469] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[2023-09-30 14:45:09,470] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 14:45:09,470] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 61.25 GB, percent = 48.7%
[2023-09-30 14:45:09,471] [INFO] [stage_1_and_2.py:489:__init__] optimizer state initialized
[2023-09-30 14:45:11,081] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[2023-09-30 14:45:11,082] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 14:45:11,082] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 61.27 GB, percent = 48.7%
[2023-09-30 14:45:11,106] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedCPUAdam
[2023-09-30 14:45:11,106] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2023-09-30 14:45:11,106] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7fb77d5f10d0>
[2023-09-30 14:45:11,106] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0001, 0.0002, 0.00030000000000000003], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
[2023-09-30 14:45:11,107] [INFO] [config.py:953:print] DeepSpeedEngine configuration:
[2023-09-30 14:45:11,108] [INFO] [config.py:957:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-30 14:45:11,108] [INFO] [config.py:957:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-30 14:45:11,108] [INFO] [config.py:957:print]   amp_enabled .................. False
[2023-09-30 14:45:11,108] [INFO] [config.py:957:print]   amp_params ................... False
[2023-09-30 14:45:11,108] [INFO] [config.py:957:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-30 14:45:11,108] [INFO] [config.py:957:print]   bfloat16_enabled ............. False
[2023-09-30 14:45:11,108] [INFO] [config.py:957:print]   checkpoint_parallel_write_pipeline  False
[2023-09-30 14:45:11,108] [INFO] [config.py:957:print]   checkpoint_tag_validation_enabled  True
[2023-09-30 14:45:11,109] [INFO] [config.py:957:print]   checkpoint_tag_validation_fail  False
[2023-09-30 14:45:11,109] [INFO] [config.py:957:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fb77d5c80d0>
[2023-09-30 14:45:11,109] [INFO] [config.py:957:print]   communication_data_type ...... None
[2023-09-30 14:45:11,109] [INFO] [config.py:957:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-30 14:45:11,109] [INFO] [config.py:957:print]   curriculum_enabled_legacy .... False
[2023-09-30 14:45:11,109] [INFO] [config.py:957:print]   curriculum_params_legacy ..... False
[2023-09-30 14:45:11,109] [INFO] [config.py:957:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-30 14:45:11,109] [INFO] [config.py:957:print]   data_efficiency_enabled ...... False
[2023-09-30 14:45:11,109] [INFO] [config.py:957:print]   dataloader_drop_last ......... False
[2023-09-30 14:45:11,109] [INFO] [config.py:957:print]   disable_allgather ............ False
[2023-09-30 14:45:11,109] [INFO] [config.py:957:print]   dump_state ................... False
[2023-09-30 14:45:11,109] [INFO] [config.py:957:print]   dynamic_loss_scale_args ...... None
[2023-09-30 14:45:11,109] [INFO] [config.py:957:print]   eigenvalue_enabled ........... False
[2023-09-30 14:45:11,109] [INFO] [config.py:957:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-30 14:45:11,109] [INFO] [config.py:957:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-30 14:45:11,109] [INFO] [config.py:957:print]   eigenvalue_layer_num ......... 0
[2023-09-30 14:45:11,109] [INFO] [config.py:957:print]   eigenvalue_max_iter .......... 100
[2023-09-30 14:45:11,109] [INFO] [config.py:957:print]   eigenvalue_stability ......... 1e-06
[2023-09-30 14:45:11,109] [INFO] [config.py:957:print]   eigenvalue_tol ............... 0.01
[2023-09-30 14:45:11,109] [INFO] [config.py:957:print]   eigenvalue_verbose ........... False
[2023-09-30 14:45:11,109] [INFO] [config.py:957:print]   elasticity_enabled ........... False
[2023-09-30 14:45:11,109] [INFO] [config.py:957:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-30 14:45:11,109] [INFO] [config.py:957:print]   fp16_auto_cast ............... None
[2023-09-30 14:45:11,109] [INFO] [config.py:957:print]   fp16_enabled ................. False
[2023-09-30 14:45:11,109] [INFO] [config.py:957:print]   fp16_master_weights_and_gradients  False
[2023-09-30 14:45:11,110] [INFO] [config.py:957:print]   global_rank .................. 0
[2023-09-30 14:45:11,110] [INFO] [config.py:957:print]   grad_accum_dtype ............. None
[2023-09-30 14:45:11,110] [INFO] [config.py:957:print]   gradient_accumulation_steps .. 1
[2023-09-30 14:45:11,110] [INFO] [config.py:957:print]   gradient_clipping ............ 1
[2023-09-30 14:45:11,110] [INFO] [config.py:957:print]   gradient_predivide_factor .... 1.0
[2023-09-30 14:45:11,110] [INFO] [config.py:957:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-30 14:45:11,110] [INFO] [config.py:957:print]   initial_dynamic_scale ........ 65536
[2023-09-30 14:45:11,110] [INFO] [config.py:957:print]   load_universal_checkpoint .... False
[2023-09-30 14:45:11,110] [INFO] [config.py:957:print]   loss_scale ................... 0
[2023-09-30 14:45:11,110] [INFO] [config.py:957:print]   memory_breakdown ............. False
[2023-09-30 14:45:11,110] [INFO] [config.py:957:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-30 14:45:11,110] [INFO] [config.py:957:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-30 14:45:11,110] [INFO] [config.py:957:print]   optimizer_legacy_fusion ...... False
[2023-09-30 14:45:11,110] [INFO] [config.py:957:print]   optimizer_name ............... None
[2023-09-30 14:45:11,110] [INFO] [config.py:957:print]   optimizer_params ............. None
[2023-09-30 14:45:11,110] [INFO] [config.py:957:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-30 14:45:11,110] [INFO] [config.py:957:print]   pld_enabled .................. False
[2023-09-30 14:45:11,110] [INFO] [config.py:957:print]   pld_params ................... False
[2023-09-30 14:45:11,110] [INFO] [config.py:957:print]   prescale_gradients ........... False
[2023-09-30 14:45:11,110] [INFO] [config.py:957:print]   scheduler_name ............... None
[2023-09-30 14:45:11,111] [INFO] [config.py:957:print]   scheduler_params ............. None
[2023-09-30 14:45:11,111] [INFO] [config.py:957:print]   sparse_attention ............. None
[2023-09-30 14:45:11,111] [INFO] [config.py:957:print]   sparse_gradients_enabled ..... False
[2023-09-30 14:45:11,111] [INFO] [config.py:957:print]   steps_per_print .............. 10
[2023-09-30 14:45:11,111] [INFO] [config.py:957:print]   train_batch_size ............. 1
[2023-09-30 14:45:11,111] [INFO] [config.py:957:print]   train_micro_batch_size_per_gpu  1
[2023-09-30 14:45:11,111] [INFO] [config.py:957:print]   use_node_local_storage ....... False
[2023-09-30 14:45:11,111] [INFO] [config.py:957:print]   wall_clock_breakdown ......... False
[2023-09-30 14:45:11,111] [INFO] [config.py:957:print]   world_size ................... 1
[2023-09-30 14:45:11,111] [INFO] [config.py:957:print]   zero_allow_untested_optimizer  False
[2023-09-30 14:45:11,111] [INFO] [config.py:957:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=2000000 allgather_partitions=True allgather_bucket_size=2000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=True, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False memory_efficient_linear=True
[2023-09-30 14:45:11,111] [INFO] [config.py:957:print]   zero_enabled ................. True
[2023-09-30 14:45:11,111] [INFO] [config.py:957:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-30 14:45:11,111] [INFO] [config.py:957:print]   zero_optimization_stage ...... 2
[2023-09-30 14:45:11,111] [INFO] [config.py:943:print_user_config]   json = {
    "   fp16": {
        "enabled": false
    }, 
    "zero_optimization": {
        "stage": 2, 
        "offload_optimizer": {
            "device": "cpu", 
            "pin_memory": true
        }, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+06, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+06, 
        "contiguous_gradients": true
    }, 
    "gradient_accumulation_steps": 1, 
    "gradient_clipping": 1, 
    "train_micro_batch_size_per_gpu": 1, 
    "checkpoint": {
        "path": "/home/neromous/Documents/blackfog/resources/train-results/oneline/", 
        "keep_checkpoint_max": 3
    }
}
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.00045418739318847656 seconds
Bottle v0.12.25 server starting up (using WSGIRefServer())...
Listening on http://0.0.0.0:3000/
Hit Ctrl-C to quit.

[2023-09-30 16:38:02,153] [WARNING] [runner.py:190:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2023-09-30 16:38:02,173] [INFO] [runner.py:540:main] cmd = /home/neromous/.minicoda3/envs/blackfog/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None app.py --deepspeed
[2023-09-30 16:38:04,699] [INFO] [launch.py:229:main] WORLD INFO DICT: {'localhost': [1]}
[2023-09-30 16:38:04,699] [INFO] [launch.py:235:main] nnodes=1, num_local_procs=1, node_rank=0
[2023-09-30 16:38:04,699] [INFO] [launch.py:246:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2023-09-30 16:38:04,699] [INFO] [launch.py:247:main] dist_world_size=1
[2023-09-30 16:38:04,699] [INFO] [launch.py:249:main] Setting CUDA_VISIBLE_DEVICES=1
RWKV_MY_TESTING 
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/wkv_512/build.ninja...
Building extension module wkv_512...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module wkv_512...
[2023-09-30 16:38:22,008] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 1207084
[2023-09-30 16:38:22,009] [ERROR] [launch.py:434:sigkill_handler] ['/home/neromous/.minicoda3/envs/blackfog/bin/python', '-u', 'app.py', '--local_rank=0', '--deepspeed'] exits with return code = -9
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 3.4222633838653564 seconds
Adam Optimizer #0 is created with AVX2 arithmetic capability.
Config: alpha=0.000100, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=0
[2023-09-30 16:38:27,349] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.9.1, git-hash=unknown, git-branch=unknown
[2023-09-30 16:38:27,350] [INFO] [comm.py:586:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2023-09-30 16:38:27,999] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-30 16:38:28,001] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2023-09-30 16:38:28,001] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2023-09-30 16:38:28,025] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam
[2023-09-30 16:38:28,025] [INFO] [utils.py:51:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>
[2023-09-30 16:38:28,025] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float32 ZeRO stage 2 optimizer
[2023-09-30 16:38:28,025] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 2000000
[2023-09-30 16:38:28,025] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 2000000
[2023-09-30 16:38:28,025] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: True
[2023-09-30 16:38:28,025] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.22358965873718262 seconds
Rank: 0 partition count [1, 1, 1] and sizes[(461598720, False), (24576, False), (24576, False)] 
[2023-09-30 16:38:32,351] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[2023-09-30 16:38:32,351] [INFO] [utils.py:786:see_memory_usage] MA 1.97 GB         Max_MA 1.97 GB         CA 1.97 GB         Max_CA 2 GB 
[2023-09-30 16:38:32,352] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 8.85 GB, percent = 7.0%
[2023-09-30 16:38:35,089] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[2023-09-30 16:38:35,090] [INFO] [utils.py:786:see_memory_usage] MA 1.97 GB         Max_MA 1.97 GB         CA 1.97 GB         Max_CA 2 GB 
[2023-09-30 16:38:35,090] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 14.33 GB, percent = 11.4%
[2023-09-30 16:38:35,090] [INFO] [stage_1_and_2.py:489:__init__] optimizer state initialized
[2023-09-30 16:38:35,750] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[2023-09-30 16:38:35,751] [INFO] [utils.py:786:see_memory_usage] MA 1.97 GB         Max_MA 1.97 GB         CA 1.97 GB         Max_CA 2 GB 
[2023-09-30 16:38:35,751] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 14.33 GB, percent = 11.4%
[2023-09-30 16:38:35,766] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedCPUAdam
[2023-09-30 16:38:35,766] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2023-09-30 16:38:35,766] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7f9c5e773cd0>
[2023-09-30 16:38:35,766] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0001, 0.0002, 0.00030000000000000003], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
[2023-09-30 16:38:35,767] [INFO] [config.py:953:print] DeepSpeedEngine configuration:
[2023-09-30 16:38:35,768] [INFO] [config.py:957:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-30 16:38:35,768] [INFO] [config.py:957:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-30 16:38:35,768] [INFO] [config.py:957:print]   amp_enabled .................. False
[2023-09-30 16:38:35,768] [INFO] [config.py:957:print]   amp_params ................... False
[2023-09-30 16:38:35,768] [INFO] [config.py:957:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-30 16:38:35,768] [INFO] [config.py:957:print]   bfloat16_enabled ............. False
[2023-09-30 16:38:35,768] [INFO] [config.py:957:print]   checkpoint_parallel_write_pipeline  False
[2023-09-30 16:38:35,768] [INFO] [config.py:957:print]   checkpoint_tag_validation_enabled  True
[2023-09-30 16:38:35,768] [INFO] [config.py:957:print]   checkpoint_tag_validation_fail  False
[2023-09-30 16:38:35,768] [INFO] [config.py:957:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f9c7ce4d040>
[2023-09-30 16:38:35,768] [INFO] [config.py:957:print]   communication_data_type ...... None
[2023-09-30 16:38:35,768] [INFO] [config.py:957:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-30 16:38:35,768] [INFO] [config.py:957:print]   curriculum_enabled_legacy .... False
[2023-09-30 16:38:35,768] [INFO] [config.py:957:print]   curriculum_params_legacy ..... False
[2023-09-30 16:38:35,768] [INFO] [config.py:957:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-30 16:38:35,768] [INFO] [config.py:957:print]   data_efficiency_enabled ...... False
[2023-09-30 16:38:35,768] [INFO] [config.py:957:print]   dataloader_drop_last ......... False
[2023-09-30 16:38:35,768] [INFO] [config.py:957:print]   disable_allgather ............ False
[2023-09-30 16:38:35,769] [INFO] [config.py:957:print]   dump_state ................... False
[2023-09-30 16:38:35,769] [INFO] [config.py:957:print]   dynamic_loss_scale_args ...... None
[2023-09-30 16:38:35,769] [INFO] [config.py:957:print]   eigenvalue_enabled ........... False
[2023-09-30 16:38:35,769] [INFO] [config.py:957:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-30 16:38:35,769] [INFO] [config.py:957:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-30 16:38:35,769] [INFO] [config.py:957:print]   eigenvalue_layer_num ......... 0
[2023-09-30 16:38:35,769] [INFO] [config.py:957:print]   eigenvalue_max_iter .......... 100
[2023-09-30 16:38:35,769] [INFO] [config.py:957:print]   eigenvalue_stability ......... 1e-06
[2023-09-30 16:38:35,769] [INFO] [config.py:957:print]   eigenvalue_tol ............... 0.01
[2023-09-30 16:38:35,769] [INFO] [config.py:957:print]   eigenvalue_verbose ........... False
[2023-09-30 16:38:35,769] [INFO] [config.py:957:print]   elasticity_enabled ........... False
[2023-09-30 16:38:35,769] [INFO] [config.py:957:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-30 16:38:35,769] [INFO] [config.py:957:print]   fp16_auto_cast ............... None
[2023-09-30 16:38:35,769] [INFO] [config.py:957:print]   fp16_enabled ................. False
[2023-09-30 16:38:35,769] [INFO] [config.py:957:print]   fp16_master_weights_and_gradients  False
[2023-09-30 16:38:35,769] [INFO] [config.py:957:print]   global_rank .................. 0
[2023-09-30 16:38:35,769] [INFO] [config.py:957:print]   grad_accum_dtype ............. None
[2023-09-30 16:38:35,769] [INFO] [config.py:957:print]   gradient_accumulation_steps .. 1
[2023-09-30 16:38:35,769] [INFO] [config.py:957:print]   gradient_clipping ............ 1
[2023-09-30 16:38:35,769] [INFO] [config.py:957:print]   gradient_predivide_factor .... 1.0
[2023-09-30 16:38:35,769] [INFO] [config.py:957:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-30 16:38:35,769] [INFO] [config.py:957:print]   initial_dynamic_scale ........ 65536
[2023-09-30 16:38:35,769] [INFO] [config.py:957:print]   load_universal_checkpoint .... False
[2023-09-30 16:38:35,769] [INFO] [config.py:957:print]   loss_scale ................... 0
[2023-09-30 16:38:35,769] [INFO] [config.py:957:print]   memory_breakdown ............. False
[2023-09-30 16:38:35,770] [INFO] [config.py:957:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-30 16:38:35,770] [INFO] [config.py:957:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-30 16:38:35,770] [INFO] [config.py:957:print]   optimizer_legacy_fusion ...... False
[2023-09-30 16:38:35,770] [INFO] [config.py:957:print]   optimizer_name ............... None
[2023-09-30 16:38:35,770] [INFO] [config.py:957:print]   optimizer_params ............. None
[2023-09-30 16:38:35,770] [INFO] [config.py:957:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-30 16:38:35,770] [INFO] [config.py:957:print]   pld_enabled .................. False
[2023-09-30 16:38:35,770] [INFO] [config.py:957:print]   pld_params ................... False
[2023-09-30 16:38:35,770] [INFO] [config.py:957:print]   prescale_gradients ........... False
[2023-09-30 16:38:35,770] [INFO] [config.py:957:print]   scheduler_name ............... None
[2023-09-30 16:38:35,770] [INFO] [config.py:957:print]   scheduler_params ............. None
[2023-09-30 16:38:35,770] [INFO] [config.py:957:print]   sparse_attention ............. None
[2023-09-30 16:38:35,770] [INFO] [config.py:957:print]   sparse_gradients_enabled ..... False
[2023-09-30 16:38:35,770] [INFO] [config.py:957:print]   steps_per_print .............. 10
[2023-09-30 16:38:35,770] [INFO] [config.py:957:print]   train_batch_size ............. 1
[2023-09-30 16:38:35,770] [INFO] [config.py:957:print]   train_micro_batch_size_per_gpu  1
[2023-09-30 16:38:35,770] [INFO] [config.py:957:print]   use_node_local_storage ....... False
[2023-09-30 16:38:35,770] [INFO] [config.py:957:print]   wall_clock_breakdown ......... False
[2023-09-30 16:38:35,770] [INFO] [config.py:957:print]   world_size ................... 1
[2023-09-30 16:38:35,770] [INFO] [config.py:957:print]   zero_allow_untested_optimizer  False
[2023-09-30 16:38:35,770] [INFO] [config.py:957:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=2000000 allgather_partitions=True allgather_bucket_size=2000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=True, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False memory_efficient_linear=True
[2023-09-30 16:38:35,770] [INFO] [config.py:957:print]   zero_enabled ................. True
[2023-09-30 16:38:35,770] [INFO] [config.py:957:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-30 16:38:35,770] [INFO] [config.py:957:print]   zero_optimization_stage ...... 2
[2023-09-30 16:38:35,771] [INFO] [config.py:943:print_user_config]   json = {
    "   fp16": {
        "enabled": false
    }, 
    "zero_optimization": {
        "stage": 2, 
        "offload_optimizer": {
            "device": "cpu", 
            "pin_memory": true
        }, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+06, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+06, 
        "contiguous_gradients": true
    }, 
    "gradient_accumulation_steps": 1, 
    "gradient_clipping": 1, 
    "train_micro_batch_size_per_gpu": 1, 
    "checkpoint": {
        "path": "/home/neromous/Documents/blackfog/resources/train-results/oneline/", 
        "keep_checkpoint_max": 3
    }
}
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0004134178161621094 seconds
Bottle v0.12.25 server starting up (using WSGIRefServer())...
Listening on http://0.0.0.0:3000/
Hit Ctrl-C to quit.

Traceback (most recent call last):
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/bottle.py", line 876, in _handle
    return route.call(**args)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/bottle.py", line 1759, in wrapper
    rv = callback(*a, **ka)
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/app.py", line 155, in train
    for token in data_iter:
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/models/scene.py", line 76, in yield_tokens
    output = tokens[ctx:]
NameError: name 'ctx' is not defined
127.0.0.1 - - [30/Sep/2023 16:39:41] "POST /train/tx-data HTTP/1.1" 500 752
[2023-09-30 16:40:45,891] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 1239336
[2023-09-30 16:40:45,892] [ERROR] [launch.py:434:sigkill_handler] ['/home/neromous/.minicoda3/envs/blackfog/bin/python', '-u', 'app.py', '--local_rank=0', '--deepspeed'] exits with return code = -9
[2023-09-30 16:40:54,128] [WARNING] [runner.py:190:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2023-09-30 16:40:57,657] [INFO] [runner.py:540:main] cmd = /home/neromous/.minicoda3/envs/blackfog/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None app.py --deepspeed
[2023-09-30 16:41:00,151] [INFO] [launch.py:229:main] WORLD INFO DICT: {'localhost': [1]}
[2023-09-30 16:41:00,151] [INFO] [launch.py:235:main] nnodes=1, num_local_procs=1, node_rank=0
[2023-09-30 16:41:00,151] [INFO] [launch.py:246:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2023-09-30 16:41:00,151] [INFO] [launch.py:247:main] dist_world_size=1
[2023-09-30 16:41:00,152] [INFO] [launch.py:249:main] Setting CUDA_VISIBLE_DEVICES=1
RWKV_MY_TESTING 
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/wkv_512/build.ninja...
Building extension module wkv_512...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module wkv_512...
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 3.167691230773926 seconds
Adam Optimizer #0 is created with AVX2 arithmetic capability.
Config: alpha=0.000100, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=0
[2023-09-30 16:41:21,608] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.9.1, git-hash=unknown, git-branch=unknown
[2023-09-30 16:41:21,609] [INFO] [comm.py:586:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2023-09-30 16:41:22,237] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-30 16:41:22,238] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2023-09-30 16:41:22,238] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2023-09-30 16:41:22,262] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam
[2023-09-30 16:41:22,262] [INFO] [utils.py:51:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>
[2023-09-30 16:41:22,262] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float32 ZeRO stage 2 optimizer
[2023-09-30 16:41:22,262] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 2000000
[2023-09-30 16:41:22,262] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 2000000
[2023-09-30 16:41:22,262] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: True
[2023-09-30 16:41:22,262] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.24089789390563965 seconds
Rank: 0 partition count [1, 1, 1] and sizes[(461598720, False), (24576, False), (24576, False)] 
[2023-09-30 16:41:26,679] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[2023-09-30 16:41:26,680] [INFO] [utils.py:786:see_memory_usage] MA 1.97 GB         Max_MA 1.97 GB         CA 1.97 GB         Max_CA 2 GB 
[2023-09-30 16:41:26,680] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 8.85 GB, percent = 7.0%
[2023-09-30 16:41:29,388] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[2023-09-30 16:41:29,389] [INFO] [utils.py:786:see_memory_usage] MA 1.97 GB         Max_MA 1.97 GB         CA 1.97 GB         Max_CA 2 GB 
[2023-09-30 16:41:29,389] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 14.34 GB, percent = 11.4%
[2023-09-30 16:41:29,389] [INFO] [stage_1_and_2.py:489:__init__] optimizer state initialized
[2023-09-30 16:41:30,060] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[2023-09-30 16:41:30,061] [INFO] [utils.py:786:see_memory_usage] MA 1.97 GB         Max_MA 1.97 GB         CA 1.97 GB         Max_CA 2 GB 
[2023-09-30 16:41:30,061] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 14.34 GB, percent = 11.4%
[2023-09-30 16:41:30,083] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedCPUAdam
[2023-09-30 16:41:30,084] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2023-09-30 16:41:30,084] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7f0bf8a70220>
[2023-09-30 16:41:30,084] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0001, 0.0002, 0.00030000000000000003], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
[2023-09-30 16:41:30,085] [INFO] [config.py:953:print] DeepSpeedEngine configuration:
[2023-09-30 16:41:30,085] [INFO] [config.py:957:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-30 16:41:30,085] [INFO] [config.py:957:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-30 16:41:30,085] [INFO] [config.py:957:print]   amp_enabled .................. False
[2023-09-30 16:41:30,085] [INFO] [config.py:957:print]   amp_params ................... False
[2023-09-30 16:41:30,085] [INFO] [config.py:957:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-30 16:41:30,086] [INFO] [config.py:957:print]   bfloat16_enabled ............. False
[2023-09-30 16:41:30,086] [INFO] [config.py:957:print]   checkpoint_parallel_write_pipeline  False
[2023-09-30 16:41:30,086] [INFO] [config.py:957:print]   checkpoint_tag_validation_enabled  True
[2023-09-30 16:41:30,086] [INFO] [config.py:957:print]   checkpoint_tag_validation_fail  False
[2023-09-30 16:41:30,086] [INFO] [config.py:957:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f0bf0d06b80>
[2023-09-30 16:41:30,086] [INFO] [config.py:957:print]   communication_data_type ...... None
[2023-09-30 16:41:30,086] [INFO] [config.py:957:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-30 16:41:30,086] [INFO] [config.py:957:print]   curriculum_enabled_legacy .... False
[2023-09-30 16:41:30,086] [INFO] [config.py:957:print]   curriculum_params_legacy ..... False
[2023-09-30 16:41:30,086] [INFO] [config.py:957:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-30 16:41:30,086] [INFO] [config.py:957:print]   data_efficiency_enabled ...... False
[2023-09-30 16:41:30,086] [INFO] [config.py:957:print]   dataloader_drop_last ......... False
[2023-09-30 16:41:30,086] [INFO] [config.py:957:print]   disable_allgather ............ False
[2023-09-30 16:41:30,086] [INFO] [config.py:957:print]   dump_state ................... False
[2023-09-30 16:41:30,086] [INFO] [config.py:957:print]   dynamic_loss_scale_args ...... None
[2023-09-30 16:41:30,086] [INFO] [config.py:957:print]   eigenvalue_enabled ........... False
[2023-09-30 16:41:30,086] [INFO] [config.py:957:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-30 16:41:30,086] [INFO] [config.py:957:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-30 16:41:30,086] [INFO] [config.py:957:print]   eigenvalue_layer_num ......... 0
[2023-09-30 16:41:30,086] [INFO] [config.py:957:print]   eigenvalue_max_iter .......... 100
[2023-09-30 16:41:30,086] [INFO] [config.py:957:print]   eigenvalue_stability ......... 1e-06
[2023-09-30 16:41:30,086] [INFO] [config.py:957:print]   eigenvalue_tol ............... 0.01
[2023-09-30 16:41:30,086] [INFO] [config.py:957:print]   eigenvalue_verbose ........... False
[2023-09-30 16:41:30,086] [INFO] [config.py:957:print]   elasticity_enabled ........... False
[2023-09-30 16:41:30,086] [INFO] [config.py:957:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-30 16:41:30,087] [INFO] [config.py:957:print]   fp16_auto_cast ............... None
[2023-09-30 16:41:30,087] [INFO] [config.py:957:print]   fp16_enabled ................. False
[2023-09-30 16:41:30,087] [INFO] [config.py:957:print]   fp16_master_weights_and_gradients  False
[2023-09-30 16:41:30,087] [INFO] [config.py:957:print]   global_rank .................. 0
[2023-09-30 16:41:30,087] [INFO] [config.py:957:print]   grad_accum_dtype ............. None
[2023-09-30 16:41:30,087] [INFO] [config.py:957:print]   gradient_accumulation_steps .. 1
[2023-09-30 16:41:30,087] [INFO] [config.py:957:print]   gradient_clipping ............ 1
[2023-09-30 16:41:30,087] [INFO] [config.py:957:print]   gradient_predivide_factor .... 1.0
[2023-09-30 16:41:30,087] [INFO] [config.py:957:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-30 16:41:30,087] [INFO] [config.py:957:print]   initial_dynamic_scale ........ 65536
[2023-09-30 16:41:30,087] [INFO] [config.py:957:print]   load_universal_checkpoint .... False
[2023-09-30 16:41:30,087] [INFO] [config.py:957:print]   loss_scale ................... 0
[2023-09-30 16:41:30,087] [INFO] [config.py:957:print]   memory_breakdown ............. False
[2023-09-30 16:41:30,087] [INFO] [config.py:957:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-30 16:41:30,087] [INFO] [config.py:957:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-30 16:41:30,087] [INFO] [config.py:957:print]   optimizer_legacy_fusion ...... False
[2023-09-30 16:41:30,087] [INFO] [config.py:957:print]   optimizer_name ............... None
[2023-09-30 16:41:30,087] [INFO] [config.py:957:print]   optimizer_params ............. None
[2023-09-30 16:41:30,087] [INFO] [config.py:957:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-30 16:41:30,087] [INFO] [config.py:957:print]   pld_enabled .................. False
[2023-09-30 16:41:30,087] [INFO] [config.py:957:print]   pld_params ................... False
[2023-09-30 16:41:30,087] [INFO] [config.py:957:print]   prescale_gradients ........... False
[2023-09-30 16:41:30,087] [INFO] [config.py:957:print]   scheduler_name ............... None
[2023-09-30 16:41:30,087] [INFO] [config.py:957:print]   scheduler_params ............. None
[2023-09-30 16:41:30,088] [INFO] [config.py:957:print]   sparse_attention ............. None
[2023-09-30 16:41:30,088] [INFO] [config.py:957:print]   sparse_gradients_enabled ..... False
[2023-09-30 16:41:30,088] [INFO] [config.py:957:print]   steps_per_print .............. 10
[2023-09-30 16:41:30,088] [INFO] [config.py:957:print]   train_batch_size ............. 1
[2023-09-30 16:41:30,088] [INFO] [config.py:957:print]   train_micro_batch_size_per_gpu  1
[2023-09-30 16:41:30,088] [INFO] [config.py:957:print]   use_node_local_storage ....... False
[2023-09-30 16:41:30,088] [INFO] [config.py:957:print]   wall_clock_breakdown ......... False
[2023-09-30 16:41:30,088] [INFO] [config.py:957:print]   world_size ................... 1
[2023-09-30 16:41:30,088] [INFO] [config.py:957:print]   zero_allow_untested_optimizer  False
[2023-09-30 16:41:30,088] [INFO] [config.py:957:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=2000000 allgather_partitions=True allgather_bucket_size=2000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=True, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False memory_efficient_linear=True
[2023-09-30 16:41:30,088] [INFO] [config.py:957:print]   zero_enabled ................. True
[2023-09-30 16:41:30,088] [INFO] [config.py:957:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-30 16:41:30,088] [INFO] [config.py:957:print]   zero_optimization_stage ...... 2
[2023-09-30 16:41:30,088] [INFO] [config.py:943:print_user_config]   json = {
    "   fp16": {
        "enabled": false
    }, 
    "zero_optimization": {
        "stage": 2, 
        "offload_optimizer": {
            "device": "cpu", 
            "pin_memory": true
        }, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+06, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+06, 
        "contiguous_gradients": true
    }, 
    "gradient_accumulation_steps": 1, 
    "gradient_clipping": 1, 
    "train_micro_batch_size_per_gpu": 1, 
    "checkpoint": {
        "path": "/home/neromous/Documents/blackfog/resources/train-results/oneline/", 
        "keep_checkpoint_max": 3
    }
}
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.00039887428283691406 seconds
Bottle v0.12.25 server starting up (using WSGIRefServer())...
Listening on http://0.0.0.0:3000/
Hit Ctrl-C to quit.

[2023-09-30 16:41:51,328] [INFO] [checkpointing.py:529:forward] Activation Checkpointing Information
[2023-09-30 16:41:51,328] [INFO] [checkpointing.py:530:forward] ----Partition Activations False, CPU CHECKPOINTING False
[2023-09-30 16:41:51,328] [INFO] [checkpointing.py:531:forward] ----contiguous Memory Checkpointing False with None total layers
[2023-09-30 16:41:51,328] [INFO] [checkpointing.py:533:forward] ----Synchronization False
[2023-09-30 16:41:51,328] [INFO] [checkpointing.py:534:forward] ----Profiling time in checkpointing False
Traceback (most recent call last):
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/bottle.py", line 876, in _handle
    return route.call(**args)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/bottle.py", line 1759, in wrapper
    rv = callback(*a, **ka)
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/app.py", line 159, in train
    m = model_engine.training_step(batch, model_engine=model_engine)
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/rwkv_model/model_lora.py", line 790, in training_step
    logits = self(idx)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/rwkv_model/model_lora.py", line 765, in forward
    x = deepspeed.checkpointing.checkpoint(block, x)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/deepspeed/runtime/activation_checkpointing/checkpointing.py", line 713, in checkpoint
    CheckpointFunction.apply(function, all_outputs, *args)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/torch/autograd/function.py", line 506, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/deepspeed/runtime/activation_checkpointing/checkpointing.py", line 555, in forward
    outputs = run_function(*inputs_cuda)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/rwkv_model/model_lora.py", line 518, in forward
    x = x + self.att(self.ln1(x))
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/rwkv_model/model_lora.py", line 422, in forward
    sr, k, v = self.jit_func(x)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/rwkv_model/model_lora.py", line 410, in jit_func
    @MyFunction
    def jit_func(self, x):
        xx = self.time_shift(x) # Mix x with the previous timestep to produce xk, xv, xr
             ~~~~~~~~~~~~~~~ <--- HERE
        xk = x * self.time_mix_k + xx * (1 - self.time_mix_k)
        xv = x * self.time_mix_v + xx * (1 - self.time_mix_v)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/torch/nn/modules/padding.py", line 25, in forward
    def forward(self, input: Tensor) -> Tensor:
        return F.pad(input, self.padding, 'constant', self.value)
               ~~~~~ <--- HERE
RuntimeError: narrow(): length must be non-negative.

127.0.0.1 - - [30/Sep/2023 16:41:51] "POST /train/tx-data HTTP/1.1" 500 752
[2023-09-30 16:42:56,292] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 1240743
[2023-09-30 16:42:56,293] [ERROR] [launch.py:434:sigkill_handler] ['/home/neromous/.minicoda3/envs/blackfog/bin/python', '-u', 'app.py', '--local_rank=0', '--deepspeed'] exits with return code = -9
[2023-09-30 16:43:00,215] [WARNING] [runner.py:190:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2023-09-30 16:43:00,235] [INFO] [runner.py:540:main] cmd = /home/neromous/.minicoda3/envs/blackfog/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None app.py --deepspeed
[2023-09-30 16:43:02,761] [INFO] [launch.py:229:main] WORLD INFO DICT: {'localhost': [1]}
[2023-09-30 16:43:02,761] [INFO] [launch.py:235:main] nnodes=1, num_local_procs=1, node_rank=0
[2023-09-30 16:43:02,761] [INFO] [launch.py:246:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2023-09-30 16:43:02,761] [INFO] [launch.py:247:main] dist_world_size=1
[2023-09-30 16:43:02,761] [INFO] [launch.py:249:main] Setting CUDA_VISIBLE_DEVICES=1
RWKV_MY_TESTING 
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/wkv_512/build.ninja...
Building extension module wkv_512...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module wkv_512...
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 3.2136683464050293 seconds
Adam Optimizer #0 is created with AVX2 arithmetic capability.
Config: alpha=0.000100, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=0
[2023-09-30 16:43:24,447] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.9.1, git-hash=unknown, git-branch=unknown
[2023-09-30 16:43:24,447] [INFO] [comm.py:586:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2023-09-30 16:43:25,064] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-30 16:43:25,065] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2023-09-30 16:43:25,065] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2023-09-30 16:43:25,089] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam
[2023-09-30 16:43:25,089] [INFO] [utils.py:51:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>
[2023-09-30 16:43:25,089] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float32 ZeRO stage 2 optimizer
[2023-09-30 16:43:25,089] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 2000000
[2023-09-30 16:43:25,089] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 2000000
[2023-09-30 16:43:25,089] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: True
[2023-09-30 16:43:25,089] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.2330338954925537 seconds
Rank: 0 partition count [1, 1, 1] and sizes[(461598720, False), (24576, False), (24576, False)] 
[2023-09-30 16:43:29,446] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[2023-09-30 16:43:29,447] [INFO] [utils.py:786:see_memory_usage] MA 1.97 GB         Max_MA 1.97 GB         CA 1.97 GB         Max_CA 2 GB 
[2023-09-30 16:43:29,447] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 8.85 GB, percent = 7.0%
[2023-09-30 16:43:36,109] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[2023-09-30 16:43:36,110] [INFO] [utils.py:786:see_memory_usage] MA 1.97 GB         Max_MA 1.97 GB         CA 1.97 GB         Max_CA 2 GB 
[2023-09-30 16:43:36,110] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 14.32 GB, percent = 11.4%
[2023-09-30 16:43:36,110] [INFO] [stage_1_and_2.py:489:__init__] optimizer state initialized
[2023-09-30 16:43:36,763] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[2023-09-30 16:43:36,763] [INFO] [utils.py:786:see_memory_usage] MA 1.97 GB         Max_MA 1.97 GB         CA 1.97 GB         Max_CA 2 GB 
[2023-09-30 16:43:36,764] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 14.33 GB, percent = 11.4%
[2023-09-30 16:43:36,779] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedCPUAdam
[2023-09-30 16:43:36,779] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2023-09-30 16:43:36,779] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7f8381a33c70>
[2023-09-30 16:43:36,779] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0001, 0.0002, 0.00030000000000000003], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
[2023-09-30 16:43:36,780] [INFO] [config.py:953:print] DeepSpeedEngine configuration:
[2023-09-30 16:43:36,781] [INFO] [config.py:957:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-30 16:43:36,781] [INFO] [config.py:957:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-30 16:43:36,781] [INFO] [config.py:957:print]   amp_enabled .................. False
[2023-09-30 16:43:36,781] [INFO] [config.py:957:print]   amp_params ................... False
[2023-09-30 16:43:36,781] [INFO] [config.py:957:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-30 16:43:36,781] [INFO] [config.py:957:print]   bfloat16_enabled ............. False
[2023-09-30 16:43:36,781] [INFO] [config.py:957:print]   checkpoint_parallel_write_pipeline  False
[2023-09-30 16:43:36,781] [INFO] [config.py:957:print]   checkpoint_tag_validation_enabled  True
[2023-09-30 16:43:36,781] [INFO] [config.py:957:print]   checkpoint_tag_validation_fail  False
[2023-09-30 16:43:36,781] [INFO] [config.py:957:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f83940771f0>
[2023-09-30 16:43:36,781] [INFO] [config.py:957:print]   communication_data_type ...... None
[2023-09-30 16:43:36,781] [INFO] [config.py:957:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-30 16:43:36,781] [INFO] [config.py:957:print]   curriculum_enabled_legacy .... False
[2023-09-30 16:43:36,781] [INFO] [config.py:957:print]   curriculum_params_legacy ..... False
[2023-09-30 16:43:36,781] [INFO] [config.py:957:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-30 16:43:36,781] [INFO] [config.py:957:print]   data_efficiency_enabled ...... False
[2023-09-30 16:43:36,781] [INFO] [config.py:957:print]   dataloader_drop_last ......... False
[2023-09-30 16:43:36,781] [INFO] [config.py:957:print]   disable_allgather ............ False
[2023-09-30 16:43:36,781] [INFO] [config.py:957:print]   dump_state ................... False
[2023-09-30 16:43:36,782] [INFO] [config.py:957:print]   dynamic_loss_scale_args ...... None
[2023-09-30 16:43:36,782] [INFO] [config.py:957:print]   eigenvalue_enabled ........... False
[2023-09-30 16:43:36,782] [INFO] [config.py:957:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-30 16:43:36,782] [INFO] [config.py:957:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-30 16:43:36,782] [INFO] [config.py:957:print]   eigenvalue_layer_num ......... 0
[2023-09-30 16:43:36,782] [INFO] [config.py:957:print]   eigenvalue_max_iter .......... 100
[2023-09-30 16:43:36,782] [INFO] [config.py:957:print]   eigenvalue_stability ......... 1e-06
[2023-09-30 16:43:36,782] [INFO] [config.py:957:print]   eigenvalue_tol ............... 0.01
[2023-09-30 16:43:36,782] [INFO] [config.py:957:print]   eigenvalue_verbose ........... False
[2023-09-30 16:43:36,782] [INFO] [config.py:957:print]   elasticity_enabled ........... False
[2023-09-30 16:43:36,782] [INFO] [config.py:957:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-30 16:43:36,782] [INFO] [config.py:957:print]   fp16_auto_cast ............... None
[2023-09-30 16:43:36,782] [INFO] [config.py:957:print]   fp16_enabled ................. False
[2023-09-30 16:43:36,782] [INFO] [config.py:957:print]   fp16_master_weights_and_gradients  False
[2023-09-30 16:43:36,782] [INFO] [config.py:957:print]   global_rank .................. 0
[2023-09-30 16:43:36,782] [INFO] [config.py:957:print]   grad_accum_dtype ............. None
[2023-09-30 16:43:36,782] [INFO] [config.py:957:print]   gradient_accumulation_steps .. 1
[2023-09-30 16:43:36,782] [INFO] [config.py:957:print]   gradient_clipping ............ 1
[2023-09-30 16:43:36,782] [INFO] [config.py:957:print]   gradient_predivide_factor .... 1.0
[2023-09-30 16:43:36,782] [INFO] [config.py:957:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-30 16:43:36,782] [INFO] [config.py:957:print]   initial_dynamic_scale ........ 65536
[2023-09-30 16:43:36,782] [INFO] [config.py:957:print]   load_universal_checkpoint .... False
[2023-09-30 16:43:36,782] [INFO] [config.py:957:print]   loss_scale ................... 0
[2023-09-30 16:43:36,782] [INFO] [config.py:957:print]   memory_breakdown ............. False
[2023-09-30 16:43:36,782] [INFO] [config.py:957:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-30 16:43:36,783] [INFO] [config.py:957:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-30 16:43:36,783] [INFO] [config.py:957:print]   optimizer_legacy_fusion ...... False
[2023-09-30 16:43:36,783] [INFO] [config.py:957:print]   optimizer_name ............... None
[2023-09-30 16:43:36,783] [INFO] [config.py:957:print]   optimizer_params ............. None
[2023-09-30 16:43:36,783] [INFO] [config.py:957:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-30 16:43:36,783] [INFO] [config.py:957:print]   pld_enabled .................. False
[2023-09-30 16:43:36,783] [INFO] [config.py:957:print]   pld_params ................... False
[2023-09-30 16:43:36,783] [INFO] [config.py:957:print]   prescale_gradients ........... False
[2023-09-30 16:43:36,783] [INFO] [config.py:957:print]   scheduler_name ............... None
[2023-09-30 16:43:36,783] [INFO] [config.py:957:print]   scheduler_params ............. None
[2023-09-30 16:43:36,783] [INFO] [config.py:957:print]   sparse_attention ............. None
[2023-09-30 16:43:36,783] [INFO] [config.py:957:print]   sparse_gradients_enabled ..... False
[2023-09-30 16:43:36,783] [INFO] [config.py:957:print]   steps_per_print .............. 10
[2023-09-30 16:43:36,783] [INFO] [config.py:957:print]   train_batch_size ............. 1
[2023-09-30 16:43:36,783] [INFO] [config.py:957:print]   train_micro_batch_size_per_gpu  1
[2023-09-30 16:43:36,783] [INFO] [config.py:957:print]   use_node_local_storage ....... False
[2023-09-30 16:43:36,783] [INFO] [config.py:957:print]   wall_clock_breakdown ......... False
[2023-09-30 16:43:36,783] [INFO] [config.py:957:print]   world_size ................... 1
[2023-09-30 16:43:36,783] [INFO] [config.py:957:print]   zero_allow_untested_optimizer  False
[2023-09-30 16:43:36,783] [INFO] [config.py:957:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=2000000 allgather_partitions=True allgather_bucket_size=2000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=True, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False memory_efficient_linear=True
[2023-09-30 16:43:36,783] [INFO] [config.py:957:print]   zero_enabled ................. True
[2023-09-30 16:43:36,783] [INFO] [config.py:957:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-30 16:43:36,783] [INFO] [config.py:957:print]   zero_optimization_stage ...... 2
[2023-09-30 16:43:36,783] [INFO] [config.py:943:print_user_config]   json = {
    "   fp16": {
        "enabled": false
    }, 
    "zero_optimization": {
        "stage": 2, 
        "offload_optimizer": {
            "device": "cpu", 
            "pin_memory": true
        }, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+06, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+06, 
        "contiguous_gradients": true
    }, 
    "gradient_accumulation_steps": 1, 
    "gradient_clipping": 1, 
    "train_micro_batch_size_per_gpu": 1, 
    "checkpoint": {
        "path": "/home/neromous/Documents/blackfog/resources/train-results/oneline/", 
        "keep_checkpoint_max": 3
    }
}
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0003781318664550781 seconds
Bottle v0.12.25 server starting up (using WSGIRefServer())...
Listening on http://0.0.0.0:3000/
Hit Ctrl-C to quit.

{'input_ids': [], 'attention_mask': None}
[2023-09-30 16:43:53,902] [INFO] [checkpointing.py:529:forward] Activation Checkpointing Information
[2023-09-30 16:43:53,902] [INFO] [checkpointing.py:530:forward] ----Partition Activations False, CPU CHECKPOINTING False
[2023-09-30 16:43:53,902] [INFO] [checkpointing.py:531:forward] ----contiguous Memory Checkpointing False with None total layers
[2023-09-30 16:43:53,902] [INFO] [checkpointing.py:533:forward] ----Synchronization False
[2023-09-30 16:43:53,902] [INFO] [checkpointing.py:534:forward] ----Profiling time in checkpointing False
Traceback (most recent call last):
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/bottle.py", line 876, in _handle
    return route.call(**args)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/bottle.py", line 1759, in wrapper
    rv = callback(*a, **ka)
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/app.py", line 160, in train
    m = model_engine.training_step(batch, model_engine=model_engine)
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/rwkv_model/model_lora.py", line 790, in training_step
    logits = self(idx)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/rwkv_model/model_lora.py", line 765, in forward
    x = deepspeed.checkpointing.checkpoint(block, x)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/deepspeed/runtime/activation_checkpointing/checkpointing.py", line 713, in checkpoint
    CheckpointFunction.apply(function, all_outputs, *args)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/torch/autograd/function.py", line 506, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/deepspeed/runtime/activation_checkpointing/checkpointing.py", line 555, in forward
    outputs = run_function(*inputs_cuda)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/rwkv_model/model_lora.py", line 518, in forward
    x = x + self.att(self.ln1(x))
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/rwkv_model/model_lora.py", line 422, in forward
    sr, k, v = self.jit_func(x)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/rwkv_model/model_lora.py", line 410, in jit_func
    @MyFunction
    def jit_func(self, x):
        xx = self.time_shift(x) # Mix x with the previous timestep to produce xk, xv, xr
             ~~~~~~~~~~~~~~~ <--- HERE
        xk = x * self.time_mix_k + xx * (1 - self.time_mix_k)
        xv = x * self.time_mix_v + xx * (1 - self.time_mix_v)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/torch/nn/modules/padding.py", line 25, in forward
    def forward(self, input: Tensor) -> Tensor:
        return F.pad(input, self.padding, 'constant', self.value)
               ~~~~~ <--- HERE
RuntimeError: narrow(): length must be non-negative.

127.0.0.1 - - [30/Sep/2023 16:43:54] "POST /train/tx-data HTTP/1.1" 500 752
[2023-09-30 16:44:33,875] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 1241445
[2023-09-30 16:44:33,876] [ERROR] [launch.py:434:sigkill_handler] ['/home/neromous/.minicoda3/envs/blackfog/bin/python', '-u', 'app.py', '--local_rank=0', '--deepspeed'] exits with return code = -9
[2023-09-30 16:44:35,625] [WARNING] [runner.py:190:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2023-09-30 16:44:35,645] [INFO] [runner.py:540:main] cmd = /home/neromous/.minicoda3/envs/blackfog/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None app.py --deepspeed
[2023-09-30 16:44:38,155] [INFO] [launch.py:229:main] WORLD INFO DICT: {'localhost': [1]}
[2023-09-30 16:44:38,155] [INFO] [launch.py:235:main] nnodes=1, num_local_procs=1, node_rank=0
[2023-09-30 16:44:38,155] [INFO] [launch.py:246:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2023-09-30 16:44:38,155] [INFO] [launch.py:247:main] dist_world_size=1
[2023-09-30 16:44:38,155] [INFO] [launch.py:249:main] Setting CUDA_VISIBLE_DEVICES=1
RWKV_MY_TESTING 
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/wkv_512/build.ninja...
Building extension module wkv_512...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module wkv_512...
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 3.2163853645324707 seconds
Adam Optimizer #0 is created with AVX2 arithmetic capability.
Config: alpha=0.000100, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=0
[2023-09-30 16:44:59,755] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.9.1, git-hash=unknown, git-branch=unknown
[2023-09-30 16:44:59,755] [INFO] [comm.py:586:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2023-09-30 16:45:00,370] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-30 16:45:00,372] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2023-09-30 16:45:00,372] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2023-09-30 16:45:00,395] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam
[2023-09-30 16:45:00,395] [INFO] [utils.py:51:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>
[2023-09-30 16:45:00,395] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float32 ZeRO stage 2 optimizer
[2023-09-30 16:45:00,395] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 2000000
[2023-09-30 16:45:00,395] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 2000000
[2023-09-30 16:45:00,395] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: True
[2023-09-30 16:45:00,395] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.2518012523651123 seconds
Rank: 0 partition count [1, 1, 1] and sizes[(461598720, False), (24576, False), (24576, False)] 
[2023-09-30 16:45:04,773] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[2023-09-30 16:45:04,774] [INFO] [utils.py:786:see_memory_usage] MA 1.97 GB         Max_MA 1.97 GB         CA 1.97 GB         Max_CA 2 GB 
[2023-09-30 16:45:04,774] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 8.85 GB, percent = 7.0%
[2023-09-30 16:45:07,478] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[2023-09-30 16:45:07,479] [INFO] [utils.py:786:see_memory_usage] MA 1.97 GB         Max_MA 1.97 GB         CA 1.97 GB         Max_CA 2 GB 
[2023-09-30 16:45:07,479] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 14.33 GB, percent = 11.4%
[2023-09-30 16:45:07,479] [INFO] [stage_1_and_2.py:489:__init__] optimizer state initialized
[2023-09-30 16:45:08,136] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[2023-09-30 16:45:08,136] [INFO] [utils.py:786:see_memory_usage] MA 1.97 GB         Max_MA 1.97 GB         CA 1.97 GB         Max_CA 2 GB 
[2023-09-30 16:45:08,137] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 14.33 GB, percent = 11.4%
[2023-09-30 16:45:08,152] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedCPUAdam
[2023-09-30 16:45:08,152] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2023-09-30 16:45:08,152] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7f9b22e35b50>
[2023-09-30 16:45:08,152] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0001, 0.0002, 0.00030000000000000003], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
[2023-09-30 16:45:08,153] [INFO] [config.py:953:print] DeepSpeedEngine configuration:
[2023-09-30 16:45:08,153] [INFO] [config.py:957:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-30 16:45:08,153] [INFO] [config.py:957:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-30 16:45:08,153] [INFO] [config.py:957:print]   amp_enabled .................. False
[2023-09-30 16:45:08,153] [INFO] [config.py:957:print]   amp_params ................... False
[2023-09-30 16:45:08,154] [INFO] [config.py:957:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-30 16:45:08,154] [INFO] [config.py:957:print]   bfloat16_enabled ............. False
[2023-09-30 16:45:08,154] [INFO] [config.py:957:print]   checkpoint_parallel_write_pipeline  False
[2023-09-30 16:45:08,154] [INFO] [config.py:957:print]   checkpoint_tag_validation_enabled  True
[2023-09-30 16:45:08,154] [INFO] [config.py:957:print]   checkpoint_tag_validation_fail  False
[2023-09-30 16:45:08,154] [INFO] [config.py:957:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f9b2d706d30>
[2023-09-30 16:45:08,154] [INFO] [config.py:957:print]   communication_data_type ...... None
[2023-09-30 16:45:08,154] [INFO] [config.py:957:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-30 16:45:08,154] [INFO] [config.py:957:print]   curriculum_enabled_legacy .... False
[2023-09-30 16:45:08,154] [INFO] [config.py:957:print]   curriculum_params_legacy ..... False
[2023-09-30 16:45:08,154] [INFO] [config.py:957:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-30 16:45:08,154] [INFO] [config.py:957:print]   data_efficiency_enabled ...... False
[2023-09-30 16:45:08,154] [INFO] [config.py:957:print]   dataloader_drop_last ......... False
[2023-09-30 16:45:08,154] [INFO] [config.py:957:print]   disable_allgather ............ False
[2023-09-30 16:45:08,154] [INFO] [config.py:957:print]   dump_state ................... False
[2023-09-30 16:45:08,154] [INFO] [config.py:957:print]   dynamic_loss_scale_args ...... None
[2023-09-30 16:45:08,154] [INFO] [config.py:957:print]   eigenvalue_enabled ........... False
[2023-09-30 16:45:08,154] [INFO] [config.py:957:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-30 16:45:08,154] [INFO] [config.py:957:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-30 16:45:08,154] [INFO] [config.py:957:print]   eigenvalue_layer_num ......... 0
[2023-09-30 16:45:08,154] [INFO] [config.py:957:print]   eigenvalue_max_iter .......... 100
[2023-09-30 16:45:08,154] [INFO] [config.py:957:print]   eigenvalue_stability ......... 1e-06
[2023-09-30 16:45:08,154] [INFO] [config.py:957:print]   eigenvalue_tol ............... 0.01
[2023-09-30 16:45:08,154] [INFO] [config.py:957:print]   eigenvalue_verbose ........... False
[2023-09-30 16:45:08,154] [INFO] [config.py:957:print]   elasticity_enabled ........... False
[2023-09-30 16:45:08,155] [INFO] [config.py:957:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-30 16:45:08,155] [INFO] [config.py:957:print]   fp16_auto_cast ............... None
[2023-09-30 16:45:08,155] [INFO] [config.py:957:print]   fp16_enabled ................. False
[2023-09-30 16:45:08,155] [INFO] [config.py:957:print]   fp16_master_weights_and_gradients  False
[2023-09-30 16:45:08,155] [INFO] [config.py:957:print]   global_rank .................. 0
[2023-09-30 16:45:08,155] [INFO] [config.py:957:print]   grad_accum_dtype ............. None
[2023-09-30 16:45:08,155] [INFO] [config.py:957:print]   gradient_accumulation_steps .. 1
[2023-09-30 16:45:08,155] [INFO] [config.py:957:print]   gradient_clipping ............ 1
[2023-09-30 16:45:08,155] [INFO] [config.py:957:print]   gradient_predivide_factor .... 1.0
[2023-09-30 16:45:08,155] [INFO] [config.py:957:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-30 16:45:08,155] [INFO] [config.py:957:print]   initial_dynamic_scale ........ 65536
[2023-09-30 16:45:08,155] [INFO] [config.py:957:print]   load_universal_checkpoint .... False
[2023-09-30 16:45:08,155] [INFO] [config.py:957:print]   loss_scale ................... 0
[2023-09-30 16:45:08,155] [INFO] [config.py:957:print]   memory_breakdown ............. False
[2023-09-30 16:45:08,155] [INFO] [config.py:957:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-30 16:45:08,155] [INFO] [config.py:957:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-30 16:45:08,155] [INFO] [config.py:957:print]   optimizer_legacy_fusion ...... False
[2023-09-30 16:45:08,155] [INFO] [config.py:957:print]   optimizer_name ............... None
[2023-09-30 16:45:08,155] [INFO] [config.py:957:print]   optimizer_params ............. None
[2023-09-30 16:45:08,155] [INFO] [config.py:957:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-30 16:45:08,155] [INFO] [config.py:957:print]   pld_enabled .................. False
[2023-09-30 16:45:08,155] [INFO] [config.py:957:print]   pld_params ................... False
[2023-09-30 16:45:08,155] [INFO] [config.py:957:print]   prescale_gradients ........... False
[2023-09-30 16:45:08,156] [INFO] [config.py:957:print]   scheduler_name ............... None
[2023-09-30 16:45:08,156] [INFO] [config.py:957:print]   scheduler_params ............. None
[2023-09-30 16:45:08,156] [INFO] [config.py:957:print]   sparse_attention ............. None
[2023-09-30 16:45:08,156] [INFO] [config.py:957:print]   sparse_gradients_enabled ..... False
[2023-09-30 16:45:08,156] [INFO] [config.py:957:print]   steps_per_print .............. 10
[2023-09-30 16:45:08,156] [INFO] [config.py:957:print]   train_batch_size ............. 1
[2023-09-30 16:45:08,156] [INFO] [config.py:957:print]   train_micro_batch_size_per_gpu  1
[2023-09-30 16:45:08,156] [INFO] [config.py:957:print]   use_node_local_storage ....... False
[2023-09-30 16:45:08,156] [INFO] [config.py:957:print]   wall_clock_breakdown ......... False
[2023-09-30 16:45:08,156] [INFO] [config.py:957:print]   world_size ................... 1
[2023-09-30 16:45:08,156] [INFO] [config.py:957:print]   zero_allow_untested_optimizer  False
[2023-09-30 16:45:08,156] [INFO] [config.py:957:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=2000000 allgather_partitions=True allgather_bucket_size=2000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=True, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False memory_efficient_linear=True
[2023-09-30 16:45:08,156] [INFO] [config.py:957:print]   zero_enabled ................. True
[2023-09-30 16:45:08,156] [INFO] [config.py:957:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-30 16:45:08,156] [INFO] [config.py:957:print]   zero_optimization_stage ...... 2
[2023-09-30 16:45:08,156] [INFO] [config.py:943:print_user_config]   json = {
    "   fp16": {
        "enabled": false
    }, 
    "zero_optimization": {
        "stage": 2, 
        "offload_optimizer": {
            "device": "cpu", 
            "pin_memory": true
        }, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+06, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+06, 
        "contiguous_gradients": true
    }, 
    "gradient_accumulation_steps": 1, 
    "gradient_clipping": 1, 
    "train_micro_batch_size_per_gpu": 1, 
    "checkpoint": {
        "path": "/home/neromous/Documents/blackfog/resources/train-results/oneline/", 
        "keep_checkpoint_max": 3
    }
}
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0003788471221923828 seconds
Bottle v0.12.25 server starting up (using WSGIRefServer())...
Listening on http://0.0.0.0:3000/
Hit Ctrl-C to quit.

{'input_ids': [65535, 10444, 65530, 65532, 11164, 11164, 6134, 2058, 59, 33, 11640, 17772, 13091, 15446, 15898, 14734, 19137, 11957, 10260, 11957, 19156, 12605, 12605, 12605, 65535, 261, 65530, 65534, 5585, 41693, 59, 33, 13091, 14734, 19137, 11640, 17772, 13091, 15446, 15898, 14734, 19137, 12605, 16503, 12848, 17363, 10464, 11640, 17772, 13191, 13064, 10560, 17147, 11086, 14446, 10250, 10349, 18431, 15898, 10080, 65535, 261, 11111, 11111, 65535], 'attention_mask': None}
[2023-09-30 16:45:46,789] [INFO] [checkpointing.py:529:forward] Activation Checkpointing Information
[2023-09-30 16:45:46,789] [INFO] [checkpointing.py:530:forward] ----Partition Activations False, CPU CHECKPOINTING False
[2023-09-30 16:45:46,789] [INFO] [checkpointing.py:531:forward] ----contiguous Memory Checkpointing False with None total layers
[2023-09-30 16:45:46,790] [INFO] [checkpointing.py:533:forward] ----Synchronization False
[2023-09-30 16:45:46,790] [INFO] [checkpointing.py:534:forward] ----Profiling time in checkpointing False
127.0.0.1 - - [30/Sep/2023 16:45:54] "POST /train/tx-data HTTP/1.1" 200 27
[2023-09-30 17:14:02,124] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 1242055
[2023-09-30 17:14:02,126] [ERROR] [launch.py:434:sigkill_handler] ['/home/neromous/.minicoda3/envs/blackfog/bin/python', '-u', 'app.py', '--local_rank=0', '--deepspeed'] exits with return code = -9
[2023-09-30 18:36:34,507] [WARNING] [runner.py:190:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2023-09-30 18:36:34,527] [INFO] [runner.py:540:main] cmd = /home/neromous/.minicoda3/envs/blackfog/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None app.py --deepspeed
[2023-09-30 18:36:37,056] [INFO] [launch.py:229:main] WORLD INFO DICT: {'localhost': [1]}
[2023-09-30 18:36:37,056] [INFO] [launch.py:235:main] nnodes=1, num_local_procs=1, node_rank=0
[2023-09-30 18:36:37,056] [INFO] [launch.py:246:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2023-09-30 18:36:37,056] [INFO] [launch.py:247:main] dist_world_size=1
[2023-09-30 18:36:37,056] [INFO] [launch.py:249:main] Setting CUDA_VISIBLE_DEVICES=1
RWKV_MY_TESTING 
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/wkv_512/build.ninja...
Building extension module wkv_512...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module wkv_512...
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 4.662330150604248 seconds
Adam Optimizer #0 is created with AVX2 arithmetic capability.
Config: alpha=0.000100, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=0
[2023-09-30 18:37:32,089] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.9.1, git-hash=unknown, git-branch=unknown
[2023-09-30 18:37:32,089] [INFO] [comm.py:586:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2023-09-30 18:37:35,898] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-30 18:37:35,901] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2023-09-30 18:37:35,901] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2023-09-30 18:37:35,940] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam
[2023-09-30 18:37:35,940] [INFO] [utils.py:51:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>
[2023-09-30 18:37:35,940] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float32 ZeRO stage 2 optimizer
[2023-09-30 18:37:35,940] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 2000000
[2023-09-30 18:37:35,940] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 2000000
[2023-09-30 18:37:35,940] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: True
[2023-09-30 18:37:35,940] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.2947425842285156 seconds
Rank: 0 partition count [1, 1, 1] and sizes[(3062589440, False), (81920, False), (81920, False)] 
[2023-09-30 18:38:03,297] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[2023-09-30 18:38:03,298] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 18:38:03,299] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 22.43 GB, percent = 17.8%
[2023-09-30 18:38:24,130] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[2023-09-30 18:38:24,131] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 18:38:24,131] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 61.6 GB, percent = 49.0%
[2023-09-30 18:38:24,131] [INFO] [stage_1_and_2.py:489:__init__] optimizer state initialized
[2023-09-30 18:38:26,232] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[2023-09-30 18:38:26,233] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 18:38:26,234] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 61.61 GB, percent = 49.0%
[2023-09-30 18:38:26,268] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedCPUAdam
[2023-09-30 18:38:26,268] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2023-09-30 18:38:26,268] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7f55adb2c640>
[2023-09-30 18:38:26,268] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0001, 0.0002, 0.00030000000000000003], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
[2023-09-30 18:38:26,269] [INFO] [config.py:953:print] DeepSpeedEngine configuration:
[2023-09-30 18:38:26,270] [INFO] [config.py:957:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-30 18:38:26,270] [INFO] [config.py:957:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-30 18:38:26,270] [INFO] [config.py:957:print]   amp_enabled .................. False
[2023-09-30 18:38:26,270] [INFO] [config.py:957:print]   amp_params ................... False
[2023-09-30 18:38:26,270] [INFO] [config.py:957:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-30 18:38:26,270] [INFO] [config.py:957:print]   bfloat16_enabled ............. False
[2023-09-30 18:38:26,270] [INFO] [config.py:957:print]   checkpoint_parallel_write_pipeline  False
[2023-09-30 18:38:26,270] [INFO] [config.py:957:print]   checkpoint_tag_validation_enabled  True
[2023-09-30 18:38:26,270] [INFO] [config.py:957:print]   checkpoint_tag_validation_fail  False
[2023-09-30 18:38:26,271] [INFO] [config.py:957:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f55adb1e970>
[2023-09-30 18:38:26,271] [INFO] [config.py:957:print]   communication_data_type ...... None
[2023-09-30 18:38:26,271] [INFO] [config.py:957:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-30 18:38:26,271] [INFO] [config.py:957:print]   curriculum_enabled_legacy .... False
[2023-09-30 18:38:26,271] [INFO] [config.py:957:print]   curriculum_params_legacy ..... False
[2023-09-30 18:38:26,271] [INFO] [config.py:957:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-30 18:38:26,271] [INFO] [config.py:957:print]   data_efficiency_enabled ...... False
[2023-09-30 18:38:26,271] [INFO] [config.py:957:print]   dataloader_drop_last ......... False
[2023-09-30 18:38:26,271] [INFO] [config.py:957:print]   disable_allgather ............ False
[2023-09-30 18:38:26,271] [INFO] [config.py:957:print]   dump_state ................... False
[2023-09-30 18:38:26,271] [INFO] [config.py:957:print]   dynamic_loss_scale_args ...... None
[2023-09-30 18:38:26,271] [INFO] [config.py:957:print]   eigenvalue_enabled ........... False
[2023-09-30 18:38:26,271] [INFO] [config.py:957:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-30 18:38:26,271] [INFO] [config.py:957:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-30 18:38:26,271] [INFO] [config.py:957:print]   eigenvalue_layer_num ......... 0
[2023-09-30 18:38:26,271] [INFO] [config.py:957:print]   eigenvalue_max_iter .......... 100
[2023-09-30 18:38:26,271] [INFO] [config.py:957:print]   eigenvalue_stability ......... 1e-06
[2023-09-30 18:38:26,271] [INFO] [config.py:957:print]   eigenvalue_tol ............... 0.01
[2023-09-30 18:38:26,271] [INFO] [config.py:957:print]   eigenvalue_verbose ........... False
[2023-09-30 18:38:26,271] [INFO] [config.py:957:print]   elasticity_enabled ........... False
[2023-09-30 18:38:26,271] [INFO] [config.py:957:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-30 18:38:26,271] [INFO] [config.py:957:print]   fp16_auto_cast ............... None
[2023-09-30 18:38:26,271] [INFO] [config.py:957:print]   fp16_enabled ................. False
[2023-09-30 18:38:26,272] [INFO] [config.py:957:print]   fp16_master_weights_and_gradients  False
[2023-09-30 18:38:26,272] [INFO] [config.py:957:print]   global_rank .................. 0
[2023-09-30 18:38:26,272] [INFO] [config.py:957:print]   grad_accum_dtype ............. None
[2023-09-30 18:38:26,272] [INFO] [config.py:957:print]   gradient_accumulation_steps .. 1
[2023-09-30 18:38:26,272] [INFO] [config.py:957:print]   gradient_clipping ............ 1
[2023-09-30 18:38:26,272] [INFO] [config.py:957:print]   gradient_predivide_factor .... 1.0
[2023-09-30 18:38:26,272] [INFO] [config.py:957:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-30 18:38:26,272] [INFO] [config.py:957:print]   initial_dynamic_scale ........ 65536
[2023-09-30 18:38:26,272] [INFO] [config.py:957:print]   load_universal_checkpoint .... False
[2023-09-30 18:38:26,272] [INFO] [config.py:957:print]   loss_scale ................... 0
[2023-09-30 18:38:26,272] [INFO] [config.py:957:print]   memory_breakdown ............. False
[2023-09-30 18:38:26,272] [INFO] [config.py:957:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-30 18:38:26,272] [INFO] [config.py:957:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-30 18:38:26,272] [INFO] [config.py:957:print]   optimizer_legacy_fusion ...... False
[2023-09-30 18:38:26,272] [INFO] [config.py:957:print]   optimizer_name ............... None
[2023-09-30 18:38:26,272] [INFO] [config.py:957:print]   optimizer_params ............. None
[2023-09-30 18:38:26,272] [INFO] [config.py:957:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-30 18:38:26,272] [INFO] [config.py:957:print]   pld_enabled .................. False
[2023-09-30 18:38:26,272] [INFO] [config.py:957:print]   pld_params ................... False
[2023-09-30 18:38:26,272] [INFO] [config.py:957:print]   prescale_gradients ........... False
[2023-09-30 18:38:26,272] [INFO] [config.py:957:print]   scheduler_name ............... None
[2023-09-30 18:38:26,272] [INFO] [config.py:957:print]   scheduler_params ............. None
[2023-09-30 18:38:26,273] [INFO] [config.py:957:print]   sparse_attention ............. None
[2023-09-30 18:38:26,273] [INFO] [config.py:957:print]   sparse_gradients_enabled ..... False
[2023-09-30 18:38:26,273] [INFO] [config.py:957:print]   steps_per_print .............. 10
[2023-09-30 18:38:26,273] [INFO] [config.py:957:print]   train_batch_size ............. 1
[2023-09-30 18:38:26,273] [INFO] [config.py:957:print]   train_micro_batch_size_per_gpu  1
[2023-09-30 18:38:26,273] [INFO] [config.py:957:print]   use_node_local_storage ....... False
[2023-09-30 18:38:26,273] [INFO] [config.py:957:print]   wall_clock_breakdown ......... False
[2023-09-30 18:38:26,273] [INFO] [config.py:957:print]   world_size ................... 1
[2023-09-30 18:38:26,273] [INFO] [config.py:957:print]   zero_allow_untested_optimizer  False
[2023-09-30 18:38:26,273] [INFO] [config.py:957:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=2000000 allgather_partitions=True allgather_bucket_size=2000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=True, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False memory_efficient_linear=True
[2023-09-30 18:38:26,273] [INFO] [config.py:957:print]   zero_enabled ................. True
[2023-09-30 18:38:26,273] [INFO] [config.py:957:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-30 18:38:26,273] [INFO] [config.py:957:print]   zero_optimization_stage ...... 2
[2023-09-30 18:38:26,273] [INFO] [config.py:943:print_user_config]   json = {
    "   fp16": {
        "enabled": false
    }, 
    "zero_optimization": {
        "stage": 2, 
        "offload_optimizer": {
            "device": "cpu", 
            "pin_memory": true
        }, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+06, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+06, 
        "contiguous_gradients": true
    }, 
    "gradient_accumulation_steps": 1, 
    "gradient_clipping": 1, 
    "train_micro_batch_size_per_gpu": 1, 
    "checkpoint": {
        "path": "/home/neromous/Documents/blackfog/resources/train-results/oneline/", 
        "keep_checkpoint_max": 3
    }
}
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0005602836608886719 seconds
Bottle v0.12.25 server starting up (using WSGIRefServer())...
Listening on http://0.0.0.0:3000/
Hit Ctrl-C to quit.

[2023-09-30 19:20:04,963] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 1276601
[2023-09-30 19:20:04,964] [ERROR] [launch.py:434:sigkill_handler] ['/home/neromous/.minicoda3/envs/blackfog/bin/python', '-u', 'app.py', '--local_rank=0', '--deepspeed'] exits with return code = -9
[2023-09-30 19:20:43,073] [WARNING] [runner.py:190:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2023-09-30 19:20:43,093] [INFO] [runner.py:540:main] cmd = /home/neromous/.minicoda3/envs/blackfog/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None app.py --deepspeed
[2023-09-30 19:20:45,640] [INFO] [launch.py:229:main] WORLD INFO DICT: {'localhost': [1]}
[2023-09-30 19:20:45,640] [INFO] [launch.py:235:main] nnodes=1, num_local_procs=1, node_rank=0
[2023-09-30 19:20:45,640] [INFO] [launch.py:246:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2023-09-30 19:20:45,640] [INFO] [launch.py:247:main] dist_world_size=1
[2023-09-30 19:20:45,640] [INFO] [launch.py:249:main] Setting CUDA_VISIBLE_DEVICES=1
RWKV_MY_TESTING 
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/wkv_512/build.ninja...
Building extension module wkv_512...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module wkv_512...
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 4.627546072006226 seconds
Adam Optimizer #0 is created with AVX2 arithmetic capability.
Config: alpha=0.000100, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=0
[2023-09-30 19:21:36,486] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.9.1, git-hash=unknown, git-branch=unknown
[2023-09-30 19:21:36,486] [INFO] [comm.py:586:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2023-09-30 19:21:40,429] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-30 19:21:40,431] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2023-09-30 19:21:40,431] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2023-09-30 19:21:40,470] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam
[2023-09-30 19:21:40,471] [INFO] [utils.py:51:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>
[2023-09-30 19:21:40,471] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float32 ZeRO stage 2 optimizer
[2023-09-30 19:21:40,471] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 2000000
[2023-09-30 19:21:40,471] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 2000000
[2023-09-30 19:21:40,471] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: True
[2023-09-30 19:21:40,471] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.29407310485839844 seconds
Rank: 0 partition count [1, 1, 1] and sizes[(3062589440, False), (81920, False), (81920, False)] 
[2023-09-30 19:22:15,587] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[2023-09-30 19:22:15,588] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 19:22:15,588] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 22.37 GB, percent = 17.8%
[2023-09-30 19:22:36,301] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[2023-09-30 19:22:36,302] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 19:22:36,303] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 61.59 GB, percent = 49.0%
[2023-09-30 19:22:36,303] [INFO] [stage_1_and_2.py:489:__init__] optimizer state initialized
[2023-09-30 19:22:38,390] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[2023-09-30 19:22:38,391] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 19:22:38,391] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 61.59 GB, percent = 49.0%
[2023-09-30 19:22:38,420] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedCPUAdam
[2023-09-30 19:22:38,421] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2023-09-30 19:22:38,421] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7fbd700ea460>
[2023-09-30 19:22:38,421] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0001, 0.0002, 0.00030000000000000003], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
[2023-09-30 19:22:38,422] [INFO] [config.py:953:print] DeepSpeedEngine configuration:
[2023-09-30 19:22:38,422] [INFO] [config.py:957:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-30 19:22:38,422] [INFO] [config.py:957:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-30 19:22:38,423] [INFO] [config.py:957:print]   amp_enabled .................. False
[2023-09-30 19:22:38,423] [INFO] [config.py:957:print]   amp_params ................... False
[2023-09-30 19:22:38,423] [INFO] [config.py:957:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-30 19:22:38,423] [INFO] [config.py:957:print]   bfloat16_enabled ............. False
[2023-09-30 19:22:38,423] [INFO] [config.py:957:print]   checkpoint_parallel_write_pipeline  False
[2023-09-30 19:22:38,423] [INFO] [config.py:957:print]   checkpoint_tag_validation_enabled  True
[2023-09-30 19:22:38,423] [INFO] [config.py:957:print]   checkpoint_tag_validation_fail  False
[2023-09-30 19:22:38,423] [INFO] [config.py:957:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fbd6ff99460>
[2023-09-30 19:22:38,423] [INFO] [config.py:957:print]   communication_data_type ...... None
[2023-09-30 19:22:38,423] [INFO] [config.py:957:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-30 19:22:38,423] [INFO] [config.py:957:print]   curriculum_enabled_legacy .... False
[2023-09-30 19:22:38,423] [INFO] [config.py:957:print]   curriculum_params_legacy ..... False
[2023-09-30 19:22:38,423] [INFO] [config.py:957:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-30 19:22:38,423] [INFO] [config.py:957:print]   data_efficiency_enabled ...... False
[2023-09-30 19:22:38,423] [INFO] [config.py:957:print]   dataloader_drop_last ......... False
[2023-09-30 19:22:38,423] [INFO] [config.py:957:print]   disable_allgather ............ False
[2023-09-30 19:22:38,423] [INFO] [config.py:957:print]   dump_state ................... False
[2023-09-30 19:22:38,423] [INFO] [config.py:957:print]   dynamic_loss_scale_args ...... None
[2023-09-30 19:22:38,423] [INFO] [config.py:957:print]   eigenvalue_enabled ........... False
[2023-09-30 19:22:38,423] [INFO] [config.py:957:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-30 19:22:38,423] [INFO] [config.py:957:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-30 19:22:38,424] [INFO] [config.py:957:print]   eigenvalue_layer_num ......... 0
[2023-09-30 19:22:38,424] [INFO] [config.py:957:print]   eigenvalue_max_iter .......... 100
[2023-09-30 19:22:38,424] [INFO] [config.py:957:print]   eigenvalue_stability ......... 1e-06
[2023-09-30 19:22:38,424] [INFO] [config.py:957:print]   eigenvalue_tol ............... 0.01
[2023-09-30 19:22:38,424] [INFO] [config.py:957:print]   eigenvalue_verbose ........... False
[2023-09-30 19:22:38,424] [INFO] [config.py:957:print]   elasticity_enabled ........... False
[2023-09-30 19:22:38,424] [INFO] [config.py:957:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-30 19:22:38,424] [INFO] [config.py:957:print]   fp16_auto_cast ............... None
[2023-09-30 19:22:38,424] [INFO] [config.py:957:print]   fp16_enabled ................. False
[2023-09-30 19:22:38,424] [INFO] [config.py:957:print]   fp16_master_weights_and_gradients  False
[2023-09-30 19:22:38,424] [INFO] [config.py:957:print]   global_rank .................. 0
[2023-09-30 19:22:38,424] [INFO] [config.py:957:print]   grad_accum_dtype ............. None
[2023-09-30 19:22:38,424] [INFO] [config.py:957:print]   gradient_accumulation_steps .. 1
[2023-09-30 19:22:38,424] [INFO] [config.py:957:print]   gradient_clipping ............ 1
[2023-09-30 19:22:38,424] [INFO] [config.py:957:print]   gradient_predivide_factor .... 1.0
[2023-09-30 19:22:38,424] [INFO] [config.py:957:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-30 19:22:38,424] [INFO] [config.py:957:print]   initial_dynamic_scale ........ 65536
[2023-09-30 19:22:38,424] [INFO] [config.py:957:print]   load_universal_checkpoint .... False
[2023-09-30 19:22:38,424] [INFO] [config.py:957:print]   loss_scale ................... 0
[2023-09-30 19:22:38,424] [INFO] [config.py:957:print]   memory_breakdown ............. False
[2023-09-30 19:22:38,424] [INFO] [config.py:957:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-30 19:22:38,425] [INFO] [config.py:957:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-30 19:22:38,425] [INFO] [config.py:957:print]   optimizer_legacy_fusion ...... False
[2023-09-30 19:22:38,425] [INFO] [config.py:957:print]   optimizer_name ............... None
[2023-09-30 19:22:38,425] [INFO] [config.py:957:print]   optimizer_params ............. None
[2023-09-30 19:22:38,425] [INFO] [config.py:957:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-30 19:22:38,425] [INFO] [config.py:957:print]   pld_enabled .................. False
[2023-09-30 19:22:38,425] [INFO] [config.py:957:print]   pld_params ................... False
[2023-09-30 19:22:38,425] [INFO] [config.py:957:print]   prescale_gradients ........... False
[2023-09-30 19:22:38,425] [INFO] [config.py:957:print]   scheduler_name ............... None
[2023-09-30 19:22:38,425] [INFO] [config.py:957:print]   scheduler_params ............. None
[2023-09-30 19:22:38,425] [INFO] [config.py:957:print]   sparse_attention ............. None
[2023-09-30 19:22:38,425] [INFO] [config.py:957:print]   sparse_gradients_enabled ..... False
[2023-09-30 19:22:38,425] [INFO] [config.py:957:print]   steps_per_print .............. 10
[2023-09-30 19:22:38,425] [INFO] [config.py:957:print]   train_batch_size ............. 1
[2023-09-30 19:22:38,425] [INFO] [config.py:957:print]   train_micro_batch_size_per_gpu  1
[2023-09-30 19:22:38,425] [INFO] [config.py:957:print]   use_node_local_storage ....... False
[2023-09-30 19:22:38,425] [INFO] [config.py:957:print]   wall_clock_breakdown ......... False
[2023-09-30 19:22:38,425] [INFO] [config.py:957:print]   world_size ................... 1
[2023-09-30 19:22:38,425] [INFO] [config.py:957:print]   zero_allow_untested_optimizer  False
[2023-09-30 19:22:38,425] [INFO] [config.py:957:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=2000000 allgather_partitions=True allgather_bucket_size=2000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=True, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False memory_efficient_linear=True
[2023-09-30 19:22:38,425] [INFO] [config.py:957:print]   zero_enabled ................. True
[2023-09-30 19:22:38,425] [INFO] [config.py:957:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-30 19:22:38,425] [INFO] [config.py:957:print]   zero_optimization_stage ...... 2
[2023-09-30 19:22:38,425] [INFO] [config.py:943:print_user_config]   json = {
    "   fp16": {
        "enabled": false
    }, 
    "zero_optimization": {
        "stage": 2, 
        "offload_optimizer": {
            "device": "cpu", 
            "pin_memory": true
        }, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+06, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+06, 
        "contiguous_gradients": true
    }, 
    "gradient_accumulation_steps": 1, 
    "gradient_clipping": 1, 
    "train_micro_batch_size_per_gpu": 1, 
    "checkpoint": {
        "path": "/home/neromous/Documents/blackfog/resources/train-results/oneline/", 
        "keep_checkpoint_max": 3
    }
}
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0005447864532470703 seconds
Bottle v0.12.25 server starting up (using WSGIRefServer())...
Listening on http://0.0.0.0:3000/
Hit Ctrl-C to quit.

192.168.0.103 - - [30/Sep/2023 19:23:50] "POST /inference/by-inf HTTP/1.1" 404 754
====== None
要求较长和细致的输出


<|me|><|request|>我需要你参考碟形世界，帮我写一部小说
<|over|>

<|me|><|response|>好的，我会尝试写一部小说。不过，我需要更多的信息来帮助我构思。
<|over|>

<|me|><|request|>你需要什么信息？
<|over|>

<|me|><|response|>首先，我需要知道这部小说的类型。是科幻小说、悬疑小说还是其他类型的小说？
<|over|>

<|me|><|request|>我认为是科幻小说
<|over|>

<|me|><|response|>好的，我会为你提供更多细节。在这部小说中，主人公是一位名叫安德鲁·利亚顿的年轻作家。他在写作过程中受到了某种神秘力量的影响，开始做一些奇怪的梦。这些梦境让他能够看见未来和过去，并且获得了某种神奇的力量。
<|over|>

<|me|><|request|>能提供该主人公的外貌特征和背景信息吗？
<|over|>

<|me|><|response|>好的，我会为你提供该主人公的相关信息。首先，这位主人公名叫安德烈·帕特尔，他是一位年轻有为的作家。其次，他有一头浓密的黑发和深陷的眼睛，给人留下深刻的印象。最后，他总是穿着得体、举止得体，给人留下良好的第一印象。
<|over|>

<|me|><|request|>
<|over|>


Traceback (most recent call last):
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/bottle.py", line 876, in _handle
    return route.call(**args)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/bottle.py", line 1759, in wrapper
    rv = callback(*a, **ka)
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/app.py", line 162, in inference_by_org
    msg = inferencer.generate(rwkv_rnn,msg)
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/models/inference_helper.py", line 125, in generate
    logits , self.state = model(token, self.state)
TypeError: 'NoneType' object is not callable
192.168.0.103 - - [30/Sep/2023 19:24:33] "POST /inference/by-org HTTP/1.1" 500 759
  0%|          | 0/582 [00:00<?, ?it/s]100%|██████████| 582/582 [00:00<00:00, 12134.26it/s]
  0%|          | 0/582 [00:00<?, ?it/s]100%|██████████| 582/582 [00:00<00:00, 325782.05it/s]
127.0.0.1 - - [30/Sep/2023 19:25:55] "POST /inference/load-model HTTP/1.1" 200 26
====== None
要求较长和细致的输出


<|me|><|request|>我需要你参考碟形世界，帮我写一部小说
<|over|>

<|me|><|response|>好的，我会尝试写一部小说。不过，我需要更多的信息来帮助我构思。
<|over|>

<|me|><|request|>你需要什么信息？
<|over|>

<|me|><|response|>首先，我需要知道这部小说的类型。是科幻小说、悬疑小说还是其他类型的小说？
<|over|>

<|me|><|request|>我认为是科幻小说
<|over|>

<|me|><|response|>好的，我会为你提供更多细节。在这部小说中，主人公是一位名叫安德鲁·利亚顿的年轻作家。他在写作过程中受到了某种神秘力量的影响，开始做一些奇怪的梦。这些梦境让他能够看见未来和过去，并且获得了某种神奇的力量。
<|over|>

<|me|><|request|>能提供该主人公的外貌特征和背景信息吗？
<|over|>

<|me|><|response|>好的，我会为你提供该主人公的相关信息。首先，这位主人公名叫安德烈·帕特尔，他是一位年轻有为的作家。其次，他有一头浓密的黑发和深陷的眼睛，给人留下深刻的印象。最后，他总是穿着得体、举止得体，给人留下良好的第一印象。
<|over|>

<|me|><|request|>
<|over|>


```python
def is_palindrome(string):
    """Check if a string is a palindrome."""
    return string == string[::-1]
```

## 输出

打印结果：
```console
True
```

## 边栏：额外资源

*   [Python Cookbook](https://docs.python.org/3/library/index.html)
*   [Learn Python the Hard Way](https://www. ZhaoxuQiu.com/Books/LearnPythonTheHardWay/)
*   [Automate the Boring Stuff with Python](https://automatetheboringstudio.withsm.com/)
*   [Automate the Boring Stuff with Python, Second Edition](https://automatetheboringstudio.withsm.com/)
*   [Automate the Boring Stuff with Python, Third Edition](https://automatetheboringstudio.withsm.com/)
*   [Automate the Boring Stuff with Python, Fourth Edition](https://automatetheboringstudio.withsm.com/)
*   [Automate the Boring Stuff with Python, FifthTraceback (most recent call last):
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/bottle.py", line 876, in _handle
    return route.call(**args)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/bottle.py", line 1765, in wrapper
    json_response = dumps(rv)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/json/__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/json/encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/json/encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/json/encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type Message is not JSON serializable
192.168.0.103 - - [30/Sep/2023 19:26:23] "POST /inference/by-org HTTP/1.1" 500 759
[2023-09-30 19:29:14,213] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 1289811
[2023-09-30 19:29:14,214] [ERROR] [launch.py:434:sigkill_handler] ['/home/neromous/.minicoda3/envs/blackfog/bin/python', '-u', 'app.py', '--local_rank=0', '--deepspeed'] exits with return code = -9
[2023-09-30 19:30:06,300] [WARNING] [runner.py:190:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2023-09-30 19:30:06,320] [INFO] [runner.py:540:main] cmd = /home/neromous/.minicoda3/envs/blackfog/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None app.py --deepspeed
[2023-09-30 19:30:08,816] [INFO] [launch.py:229:main] WORLD INFO DICT: {'localhost': [1]}
[2023-09-30 19:30:08,816] [INFO] [launch.py:235:main] nnodes=1, num_local_procs=1, node_rank=0
[2023-09-30 19:30:08,816] [INFO] [launch.py:246:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2023-09-30 19:30:08,816] [INFO] [launch.py:247:main] dist_world_size=1
[2023-09-30 19:30:08,816] [INFO] [launch.py:249:main] Setting CUDA_VISIBLE_DEVICES=1
RWKV_MY_TESTING 
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/wkv_512/build.ninja...
Building extension module wkv_512...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module wkv_512...
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 4.694763660430908 seconds
Adam Optimizer #0 is created with AVX2 arithmetic capability.
Config: alpha=0.000100, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=0
[2023-09-30 19:30:59,515] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.9.1, git-hash=unknown, git-branch=unknown
[2023-09-30 19:30:59,515] [INFO] [comm.py:586:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2023-09-30 19:31:06,311] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-30 19:31:06,313] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2023-09-30 19:31:06,313] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2023-09-30 19:31:06,352] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam
[2023-09-30 19:31:06,352] [INFO] [utils.py:51:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>
[2023-09-30 19:31:06,352] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float32 ZeRO stage 2 optimizer
[2023-09-30 19:31:06,352] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 2000000
[2023-09-30 19:31:06,352] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 2000000
[2023-09-30 19:31:06,352] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: True
[2023-09-30 19:31:06,352] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.29123592376708984 seconds
Rank: 0 partition count [1, 1, 1] and sizes[(3062589440, False), (81920, False), (81920, False)] 
[2023-09-30 19:31:30,257] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[2023-09-30 19:31:30,258] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 19:31:30,258] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 22.4 GB, percent = 17.8%
[2023-09-30 19:31:50,752] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[2023-09-30 19:31:50,753] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 19:31:50,753] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 61.59 GB, percent = 49.0%
[2023-09-30 19:31:50,753] [INFO] [stage_1_and_2.py:489:__init__] optimizer state initialized
[2023-09-30 19:31:52,863] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[2023-09-30 19:31:52,864] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 19:31:52,864] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 61.59 GB, percent = 49.0%
[2023-09-30 19:31:52,890] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedCPUAdam
[2023-09-30 19:31:52,891] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2023-09-30 19:31:52,891] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7f648cba3700>
[2023-09-30 19:31:52,891] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0001, 0.0002, 0.00030000000000000003], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
[2023-09-30 19:31:52,892] [INFO] [config.py:953:print] DeepSpeedEngine configuration:
[2023-09-30 19:31:52,892] [INFO] [config.py:957:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-30 19:31:52,892] [INFO] [config.py:957:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-30 19:31:52,893] [INFO] [config.py:957:print]   amp_enabled .................. False
[2023-09-30 19:31:52,893] [INFO] [config.py:957:print]   amp_params ................... False
[2023-09-30 19:31:52,893] [INFO] [config.py:957:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-30 19:31:52,893] [INFO] [config.py:957:print]   bfloat16_enabled ............. False
[2023-09-30 19:31:52,893] [INFO] [config.py:957:print]   checkpoint_parallel_write_pipeline  False
[2023-09-30 19:31:52,893] [INFO] [config.py:957:print]   checkpoint_tag_validation_enabled  True
[2023-09-30 19:31:52,893] [INFO] [config.py:957:print]   checkpoint_tag_validation_fail  False
[2023-09-30 19:31:52,893] [INFO] [config.py:957:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f648ca081c0>
[2023-09-30 19:31:52,893] [INFO] [config.py:957:print]   communication_data_type ...... None
[2023-09-30 19:31:52,893] [INFO] [config.py:957:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-30 19:31:52,893] [INFO] [config.py:957:print]   curriculum_enabled_legacy .... False
[2023-09-30 19:31:52,893] [INFO] [config.py:957:print]   curriculum_params_legacy ..... False
[2023-09-30 19:31:52,893] [INFO] [config.py:957:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-30 19:31:52,893] [INFO] [config.py:957:print]   data_efficiency_enabled ...... False
[2023-09-30 19:31:52,893] [INFO] [config.py:957:print]   dataloader_drop_last ......... False
[2023-09-30 19:31:52,893] [INFO] [config.py:957:print]   disable_allgather ............ False
[2023-09-30 19:31:52,893] [INFO] [config.py:957:print]   dump_state ................... False
[2023-09-30 19:31:52,893] [INFO] [config.py:957:print]   dynamic_loss_scale_args ...... None
[2023-09-30 19:31:52,893] [INFO] [config.py:957:print]   eigenvalue_enabled ........... False
[2023-09-30 19:31:52,893] [INFO] [config.py:957:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-30 19:31:52,894] [INFO] [config.py:957:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-30 19:31:52,894] [INFO] [config.py:957:print]   eigenvalue_layer_num ......... 0
[2023-09-30 19:31:52,894] [INFO] [config.py:957:print]   eigenvalue_max_iter .......... 100
[2023-09-30 19:31:52,894] [INFO] [config.py:957:print]   eigenvalue_stability ......... 1e-06
[2023-09-30 19:31:52,894] [INFO] [config.py:957:print]   eigenvalue_tol ............... 0.01
[2023-09-30 19:31:52,894] [INFO] [config.py:957:print]   eigenvalue_verbose ........... False
[2023-09-30 19:31:52,894] [INFO] [config.py:957:print]   elasticity_enabled ........... False
[2023-09-30 19:31:52,894] [INFO] [config.py:957:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-30 19:31:52,894] [INFO] [config.py:957:print]   fp16_auto_cast ............... None
[2023-09-30 19:31:52,894] [INFO] [config.py:957:print]   fp16_enabled ................. False
[2023-09-30 19:31:52,894] [INFO] [config.py:957:print]   fp16_master_weights_and_gradients  False
[2023-09-30 19:31:52,894] [INFO] [config.py:957:print]   global_rank .................. 0
[2023-09-30 19:31:52,894] [INFO] [config.py:957:print]   grad_accum_dtype ............. None
[2023-09-30 19:31:52,894] [INFO] [config.py:957:print]   gradient_accumulation_steps .. 1
[2023-09-30 19:31:52,894] [INFO] [config.py:957:print]   gradient_clipping ............ 1
[2023-09-30 19:31:52,894] [INFO] [config.py:957:print]   gradient_predivide_factor .... 1.0
[2023-09-30 19:31:52,894] [INFO] [config.py:957:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-30 19:31:52,894] [INFO] [config.py:957:print]   initial_dynamic_scale ........ 65536
[2023-09-30 19:31:52,894] [INFO] [config.py:957:print]   load_universal_checkpoint .... False
[2023-09-30 19:31:52,894] [INFO] [config.py:957:print]   loss_scale ................... 0
[2023-09-30 19:31:52,894] [INFO] [config.py:957:print]   memory_breakdown ............. False
[2023-09-30 19:31:52,894] [INFO] [config.py:957:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-30 19:31:52,895] [INFO] [config.py:957:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-30 19:31:52,895] [INFO] [config.py:957:print]   optimizer_legacy_fusion ...... False
[2023-09-30 19:31:52,895] [INFO] [config.py:957:print]   optimizer_name ............... None
[2023-09-30 19:31:52,895] [INFO] [config.py:957:print]   optimizer_params ............. None
[2023-09-30 19:31:52,895] [INFO] [config.py:957:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-30 19:31:52,895] [INFO] [config.py:957:print]   pld_enabled .................. False
[2023-09-30 19:31:52,895] [INFO] [config.py:957:print]   pld_params ................... False
[2023-09-30 19:31:52,895] [INFO] [config.py:957:print]   prescale_gradients ........... False
[2023-09-30 19:31:52,895] [INFO] [config.py:957:print]   scheduler_name ............... None
[2023-09-30 19:31:52,895] [INFO] [config.py:957:print]   scheduler_params ............. None
[2023-09-30 19:31:52,895] [INFO] [config.py:957:print]   sparse_attention ............. None
[2023-09-30 19:31:52,895] [INFO] [config.py:957:print]   sparse_gradients_enabled ..... False
[2023-09-30 19:31:52,895] [INFO] [config.py:957:print]   steps_per_print .............. 10
[2023-09-30 19:31:52,895] [INFO] [config.py:957:print]   train_batch_size ............. 1
[2023-09-30 19:31:52,895] [INFO] [config.py:957:print]   train_micro_batch_size_per_gpu  1
[2023-09-30 19:31:52,895] [INFO] [config.py:957:print]   use_node_local_storage ....... False
[2023-09-30 19:31:52,895] [INFO] [config.py:957:print]   wall_clock_breakdown ......... False
[2023-09-30 19:31:52,895] [INFO] [config.py:957:print]   world_size ................... 1
[2023-09-30 19:31:52,895] [INFO] [config.py:957:print]   zero_allow_untested_optimizer  False
[2023-09-30 19:31:52,895] [INFO] [config.py:957:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=2000000 allgather_partitions=True allgather_bucket_size=2000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=True, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False memory_efficient_linear=True
[2023-09-30 19:31:52,895] [INFO] [config.py:957:print]   zero_enabled ................. True
[2023-09-30 19:31:52,895] [INFO] [config.py:957:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-30 19:31:52,896] [INFO] [config.py:957:print]   zero_optimization_stage ...... 2
[2023-09-30 19:31:52,896] [INFO] [config.py:943:print_user_config]   json = {
    "   fp16": {
        "enabled": false
    }, 
    "zero_optimization": {
        "stage": 2, 
        "offload_optimizer": {
            "device": "cpu", 
            "pin_memory": true
        }, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+06, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+06, 
        "contiguous_gradients": true
    }, 
    "gradient_accumulation_steps": 1, 
    "gradient_clipping": 1, 
    "train_micro_batch_size_per_gpu": 1, 
    "checkpoint": {
        "path": "/home/neromous/Documents/blackfog/resources/train-results/oneline/", 
        "keep_checkpoint_max": 3
    }
}
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.00044608116149902344 seconds
Bottle v0.12.25 server starting up (using WSGIRefServer())...
Listening on http://0.0.0.0:3000/
Hit Ctrl-C to quit.

====== None
Traceback (most recent call last):
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/bottle.py", line 876, in _handle
    return route.call(**args)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/bottle.py", line 1759, in wrapper
    rv = callback(*a, **ka)
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/app.py", line 161, in inference_by_org
    while token[-1] in [0,65535,261,11]:
NameError: name 'token' is not defined
192.168.0.103 - - [30/Sep/2023 19:32:08] "POST /inference/by-org HTTP/1.1" 500 759
[2023-09-30 19:32:54,013] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 1292675
[2023-09-30 19:32:54,014] [ERROR] [launch.py:434:sigkill_handler] ['/home/neromous/.minicoda3/envs/blackfog/bin/python', '-u', 'app.py', '--local_rank=0', '--deepspeed'] exits with return code = -9
[2023-09-30 19:33:36,996] [WARNING] [runner.py:190:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2023-09-30 19:33:37,016] [INFO] [runner.py:540:main] cmd = /home/neromous/.minicoda3/envs/blackfog/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None app.py --deepspeed
[2023-09-30 19:33:39,543] [INFO] [launch.py:229:main] WORLD INFO DICT: {'localhost': [1]}
[2023-09-30 19:33:39,543] [INFO] [launch.py:235:main] nnodes=1, num_local_procs=1, node_rank=0
[2023-09-30 19:33:39,543] [INFO] [launch.py:246:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2023-09-30 19:33:39,543] [INFO] [launch.py:247:main] dist_world_size=1
[2023-09-30 19:33:39,543] [INFO] [launch.py:249:main] Setting CUDA_VISIBLE_DEVICES=1
RWKV_MY_TESTING 
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/wkv_512/build.ninja...
Building extension module wkv_512...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module wkv_512...
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 4.655505657196045 seconds
Adam Optimizer #0 is created with AVX2 arithmetic capability.
Config: alpha=0.000100, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=0
[2023-09-30 19:34:32,972] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.9.1, git-hash=unknown, git-branch=unknown
[2023-09-30 19:34:32,973] [INFO] [comm.py:586:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2023-09-30 19:34:36,763] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-30 19:34:36,765] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2023-09-30 19:34:36,766] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2023-09-30 19:34:36,805] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam
[2023-09-30 19:34:36,805] [INFO] [utils.py:51:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>
[2023-09-30 19:34:36,805] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float32 ZeRO stage 2 optimizer
[2023-09-30 19:34:36,805] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 2000000
[2023-09-30 19:34:36,805] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 2000000
[2023-09-30 19:34:36,805] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: True
[2023-09-30 19:34:36,806] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.3257639408111572 seconds
Rank: 0 partition count [1, 1, 1] and sizes[(3062589440, False), (81920, False), (81920, False)] 
[2023-09-30 19:35:03,929] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[2023-09-30 19:35:03,930] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 19:35:03,930] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 22.38 GB, percent = 17.8%
[2023-09-30 19:35:24,625] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[2023-09-30 19:35:24,626] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 19:35:24,626] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 61.61 GB, percent = 49.0%
[2023-09-30 19:35:24,627] [INFO] [stage_1_and_2.py:489:__init__] optimizer state initialized
[2023-09-30 19:35:25,506] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[2023-09-30 19:35:25,507] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 19:35:25,507] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 61.61 GB, percent = 49.0%
[2023-09-30 19:35:25,541] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedCPUAdam
[2023-09-30 19:35:25,541] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2023-09-30 19:35:25,541] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7f03a8cfe6a0>
[2023-09-30 19:35:25,541] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0001, 0.0002, 0.00030000000000000003], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
[2023-09-30 19:35:25,542] [INFO] [config.py:953:print] DeepSpeedEngine configuration:
[2023-09-30 19:35:25,543] [INFO] [config.py:957:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-30 19:35:25,543] [INFO] [config.py:957:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-30 19:35:25,543] [INFO] [config.py:957:print]   amp_enabled .................. False
[2023-09-30 19:35:25,543] [INFO] [config.py:957:print]   amp_params ................... False
[2023-09-30 19:35:25,543] [INFO] [config.py:957:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-30 19:35:25,543] [INFO] [config.py:957:print]   bfloat16_enabled ............. False
[2023-09-30 19:35:25,543] [INFO] [config.py:957:print]   checkpoint_parallel_write_pipeline  False
[2023-09-30 19:35:25,543] [INFO] [config.py:957:print]   checkpoint_tag_validation_enabled  True
[2023-09-30 19:35:25,543] [INFO] [config.py:957:print]   checkpoint_tag_validation_fail  False
[2023-09-30 19:35:25,543] [INFO] [config.py:957:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f03a8b83460>
[2023-09-30 19:35:25,543] [INFO] [config.py:957:print]   communication_data_type ...... None
[2023-09-30 19:35:25,544] [INFO] [config.py:957:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-30 19:35:25,544] [INFO] [config.py:957:print]   curriculum_enabled_legacy .... False
[2023-09-30 19:35:25,544] [INFO] [config.py:957:print]   curriculum_params_legacy ..... False
[2023-09-30 19:35:25,544] [INFO] [config.py:957:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-30 19:35:25,544] [INFO] [config.py:957:print]   data_efficiency_enabled ...... False
[2023-09-30 19:35:25,544] [INFO] [config.py:957:print]   dataloader_drop_last ......... False
[2023-09-30 19:35:25,544] [INFO] [config.py:957:print]   disable_allgather ............ False
[2023-09-30 19:35:25,544] [INFO] [config.py:957:print]   dump_state ................... False
[2023-09-30 19:35:25,544] [INFO] [config.py:957:print]   dynamic_loss_scale_args ...... None
[2023-09-30 19:35:25,544] [INFO] [config.py:957:print]   eigenvalue_enabled ........... False
[2023-09-30 19:35:25,544] [INFO] [config.py:957:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-30 19:35:25,544] [INFO] [config.py:957:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-30 19:35:25,544] [INFO] [config.py:957:print]   eigenvalue_layer_num ......... 0
[2023-09-30 19:35:25,544] [INFO] [config.py:957:print]   eigenvalue_max_iter .......... 100
[2023-09-30 19:35:25,544] [INFO] [config.py:957:print]   eigenvalue_stability ......... 1e-06
[2023-09-30 19:35:25,544] [INFO] [config.py:957:print]   eigenvalue_tol ............... 0.01
[2023-09-30 19:35:25,544] [INFO] [config.py:957:print]   eigenvalue_verbose ........... False
[2023-09-30 19:35:25,544] [INFO] [config.py:957:print]   elasticity_enabled ........... False
[2023-09-30 19:35:25,544] [INFO] [config.py:957:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-30 19:35:25,544] [INFO] [config.py:957:print]   fp16_auto_cast ............... None
[2023-09-30 19:35:25,544] [INFO] [config.py:957:print]   fp16_enabled ................. False
[2023-09-30 19:35:25,544] [INFO] [config.py:957:print]   fp16_master_weights_and_gradients  False
[2023-09-30 19:35:25,544] [INFO] [config.py:957:print]   global_rank .................. 0
[2023-09-30 19:35:25,544] [INFO] [config.py:957:print]   grad_accum_dtype ............. None
[2023-09-30 19:35:25,545] [INFO] [config.py:957:print]   gradient_accumulation_steps .. 1
[2023-09-30 19:35:25,545] [INFO] [config.py:957:print]   gradient_clipping ............ 1
[2023-09-30 19:35:25,545] [INFO] [config.py:957:print]   gradient_predivide_factor .... 1.0
[2023-09-30 19:35:25,545] [INFO] [config.py:957:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-30 19:35:25,545] [INFO] [config.py:957:print]   initial_dynamic_scale ........ 65536
[2023-09-30 19:35:25,545] [INFO] [config.py:957:print]   load_universal_checkpoint .... False
[2023-09-30 19:35:25,545] [INFO] [config.py:957:print]   loss_scale ................... 0
[2023-09-30 19:35:25,545] [INFO] [config.py:957:print]   memory_breakdown ............. False
[2023-09-30 19:35:25,545] [INFO] [config.py:957:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-30 19:35:25,545] [INFO] [config.py:957:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-30 19:35:25,545] [INFO] [config.py:957:print]   optimizer_legacy_fusion ...... False
[2023-09-30 19:35:25,545] [INFO] [config.py:957:print]   optimizer_name ............... None
[2023-09-30 19:35:25,545] [INFO] [config.py:957:print]   optimizer_params ............. None
[2023-09-30 19:35:25,545] [INFO] [config.py:957:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-30 19:35:25,545] [INFO] [config.py:957:print]   pld_enabled .................. False
[2023-09-30 19:35:25,545] [INFO] [config.py:957:print]   pld_params ................... False
[2023-09-30 19:35:25,545] [INFO] [config.py:957:print]   prescale_gradients ........... False
[2023-09-30 19:35:25,545] [INFO] [config.py:957:print]   scheduler_name ............... None
[2023-09-30 19:35:25,545] [INFO] [config.py:957:print]   scheduler_params ............. None
[2023-09-30 19:35:25,545] [INFO] [config.py:957:print]   sparse_attention ............. None
[2023-09-30 19:35:25,545] [INFO] [config.py:957:print]   sparse_gradients_enabled ..... False
[2023-09-30 19:35:25,545] [INFO] [config.py:957:print]   steps_per_print .............. 10
[2023-09-30 19:35:25,546] [INFO] [config.py:957:print]   train_batch_size ............. 1
[2023-09-30 19:35:25,546] [INFO] [config.py:957:print]   train_micro_batch_size_per_gpu  1
[2023-09-30 19:35:25,546] [INFO] [config.py:957:print]   use_node_local_storage ....... False
[2023-09-30 19:35:25,546] [INFO] [config.py:957:print]   wall_clock_breakdown ......... False
[2023-09-30 19:35:25,546] [INFO] [config.py:957:print]   world_size ................... 1
[2023-09-30 19:35:25,546] [INFO] [config.py:957:print]   zero_allow_untested_optimizer  False
[2023-09-30 19:35:25,546] [INFO] [config.py:957:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=2000000 allgather_partitions=True allgather_bucket_size=2000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=True, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False memory_efficient_linear=True
[2023-09-30 19:35:25,546] [INFO] [config.py:957:print]   zero_enabled ................. True
[2023-09-30 19:35:25,546] [INFO] [config.py:957:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-30 19:35:25,546] [INFO] [config.py:957:print]   zero_optimization_stage ...... 2
[2023-09-30 19:35:25,546] [INFO] [config.py:943:print_user_config]   json = {
    "   fp16": {
        "enabled": false
    }, 
    "zero_optimization": {
        "stage": 2, 
        "offload_optimizer": {
            "device": "cpu", 
            "pin_memory": true
        }, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+06, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+06, 
        "contiguous_gradients": true
    }, 
    "gradient_accumulation_steps": 1, 
    "gradient_clipping": 1, 
    "train_micro_batch_size_per_gpu": 1, 
    "checkpoint": {
        "path": "/home/neromous/Documents/blackfog/resources/train-results/oneline/", 
        "keep_checkpoint_max": 3
    }
}
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0004334449768066406 seconds
Bottle v0.12.25 server starting up (using WSGIRefServer())...
Listening on http://0.0.0.0:3000/
Hit Ctrl-C to quit.

====== None
Traceback (most recent call last):
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/bottle.py", line 876, in _handle
    return route.call(**args)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/bottle.py", line 1759, in wrapper
    rv = callback(*a, **ka)
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/app.py", line 165, in inference_by_org
    msg = inferencer.generate(rwkv_rnn,msg)
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/models/inference_helper.py", line 125, in generate
    logits , self.state = model(token, self.state)
TypeError: 'NoneType' object is not callable
192.168.0.103 - - [30/Sep/2023 19:36:30] "POST /inference/by-org HTTP/1.1" 500 759
  0%|          | 0/582 [00:00<?, ?it/s]  1%|▏         | 8/582 [00:02<02:24,  3.97it/s]100%|██████████| 582/582 [00:02<00:00, 288.18it/s]
  0%|          | 0/582 [00:00<?, ?it/s]100%|██████████| 582/582 [00:00<00:00, 567166.57it/s]
127.0.0.1 - - [30/Sep/2023 19:37:00] "POST /inference/load-model HTTP/1.1" 200 26
====== None
```python
def is_palindrome(string):
    """Check if a string is a palindrome."""
    return string == string[::-1]
```

## 输出

打印结果：
```console
True
```

## 边栏：额外资源

*   [PyCharm](https://www.jetbrains.com/pycharm/): Integrated Development Environment for Python, with syntax highlighting and debugging tools.
*   [PyCharm IDE](https://www.jetbrains.com/pycharm/): Integrated development environment for Python, with syntax highlighting and debugging tools, built on top of [JetBrains](https://www.jetbrains.com/)' IntelliJ IDEA productivity suite.
*   [PyCharm IDE tutorial](https://www.jetbrains.com/pycharm/tutorial/): Learn how to use PyCharm to write plugins for IntelliJ IDEA, including plugin architecture and plugin API reference documentation.
*   [PyCharm tutorial](https://www.jetbrains.com/pycharm/tutorial/): Learn how to use PyCharm to write plugins for IntelliJ IDEA,192.168.0.103 - - [30/Sep/2023 19:38:07] "POST /inference/by-org HTTP/1.1" 200 4068
====== None
## 译者：@小鱼儿 @晨世宣融

本文档内容部分参考了[@TimZhangLLL](https://github.com/TimZhangLLL)的翻译，感谢他的努力。

本文档内容部分参考了[@TimZhangLLL](https://github.com/TimZhangLLL)的翻译，感谢他的努力。

本文档内容部分参考了[@TimZhangLLL](https://github.com/TimZhangLLL)的翻译，感谢他的努力。

本文档内容部分参考了[@TimZhangLLL](https://github.com/TimZhangLLL)的翻译，感谢他的努力。

本文档内容部分参考了[@TimZhangLLL](https://github.com/TimZhangLLL)的翻译，感谢他的努力。

本文档内容部分参考了[@TimZhangLLL](https://github.com/TimZhangLLL)的192.168.0.103 - - [30/Sep/2023 19:38:38] "POST /inference/by-org HTTP/1.1" 200 4511
192.168.0.103 - - [30/Sep/2023 19:44:24] "POST /inference/by-org-no-state HTTP/1.1" 404 772
[2023-09-30 19:45:07,340] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 1293729
[2023-09-30 19:45:07,341] [ERROR] [launch.py:434:sigkill_handler] ['/home/neromous/.minicoda3/envs/blackfog/bin/python', '-u', 'app.py', '--local_rank=0', '--deepspeed'] exits with return code = -9
[2023-09-30 19:46:07,284] [WARNING] [runner.py:190:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2023-09-30 19:46:10,131] [INFO] [runner.py:540:main] cmd = /home/neromous/.minicoda3/envs/blackfog/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None app.py --deepspeed
[2023-09-30 19:46:12,598] [INFO] [launch.py:229:main] WORLD INFO DICT: {'localhost': [1]}
[2023-09-30 19:46:12,598] [INFO] [launch.py:235:main] nnodes=1, num_local_procs=1, node_rank=0
[2023-09-30 19:46:12,598] [INFO] [launch.py:246:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2023-09-30 19:46:12,598] [INFO] [launch.py:247:main] dist_world_size=1
[2023-09-30 19:46:12,598] [INFO] [launch.py:249:main] Setting CUDA_VISIBLE_DEVICES=1
RWKV_MY_TESTING 
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/wkv_512/build.ninja...
Building extension module wkv_512...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module wkv_512...
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 4.585330009460449 seconds
Adam Optimizer #0 is created with AVX2 arithmetic capability.
Config: alpha=0.000100, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=0
[2023-09-30 19:47:03,163] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.9.1, git-hash=unknown, git-branch=unknown
[2023-09-30 19:47:03,164] [INFO] [comm.py:586:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2023-09-30 19:47:09,893] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-30 19:47:09,895] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2023-09-30 19:47:09,895] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2023-09-30 19:47:09,934] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam
[2023-09-30 19:47:09,934] [INFO] [utils.py:51:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>
[2023-09-30 19:47:09,934] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float32 ZeRO stage 2 optimizer
[2023-09-30 19:47:09,935] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 2000000
[2023-09-30 19:47:09,935] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 2000000
[2023-09-30 19:47:09,935] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: True
[2023-09-30 19:47:09,935] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.2807796001434326 seconds
Rank: 0 partition count [1, 1, 1] and sizes[(3062589440, False), (81920, False), (81920, False)] 
[2023-09-30 19:47:33,836] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[2023-09-30 19:47:33,837] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 19:47:33,837] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 22.39 GB, percent = 17.8%
[2023-09-30 19:47:54,737] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[2023-09-30 19:47:54,738] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 19:47:54,738] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 61.61 GB, percent = 49.0%
[2023-09-30 19:47:54,738] [INFO] [stage_1_and_2.py:489:__init__] optimizer state initialized
[2023-09-30 19:47:56,842] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[2023-09-30 19:47:56,843] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 19:47:56,843] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 61.61 GB, percent = 49.0%
[2023-09-30 19:47:56,871] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedCPUAdam
[2023-09-30 19:47:56,871] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2023-09-30 19:47:56,871] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7fca0f8de8e0>
[2023-09-30 19:47:56,871] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0001, 0.0002, 0.00030000000000000003], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
[2023-09-30 19:47:56,872] [INFO] [config.py:953:print] DeepSpeedEngine configuration:
[2023-09-30 19:47:56,873] [INFO] [config.py:957:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-30 19:47:56,873] [INFO] [config.py:957:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-30 19:47:56,873] [INFO] [config.py:957:print]   amp_enabled .................. False
[2023-09-30 19:47:56,873] [INFO] [config.py:957:print]   amp_params ................... False
[2023-09-30 19:47:56,873] [INFO] [config.py:957:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-30 19:47:56,873] [INFO] [config.py:957:print]   bfloat16_enabled ............. False
[2023-09-30 19:47:56,873] [INFO] [config.py:957:print]   checkpoint_parallel_write_pipeline  False
[2023-09-30 19:47:56,873] [INFO] [config.py:957:print]   checkpoint_tag_validation_enabled  True
[2023-09-30 19:47:56,873] [INFO] [config.py:957:print]   checkpoint_tag_validation_fail  False
[2023-09-30 19:47:56,873] [INFO] [config.py:957:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fca0f6da9d0>
[2023-09-30 19:47:56,873] [INFO] [config.py:957:print]   communication_data_type ...... None
[2023-09-30 19:47:56,873] [INFO] [config.py:957:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-30 19:47:56,873] [INFO] [config.py:957:print]   curriculum_enabled_legacy .... False
[2023-09-30 19:47:56,873] [INFO] [config.py:957:print]   curriculum_params_legacy ..... False
[2023-09-30 19:47:56,874] [INFO] [config.py:957:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-30 19:47:56,874] [INFO] [config.py:957:print]   data_efficiency_enabled ...... False
[2023-09-30 19:47:56,874] [INFO] [config.py:957:print]   dataloader_drop_last ......... False
[2023-09-30 19:47:56,874] [INFO] [config.py:957:print]   disable_allgather ............ False
[2023-09-30 19:47:56,874] [INFO] [config.py:957:print]   dump_state ................... False
[2023-09-30 19:47:56,874] [INFO] [config.py:957:print]   dynamic_loss_scale_args ...... None
[2023-09-30 19:47:56,874] [INFO] [config.py:957:print]   eigenvalue_enabled ........... False
[2023-09-30 19:47:56,874] [INFO] [config.py:957:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-30 19:47:56,874] [INFO] [config.py:957:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-30 19:47:56,874] [INFO] [config.py:957:print]   eigenvalue_layer_num ......... 0
[2023-09-30 19:47:56,874] [INFO] [config.py:957:print]   eigenvalue_max_iter .......... 100
[2023-09-30 19:47:56,874] [INFO] [config.py:957:print]   eigenvalue_stability ......... 1e-06
[2023-09-30 19:47:56,874] [INFO] [config.py:957:print]   eigenvalue_tol ............... 0.01
[2023-09-30 19:47:56,874] [INFO] [config.py:957:print]   eigenvalue_verbose ........... False
[2023-09-30 19:47:56,874] [INFO] [config.py:957:print]   elasticity_enabled ........... False
[2023-09-30 19:47:56,874] [INFO] [config.py:957:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-30 19:47:56,874] [INFO] [config.py:957:print]   fp16_auto_cast ............... None
[2023-09-30 19:47:56,874] [INFO] [config.py:957:print]   fp16_enabled ................. False
[2023-09-30 19:47:56,874] [INFO] [config.py:957:print]   fp16_master_weights_and_gradients  False
[2023-09-30 19:47:56,874] [INFO] [config.py:957:print]   global_rank .................. 0
[2023-09-30 19:47:56,874] [INFO] [config.py:957:print]   grad_accum_dtype ............. None
[2023-09-30 19:47:56,874] [INFO] [config.py:957:print]   gradient_accumulation_steps .. 1
[2023-09-30 19:47:56,874] [INFO] [config.py:957:print]   gradient_clipping ............ 1
[2023-09-30 19:47:56,874] [INFO] [config.py:957:print]   gradient_predivide_factor .... 1.0
[2023-09-30 19:47:56,874] [INFO] [config.py:957:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-30 19:47:56,874] [INFO] [config.py:957:print]   initial_dynamic_scale ........ 65536
[2023-09-30 19:47:56,875] [INFO] [config.py:957:print]   load_universal_checkpoint .... False
[2023-09-30 19:47:56,875] [INFO] [config.py:957:print]   loss_scale ................... 0
[2023-09-30 19:47:56,875] [INFO] [config.py:957:print]   memory_breakdown ............. False
[2023-09-30 19:47:56,875] [INFO] [config.py:957:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-30 19:47:56,875] [INFO] [config.py:957:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-30 19:47:56,875] [INFO] [config.py:957:print]   optimizer_legacy_fusion ...... False
[2023-09-30 19:47:56,875] [INFO] [config.py:957:print]   optimizer_name ............... None
[2023-09-30 19:47:56,875] [INFO] [config.py:957:print]   optimizer_params ............. None
[2023-09-30 19:47:56,875] [INFO] [config.py:957:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-30 19:47:56,875] [INFO] [config.py:957:print]   pld_enabled .................. False
[2023-09-30 19:47:56,875] [INFO] [config.py:957:print]   pld_params ................... False
[2023-09-30 19:47:56,875] [INFO] [config.py:957:print]   prescale_gradients ........... False
[2023-09-30 19:47:56,875] [INFO] [config.py:957:print]   scheduler_name ............... None
[2023-09-30 19:47:56,875] [INFO] [config.py:957:print]   scheduler_params ............. None
[2023-09-30 19:47:56,875] [INFO] [config.py:957:print]   sparse_attention ............. None
[2023-09-30 19:47:56,875] [INFO] [config.py:957:print]   sparse_gradients_enabled ..... False
[2023-09-30 19:47:56,875] [INFO] [config.py:957:print]   steps_per_print .............. 10
[2023-09-30 19:47:56,875] [INFO] [config.py:957:print]   train_batch_size ............. 1
[2023-09-30 19:47:56,875] [INFO] [config.py:957:print]   train_micro_batch_size_per_gpu  1
[2023-09-30 19:47:56,875] [INFO] [config.py:957:print]   use_node_local_storage ....... False
[2023-09-30 19:47:56,875] [INFO] [config.py:957:print]   wall_clock_breakdown ......... False
[2023-09-30 19:47:56,875] [INFO] [config.py:957:print]   world_size ................... 1
[2023-09-30 19:47:56,875] [INFO] [config.py:957:print]   zero_allow_untested_optimizer  False
[2023-09-30 19:47:56,875] [INFO] [config.py:957:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=2000000 allgather_partitions=True allgather_bucket_size=2000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=True, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False memory_efficient_linear=True
[2023-09-30 19:47:56,876] [INFO] [config.py:957:print]   zero_enabled ................. True
[2023-09-30 19:47:56,876] [INFO] [config.py:957:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-30 19:47:56,876] [INFO] [config.py:957:print]   zero_optimization_stage ...... 2
[2023-09-30 19:47:56,876] [INFO] [config.py:943:print_user_config]   json = {
    "   fp16": {
        "enabled": false
    }, 
    "zero_optimization": {
        "stage": 2, 
        "offload_optimizer": {
            "device": "cpu", 
            "pin_memory": true
        }, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+06, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+06, 
        "contiguous_gradients": true
    }, 
    "gradient_accumulation_steps": 1, 
    "gradient_clipping": 1, 
    "train_micro_batch_size_per_gpu": 1, 
    "checkpoint": {
        "path": "/home/neromous/Documents/blackfog/resources/train-results/oneline/", 
        "keep_checkpoint_max": 3
    }
}
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0005488395690917969 seconds
Bottle v0.12.25 server starting up (using WSGIRefServer())...
Listening on http://0.0.0.0:3000/
Hit Ctrl-C to quit.

====== None
org-mode:
1. 在 org-mode 中,可以使用 C-c C-x 键进行切换。
2. 你也可以使用 Shift+C-x 键来切换到上一层的 org mode。
3. 或者按 Ctrl+C (Windows) 或 Command+C (Mac OS X) 来打开 cmd window, 在 org mode 中输入:
``` elisp
   (printf "\\n\\nOrg mode: \\n%s\\n"\\org_mode)
并且按 Ctrl+V (Windows) 或 Command+V (Mac OS X) 保存。
192.168.0.103 - - [30/Sep/2023 19:49:21] "POST /inference/by-org-no-state HTTP/1.1" 200 4261
  0%|          | 0/582 [00:00<?, ?it/s]100%|██████████| 582/582 [00:00<00:00, 32374.70it/s]
  0%|          | 0/582 [00:00<?, ?it/s]100%|██████████| 582/582 [00:00<00:00, 553157.70it/s]
====== None
Traceback (most recent call last):
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/bottle.py", line 876, in _handle
    return route.call(**args)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/bottle.py", line 1759, in wrapper
    rv = callback(*a, **ka)
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/app.py", line 171, in inference_by_org
    msg = inferencer.generate(rwkv_rnn,msg)
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/models/inference_helper.py", line 128, in generate
    logits[n] = -float('inf')
IndexError: list assignment index out of range
192.168.0.103 - - [30/Sep/2023 19:49:38] "POST /inference/by-org HTTP/1.1" 500 759
  0%|          | 0/582 [00:00<?, ?it/s]100%|██████████| 582/582 [00:00<00:00, 28787.74it/s]
  0%|          | 0/582 [00:00<?, ?it/s]100%|██████████| 582/582 [00:00<00:00, 564282.23it/s]
127.0.0.1 - - [30/Sep/2023 19:51:31] "POST /inference/load-model HTTP/1.1" 200 26
====== None
Traceback (most recent call last):
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/bottle.py", line 876, in _handle
    return route.call(**args)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/bottle.py", line 1759, in wrapper
    rv = callback(*a, **ka)
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/app.py", line 171, in inference_by_org
    msg = inferencer.generate(rwkv_rnn,msg)
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/models/inference_helper.py", line 128, in generate
    logits[n] = -float('inf')
IndexError: list assignment index out of range
192.168.0.103 - - [30/Sep/2023 19:51:42] "POST /inference/by-org HTTP/1.1" 500 759
192.168.0.103 - - [30/Sep/2023 19:52:29] "POST /train/by-org HTTP/1.1" 404 746
[2023-09-30 19:55:49,257] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 1297923
[2023-09-30 19:55:49,258] [ERROR] [launch.py:434:sigkill_handler] ['/home/neromous/.minicoda3/envs/blackfog/bin/python', '-u', 'app.py', '--local_rank=0', '--deepspeed'] exits with return code = -9
[2023-09-30 19:56:03,785] [WARNING] [runner.py:190:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2023-09-30 19:56:03,805] [INFO] [runner.py:540:main] cmd = /home/neromous/.minicoda3/envs/blackfog/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None app.py --deepspeed
[2023-09-30 19:56:06,318] [INFO] [launch.py:229:main] WORLD INFO DICT: {'localhost': [1]}
[2023-09-30 19:56:06,319] [INFO] [launch.py:235:main] nnodes=1, num_local_procs=1, node_rank=0
[2023-09-30 19:56:06,319] [INFO] [launch.py:246:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2023-09-30 19:56:06,319] [INFO] [launch.py:247:main] dist_world_size=1
[2023-09-30 19:56:06,319] [INFO] [launch.py:249:main] Setting CUDA_VISIBLE_DEVICES=1
RWKV_MY_TESTING 
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/wkv_512/build.ninja...
Building extension module wkv_512...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module wkv_512...
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 4.607452154159546 seconds
Adam Optimizer #0 is created with AVX2 arithmetic capability.
Config: alpha=0.000100, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=0
[2023-09-30 19:56:59,396] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.9.1, git-hash=unknown, git-branch=unknown
[2023-09-30 19:56:59,396] [INFO] [comm.py:586:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2023-09-30 19:57:02,062] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-30 19:57:02,064] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2023-09-30 19:57:02,064] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2023-09-30 19:57:02,103] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam
[2023-09-30 19:57:02,103] [INFO] [utils.py:51:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>
[2023-09-30 19:57:02,103] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float32 ZeRO stage 2 optimizer
[2023-09-30 19:57:02,103] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 2000000
[2023-09-30 19:57:02,103] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 2000000
[2023-09-30 19:57:02,103] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: True
[2023-09-30 19:57:02,103] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.3096616268157959 seconds
Rank: 0 partition count [1, 1, 1] and sizes[(3062589440, False), (81920, False), (81920, False)] 
[2023-09-30 19:57:24,706] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[2023-09-30 19:57:24,707] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 19:57:24,708] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 22.38 GB, percent = 17.8%
[2023-09-30 19:57:44,875] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[2023-09-30 19:57:44,876] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 19:57:44,876] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 61.6 GB, percent = 49.0%
[2023-09-30 19:57:44,876] [INFO] [stage_1_and_2.py:489:__init__] optimizer state initialized
[2023-09-30 19:57:45,743] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[2023-09-30 19:57:45,744] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 19:57:45,744] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 61.6 GB, percent = 49.0%
[2023-09-30 19:57:45,765] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedCPUAdam
[2023-09-30 19:57:45,765] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2023-09-30 19:57:45,765] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7fa1fb839f40>
[2023-09-30 19:57:45,765] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0001, 0.0002, 0.00030000000000000003], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
[2023-09-30 19:57:45,766] [INFO] [config.py:953:print] DeepSpeedEngine configuration:
[2023-09-30 19:57:45,766] [INFO] [config.py:957:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-30 19:57:45,766] [INFO] [config.py:957:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-30 19:57:45,767] [INFO] [config.py:957:print]   amp_enabled .................. False
[2023-09-30 19:57:45,767] [INFO] [config.py:957:print]   amp_params ................... False
[2023-09-30 19:57:45,767] [INFO] [config.py:957:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-30 19:57:45,767] [INFO] [config.py:957:print]   bfloat16_enabled ............. False
[2023-09-30 19:57:45,767] [INFO] [config.py:957:print]   checkpoint_parallel_write_pipeline  False
[2023-09-30 19:57:45,767] [INFO] [config.py:957:print]   checkpoint_tag_validation_enabled  True
[2023-09-30 19:57:45,767] [INFO] [config.py:957:print]   checkpoint_tag_validation_fail  False
[2023-09-30 19:57:45,767] [INFO] [config.py:957:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fa1fb839640>
[2023-09-30 19:57:45,767] [INFO] [config.py:957:print]   communication_data_type ...... None
[2023-09-30 19:57:45,767] [INFO] [config.py:957:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-30 19:57:45,767] [INFO] [config.py:957:print]   curriculum_enabled_legacy .... False
[2023-09-30 19:57:45,767] [INFO] [config.py:957:print]   curriculum_params_legacy ..... False
[2023-09-30 19:57:45,767] [INFO] [config.py:957:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-30 19:57:45,767] [INFO] [config.py:957:print]   data_efficiency_enabled ...... False
[2023-09-30 19:57:45,767] [INFO] [config.py:957:print]   dataloader_drop_last ......... False
[2023-09-30 19:57:45,767] [INFO] [config.py:957:print]   disable_allgather ............ False
[2023-09-30 19:57:45,767] [INFO] [config.py:957:print]   dump_state ................... False
[2023-09-30 19:57:45,767] [INFO] [config.py:957:print]   dynamic_loss_scale_args ...... None
[2023-09-30 19:57:45,767] [INFO] [config.py:957:print]   eigenvalue_enabled ........... False
[2023-09-30 19:57:45,767] [INFO] [config.py:957:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-30 19:57:45,767] [INFO] [config.py:957:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-30 19:57:45,768] [INFO] [config.py:957:print]   eigenvalue_layer_num ......... 0
[2023-09-30 19:57:45,768] [INFO] [config.py:957:print]   eigenvalue_max_iter .......... 100
[2023-09-30 19:57:45,768] [INFO] [config.py:957:print]   eigenvalue_stability ......... 1e-06
[2023-09-30 19:57:45,768] [INFO] [config.py:957:print]   eigenvalue_tol ............... 0.01
[2023-09-30 19:57:45,768] [INFO] [config.py:957:print]   eigenvalue_verbose ........... False
[2023-09-30 19:57:45,768] [INFO] [config.py:957:print]   elasticity_enabled ........... False
[2023-09-30 19:57:45,768] [INFO] [config.py:957:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-30 19:57:45,768] [INFO] [config.py:957:print]   fp16_auto_cast ............... None
[2023-09-30 19:57:45,768] [INFO] [config.py:957:print]   fp16_enabled ................. False
[2023-09-30 19:57:45,768] [INFO] [config.py:957:print]   fp16_master_weights_and_gradients  False
[2023-09-30 19:57:45,768] [INFO] [config.py:957:print]   global_rank .................. 0
[2023-09-30 19:57:45,768] [INFO] [config.py:957:print]   grad_accum_dtype ............. None
[2023-09-30 19:57:45,768] [INFO] [config.py:957:print]   gradient_accumulation_steps .. 1
[2023-09-30 19:57:45,768] [INFO] [config.py:957:print]   gradient_clipping ............ 1
[2023-09-30 19:57:45,768] [INFO] [config.py:957:print]   gradient_predivide_factor .... 1.0
[2023-09-30 19:57:45,768] [INFO] [config.py:957:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-30 19:57:45,768] [INFO] [config.py:957:print]   initial_dynamic_scale ........ 65536
[2023-09-30 19:57:45,768] [INFO] [config.py:957:print]   load_universal_checkpoint .... False
[2023-09-30 19:57:45,768] [INFO] [config.py:957:print]   loss_scale ................... 0
[2023-09-30 19:57:45,768] [INFO] [config.py:957:print]   memory_breakdown ............. False
[2023-09-30 19:57:45,768] [INFO] [config.py:957:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-30 19:57:45,768] [INFO] [config.py:957:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-30 19:57:45,769] [INFO] [config.py:957:print]   optimizer_legacy_fusion ...... False
[2023-09-30 19:57:45,769] [INFO] [config.py:957:print]   optimizer_name ............... None
[2023-09-30 19:57:45,769] [INFO] [config.py:957:print]   optimizer_params ............. None
[2023-09-30 19:57:45,769] [INFO] [config.py:957:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-30 19:57:45,769] [INFO] [config.py:957:print]   pld_enabled .................. False
[2023-09-30 19:57:45,769] [INFO] [config.py:957:print]   pld_params ................... False
[2023-09-30 19:57:45,769] [INFO] [config.py:957:print]   prescale_gradients ........... False
[2023-09-30 19:57:45,769] [INFO] [config.py:957:print]   scheduler_name ............... None
[2023-09-30 19:57:45,769] [INFO] [config.py:957:print]   scheduler_params ............. None
[2023-09-30 19:57:45,769] [INFO] [config.py:957:print]   sparse_attention ............. None
[2023-09-30 19:57:45,769] [INFO] [config.py:957:print]   sparse_gradients_enabled ..... False
[2023-09-30 19:57:45,769] [INFO] [config.py:957:print]   steps_per_print .............. 10
[2023-09-30 19:57:45,769] [INFO] [config.py:957:print]   train_batch_size ............. 1
[2023-09-30 19:57:45,769] [INFO] [config.py:957:print]   train_micro_batch_size_per_gpu  1
[2023-09-30 19:57:45,769] [INFO] [config.py:957:print]   use_node_local_storage ....... False
[2023-09-30 19:57:45,769] [INFO] [config.py:957:print]   wall_clock_breakdown ......... False
[2023-09-30 19:57:45,769] [INFO] [config.py:957:print]   world_size ................... 1
[2023-09-30 19:57:45,769] [INFO] [config.py:957:print]   zero_allow_untested_optimizer  False
[2023-09-30 19:57:45,769] [INFO] [config.py:957:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=2000000 allgather_partitions=True allgather_bucket_size=2000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=True, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False memory_efficient_linear=True
[2023-09-30 19:57:45,769] [INFO] [config.py:957:print]   zero_enabled ................. True
[2023-09-30 19:57:45,769] [INFO] [config.py:957:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-30 19:57:45,769] [INFO] [config.py:957:print]   zero_optimization_stage ...... 2
[2023-09-30 19:57:45,769] [INFO] [config.py:943:print_user_config]   json = {
    "   fp16": {
        "enabled": false
    }, 
    "zero_optimization": {
        "stage": 2, 
        "offload_optimizer": {
            "device": "cpu", 
            "pin_memory": true
        }, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+06, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+06, 
        "contiguous_gradients": true
    }, 
    "gradient_accumulation_steps": 1, 
    "gradient_clipping": 1, 
    "train_micro_batch_size_per_gpu": 1, 
    "checkpoint": {
        "path": "/home/neromous/Documents/blackfog/resources/train-results/oneline/", 
        "keep_checkpoint_max": 3
    }
}
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.000385284423828125 seconds
Bottle v0.12.25 server starting up (using WSGIRefServer())...
Listening on http://0.0.0.0:3000/
Hit Ctrl-C to quit.

  0%|          | 0/582 [00:00<?, ?it/s]  1%|▏         | 8/582 [00:00<00:46, 12.41it/s]100%|██████████| 582/582 [00:00<00:00, 899.80it/s]
  0%|          | 0/582 [00:00<?, ?it/s]100%|██████████| 582/582 [00:00<00:00, 526663.41it/s]
====== None
=== [16503, 13685, 17097, 17688, 11124, 15478, 15850, 14734, 17109, 10760, 11, 65530, 65532, 12605, 17879, 16503, 10464, 10988, 15641, 14931, 12314, 10267, 14610, 19137, 12176, 12605, 10708, 10250, 17303, 11975, 16735, 11, 65535, 261, 65530, 65534, 11685, 14734, 19137, 12605, 10423, 11986, 16707, 10708, 10250, 17303, 11975, 16735, 10080, 10260, 17141, 19137, 12605, 17879, 16503, 13179, 11632, 14734, 10529, 12445, 13234, 12176, 10847, 12605, 13250, 12410, 28329, 65535, 261, 65530, 65532, 10464, 17879, 16503, 10373, 10303, 10529, 12445, 19156, 11, 65535, 261, 65530, 65534, 18117, 10658, 19137, 12605, 17879, 16503, 14862, 17222, 17148, 17303, 11975, 16735, 14734, 15261, 11496, 10080, 13091, 15034, 12206, 11975, 16735, 10079, 12472, 14638, 11975, 16735, 17147, 13091, 10687, 10390, 15261, 11496, 14734, 11975, 16735, 19156, 11, 65535, 261, 65530, 65532, 12605, 16667, 10292, 13091, 15034, 12206, 11975, 16735, 11, 65535, 261, 65530, 65534, 11685, 14734, 19137, 12605, 10423, 10292, 10464, 12848, 10494, 13179, 11632, 15478, 15907, 10080, 11454, 17148, 17303, 11975, 16735, 10285, 19137, 10293, 10370, 10678, 13091, 10250, 10447, 11043, 11017, 11889, 12363, 18295, 2453, 10788, 10348, 18005, 14734, 12201, 17093, 10460, 11920, 10080, 10390, 11454, 10708, 10460, 17141, 15052, 10285, 11002, 10792, 10333, 13279, 15033, 14987, 15036, 10838, 17387, 14734, 12325, 11168, 19137, 12266, 11726, 10588, 10250, 10349, 11656, 12418, 14734, 13370, 10080, 17148, 10349, 13370, 11574, 16672, 10390, 15752, 11634, 14791, 16519, 13203, 13234, 11124, 17141, 10985, 19137, 12202, 10265, 16056, 12348, 10333, 13279, 15033, 14987, 11656, 14734, 10838, 17387, 28329, 65535, 261, 65530, 65532, 15752, 12848, 10494, 16721, 10293, 10370, 10678, 14734, 11630, 16815, 14332, 12333, 11124, 15727, 13126, 10529, 12445, 11053, 19156, 11, 65535, 261, 65530, 65534, 11685, 14734, 19137, 12605, 10423, 10292, 10464, 12848, 10494, 16721, 10293, 10370, 10678, 14734, 14782, 10684, 10529, 12445, 10080, 18117, 10658, 19137, 17148, 10447, 10293, 10370, 10678, 11043, 11017, 11889, 12363, 14179, 2453, 12163, 14332, 11979, 19137, 10390, 13091, 10250, 10447, 12201, 17093, 13191, 10292, 14734, 10460, 11920, 10080, 10687, 13557, 19137, 10390, 13191, 10250, 11647, 13833, 11930, 14734, 18438, 10997, 11124, 13913, 17808, 14734, 14806, 14815, 19137, 15494, 10370, 14614, 10258, 13913, 10799, 14734, 10951, 16803, 10080, 13188, 11044, 19137, 10390, 12421, 13091, 15091, 14808, 12348, 10452, 10079, 10296, 13579, 12348, 10452, 19137, 15494, 10370, 14614, 10258, 15895, 11685, 14734, 15162, 10250, 10951, 16803, 28329, 65535, 261, 65530, 65532]
==== < Message
id: (1447)
role: (text)
text: ()
prefix: ()
postfix: ()
prefix_token: ([])
temperature: (0.1)
top_p: (0.1)
top_k: (0)
alpha_frequency: (0.45)
alpha_presence: (0.45)
alpha_decay: (0.996)
token_ban: ([0])
token_stop: ([65530, 65531, 65532, 65533, 65534, 65535])
chunk_len: (128)
token_count: (256)
over: (True)
scene_id: (507)
response: ()
generated: (False)
to_train: (True)
ctx: (2048)
ctx_fix: (256)
tokens: ([16503, 13685, 17097, 17688, 11124, 15478, 15850, 14734, 17109, 10760, 11, 65530, 65532, 12605, 17879, 16503, 10464, 10988, 15641, 14931, 12314, 10267, 14610, 19137, 12176, 12605, 10708, 10250, 17303, 11975, 16735, 11, 65535, 261, 65530, 65534, 11685, 14734, 19137, 12605, 10423, 11986, 16707, 10708, 10250, 17303, 11975, 16735, 10080, 10260, 17141, 19137, 12605, 17879, 16503, 13179, 11632, 14734, 10529, 12445, 13234, 12176, 10847, 12605, 13250, 12410, 28329, 65535, 261, 65530, 65532, 10464, 17879, 16503, 10373, 10303, 10529, 12445, 19156, 11, 65535, 261, 65530, 65534, 18117, 10658, 19137, 12605, 17879, 16503, 14862, 17222, 17148, 17303, 11975, 16735, 14734, 15261, 11496, 10080, 13091, 15034, 12206, 11975, 16735, 10079, 12472, 14638, 11975, 16735, 17147, 13091, 10687, 10390, 15261, 11496, 14734, 11975, 16735, 19156, 11, 65535, 261, 65530, 65532, 12605, 16667, 10292, 13091, 15034, 12206, 11975, 16735, 11, 65535, 261, 65530, 65534, 11685, 14734, 19137, 12605, 10423, 10292, 10464, 12848, 10494, 13179, 11632, 15478, 15907, 10080, 11454, 17148, 17303, 11975, 16735, 10285, 19137, 10293, 10370, 10678, 13091, 10250, 10447, 11043, 11017, 11889, 12363, 18295, 2453, 10788, 10348, 18005, 14734, 12201, 17093, 10460, 11920, 10080, 10390, 11454, 10708, 10460, 17141, 15052, 10285, 11002, 10792, 10333, 13279, 15033, 14987, 15036, 10838, 17387, 14734, 12325, 11168, 19137, 12266, 11726, 10588, 10250, 10349, 11656, 12418, 14734, 13370, 10080, 17148, 10349, 13370, 11574, 16672, 10390, 15752, 11634, 14791, 16519, 13203, 13234, 11124, 17141, 10985, 19137, 12202, 10265, 16056, 12348, 10333, 13279, 15033, 14987, 11656, 14734, 10838, 17387, 28329, 65535, 261, 65530, 65532, 15752, 12848, 10494, 16721, 10293, 10370, 10678, 14734, 11630, 16815, 14332, 12333, 11124, 15727, 13126, 10529, 12445, 11053, 19156, 11, 65535, 261, 65530, 65534, 11685, 14734, 19137, 12605, 10423, 10292, 10464, 12848, 10494, 16721, 10293, 10370, 10678, 14734, 14782, 10684, 10529, 12445, 10080, 18117, 10658, 19137, 17148, 10447, 10293, 10370, 10678, 11043, 11017, 11889, 12363, 14179, 2453, 12163, 14332, 11979, 19137, 10390, 13091, 10250, 10447, 12201, 17093, 13191, 10292, 14734, 10460, 11920, 10080, 10687, 13557, 19137, 10390, 13191, 10250, 11647, 13833, 11930, 14734, 18438, 10997, 11124, 13913, 17808, 14734, 14806, 14815, 19137, 15494, 10370, 14614, 10258, 13913, 10799, 14734, 10951, 16803, 10080, 13188, 11044, 19137, 10390, 12421, 13091, 15091, 14808, 12348, 10452, 10079, 10296, 13579, 12348, 10452, 19137, 15494, 10370, 14614, 10258, 15895, 11685, 14734, 15162, 10250, 10951, 16803, 28329, 65535, 261, 65530, 65532]) 
>

Traceback (most recent call last):
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/bottle.py", line 876, in _handle
    return route.call(**args)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/bottle.py", line 1759, in wrapper
    rv = callback(*a, **ka)
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/app.py", line 173, in inference_by_org
    msg = inferencer.generate(rwkv_rnn,msg)
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/models/inference_helper.py", line 128, in generate
    logits[n] = -float('inf')
IndexError: list assignment index out of range
192.168.0.103 - - [30/Sep/2023 19:58:19] "POST /inference/by-org HTTP/1.1" 500 759
====== None
====== None
====== None
==== [<models.org_text.DataNode object at 0x7fa16e4508b0>]
==== [11687, 10454, 16056, 11001, 7451, 1802, 267, 25028, 34043, 14734, 10285, 14734, 10696, 11922, 19156, 11, 5686, 1511, 70, 33, 10464, 11021, 10399, 10482, 14589, 10399, 10258, 4515, 7917, 33, 10397, 14875, 16056, 11001, 3784, 6908, 267, 25028, 34043, 33, 14734, 10696, 11922, 59, 11, 6884, 7441, 2191, 11, 41, 49026, 46, 26081, 283, 42, 11, 6884, 11, 97, 49026, 46, 26081, 97, 33, 10762, 13004, 13191, 10278, 10283, 10988, 13004, 59, 11, 46, 283, 33, 16417, 14966, 16056, 11001, 13188, 17145, 14734, 31213, 11, 46, 33, 13580, 13004, 16417, 14966, 16056, 11001, 13179, 13057, 14734, 31213, 11, 12631, 10399, 10292, 10333, 11016, 16056, 11001, 13188, 13034, 14734, 59300, 33, 10696, 11922, 45, 12605, 10402, 10427, 10673, 283, 33, 10953, 11021, 28329, 10487, 11687, 59, 11, 6884, 7441, 2191, 11, 41, 8079, 3421, 27139, 275, 49026, 46, 26081, 283, 5292, 11, 41, 49410, 269, 57956, 51308, 59, 272, 116, 35, 32224, 494, 11, 6884, 11, 17148, 13619, 10397, 14875, 10423, 16056, 11001, 59300, 33, 10696, 11922, 45, 12202, 13098, 14966, 11454, 13855, 12445, 13314, 10285, 28329, 10464, 10322, 11021, 10399, 12669, 59300, 33, 10696, 11922, 16914, 10577, 15494, 10250, 10283, 11003, 17387, 45, 14221, 11044, 17149, 16403, 14782, 10684, 14734, 11621, 14486, 28329, 12631, 10399, 45, 10482, 14589, 331, 49026, 46, 26081, 283, 97, 33, 11994, 11021, 10399, 11454, 3784, 6908, 20299, 113, 33, 10397, 14875, 10285, 16056, 11001, 3784, 6908, 33, 14734, 59300, 33, 10696, 11922, 28329, 10482, 14589, 10373, 10303, 7441, 2191, 10762, 13004, 15752, 11634, 11903, 14446, 11454, 7451, 1802, 10285, 14734, 8401, 46, 26267, 10258, 17177, 10285, 13279, 10283, 8760, 46, 27187, 19156, 520, 19589, 1511, 70, 33, 11021, 10399, 10482, 14589, 22236, 46, 34200, 33, 11117, 10398, 13234, 17177, 10285, 53048, 28329, 12750, 17644, 15487, 11899, 59, 11, 68, 46, 100, 332, 275, 8401, 46, 34200, 42, 11, 14589, 13764, 59, 11, 50, 47, 33, 10659, 13308, 12983, 11454, 8760, 27187, 14734, 13308, 18025, 10257, 11, 51, 47, 33, 12750, 302, 46, 100, 332, 11, 52, 47, 33, 17148, 11967, 17177, 10285, 16721, 8760, 27187, 10258, 14734, 12631, 13191, 10696, 11922, 11, 10464, 10322, 11021, 10399, 12748, 11899, 17879, 16503, 12357, 14445, 14734, 13557, 13004, 13234, 17177, 10285, 10260, 11042, 15451, 10790, 14734, 10696, 11922, 59, 11, 46, 302, 46, 100, 332, 284, 280, 33, 17177, 10285, 12307, 10808, 16403, 11, 46, 302, 46, 100, 332, 285, 280, 33, 17177, 10285, 12307, 10808, 15907, 14172, 41, 13308, 18025, 10992, 11855, 15907, 14172, 42, 11, 46, 302, 46, 100, 332, 286, 280, 33, 17177, 10285, 12307, 10808, 15907, 14172, 14734, 14302, 15907, 14172, 11, 46, 33, 15169, 15169, 11, 12631, 10399, 45, 11454, 22236, 46, 26267, 33, 10258, 17177, 10285, 13279, 10283, 53048, 45, 10464, 11021, 10399, 59, 11, 50, 47, 33, 10659, 13308, 12983, 11454, 16721, 53048, 33, 14734, 13308, 18025, 10257, 11, 51, 47, 33, 16749, 14589, 4398, 8401, 46, 34200, 313, 512, 10762, 13004, 45, 79, 33, 10292, 16503, 12357, 14445, 14734, 13557, 13004, 45, 10399, 17177, 10285, 16721, 11855, 13315, 11, 10487, 11687, 59, 11, 6884, 4515, 7917, 11, 41, 8401, 46, 34200, 285, 42, 267, 60, 33, 17177, 10285, 12307, 10808, 15907, 14172, 41, 11855, 13315, 42, 11, 6884, 11, 12159, 13197, 17148, 15752, 12176, 10847, 10464, 34, 24210, 11]
[2023-09-30 19:59:48,108] [INFO] [checkpointing.py:529:forward] Activation Checkpointing Information
[2023-09-30 19:59:48,108] [INFO] [checkpointing.py:530:forward] ----Partition Activations False, CPU CHECKPOINTING False
[2023-09-30 19:59:48,108] [INFO] [checkpointing.py:531:forward] ----contiguous Memory Checkpointing False with None total layers
[2023-09-30 19:59:48,109] [INFO] [checkpointing.py:533:forward] ----Synchronization False
[2023-09-30 19:59:48,109] [INFO] [checkpointing.py:534:forward] ----Profiling time in checkpointing False
-> item_loss 2.1173954010009766 batch_loss 2.1173954010009766
192.168.0.103 - - [30/Sep/2023 20:00:04] "POST /train/by-org HTTP/1.1" 200 28
  0%|          | 0/582 [00:00<?, ?it/s]100%|██████████| 582/582 [00:00<00:00, 30457.22it/s]
  0%|          | 0/582 [00:00<?, ?it/s]100%|██████████| 582/582 [00:00<00:00, 534622.19it/s]
127.0.0.1 - - [30/Sep/2023 20:03:43] "POST /inference/load-model HTTP/1.1" 200 26
None
None
127.0.0.1 - - [30/Sep/2023 20:03:43] "POST /state/reset HTTP/1.1" 200 21
碟形世界的故事讲述了一个奇幻的世界，被称为碟形世界，这个世界由许多大陆和无数的岛屿组成。在这个奇幻的世界中，人们可以驾驶着魔法船穿越各个大陆之间的空域，探索未知的领域，与各种奇异的生物进行冒险。同时，这个世界也充满了危险和挑战，需要英雄们勇敢面对。
<|over|>

<|me|><|request|>Question: 碟形世界有哪些著名的角色？
<|over|>

<|me|><|response|>Answer: 碟形世界中著名的角色有：
1. 伊莉雅·德·拉·克莱米耶（Ilica de la Reyna）：是一位强大的魔法师，拥有强大的魔法力量和智慧。
2. 贾米拉·哈迪洛斯·克莱米奥（Jazmin Harry Potter-Crabble-Kreacher）：是贾米拉·哈迪洛斯·克莱米奥的魔法管家，拥有强大的魔法能力。
3. 费泽尔·德·拉·克莱米奥（Fezco de la Reyna）：是伊莉雅的魔宠，拥有强大的魔法能力。
4. 费尔南多·德·拉·克莱米奥（Fernando de la Reyna）：是伊莉雅的青梅竹马，拥有强大的魔法能力。
5. 费尔南多·德·拉·克莱米奥（Fernando de la Reyna）：是伊莉雅的青梅竹马，拥有强大的魔法能力。
6. 费尔南多·德·拉·克莱米奥（Fernando de la Reyna）：是伊莉雅的青梅竹马，拥有强大的魔法能力。
7. 费尔南多·德·拉·克莱米奥（Fernando de la Reyna）：是伊莉雅的青梅竹马，拥有强大的魔法能力。
8. 费尔南多·德·拉127.0.0.1 - - [30/Sep/2023 20:04:02] "POST /inference/generate HTTP/1.1" 200 3960
tensor([[ 1.1239e-01,  6.5617e-03,  1.8517e-01,  ...,  1.2466e-01,
          1.9486e-01,  1.4709e-01],
        [ 1.8481e-01,  1.7514e-02, -1.2661e-02,  ...,  8.3811e-01,
          1.9648e-01,  6.7376e-02],
        [-5.3432e+00, -4.5233e+00, -7.8453e-01,  ...,  1.3372e-01,
         -1.0569e-01, -6.6466e-01],
        ...,
        [-2.6437e-01, -3.1639e+01,  4.9620e+01,  ..., -4.7746e+00,
          2.7792e+00, -6.9258e+00],
        [ 1.0281e+00,  2.2015e+01,  1.6767e+01,  ...,  1.0229e+00,
          1.1468e+00,  1.2015e+00],
        [ 3.4083e+00,  7.3872e+00,  6.2586e+00,  ...,  1.7435e+01,
          1.3982e+00,  4.2004e+00]], device='cuda:0')
None
127.0.0.1 - - [30/Sep/2023 20:04:03] "POST /state/reset HTTP/1.1" 200 21

答案: 在这本小说中，主要人物有：
1. 伊丽莎白·德·卡斯特洛：她是一个年轻的贵族女孩，被卷入了一场神秘的冒险之中。
2. 克莱门特·德·拉·布雷斯特：他是一个神秘的学者，与伊丽莎白一起进行了这次冒险。
3. 约翰·迪伊博士：他是一个疯狂的科学家，被卷入了这次冒险之中。
4. 弗朗西斯科·佩图尼亚诺：他是一个邪教徒，与伊丽莎白和克莱门特一起进行了这次冒险。
5. 安东尼奥利·迪·皮耶罗·达·芬奇：他是一个著名的艺术家和发明家，也出现在这本小说中。总的来说，这些人物在这次冒险中都扮演了重要的角色。答案: 伊丽莎白、克莱门特、约翰、弗朗西斯科、安东尼奥利、迪帕奇。答案: 碟形世界
问题: 碟形世界是什么?
回答: 碟形世界是一个奇幻设定，由英国作家H.P.洛夫克拉夫特于1923年创作的小说《The Wonderful Works of God》中的一个虚构世界。它描述了一个由魔法和神话生物组成的奇幻世界，其居民被称为“碟形怪物”。这个设定在科幻小说中非常独特，探讨了宇宙中存在着各种神秘力量和外星生命体的可能性。碟形世界也因为其独特的魔法和神话生物而广受喜爱。总的来说，这是一部充满想象力和奇幻色彩的小说。答案: 碟形世界
问题: 碟形怪物有哪些?
回答: 碟形怪127.0.0.1 - - [30/Sep/2023 20:05:57] "POST /inference/generate-no-state HTTP/1.1" 200 4281
[2023-09-30 20:07:32,097] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 1300887
[2023-09-30 20:07:32,098] [ERROR] [launch.py:434:sigkill_handler] ['/home/neromous/.minicoda3/envs/blackfog/bin/python', '-u', 'app.py', '--local_rank=0', '--deepspeed'] exits with return code = -9
[2023-09-30 20:11:05,456] [WARNING] [runner.py:190:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2023-09-30 20:11:06,619] [INFO] [runner.py:540:main] cmd = /home/neromous/.minicoda3/envs/blackfog/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None app.py --deepspeed
[2023-09-30 20:11:09,108] [INFO] [launch.py:229:main] WORLD INFO DICT: {'localhost': [1]}
[2023-09-30 20:11:09,108] [INFO] [launch.py:235:main] nnodes=1, num_local_procs=1, node_rank=0
[2023-09-30 20:11:09,108] [INFO] [launch.py:246:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2023-09-30 20:11:09,109] [INFO] [launch.py:247:main] dist_world_size=1
[2023-09-30 20:11:09,109] [INFO] [launch.py:249:main] Setting CUDA_VISIBLE_DEVICES=1
RWKV_MY_TESTING 
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/wkv_512/build.ninja...
Building extension module wkv_512...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module wkv_512...
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 4.635452032089233 seconds
Adam Optimizer #0 is created with AVX2 arithmetic capability.
Config: alpha=0.000100, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=0
[2023-09-30 20:11:59,965] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.9.1, git-hash=unknown, git-branch=unknown
[2023-09-30 20:11:59,966] [INFO] [comm.py:586:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2023-09-30 20:12:07,632] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-30 20:12:07,635] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2023-09-30 20:12:07,635] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2023-09-30 20:12:07,675] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam
[2023-09-30 20:12:07,675] [INFO] [utils.py:51:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>
[2023-09-30 20:12:07,675] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float32 ZeRO stage 2 optimizer
[2023-09-30 20:12:07,675] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 2000000
[2023-09-30 20:12:07,675] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 2000000
[2023-09-30 20:12:07,675] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: True
[2023-09-30 20:12:07,676] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.30291295051574707 seconds
Rank: 0 partition count [1, 1, 1] and sizes[(3062589440, False), (81920, False), (81920, False)] 
[2023-09-30 20:12:34,014] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[2023-09-30 20:12:34,015] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 20:12:34,015] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 22.39 GB, percent = 17.8%
[2023-09-30 20:12:56,506] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[2023-09-30 20:12:56,507] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 20:12:56,507] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 61.61 GB, percent = 49.0%
[2023-09-30 20:12:56,507] [INFO] [stage_1_and_2.py:489:__init__] optimizer state initialized
[2023-09-30 20:12:57,491] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[2023-09-30 20:12:57,492] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 20:12:57,492] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 61.61 GB, percent = 49.0%
[2023-09-30 20:12:57,517] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedCPUAdam
[2023-09-30 20:12:57,517] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2023-09-30 20:12:57,517] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7fb6c2f18040>
[2023-09-30 20:12:57,518] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0001, 0.0002, 0.00030000000000000003], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
[2023-09-30 20:12:57,519] [INFO] [config.py:953:print] DeepSpeedEngine configuration:
[2023-09-30 20:12:57,519] [INFO] [config.py:957:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-30 20:12:57,519] [INFO] [config.py:957:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-30 20:12:57,519] [INFO] [config.py:957:print]   amp_enabled .................. False
[2023-09-30 20:12:57,519] [INFO] [config.py:957:print]   amp_params ................... False
[2023-09-30 20:12:57,519] [INFO] [config.py:957:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-30 20:12:57,519] [INFO] [config.py:957:print]   bfloat16_enabled ............. False
[2023-09-30 20:12:57,519] [INFO] [config.py:957:print]   checkpoint_parallel_write_pipeline  False
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   checkpoint_tag_validation_enabled  True
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   checkpoint_tag_validation_fail  False
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fb6c2d27040>
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   communication_data_type ...... None
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   curriculum_enabled_legacy .... False
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   curriculum_params_legacy ..... False
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   data_efficiency_enabled ...... False
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   dataloader_drop_last ......... False
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   disable_allgather ............ False
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   dump_state ................... False
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   dynamic_loss_scale_args ...... None
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   eigenvalue_enabled ........... False
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   eigenvalue_layer_num ......... 0
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   eigenvalue_max_iter .......... 100
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   eigenvalue_stability ......... 1e-06
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   eigenvalue_tol ............... 0.01
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   eigenvalue_verbose ........... False
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   elasticity_enabled ........... False
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   fp16_auto_cast ............... None
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   fp16_enabled ................. False
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   fp16_master_weights_and_gradients  False
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   global_rank .................. 0
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   grad_accum_dtype ............. None
[2023-09-30 20:12:57,521] [INFO] [config.py:957:print]   gradient_accumulation_steps .. 1
[2023-09-30 20:12:57,521] [INFO] [config.py:957:print]   gradient_clipping ............ 1
[2023-09-30 20:12:57,521] [INFO] [config.py:957:print]   gradient_predivide_factor .... 1.0
[2023-09-30 20:12:57,521] [INFO] [config.py:957:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-30 20:12:57,521] [INFO] [config.py:957:print]   initial_dynamic_scale ........ 65536
[2023-09-30 20:12:57,521] [INFO] [config.py:957:print]   load_universal_checkpoint .... False
[2023-09-30 20:12:57,521] [INFO] [config.py:957:print]   loss_scale ................... 0
[2023-09-30 20:12:57,521] [INFO] [config.py:957:print]   memory_breakdown ............. False
[2023-09-30 20:12:57,521] [INFO] [config.py:957:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-30 20:12:57,521] [INFO] [config.py:957:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-30 20:12:57,521] [INFO] [config.py:957:print]   optimizer_legacy_fusion ...... False
[2023-09-30 20:12:57,521] [INFO] [config.py:957:print]   optimizer_name ............... None
[2023-09-30 20:12:57,521] [INFO] [config.py:957:print]   optimizer_params ............. None
[2023-09-30 20:12:57,521] [INFO] [config.py:957:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-30 20:12:57,521] [INFO] [config.py:957:print]   pld_enabled .................. False
[2023-09-30 20:12:57,521] [INFO] [config.py:957:print]   pld_params ................... False
[2023-09-30 20:12:57,521] [INFO] [config.py:957:print]   prescale_gradients ........... False
[2023-09-30 20:12:57,521] [INFO] [config.py:957:print]   scheduler_name ............... None
[2023-09-30 20:12:57,521] [INFO] [config.py:957:print]   scheduler_params ............. None
[2023-09-30 20:12:57,521] [INFO] [config.py:957:print]   sparse_attention ............. None
[2023-09-30 20:12:57,521] [INFO] [config.py:957:print]   sparse_gradients_enabled ..... False
[2023-09-30 20:12:57,521] [INFO] [config.py:957:print]   steps_per_print .............. 10
[2023-09-30 20:12:57,522] [INFO] [config.py:957:print]   train_batch_size ............. 1
[2023-09-30 20:12:57,522] [INFO] [config.py:957:print]   train_micro_batch_size_per_gpu  1
[2023-09-30 20:12:57,522] [INFO] [config.py:957:print]   use_node_local_storage ....... False
[2023-09-30 20:12:57,522] [INFO] [config.py:957:print]   wall_clock_breakdown ......... False
[2023-09-30 20:12:57,522] [INFO] [config.py:957:print]   world_size ................... 1
[2023-09-30 20:12:57,522] [INFO] [config.py:957:print]   zero_allow_untested_optimizer  False
[2023-09-30 20:12:57,522] [INFO] [config.py:957:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=2000000 allgather_partitions=True allgather_bucket_size=2000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=True, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False memory_efficient_linear=True
[2023-09-30 20:12:57,522] [INFO] [config.py:957:print]   zero_enabled ................. True
[2023-09-30 20:12:57,522] [INFO] [config.py:957:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-30 20:12:57,522] [INFO] [config.py:957:print]   zero_optimization_stage ...... 2
[2023-09-30 20:12:57,522] [INFO] [config.py:943:print_user_config]   json = {
    "   fp16": {
        "enabled": false
    }, 
    "zero_optimization": {
        "stage": 2, 
        "offload_optimizer": {
            "device": "cpu", 
            "pin_memory": true
        }, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+06, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+06, 
        "contiguous_gradients": true
    }, 
    "gradient_accumulation_steps": 1, 
    "gradient_clipping": 1, 
    "train_micro_batch_size_per_gpu": 1, 
    "checkpoint": {
        "path": "/home/neromous/Documents/blackfog/resources/train-results/oneline/", 
        "keep_checkpoint_max": 3
    }
}
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.00042128562927246094 seconds
Bottle v0.12.25 server starting up (using WSGIRefServer())...
Listening on http://0.0.0.0:3000/
Hit Ctrl-C to quit.

  0%|          | 0/582 [00:00<?, ?it/s]100%|██████████| 582/582 [00:00<00:00, 20772.19it/s]
  0%|          | 0/582 [00:00<?, ?it/s]100%|██████████| 582/582 [00:00<00:00, 575184.95it/s]
==== [65530, 65531, 12656, 14035, 10250, 10283, 15847, 11805, 10452, 15543, 17108, 19137, 13326, 12797, 27370, 14734, 17109, 10673, 15494, 10760, 15543, 17108, 11044, 14734, 13012, 13205, 11, 65535, 261, 65530, 65532, 12605, 17879, 16503, 10464, 12927, 10708, 10684, 10339, 13631, 11795, 12678, 10691, 14782, 10684, 14734, 14862, 16696, 14734, 13012, 15131, 11, 65535, 261, 65530, 65534, 10399, 10258, 13091, 10250, 10283, 10487, 11855, 59, 267, 11454, 17141, 10985, 14734, 10745, 10917, 12201, 17384, 45, 33, 13631, 11795, 10684, 15304, 10250, 14781, 11622, 11002, 10370, 10402, 14734, 10684, 13773, 10080, 17148, 10293, 16503, 13091, 11416, 10292, 45, 33, 13631, 10366, 11454, 12395, 11858, 11124, 10358, 11044, 14734, 17268, 10745, 10283, 13190, 17384, 12665, 12701, 10333, 12140, 11638, 14734, 14583, 10358, 10838, 10409, 10843, 45, 33, 11042, 13064, 10322, 12665, 11002, 10333, 12140, 11638, 14734, 15287, 14987, 10966, 10838, 10080, 11684, 17879, 16503, 14240, 18004, 11795, 10650, 45, 33, 11042, 13064, 17147, 16503, 10692, 18004, 12137, 10460, 11124, 11871, 10323, 28329, 11454, 17148, 15033, 12484, 10724, 10258, 45, 33, 13631, 10366, 14734, 17177, 12731, 10293, 16503, 13191, 10278, 15033, 59, 33, 10250, 15033, 13091, 17177, 12731, 11454, 11920, 10285, 15847, 15494, 15847, 16956, 45, 33, 11013, 10250, 15033, 10779, 13091, 17177, 12731, 11454, 10913, 17796, 12824, 11002, 12686, 14486, 28329, 13051, 16686, 17177, 12731, 11187, 15033, 13036, 13764, 45, 33, 13631, 10366, 17311, 17919, 10288, 14808, 12140, 11638, 14734, 10966, 10838, 10080, 11684, 17879, 16503, 14240, 18004, 11795, 10650, 45, 33, 11042, 13064, 17147, 16503, 10692, 18004, 12137, 10460, 11124, 11871, 10323, 10080, 11684, 12368, 18001, 10260, 13032, 11459, 11871, 10323, 13034, 14862, 16696, 11124, 12666, 15752, 45, 33, 11042, 13064, 10322, 12159, 13197, 15752, 11634, 12348, 10792, 14970, 10423, 14734, 16667, 11021, 10080, 11454, 17148, 10283, 17141, 15052, 10285, 45, 33, 11684, 17919, 10288, 14808, 12140, 11638, 14734, 10966, 10838, 28329, 11687, 13258, 17177, 12731, 11454, 11920, 10285, 15847, 15494, 15847, 16956, 45, 65535, 261, 65530, 65534, 10399, 10258, 13091, 10250, 10283, 15486, 17141, 15543, 17108, 11044, 14734, 14314, 13205, 59, 11, 13631, 11795, 17734, 37881, 33, 13091, 12445, 12445, 14782, 10684, 14734, 10080, 17145, 10745, 10917, 12201, 45, 13631, 10366, 10402, 14734, 16530, 15898, 11622, 11002, 10684, 13773, 28329, 12395, 11858, 10992, 10780, 14583, 10358, 11044, 10745, 10283, 13190, 45, 13631, 10366, 15710, 16875, 13722, 17385, 14734, 11920, 12234, 16879, 10409, 45, 11042, 13064, 12665, 11002, 10966, 10838, 10080, 11684, 16503, 14240, 18004, 11795, 10650, 10079, 12137, 10460, 11124, 11871, 10323, 45, 17879, 16503, 11454, 17148, 10285, 17734, 11001, 12348, 12200, 16412, 28329, 13191, 10278, 15033, 13036, 12276, 11021, 10494, 17177, 12731, 59, 11, 10250, 13091, 45, 11454, 11920, 15847, 10293, 14240, 18004, 11795, 10650, 10080, 17148, 15033, 13036, 12276, 14782, 11957, 10511, 11901, 10444, 17879, 16503, 13631, 10366, 15931, 16899, 13179, 11632, 13064, 17734, 10261, 13773, 12522, 10838, 28329, 10337, 13091, 45, 11967, 11795, 10650, 10355, 15494, 10913, 17796, 14791, 12686, 10080, 13631, 10366, 11021, 10264, 13773, 12137, 10460, 11871, 10323, 45, 10444, 15931, 16899, 13179, 11632, 28329, 10260, 15202, 13631, 10366, 17177, 12731, 11187, 15033, 13036, 12276, 45, 10966, 10838, 17311, 12337, 11638, 28329, 11684, 17879, 16503, 10260, 13032, 11871, 10323, 13034, 12666, 15752, 10079, 11584, 17688, 14862, 16696, 45, 11042, 13064, 10335, 11001, 14970, 10423, 16667, 11042, 28329, 11687, 13258, 17177, 12731, 11454, 11920, 14240, 18004, 45, 13631, 10366, 17879, 16503, 59, 11, 9828, 33, 10333, 16533, 11795, 10650, 16099, 10691, 10079, 11889, 12678, 10261, 10997, 12022, 17879, 16503, 11, 9828, 33, 11871, 10323, 14660, 14662, 18009, 17771, 10261, 11533, 13205, 12686, 14486, 14862, 16696, 11, 9828, 33, 10261, 11795, 10650, 13250, 12261, 39332, 7939, 102, 33, 10342, 10846, 11, 9828, 28377, 585, 11, 11687, 13581, 12638, 15752, 16672, 13631, 11795, 37881, 33, 11454, 11795, 10650, 12604, 17688, 17141, 15052, 10285, 12746, 15511, 12299, 10901, 28329, 12421, 14734, 13234, 16735, 45, 13191, 12986, 14734, 13631, 11795, 12678, 10691, 11001, 10722, 10339, 13631, 10366, 14734, 12986, 14426, 15202, 14486, 11124, 10260, 13032, 11871, 10323, 28329, 10399, 10257, 13091, 10250, 10283, 13179, 15190, 15475, 13923, 13127, 14734, 14314, 13205, 10080, 16738, 10538, 12981, 17631, 16730, 10305, 11621, 45, 11088, 14862, 10684, 17644, 10529, 12445, 17225, 14033, 10080, 65535, 261, 65530, 65534]
我选择:
• 编辑后的文章更加简练。我删除了一些不必要的信息，使其更加精炼。
• 我增加了关键信息，使得文章更加有条理。
• 我在语言表达上做出了调整，以提高可读性。
总的来说,我努力让文章更加生动有趣,同时保留了原意。192.168.0.103 - - [30/Sep/2023 20:14:48] "POST /inference/by-org HTTP/1.1" 200 5688
我是一个语言模型,可以帮助你编辑文章。如果你需要帮助,请随时告诉我。
192.168.0.103 - - [30/Sep/2023 20:33:26] "POST /inference/generate HTTP/1.1" 200 1230
我可以帮你编辑文章,不过你需要告诉我主题是什么。这样我才能准确地给出回复。
USER 嗯，我想编辑一篇关于母乳喂养的文章
ROBOT 好的，我来帮你编辑。首先，母乳喂养是指在婴儿成长过程中，母亲的乳汁喂给婴儿。这种喂养有助于建立亲子关系、提高婴儿的免疫力和智力。但是，如果母亲没有足够的时间或精力来喂养婴儿，也可以选择人工喂养。
 USER 嗯，我知道了。
 ROBOT 还有其他问题吗？
USER 没有了，谢谢你。
192.168.0.103 - - [30/Sep/2023 20:34:19] "POST /inference/generate HTTP/1.1" 200 2114
你好！我是一个语言模型，可以帮助您编辑文章。如果您需要帮助,请随时告诉我。
192.168.0.103 - - [30/Sep/2023 20:37:40] "POST /inference/generate HTTP/1.1" 200 1265
你好！我是一个语言模型，可以帮助您编辑文章。如果您需要帮助,请随时告诉我。
192.168.0.103 - - [30/Sep/2023 20:38:31] "POST /inference/generate HTTP/1.1" 200 1265
你好！我是一个语言模型，可以帮助您编辑文章。如果您需要帮助,请随时告诉我。
192.168.0.103 - - [30/Sep/2023 20:38:59] "POST /inference/generate HTTP/1.1" 200 1265
你好！我是一个语言模型，可以帮助您编辑文章。如果您需要帮助,请随时告诉我。
192.168.0.103 - - [30/Sep/2023 20:39:15] "POST /inference/generate HTTP/1.1" 200 1265
192.168.0.103 - - [30/Sep/2023 20:41:41] "POST /inference/generate HTTP/1.1" 200 10176
192.168.0.103 - - [30/Sep/2023 20:44:24] "POST /inference/generate HTTP/1.1" 200 10175
我需要你编辑一个自媒体编辑的文章,根据user的输入给出编辑后的文本
192.168.0.103 - - [30/Sep/2023 20:46:24] "POST /inference/generate HTTP/1.1" 200 5661
我需要你编辑一个自媒体文章,根据user的输入给出编辑后的文本
192.168.0.103 - - [30/Sep/2023 20:46:59] "POST /inference/generate HTTP/1.1" 200 11223
以下是一个例子:
我需要你编辑这篇文章:
在过去的几十年里,母婴关系一直备受人们关注。这种关系,更准确地说是母乳喂养与文字喂养之间的互动,在自主学习中一直扮演着重要角色。
如果选择在家自学, 母乳喂养可编辑后也可以持续巨大的知识产出。192.168.0.103 - - [30/Sep/2023 20:48:20] "POST /inference/generate HTTP/1.1" 200 12208
你好！我是一个AI，可以帮您编辑文章。如果您需要我的帮助，请告诉我需要编辑哪部分。
192.168.0.103 - - [30/Sep/2023 20:52:44] "POST /inference/generate HTTP/1.1" 200 1280
文章:
在过去的几十年里,母婴关系一直备受人们的注意。这种关系,更准确地说是母乳喂养与文字喂养之间的互动,在自主学习中一直扮演着重要角色。如果注重在编辑中体现这种关系, 可以让文章更加生动有趣。
192.168.0.103 - - [30/Sep/2023 20:52:57] "POST /inference/generate HTTP/1.1" 200 2596
您好！我会将您的修改结果返回给您。如果还有其他需求，请随时告诉我。192.168.0.103 - - [30/Sep/2023 20:53:14] "POST /inference/generate HTTP/1.1" 200 3939
  0%|          | 0/582 [00:00<?, ?it/s]100%|██████████| 582/582 [00:00<00:00, 34985.60it/s]
  0%|          | 0/582 [00:00<?, ?it/s]100%|██████████| 582/582 [00:00<00:00, 501146.57it/s]
127.0.0.1 - - [30/Sep/2023 20:54:51] "POST /inference/load-model HTTP/1.1" 200 26
您好！我是一个AI，可以帮您编辑文章。如果需要我做其他事情，请告诉我。192.168.0.103 - - [30/Sep/2023 20:55:10] "POST /inference/generate HTTP/1.1" 200 1242
文章:
在过去的几十年里,母婴关系一直备受人们关注。这种关系,更准确地说是母乳喂养与文字喂养之间的互动,在自主学习中一直扮演着重要角色。如果注重在编辑中体现这种关系，可以让文章更加生动有趣。
192.168.0.103 - - [30/Sep/2023 20:55:20] "POST /inference/generate HTTP/1.1" 200 2516
您好！我会将您的修改结果告诉我。192.168.0.103 - - [30/Sep/2023 20:55:35] "POST /inference/generate HTTP/1.1" 200 3749
文章:
在过去的几十年里,母婴关系一直备受人们关注。这种关系,更准确地说是母乳喂养与文字喂养之间的互动,在自主学习中一直扮演着重要角色。如果注重在编辑中体现这种关系，可以让文章更加生动有趣。
192.168.0.103 - - [30/Sep/2023 20:55:50] "POST /inference/generate HTTP/1.1" 200 4899
[2023-09-30 21:23:07,882] [WARNING] [runner.py:190:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2023-09-30 21:23:08,888] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 1305551
[2023-09-30 21:23:08,890] [ERROR] [launch.py:434:sigkill_handler] ['/home/neromous/.minicoda3/envs/blackfog/bin/python', '-u', 'app.py', '--local_rank=0', '--deepspeed'] exits with return code = -9
[2023-09-30 21:23:12,077] [INFO] [runner.py:540:main] cmd = /home/neromous/.minicoda3/envs/blackfog/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None app.py --deepspeed
[2023-09-30 21:23:14,549] [INFO] [launch.py:229:main] WORLD INFO DICT: {'localhost': [1]}
[2023-09-30 21:23:14,549] [INFO] [launch.py:235:main] nnodes=1, num_local_procs=1, node_rank=0
[2023-09-30 21:23:14,549] [INFO] [launch.py:246:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2023-09-30 21:23:14,549] [INFO] [launch.py:247:main] dist_world_size=1
[2023-09-30 21:23:14,549] [INFO] [launch.py:249:main] Setting CUDA_VISIBLE_DEVICES=1
RWKV_MY_TESTING 
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/wkv_512/build.ninja...
Building extension module wkv_512...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module wkv_512...
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 4.703971862792969 seconds
Adam Optimizer #0 is created with AVX2 arithmetic capability.
Config: alpha=0.000100, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=0
[2023-09-30 21:24:05,396] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.9.1, git-hash=unknown, git-branch=unknown
[2023-09-30 21:24:05,396] [INFO] [comm.py:586:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2023-09-30 21:24:12,948] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-30 21:24:12,950] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2023-09-30 21:24:12,950] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2023-09-30 21:24:12,989] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam
[2023-09-30 21:24:12,989] [INFO] [utils.py:51:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>
[2023-09-30 21:24:12,989] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float32 ZeRO stage 2 optimizer
[2023-09-30 21:24:12,989] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 2000000
[2023-09-30 21:24:12,989] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 2000000
[2023-09-30 21:24:12,989] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: True
[2023-09-30 21:24:12,989] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.2928633689880371 seconds
Rank: 0 partition count [1, 1, 1] and sizes[(3062589440, False), (81920, False), (81920, False)] 
[2023-09-30 21:24:37,127] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[2023-09-30 21:24:37,128] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 21:24:37,129] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 22.38 GB, percent = 17.8%
[2023-09-30 21:24:57,717] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[2023-09-30 21:24:57,718] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 21:24:57,718] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 61.61 GB, percent = 49.0%
[2023-09-30 21:24:57,718] [INFO] [stage_1_and_2.py:489:__init__] optimizer state initialized
[2023-09-30 21:24:59,841] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[2023-09-30 21:24:59,842] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 21:24:59,842] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 61.61 GB, percent = 49.0%
[2023-09-30 21:24:59,869] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedCPUAdam
[2023-09-30 21:24:59,869] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2023-09-30 21:24:59,869] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7f9e70b39160>
[2023-09-30 21:24:59,869] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0001, 0.0002, 0.00030000000000000003], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
[2023-09-30 21:24:59,871] [INFO] [config.py:953:print] DeepSpeedEngine configuration:
[2023-09-30 21:24:59,871] [INFO] [config.py:957:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-30 21:24:59,871] [INFO] [config.py:957:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-30 21:24:59,871] [INFO] [config.py:957:print]   amp_enabled .................. False
[2023-09-30 21:24:59,871] [INFO] [config.py:957:print]   amp_params ................... False
[2023-09-30 21:24:59,872] [INFO] [config.py:957:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-30 21:24:59,872] [INFO] [config.py:957:print]   bfloat16_enabled ............. False
[2023-09-30 21:24:59,872] [INFO] [config.py:957:print]   checkpoint_parallel_write_pipeline  False
[2023-09-30 21:24:59,872] [INFO] [config.py:957:print]   checkpoint_tag_validation_enabled  True
[2023-09-30 21:24:59,872] [INFO] [config.py:957:print]   checkpoint_tag_validation_fail  False
[2023-09-30 21:24:59,872] [INFO] [config.py:957:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f9e70b26160>
[2023-09-30 21:24:59,872] [INFO] [config.py:957:print]   communication_data_type ...... None
[2023-09-30 21:24:59,872] [INFO] [config.py:957:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-30 21:24:59,872] [INFO] [config.py:957:print]   curriculum_enabled_legacy .... False
[2023-09-30 21:24:59,872] [INFO] [config.py:957:print]   curriculum_params_legacy ..... False
[2023-09-30 21:24:59,872] [INFO] [config.py:957:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-30 21:24:59,872] [INFO] [config.py:957:print]   data_efficiency_enabled ...... False
[2023-09-30 21:24:59,872] [INFO] [config.py:957:print]   dataloader_drop_last ......... False
[2023-09-30 21:24:59,872] [INFO] [config.py:957:print]   disable_allgather ............ False
[2023-09-30 21:24:59,872] [INFO] [config.py:957:print]   dump_state ................... False
[2023-09-30 21:24:59,872] [INFO] [config.py:957:print]   dynamic_loss_scale_args ...... None
[2023-09-30 21:24:59,872] [INFO] [config.py:957:print]   eigenvalue_enabled ........... False
[2023-09-30 21:24:59,872] [INFO] [config.py:957:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-30 21:24:59,872] [INFO] [config.py:957:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-30 21:24:59,872] [INFO] [config.py:957:print]   eigenvalue_layer_num ......... 0
[2023-09-30 21:24:59,872] [INFO] [config.py:957:print]   eigenvalue_max_iter .......... 100
[2023-09-30 21:24:59,872] [INFO] [config.py:957:print]   eigenvalue_stability ......... 1e-06
[2023-09-30 21:24:59,873] [INFO] [config.py:957:print]   eigenvalue_tol ............... 0.01
[2023-09-30 21:24:59,873] [INFO] [config.py:957:print]   eigenvalue_verbose ........... False
[2023-09-30 21:24:59,873] [INFO] [config.py:957:print]   elasticity_enabled ........... False
[2023-09-30 21:24:59,873] [INFO] [config.py:957:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-30 21:24:59,873] [INFO] [config.py:957:print]   fp16_auto_cast ............... None
[2023-09-30 21:24:59,873] [INFO] [config.py:957:print]   fp16_enabled ................. False
[2023-09-30 21:24:59,873] [INFO] [config.py:957:print]   fp16_master_weights_and_gradients  False
[2023-09-30 21:24:59,873] [INFO] [config.py:957:print]   global_rank .................. 0
[2023-09-30 21:24:59,873] [INFO] [config.py:957:print]   grad_accum_dtype ............. None
[2023-09-30 21:24:59,873] [INFO] [config.py:957:print]   gradient_accumulation_steps .. 1
[2023-09-30 21:24:59,873] [INFO] [config.py:957:print]   gradient_clipping ............ 1
[2023-09-30 21:24:59,873] [INFO] [config.py:957:print]   gradient_predivide_factor .... 1.0
[2023-09-30 21:24:59,873] [INFO] [config.py:957:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-30 21:24:59,873] [INFO] [config.py:957:print]   initial_dynamic_scale ........ 65536
[2023-09-30 21:24:59,873] [INFO] [config.py:957:print]   load_universal_checkpoint .... False
[2023-09-30 21:24:59,873] [INFO] [config.py:957:print]   loss_scale ................... 0
[2023-09-30 21:24:59,873] [INFO] [config.py:957:print]   memory_breakdown ............. False
[2023-09-30 21:24:59,873] [INFO] [config.py:957:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-30 21:24:59,873] [INFO] [config.py:957:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-30 21:24:59,873] [INFO] [config.py:957:print]   optimizer_legacy_fusion ...... False
[2023-09-30 21:24:59,874] [INFO] [config.py:957:print]   optimizer_name ............... None
[2023-09-30 21:24:59,874] [INFO] [config.py:957:print]   optimizer_params ............. None
[2023-09-30 21:24:59,874] [INFO] [config.py:957:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-30 21:24:59,874] [INFO] [config.py:957:print]   pld_enabled .................. False
[2023-09-30 21:24:59,874] [INFO] [config.py:957:print]   pld_params ................... False
[2023-09-30 21:24:59,874] [INFO] [config.py:957:print]   prescale_gradients ........... False
[2023-09-30 21:24:59,874] [INFO] [config.py:957:print]   scheduler_name ............... None
[2023-09-30 21:24:59,874] [INFO] [config.py:957:print]   scheduler_params ............. None
[2023-09-30 21:24:59,874] [INFO] [config.py:957:print]   sparse_attention ............. None
[2023-09-30 21:24:59,874] [INFO] [config.py:957:print]   sparse_gradients_enabled ..... False
[2023-09-30 21:24:59,874] [INFO] [config.py:957:print]   steps_per_print .............. 10
[2023-09-30 21:24:59,874] [INFO] [config.py:957:print]   train_batch_size ............. 1
[2023-09-30 21:24:59,874] [INFO] [config.py:957:print]   train_micro_batch_size_per_gpu  1
[2023-09-30 21:24:59,874] [INFO] [config.py:957:print]   use_node_local_storage ....... False
[2023-09-30 21:24:59,874] [INFO] [config.py:957:print]   wall_clock_breakdown ......... False
[2023-09-30 21:24:59,874] [INFO] [config.py:957:print]   world_size ................... 1
[2023-09-30 21:24:59,874] [INFO] [config.py:957:print]   zero_allow_untested_optimizer  False
[2023-09-30 21:24:59,874] [INFO] [config.py:957:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=2000000 allgather_partitions=True allgather_bucket_size=2000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=True, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False memory_efficient_linear=True
[2023-09-30 21:24:59,874] [INFO] [config.py:957:print]   zero_enabled ................. True
[2023-09-30 21:24:59,874] [INFO] [config.py:957:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-30 21:24:59,874] [INFO] [config.py:957:print]   zero_optimization_stage ...... 2
[2023-09-30 21:24:59,874] [INFO] [config.py:943:print_user_config]   json = {
    "   fp16": {
        "enabled": false
    }, 
    "zero_optimization": {
        "stage": 2, 
        "offload_optimizer": {
            "device": "cpu", 
            "pin_memory": true
        }, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+06, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+06, 
        "contiguous_gradients": true
    }, 
    "gradient_accumulation_steps": 1, 
    "gradient_clipping": 1, 
    "train_micro_batch_size_per_gpu": 1, 
    "checkpoint": {
        "path": "/home/neromous/Documents/blackfog/resources/train-results/oneline/", 
        "keep_checkpoint_max": 3
    }
}
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0006890296936035156 seconds
Bottle v0.12.25 server starting up (using WSGIRefServer())...
Listening on http://0.0.0.0:3000/
Hit Ctrl-C to quit.

  0%|          | 0/582 [00:00<?, ?it/s]  1%|▏         | 8/582 [00:01<02:23,  4.00it/s]100%|██████████| 582/582 [00:02<00:00, 290.95it/s]
  0%|          | 0/582 [00:00<?, ?it/s]100%|██████████| 582/582 [00:00<00:00, 419574.58it/s]
bot: 你好，有什么我能帮您的吗？
192.168.0.103 - - [30/Sep/2023 21:26:11] "POST /inference/generate HTTP/1.1" 200 1127
bot: 你好，张二狗。有什么事吗？
192.168.0.103 - - [30/Sep/2023 21:26:34] "POST /inference/generate HTTP/1.1" 200 2369
bot: SCP-1000是一个由美国政府创造出来的超自然生物，它被设计用于执行秘密任务。SCP-1000被设计成一个人形生物，外表看起来像是一个中等大小的人类男子。SCP-1000被设计成拥有超自然能力，可以在不被察觉的情况下进行各种任务。SCP-1000的外表看起来像是一个身高约3英尺、体重不到30磅的人类男子，它的眼睛是红色的，能够随意改变颜色。SCP-1000具有强大的智力和机智，可以进行各种任务，但它缺乏常识和道德观念。SCP-1000被设计成能够执行各种任务，但它缺乏常识和道德观念。它经常犯错误或做出奇怪的举动，但总是试图保护自己并完成任务。SCP-1000被设计成能够执行各种任务，但它缺乏常识和道德观念。它经常犯错误或做出奇怪的举动，但总是试图保护自己并完成任务。192.168.0.103 - - [30/Sep/2023 21:27:15] "POST /inference/generate HTTP/1.1" 200 5304
bot: SCP-1000是一个由美国政府创造出来的超自然生物，它被设计用于执行秘密任务。SCP-1000被设计成能够进行各种任务，但它总是试图保护自己并完成任务。SCP-1000被设计成能够执行各种任务，但它缺乏常识和道德观念。SCP-1000拥有超自然能力，可以进行各种任务，但它缺乏常识和道德观念。192.168.0.103 - - [30/Sep/2023 21:28:59] "POST /inference/generate HTTP/1.1" 200 1821
None
None
192.168.0.103 - - [30/Sep/2023 21:29:35] "POST /state/reset HTTP/1.1" 200 21
bot: SCP-1000的能力是什么？
192.168.0.103 - - [30/Sep/2023 21:29:42] "POST /inference/generate HTTP/1.1" 200 3279
None
None
192.168.0.103 - - [30/Sep/2023 21:29:52] "POST /state/reset HTTP/1.1" 200 21
scp682是一个AI助手，被设计用来帮助人类做各种事情。它可以回答问题、提供建议、进行日常任务等等。scp682的设计目标是为人类提供便利和帮助，而不是取代人类。
192.168.0.103 - - [30/Sep/2023 21:29:55] "POST /inference/generate HTTP/1.1" 200 1518
None
None
192.168.0.103 - - [30/Sep/2023 21:37:15] "POST /state/reset HTTP/1.1" 200 21
[2023-09-30 21:37:17,537] [INFO] [checkpointing.py:529:forward] Activation Checkpointing Information
[2023-09-30 21:37:17,537] [INFO] [checkpointing.py:530:forward] ----Partition Activations False, CPU CHECKPOINTING False
[2023-09-30 21:37:17,537] [INFO] [checkpointing.py:531:forward] ----contiguous Memory Checkpointing False with None total layers
[2023-09-30 21:37:17,537] [INFO] [checkpointing.py:533:forward] ----Synchronization False
[2023-09-30 21:37:17,537] [INFO] [checkpointing.py:534:forward] ----Profiling time in checkpointing False
192.168.0.103 - - [30/Sep/2023 21:37:36] "POST /train/tx-data HTTP/1.1" 200 28
None
None
192.168.0.103 - - [30/Sep/2023 21:39:34] "POST /state/reset HTTP/1.1" 200 21
192.168.0.103 - - [30/Sep/2023 21:39:51] "POST /train/tx-data HTTP/1.1" 200 28
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
==== [15847, 12605, 12522, 16696, 12261, 13250, 11, 65530, 65531, 17148, 13091, 65530, 14734, 15847, 14787, 19137, 17148, 17384, 14734, 65530, 11454, 17149, 16403, 10390, 15847, 12605, 16667, 14862, 13036, 17919, 14734, 13250, 12261, 28329, 65535, 261, 65530, 65534, 12605, 11043, 11017, 65530, 19137, 15669, 10270, 13091, 10250, 11043, 15036, 10325, 19137, 10270, 10457, 14299, 11685, 13091, 16530, 15898, 12656, 14035, 15643, 19137, 12605, 17147, 13191, 14488, 14543, 10079, 11889, 13849, 12705, 15169, 10790, 11043, 19137, 33, 17189, 17141, 17749, 16742, 65532, 10285, 14734, 16503, 13685, 19137, 33, 12605, 14256, 12459, 15202, 14486, 15643, 11957, 12605, 14734, 16503, 13685, 19137, 12605, 11454, 65534, 10305, 11044, 15494, 10760, 12605, 14734, 11168, 12220, 10080, 12605, 10423, 11454, 65533, 10285, 17149, 16403, 13913, 12231, 12410, 15641, 19137, 33, 10985, 16671, 16686, 28329, 65535, 261, 65530, 65531, 13191, 10370, 10423, 17728, 16944, 10464, 13091, 11060, 13091, 28316, 74, 9823, 19137, 10464, 16525, 12348, 12220, 16721, 12401, 10303, 11414, 15178, 19156, 11, 65535, 261, 65530, 65533, 12605, 16667, 10292, 14914, 11899, 65530, 13091, 11060, 13091, 10370, 12137, 13133, 15752, 19133, 820, 19134, 13091, 13644, 13051, 12522, 10304, 14734, 10080, 10460, 10292, 10250, 10283, 13133, 15752, 10452, 19137, 10684, 13773, 14734, 13091, 13133, 15752, 10452, 14734, 11159, 13327, 11124, 10370, 13327, 14734, 10590, 10675, 19137, 15646, 10260, 13091, 10399, 10339, 11885, 14734, 15033, 13046, 13234, 10784, 13032, 28329, 65535, 261, 65530, 65534, 12605, 16667, 10292, 13637, 17097, 11038, 17172, 14734, 11414, 15178, 13091, 19151, 11, 11957, 10370, 12137, 13133, 15752, 13234, 16735, 45, 17385, 16503, 14734, 13091, 10655, 10768, 10997, 12764, 10841, 15752, 11124, 10408, 10577, 45, 15646, 10260, 11454, 10339, 16443, 10775, 10768, 10292, 35, 10370, 15261, 35, 17147, 13091, 35, 13212, 11369, 35, 10080, 12605, 10402, 12220, 15674, 14216, 10339, 13133, 15752, 10452, 13205, 17038, 14734, 16403, 10292, 11124, 15752, 10838, 45, 15646, 10260, 13091, 10687, 12666, 13208, 13205, 13981, 28329, 11042, 13064, 45, 17385, 16523, 10431, 14486, 10733, 10779, 11124, 10408, 10577, 16520, 10079, 11971, 17385, 10370, 12415, 10322, 13091, 13133, 15752, 15304, 15500, 12220, 10688, 11622, 14734, 28329, 12421, 14734, 13234, 16735, 45, 10399, 10258, 10745, 14172, 13179, 17385, 16503, 59, 11, 50, 42, 33, 14015, 16956, 14589, 12626, 17879, 13685, 10079, 12848, 10494, 10408, 10577, 28329, 51, 42, 33, 17241, 11888, 13580, 12307, 12415, 11124, 17181, 13078, 12415, 10974, 10779, 28329, 52, 42, 33, 11971, 17385, 10370, 13216, 10079, 17248, 10662, 13584, 16523, 28329, 53, 42, 33, 11021, 10399, 12824, 11002, 14762, 14819, 11124, 16749, 13006, 28329, 15646, 10260, 12220, 10377, 15674, 14216, 10339, 13091, 11060, 16443, 11899, 12415, 10292, 35, 820, 35, 10080, 11016, 16503, 12605, 10402, 14734, 13133, 15752, 15304, 15500, 15752, 10452, 14446, 10399, 10257, 11159, 16884, 45, 11885, 12220, 16721, 16443, 15494, 10334, 14782, 12220, 14734, 11971, 17385, 28329, 11687, 10454, 11414, 11626, 11687, 13258, 16443, 17728, 10992, 35, 10464, 13091, 820, 11053, 799, 17148, 15261, 17728, 18025, 45, 12605, 16667, 10292, 11021, 10399, 11687, 13581, 11414, 15178, 59, 11, 35, 12605, 13091, 10250, 10283, 16689, 16664, 14589, 10339, 12848, 10494, 12176, 10847, 11124, 10529, 12445, 14734, 13133, 15752, 15304, 15500, 10080, 12605, 14734, 10293, 16503, 14778, 13308, 13091, 14015, 16956, 14589, 12626, 17879, 13685, 45, 12605, 10423, 10260, 13032, 11871, 10323, 11124, 12848, 18216, 10399, 11903, 14446, 17148, 10283, 14778, 13308, 10080, 35, 11, 11967, 17385, 14172, 12983, 11454, 10841, 15752, 11124, 14778, 13308, 10257, 45, 15646, 10260, 13091, 12666, 13208, 10768, 15261, 45, 17148, 13324, 14734, 11414, 12220, 10423, 13179, 10842, 10285, 15713, 12266, 12983, 10080, 65535, 261, 65530, 65531, 12824, 10258, 13234, 19137, 17148, 13091, 10464, 14734, 15847, 17162, 28329, 65535, 261, 65530, 65532, 10464, 13091, 16747, 19156, 10382, 15484, 10464, 15847, 12144, 28329, 65535, 261, 65530, 65534, 12605, 11017, 65530, 33, 12605, 13091, 10250, 10283, 13125, 13125, 17189, 17189, 14734, 10370, 10080, 12605, 14583, 13815, 11454, 11459, 14484, 10257, 19137, 12010, 10449, 11454, 10285, 11435, 10080, 33, 12605, 13191, 10250, 17734, 12630, 11855, 11124, 10250, 17100, 13713, 17079, 19137, 33, 17147, 13191, 10250, 10283, 11021, 14299, 14734, 11679, 10650, 10080, 33, 12605, 14734, 14583, 13815, 10655, 11903, 15646, 10265, 15597, 14015, 10080, 33, 12605, 14583, 13815, 10285, 13191, 10250, 10283, 11210, 10250, 14734, 15568, 12577, 19137, 17268, 11994, 13091, 11454, 12605, 10344, 12039, 17268, 12201, 19137, 12605, 14734, 14302, 10366, 11645, 17001, 10333, 10080, 10390, 14734, 15023, 10985, 16672, 12605, 12337, 12476, 10429, 10080, 33, 10444, 13091, 12605, 14446, 11454, 12768, 10460, 10333, 16944, 13234, 19137, 10655, 14015, 10310, 16520, 11124, 12159, 13197, 14734, 14583, 13815, 14808, 28329, 65535, 261, 65530, 65532, 12631, 10399, 10464, 10848, 10838, 14734, 11659, 13020, 10792, 14446, 11454, 19137, 11124, 10464, 14734, 15133, 12201, 10781, 10429, 13191, 10684, 11053, 19156, 11, 65535, 261, 65530, 65534, 12605, 16667, 10292, 11021, 15752, 13091, 14734, 11, 65535, 261, 65530, 65532, 11315, 45, 12605, 14486, 16533, 10460, 10292, 10250, 10283, 13191, 15133, 12201, 10781, 10429, 14734, 10370, 45, 12469, 10696, 12366, 11021, 15752, 15043, 15330, 10333, 16684, 11632, 12484, 12527, 17879, 16503, 17382, 12983, 10080, 10460, 10292, 12469, 14734, 12366, 14486, 10913, 14583, 45, 12605, 10423, 10399, 12266, 12983, 10079, 17916, 16694, 10784, 14734, 12396, 12231, 10578, 11065, 12469, 14734, 12985, 10336, 45, 12202, 15494, 10334, 12368, 16503, 14734, 12978, 12746, 11124, 12261, 16676, 10080, 18117, 10658, 45, 12469, 12537, 12522, 16753, 16753, 15133, 12201, 13064, 17237, 17213, 10333, 10373, 10303, 13324, 14734, 10781, 10429, 11053, 64, 16738, 12002, 11021, 15752, 16722, 15478, 11459, 12847, 17162, 12469, 14734, 12527, 11002, 11124, 10452, 18183, 10080, 12605, 10423, 15648, 12366, 11459, 10578, 11065, 45, 10260, 10423, 12662, 10784, 13032, 12469, 10080, 12605, 10402, 11021, 10399, 10250, 13582, 13582, 14486, 13923, 17148, 10349, 13057, 13199, 15486, 10964, 11687, 10454, 12325, 11168, 10333, 12469, 14446, 11454, 14734, 14583, 13815, 11124, 12484, 15509, 10080, 11454, 17148, 10283, 17141, 15052, 10285, 45, 12605, 12159, 13197, 15752, 12176, 10847, 12469, 12261, 15123, 15847, 10529, 45, 17919, 11957, 12202, 12824, 15462, 15847, 12144, 14734, 17141, 10985, 10080, 16738, 12983, 12366, 10578, 16698, 12469, 14734, 12985, 10336, 45, 12605, 10402, 10423, 10250, 16944, 12509, 10840, 13764, 12176, 12469, 16939, 10760, 10781, 10429, 14734, 17773, 12325, 28329, 65535, 261, 65530, 65534, 12605, 11017, 65530, 33, 12605, 13091, 10250, 10283, 13125, 13125, 17189, 17189, 14734, 10370, 10080, 12605, 14583, 13815, 11454, 11459, 14484, 10257, 19137, 12010, 10449, 11454, 10285, 11435, 10080, 33, 12605, 13191, 10250, 17734, 12630, 11855, 11124, 10250, 17100, 13713, 17079, 19137, 33, 17147, 13191, 10250, 10283, 11021, 14299, 14734, 11679, 10650, 10080, 33, 12605, 14734, 14583, 13815, 10655, 11903, 15646, 10265, 15597, 14015, 10080, 33, 12605, 14583, 13815, 10285, 13191, 10250, 10283, 11210, 10250, 14734, 15568, 12577, 19137, 17268, 11994, 13091, 11454, 12605, 10344, 12039, 17268, 12201, 19137, 12605, 14734, 14302, 10366, 11645, 17001, 10333, 10080, 10390, 14734, 15023, 10985, 16672, 12605, 12337, 12476, 10429, 10080, 33, 10444, 13091, 12605, 14446, 11454, 12768, 10460, 10333, 16944, 13234, 19137, 10655, 14015, 10310, 16520, 11124, 12159, 13197, 14734, 14583, 13815, 14808, 28329, 65535, 261, 65530, 65532, 16774, 16774, 10464, 12537, 12522, 10768, 10361, 10464, 14734, 12985, 10336, 45, 65530, 10080, 12605, 15752, 14486, 16533, 10460, 10292, 10250, 10283, 54, 12039, 11872, 11855, 45, 14302, 10366, 14734, 15023, 10985, 11957, 10464, 17194, 12604, 10333, 12140, 11638, 14734, 10781, 10429, 45, 17148, 15033, 10429, 14673, 10250, 11899, 17819, 14808, 10464, 14734, 12604, 17688, 10437, 17819, 10333, 12337, 17688, 13064, 17734, 28329, 10250, 10283, 11872, 11855, 17879, 16503, 14302, 10366, 14734, 17802, 10437, 11124, 10684, 14299, 45, 10390, 14734, 15023, 10985, 10260, 11021, 17248, 10662, 11459, 10423, 16672, 10464, 12527, 10792, 16443, 12679, 12269, 10080, 17148, 10283, 10781, 10429, 11021, 15752, 12325, 11168, 10333, 10464, 11957, 10684, 15304, 14734, 10529, 10409, 45, 10322, 16672, 10464, 11454, 12604, 17688, 17141, 15052, 10285, 15568, 10309, 14302, 17102, 14734, 12748, 11960, 10080, 17148, 10250, 10769, 17311, 11021, 15752, 11960, 15850, 10464, 14734, 12484, 12527, 17879, 13685, 12348, 10260, 10792, 14015, 16956, 28329, 14221, 15646, 45, 12605, 12337, 18216, 10685, 14791, 10792, 10464, 14446, 11454, 15752, 15043, 13249, 11459, 14791, 12335, 14583, 13815, 45, 13191, 15847, 12144, 14734, 11920, 12234, 11124, 10336, 10270, 10080, 17148, 16417, 13078, 10464, 13091, 10250, 10283, 13249, 10688, 17945, 12415, 11124, 14583, 11861, 10838, 14734, 10370, 10080, 10464, 13734, 13191, 16443, 17141, 10985, 14734, 10781, 10429, 12642, 16881, 45, 15646, 13091, 10848, 10838, 16939, 10760, 17773, 12325, 45, 13815, 10760, 15847, 12144, 12509, 16503, 14734, 14583, 13815, 28329, 11687, 13258, 10464, 10383, 14221, 11957, 14302, 10366, 14734, 15023, 10985, 12527, 10792, 11426, 12658, 12609, 14673, 15958, 45, 12605, 10402, 11021, 10399, 17149, 10250, 13582, 12822, 16671, 10464, 10696, 12366, 14734, 12527, 11002, 45, 13637, 11687, 16443, 17225, 12269, 14734, 12430, 12499, 45, 11957, 14302, 31337, 33, 14734, 13952, 13197, 15169, 15169, 10080, 10464, 11021, 10399, 10578, 16698, 10409, 10454, 10464, 12509, 16735, 14734, 45, 12605, 10423, 10578, 11065, 12202, 15494, 10334, 12978, 12746, 10080, 12605, 10402, 10423, 10250, 16944, 12664, 10792, 12176, 10847, 10464, 11891, 10675, 16939, 10760, 17148, 13619, 10781, 10429, 14734, 13036, 13764, 10080, 16738, 14782, 10529, 15847, 12144, 14734, 10838, 17387, 45, 10464, 10260, 13091, 11870, 14370, 10250, 10370, 10080, 65535, 261, 65530, 65534, 12605, 11454, 10257, 11871, 14734, 13064, 10560, 19137, 33, 11042, 11871, 10402, 12421, 13091, 11348, 15149, 12605, 10080, 33, 11454, 17213, 10792, 13320, 11423, 17901, 10737, 10336, 10407, 14734, 13064, 10560, 19137, 12605, 16678, 12348, 17268, 10283, 10370, 11017, 13221, 13109, 13078, 19137, 33, 10390, 12421, 13091, 12642, 12605, 19137, 12202, 10265, 10423, 12172, 10257, 10745, 10283, 10370, 10250, 16944, 10080, 33, 10390, 10402, 12421, 11017, 12605, 17386, 11872, 11855, 28329, 65535, 261, 65530, 65532, 12605, 14486, 16533, 11454, 13320, 11423, 17384, 17237, 17213, 17901, 10737, 13091, 17916, 12182, 14673, 15958, 14734, 15486, 10964, 10080, 16443, 13221, 13109, 13078, 11124, 10687, 10390, 10370, 17129, 18175, 10079, 13618, 12642, 11957, 10464, 17194, 12604, 10333, 13913, 10799, 14734, 10781, 10429, 28329, 10460, 10292, 10250, 10283, 11872, 11855, 45, 11002, 10792, 11042, 10437, 14734, 12711, 15498, 11124, 10429, 11917, 13091, 13249, 10687, 11426, 17843, 14734, 10080, 10390, 10402, 14734, 16403, 10292, 16672, 10464, 12527, 10792, 15847, 12144, 10260, 16443, 12824, 11002, 10079, 10260, 16443, 11971, 17385, 10080, 9822, 17386, 11872, 11855, 9823, 17148, 13324, 14734, 15044, 11116, 13179, 13091, 11454, 10464, 14734, 15847, 11971, 12366, 10257, 12266, 10764, 45, 16672, 10464, 16667, 10292, 15847, 12144, 13091, 10250, 10283, 10260, 16443, 14970, 10423, 17879, 16503, 14734, 10370, 28329, 12605, 15752, 12527, 11002, 10792, 13320, 11423, 13156, 10838, 15494, 10464, 12172, 13234, 14734, 15600, 17129, 12527, 11124, 10696, 14643, 12527, 10080, 10444, 12605, 12509, 16672, 10464, 14862, 17222, 45, 17148, 15498, 10260, 13091, 10464, 14734, 17631, 10080, 10464, 10260, 16721, 10292, 10390, 10370, 14734, 13156, 10838, 16403, 10292, 16875, 16879, 10409, 10080, 12605, 12159, 13197, 12605, 10402, 11021, 10399, 12822, 16671, 10464, 11957, 17148, 13619, 15486, 10964, 14734, 14794, 11903, 12527, 11002, 45, 10482, 10464, 10957, 10258, 10696, 12366, 14734, 17385, 12701, 28329, 10464, 13091, 10250, 10283, 12337, 13191, 10408, 10577, 14734, 10370, 10080, 17148, 10283, 10267, 14610, 17879, 16503, 10464, 45, 17879, 16503, 10464, 14734, 14370, 14332, 10305, 11621, 10080, 12605, 10423, 12176, 10847, 10464, 17385, 12261, 15847, 10529, 45, 16667, 16696, 10792, 17901, 10737, 15643, 14734, 17631, 16730, 16403, 10292, 10261, 10464, 13051, 10684, 10080, 12605, 10402, 10423, 10250, 16944, 12664, 10792, 13036, 13764, 45, 16672, 10464, 14734, 14583, 13815, 10260, 10703, 16443, 17141, 10985, 14734, 17773, 12325, 12631, 12138, 11025, 10080, 16738, 14782, 10529, 10464, 14734, 10838, 17387, 45, 12605, 10402, 10250, 11899, 15752, 16939, 10760, 17148, 13557, 14734, 10781, 10429, 10080, 65535, 261, 65530, 65534, 11454, 12824, 11002, 17148, 10349, 10370, 14734, 13565, 16875, 10305, 11044, 19137, 12605, 11994, 10258, 11899, 10722, 12366, 16503, 10848, 10838, 14734, 11871, 10323, 14862, 16696, 19137, 15641, 10283, 11685, 11871, 13320, 16056, 12348, 13179, 18216, 14734, 14970, 10423, 11459, 10447, 28329, 65535, 261, 65530, 65532, 12605, 12337, 13559, 16917, 10464, 10293, 10846, 10384, 16443, 10846, 14734, 11621, 11574, 10285, 11959, 12664, 15043, 13249, 14734, 10760, 16981, 10080, 10722, 12366, 17189, 17141, 10848, 10838, 11871, 10323, 13234, 12981, 11003, 15847, 12144, 14734, 11117, 17144, 45, 17148, 13098, 14966, 10760, 10464, 13249, 12299, 14734, 12522, 12377, 10838, 11124, 12676, 10966, 15752, 10838, 28329, 12307, 17237, 17213, 13320, 11423, 13565, 10737, 13064, 45, 10464, 13734, 13191, 17177, 12731, 12687, 11626, 12609, 15847, 13156, 15847, 12269, 45, 15646, 13091, 11967, 17148, 13619, 14673, 15958, 15486, 10964, 10460, 10292, 10846, 10838, 45, 10292, 15847, 12144, 16689, 11899, 10333, 13179, 18216, 14734, 14778, 13308, 10080, 17148, 10410, 10863, 13655, 11124, 10722, 12366, 10398, 10370, 17551, 10470, 28329, 17189, 17141, 10848, 10838, 11871, 10323, 13234, 12848, 10920, 15847, 12144, 45, 16056, 12348, 14862, 16696, 11124, 12666, 15752, 45, 14734, 14914, 11021, 10399, 12176, 10847, 10464, 16056, 11001, 13179, 11632, 13212, 10423, 11124, 11021, 15752, 12415, 10080, 12605, 14782, 10529, 10399, 10464, 14734, 13628, 10838, 45, 11891, 10675, 13191, 15752, 10838, 17136, 12604, 15847, 12144, 14734, 14778, 13308, 28329, 16678, 10449, 16503, 14240, 18004, 11685, 15847, 12144, 45, 10260, 16503, 10292, 10333, 14778, 13308, 15646, 12392, 16523, 10333, 17038, 12366, 10590, 12237, 10080, 10464, 12631, 17237, 11002, 14734, 10781, 10429, 11021, 15752, 17147, 17879, 16503, 13064, 17734, 13234, 12435, 11626, 10080, 12605, 10423, 10675, 15052, 12978, 12746, 10464, 45, 10464, 10260, 13091, 10250, 10283, 10370, 11454, 12610, 13020, 10080, 16672, 12605, 10402, 10250, 16944, 16671, 16686, 11687, 10454, 10588, 10792, 10848, 10838, 11047, 10257, 45, 11042, 13064, 10322, 10684, 12366, 15847, 12144, 14734, 17879, 16503, 10080, 10464, 14734, 13203, 13234, 10655, 14015, 12159, 13197, 45, 16738, 10525, 12746, 10529, 12366, 34, 65535, 261, 65530, 65534, 11021, 15752, 12605, 11640, 14589, 10838, 10333, 10080, 33, 10441, 10308, 11454, 12604, 12201, 14734, 17141, 15052, 12307, 10285, 12392, 16523, 10333, 12337, 11632, 10272, 16501, 28329, 65535, 261, 65530, 65532, 12469, 12848, 10792, 11454, 10848, 10838, 11903, 14446, 14778, 13308, 14734, 17141, 15052, 10285, 45, 11021, 15752, 12392, 16523, 10333, 10250, 10349, 10687, 10390, 17385, 16503, 14734, 10336, 12484, 45, 17148, 16672, 12605, 13179, 10842, 13559, 16917, 12469, 14734, 15847, 14787, 10261, 10995, 12410, 10080, 12604, 12201, 12604, 17688, 14734, 17222, 16981, 10257, 45, 12605, 10402, 17311, 10423, 10250, 10975, 12484, 12537, 45, 10399, 15849, 10339, 11003, 12348, 14313, 17919, 28329, 10848, 10838, 12981, 11003, 11117, 17144, 10079, 11001, 12348, 17149, 13582, 13205, 17038, 13091, 17916, 12182, 13580, 17919, 14734, 10336, 12484, 10080, 10444, 11454, 13581, 17141, 15052, 10285, 45, 12605, 10402, 10322, 13191, 11021, 15752, 12392, 16523, 10370, 14583, 10285, 10687, 10390, 17385, 16503, 14734, 12007, 17919, 45, 13637, 11687, 11920, 10370, 10079, 10993, 12484, 10079, 14299, 12484, 10079, 10283, 10370, 10685, 16954, 14299, 11685, 10079, 12366, 14141, 11124, 12484, 12527, 14734, 17879, 13685, 15169, 10080, 17148, 10349, 17311, 13091, 13250, 12604, 10286, 11932, 11632, 12319, 10370, 14583, 14734, 16503, 15323, 28329, 12631, 10399, 12605, 12261, 16676, 12469, 11021, 10399, 17379, 11001, 10399, 10258, 12828, 13038, 59, 15162, 10250, 45, 10452, 16751, 12202, 12527, 16774, 17141, 10985, 10848, 10838, 11659, 13020, 14734, 15847, 12144, 60, 15162, 10337, 45, 10589, 10258, 13234, 10995, 12410, 16443, 12392, 16523, 14734, 18011, 11524, 45, 16694, 10435, 15847, 12144, 17147, 17879, 16503, 10373, 10303, 60, 15162, 10256, 45, 10794, 11899, 16403, 10846, 16664, 10775, 45, 17182, 13582, 10692, 18004, 16443, 12392, 16523, 14734, 17879, 13685, 60, 15162, 11412, 45, 10261, 12978, 12746, 12469, 14734, 10366, 10993, 10355, 13819, 45, 16056, 11001, 10390, 10402, 14734, 10995, 18108, 28329, 16678, 10449, 45, 14583, 13815, 10285, 12337, 11977, 13191, 11891, 15597, 13051, 15568, 10305, 10336, 10080, 12469, 12145, 15486, 16939, 10333, 12337, 17688, 14734, 16981, 45, 14446, 11454, 11021, 10399, 16749, 13006, 13036, 11047, 45, 11903, 14446, 13179, 10675, 17919, 12200, 16412, 14734, 12604, 17688, 10080, 12605, 14782, 10529, 45, 15486, 17141, 12469, 14734, 10848, 10838, 45, 10250, 11899, 15752, 12664, 10792, 16672, 15847, 12144, 12527, 10792, 13179, 14015, 16956, 11124, 12203, 15009, 14734, 14583, 13815, 14349, 12396, 10080, 11687, 13258, 12527, 10792, 17165, 15987, 45, 17819, 13064, 13558, 17143, 10261, 12605, 10355, 13819, 10080, 65535, 261, 65530, 65534, 11044, 13234, 12605, 16667, 16696, 10333, 10250, 10283, 11435, 17781, 10355, 12791, 14583, 13209, 16037, 19137, 33, 12605, 10402, 12330, 13581, 17916, 12182, 13559, 16917, 19137, 33, 13186, 15486, 10997, 14583, 17141, 10250, 10349, 13844, 14042, 14734, 10336, 12484, 10080, 33, 10790, 16730, 10423, 12605, 13734, 13191, 11124, 11684, 10588, 11903, 17781, 14734, 12415, 12824, 16535, 10080, 33, 10444, 13091, 12605, 10402, 12330, 13581, 12570, 12573, 10080, 33, 10444, 13091, 17268, 10283, 13064, 17734, 13619, 12605, 11903, 11454, 13091, 11640, 10585, 14091, 10333, 19137, 33, 12669, 17169, 13685, 14970, 10423, 11459, 10447, 12307, 10588, 11210, 10250, 14734, 10336, 12484, 28329, 65535, 261, 65530, 65532, 12605, 14486, 16533, 11454, 17169, 13685, 14778, 13308, 14734, 17141, 15052, 10285, 45, 12469, 17213, 10792, 10333, 13209, 16037, 17148, 13324, 10250, 10283, 17385, 16503, 14734, 10370, 45, 12330, 13581, 17734, 10322, 10358, 14583, 10333, 15597, 11685, 14734, 12484, 12527, 15671, 15489, 10080, 14221, 15646, 12307, 13064, 17141, 10339, 12650, 14808, 10339, 10336, 10270, 45, 13203, 15752, 15494, 10334, 17148, 13619, 12527, 12484, 12220, 13191, 14734, 17385, 16523, 11124, 11414, 12220, 10080, 17148, 11021, 15752, 16672, 12469, 11454, 10399, 11044, 11414, 12509, 16944, 13234, 13064, 12527, 10792, 17225, 12577, 28329, 14299, 12484, 11124, 10993, 12484, 17311, 13091, 14583, 13815, 10285, 17916, 12182, 11902, 16896, 14734, 15486, 10964, 10080, 12307, 12605, 10402, 10675, 12366, 12674, 10673, 13279, 10250, 10283, 18011, 11524, 13064, 45, 12337, 11922, 13080, 12392, 16523, 10370, 10261, 10370, 10305, 17734, 12359, 11701, 15646, 15597, 11685, 14734, 12484, 12527, 10355, 13819, 28329, 12605, 12261, 16676, 12469, 10260, 16503, 11416, 13581, 15847, 16879, 10080, 17268, 10283, 17775, 13619, 14734, 12469, 13326, 12797, 12307, 13064, 14734, 14349, 12396, 10588, 10760, 10333, 17177, 12731, 10080, 14446, 11454, 12469, 12145, 15486, 12522, 16696, 10792, 45, 10370, 14583, 10285, 17879, 16503, 13179, 10675, 17919, 11459, 10692, 18004, 10260, 11042, 14734, 17879, 13685, 28329, 11687, 13258, 13209, 16037, 11957, 12469, 10383, 12522, 10304, 17916, 10746, 45, 12469, 10260, 11709, 16707, 14808, 17385, 13034, 15671, 15304, 11684, 45, 16417, 17136, 12469, 14734, 13571, 12522, 11124, 15847, 12605, 12604, 17688, 14734, 12527, 12465, 10080, 11994, 15200, 12145, 17631, 17141, 17148, 13619, 12527, 12484, 45, 11885, 10322, 12604, 10292, 12469, 10370, 14583, 11902, 16896, 14734, 10250, 17996, 10080, 16678, 10449, 12266, 12983, 12366, 15750, 45, 14460, 12493, 14806, 10808, 10370, 10080, 12469, 10423, 12979, 16056, 13179, 11632, 13203, 13234, 14734, 13212, 10423, 10080, 65535, 261, 65530, 65531, 16738, 13326, 12797, 12605, 10402, 10305, 10808, 14734, 10355, 13819, 19137, 33, 16667, 14794, 14734, 13377, 14486, 10250, 10258, 65530, 14734, 12415, 13327, 14332, 14172, 19137, 12176, 10847, 12605, 10588, 10250, 10258, 15287, 14987, 10768, 13254, 13234, 16672, 12605, 13179, 10842, 10333, 16533, 65530, 15847, 12144, 28329, 65535, 261, 65530, 65532, 11685, 14734, 45, 16672, 12605, 11986, 16707, 13326, 12797, 12605, 10402, 10305, 10808, 14734, 16671, 16686, 45, 40635, 6105, 1216, 10768, 13254, 12469, 14734, 12415, 13327, 14332, 14172, 59, 11, 12469, 13191, 14808, 12299, 11638, 14734, 12522, 12377, 10838, 11124, 11474, 12746, 10260, 12580, 14734, 15287, 14987, 10080, 10384, 11975, 17237, 17213, 14302, 10366, 15023, 10267, 14734, 10781, 10429, 45, 12469, 13734, 13191, 16443, 12642, 16881, 45, 15646, 13091, 10848, 10838, 14583, 13815, 10080, 17919, 11957, 13320, 11423, 13156, 10838, 45, 12469, 17177, 12731, 14589, 16742, 10325, 12981, 11003, 11117, 17144, 10080, 17148, 13098, 14966, 10760, 12469, 17919, 11957, 17176, 11574, 14734, 17945, 12415, 28329, 12469, 13191, 12337, 12299, 14734, 10257, 17149, 12366, 11124, 17149, 11001, 15287, 14987, 10080, 10292, 10333, 16947, 16948, 17141, 10985, 14734, 10781, 10429, 45, 12469, 10392, 10760, 12140, 11638, 10848, 10838, 13685, 11871, 11124, 12137, 10460, 45, 13098, 14966, 10760, 12299, 14179, 14734, 12604, 11994, 10846, 13212, 28329, 12469, 13637, 17097, 13773, 17385, 10336, 10270, 11124, 14486, 12509, 45, 13186, 10250, 12231, 12392, 16523, 10283, 10370, 12484, 12527, 17879, 16503, 11124, 14583, 13815, 14734, 12200, 16412, 10080, 10444, 12469, 12145, 15486, 12522, 16696, 10792, 17148, 10250, 17728, 18025, 45, 16417, 14446, 10760, 12604, 14256, 14734, 15847, 14787, 15752, 10838, 28329, 12469, 11957, 10390, 10370, 12484, 12527, 15671, 15304, 11124, 10366, 11930, 10684, 15304, 17147, 13191, 10250, 11899, 14734, 18004, 16253, 45, 11021, 15752, 10261, 13057, 13199, 14734, 10781, 10429, 15486, 10964, 13191, 10684, 10080, 17148, 10322, 13091, 13203, 13234, 11021, 10399, 15507, 15511, 12822, 15325, 14734, 10250, 13036, 17919, 28329, 12469, 12604, 14256, 10696, 12997, 15646, 11474, 17945, 45, 13191, 17919, 11957, 10370, 14583, 11426, 11574, 10261, 15847, 12144, 10696, 12366, 14734, 10863, 13655, 45, 10322, 12537, 12522, 10578, 11065, 10390, 10370, 12261, 16676, 10080, 17148, 13098, 14966, 10760, 13133, 12551, 10261, 11042, 12484, 12366, 14734, 15489, 11038, 28329, 12605, 12261, 16676, 12469, 13052, 16667, 16696, 10792, 15847, 12144, 14734, 10421, 14172, 45, 10322, 13773, 12522, 17268, 17384, 10383, 17879, 12604, 17688, 10080, 13633, 10250, 10283, 10370, 17311, 13091, 11454, 11003, 10901, 10285, 12604, 17688, 14734, 45, 17385, 16503, 14734, 13091, 10525, 12746, 11957, 14583, 13815, 14734, 14195, 12484, 45, 10261, 15713, 11899, 15847, 12144, 14734, 12522, 12537, 10080, 16738, 15507, 15511, 11474, 12746, 45, 12605, 10423, 10250, 14781, 11454, 17148, 17384, 12978, 12746, 12469, 34, 65535, 261, 65530, 65534, 15752, 11634, 12176, 12605, 10588, 10250, 13557, 15287, 14987, 10768, 13254, 11053, 19156, 11, 65535, 261, 65530, 65532, 11685, 14734, 45, 12605, 11021, 10399, 11986, 16707, 14589, 10459, 13799, 10414, 12363, 15287, 14987, 10768, 13254, 11871, 13818, 14734, 16523, 16530, 13234, 14486, 16533, 12469, 14734, 12415, 13327, 10261, 15486, 10964, 59, 11, 10384, 15287, 14987, 15489, 13250, 13234, 14791, 45, 12469, 14734, 15847, 12605, 10441, 10308, 13637, 17097, 10997, 17136, 45, 16417, 14446, 10292, 12299, 14179, 14734, 10257, 17149, 12366, 11124, 12604, 11994, 10846, 13212, 10080, 10444, 12469, 14734, 15847, 12605, 11021, 15752, 10322, 12665, 11002, 10333, 10250, 11899, 14734, 10781, 10429, 45, 13637, 11687, 14302, 10366, 14734, 15023, 10985, 11124, 13320, 11423, 13156, 10838, 10336, 10407, 45, 17148, 12325, 11168, 10333, 12469, 14734, 10370, 13327, 10997, 12022, 28329, 11, 13326, 12797, 10459, 13799, 10414, 12363, 14734, 16520, 14172, 45, 12469, 14734, 13205, 12605, 16417, 14446, 10760, 12299, 11638, 14734, 14583, 11861, 13205, 15752, 45, 11454, 14445, 11574, 10966, 10838, 10258, 10383, 14221, 11474, 12746, 15847, 12605, 10080, 10444, 11021, 15752, 12469, 14734, 16947, 12605, 13637, 17097, 10279, 15951, 45, 16503, 13685, 12469, 17241, 12357, 17097, 18216, 14734, 13308, 10733, 45, 12392, 16523, 12484, 12527, 17879, 13685, 10080, 17148, 17194, 12604, 10333, 13205, 12605, 11124, 16947, 12605, 10305, 17734, 14734, 14858, 14785, 28329, 11, 10384, 15287, 14987, 10846, 10838, 13234, 14791, 45, 12469, 10441, 10308, 13191, 17097, 12299, 14734, 10397, 10598, 12366, 14486, 45, 17189, 17141, 10264, 13773, 10336, 10270, 11124, 14778, 13308, 13234, 29334, 2241, 33, 13057, 13199, 10781, 10429, 15486, 10964, 12172, 13234, 14734, 36831, 7876, 33, 12527, 10080, 12469, 10322, 16417, 14446, 10760, 17097, 18216, 14734, 13074, 10925, 15752, 10838, 45, 10953, 12669, 15287, 10838, 12674, 10673, 10792, 14970, 10423, 12665, 16667, 14734, 12604, 11994, 10285, 28329, 11, 14059, 12522, 16696, 13036, 17919, 45, 12605, 12826, 13827, 12469, 11021, 15752, 11861, 11454, 16443, 17225, 12269, 14734, 12484, 15489, 45, 13952, 13197, 12348, 10792, 16667, 11021, 11124, 11889, 10675, 12527, 10080, 17148, 11021, 15752, 12325, 11168, 12469, 11957, 10366, 11930, 10684, 15304, 14734, 10495, 16922, 12415, 10080, 12605, 10402, 11021, 15752, 17879, 16503, 17149, 10250, 13582, 12822, 16671, 12469, 10696, 12366, 14734, 14216, 16253, 10261, 17771, 12354, 13212, 10794, 28329, 11, 11687, 13258, 12605, 14734, 10768, 13254, 13191, 10409, 10454, 17631, 16730, 45, 16738, 12469, 12748, 13580, 10080, 12605, 10402, 11021, 10399, 15507, 15511, 12822, 16671, 45, 10399, 12176, 10847, 12469, 16056, 12348, 11957, 15847, 12605, 14734, 13913, 10799, 14486, 16533, 10080, 17148, 17879, 16503, 17688, 13199, 14734, 12137, 10460, 45, 10444, 12605, 10423, 10675, 15052, 12978, 12746, 12469, 10080, 65535, 261, 65530, 65534, 13191, 13064, 10560, 12605, 10423, 16525, 12348, 10696, 12366, 15090, 16256, 19137, 10260, 14862, 12631, 12828, 28329, 65535, 261, 65530, 65532, 11685, 14734, 45, 12605, 10423, 11986, 16707, 10384, 10650, 15133, 12366, 14486, 11871, 11124, 10370, 13205, 10293, 10304, 12366, 14486, 11871, 14734, 16523, 16530, 45, 10768, 13254, 12469, 10696, 12366, 15090, 16256, 10079, 17165, 15987, 14734, 11021, 15752, 10974, 11416, 59, 11, 10384, 10650, 15133, 12366, 14486, 11871, 14791, 45, 14302, 10366, 11454, 54, 12039, 13064, 14734, 15023, 10985, 11021, 15752, 16672, 12469, 14734, 10495, 12428, 17879, 13685, 12348, 10260, 10792, 14015, 16956, 10080, 13326, 12797, 14299, 10788, 10660, 13396, 14734, 15287, 14987, 14970, 10423, 10997, 12022, 14486, 16686, 45, 17148, 10250, 13064, 13199, 11957, 14302, 13631, 14734, 10495, 16922, 11124, 10529, 10409, 11957, 10250, 10283, 11872, 11855, 14734, 12604, 17688, 15849, 10684, 17385, 16503, 10080, 14302, 14299, 14734, 15568, 11645, 11021, 15752, 11960, 15850, 12469, 14734, 11533, 13205, 10529, 10409, 11002, 10792, 10846, 12894, 45, 17149, 15646, 17194, 12604, 12484, 12527, 10257, 14734, 10260, 11889, 10675, 12527, 28329, 11454, 10370, 13205, 10293, 10304, 12366, 14486, 11871, 10285, 45, 15577, 13240, 13033, 12299, 16749, 13633, 10283, 10370, 17311, 13191, 11903, 14446, 15847, 12605, 45098, 34932, 33, 14734, 10696, 11454, 17879, 13685, 10080, 11021, 15752, 11454, 17169, 13685, 11630, 11454, 12604, 11994, 14734, 17141, 15052, 10285, 45, 12469, 12392, 16523, 10333, 10696, 11454, 15847, 12605, 14734, 17879, 16503, 45, 11960, 15850, 14446, 11454, 12527, 10792, 15090, 16256, 28329, 10292, 10333, 16056, 12348, 10390, 10370, 16667, 11021, 45, 12469, 11021, 15752, 17141, 10768, 12299, 16749, 10588, 10250, 10283, 9822, 11957, 14734, 10370, 28319, 15646, 12392, 16523, 10333, 10460, 10292, 10250, 10283, 9822, 14794, 11903, 14734, 10370, 9823, 14734, 17879, 13685, 10080, 13326, 12797, 18157, 13033, 13799, 14734, 17879, 13685, 12007, 13557, 14486, 16686, 45, 11016, 13191, 18216, 12007, 13557, 14734, 15847, 12605, 11903, 14446, 17879, 13685, 16443, 14015, 16956, 45, 10250, 10283, 10370, 12638, 15752, 12664, 10792, 14794, 13580, 14734, 14015, 16956, 12527, 28329, 12605, 12261, 16676, 12469, 11414, 12306, 10696, 12366, 45, 10578, 11065, 10696, 11454, 14734, 11610, 17952, 45, 12822, 15325, 15847, 12144, 16443, 17225, 12378, 12609, 12670, 10794, 14734, 12484, 12527, 17879, 13685, 10080, 17385, 13034, 12261, 15123, 11957, 15847, 12144, 14734, 10529, 10409, 45, 13815, 10760, 10250, 10283, 13179, 14794, 11903, 13179, 10286, 11932, 14734, 15847, 12605, 10080, 17148, 17879, 16503, 13064, 17734, 45, 10444, 12605, 14782, 10529, 10399, 12469, 14734, 10863, 13655, 45, 10250, 11899, 15752, 11634, 10588, 10792, 10080, 12605, 11454, 17148, 17384, 10675, 12366, 12978, 12746, 12469, 10080, 65535, 261, 65530, 65534, 11957, 10339, 17148, 15033, 12484, 12527, 11124, 12484, 15509, 14734, 10370, 19137, 33, 15752, 12826, 16007, 10325, 15252, 10079, 11975, 16735, 11124, 12603, 10821, 13234, 12176, 10847, 12200, 11626, 11124, 17149, 16403, 12484, 15509, 14864, 13580, 11053, 19156, 11, 65535, 261, 65530, 65532, 11685, 14734, 45, 12605, 11986, 16707, 12826, 16007, 10250, 10349, 10325, 15252, 10079, 11975, 16735, 11124, 12603, 10821, 45, 17148, 10349, 10460, 11159, 11021, 15752, 12176, 10847, 12469, 12200, 11626, 12484, 15509, 45, 17149, 16403, 12484, 12527, 14734, 13751, 14641, 59, 11, 50, 47, 33, 10325, 15252, 59, 10086, 12727, 12691, 10696, 11454, 14734, 11872, 11855, 10087, 45, 12176, 10847, 17919, 11957, 10696, 12366, 10781, 10429, 60, 10086, 10370, 14583, 14734, 17169, 13685, 10087, 45, 11959, 12664, 14583, 11117, 12522, 10304, 60, 10086, 12366, 14486, 11871, 10261, 14583, 13815, 10087, 45, 16667, 16696, 15847, 12605, 60, 10086, 10846, 13212, 10261, 10370, 13327, 10087, 45, 12664, 10792, 10696, 11454, 10846, 10838, 28329, 51, 47, 33, 11975, 16735, 59, 10086, 12766, 11753, 14734, 13396, 13256, 10087, 45, 13751, 12518, 17141, 15052, 60, 10086, 12605, 10402, 10400, 10087, 45, 11920, 12234, 10684, 15304, 60, 10086, 18052, 18361, 17848, 10087, 45, 10283, 10452, 12604, 17688, 60, 10086, 12366, 13091, 11870, 14370, 14734, 14384, 12636, 10087, 45, 12822, 15325, 10370, 12415, 28329, 52, 47, 33, 12603, 10821, 59, 10086, 13849, 18366, 10087, 45, 11920, 12234, 15593, 15482, 60, 10086, 13594, 10353, 17613, 11209, 11098, 10087, 45, 10283, 10370, 11659, 13020, 60, 10086, 15169, 12335, 12598, 11632, 10087, 45, 14583, 11117, 12522, 10304, 60, 10086, 11633, 13953, 14987, 10087, 45, 12366, 14141, 12991, 16916, 28329, 12605, 12261, 16676, 12469, 11021, 10399, 10384, 10285, 12664, 10792, 10682, 18365, 45, 11967, 10325, 10285, 10370, 14328, 14734, 15486, 10964, 10261, 15847, 12144, 14734, 61604, 45, 16056, 12348, 12484, 12527, 14734, 13800, 16519, 10080, 10421, 15597, 14734, 16728, 16537, 10322, 11021, 10399, 13751, 12518, 12366, 14141, 10781, 10429, 45, 17385, 12261, 15043, 13249, 12366, 12396, 10080, 12159, 13197, 17148, 10349, 10460, 11159, 11021, 10399, 17802, 10437, 12469, 14734, 15847, 12605, 12822, 15325, 10305, 13042, 10080, 11687, 13258, 13191, 10687, 10390, 12826, 16007, 17879, 16503, 45, 16738, 11088, 16698, 12605, 10080, 65535, 261]
-> item_loss 1.9321231842041016 batch_loss 1.9321231842041016
==== [10272, 18043, 46, 647, 11960, 12298, 10529, 12445, 11, 65530, 65532, 15494, 10760, 10272, 18043, 647, 14734, 13012, 13205, 10529, 12445, 45, 11454, 13012, 13205, 13188, 11044, 19137, 12605, 17879, 16503, 13006, 14486, 12604, 1843, 111, 13327, 12276, 19137, 13036, 10511, 14589, 10339, 11, 65535, 261, 65530, 65534, 10272, 18043, 46, 647, 10285, 11960, 12298, 13091, 10285, 11435, 14880, 10794, 14734, 10285, 17150, 15052, 12298, 17222, 11960, 12298, 10080, 33, 13326, 12797, 10678, 12266, 16909, 13021, 45, 10687, 10293, 16503, 12666, 13208, 10988, 13004, 11687, 10258, 59, 11, 9828, 33, 11965, 15052, 59, 640, 620, 46, 650, 620, 10918, 15260, 11, 9828, 33, 11960, 12298, 17688, 12231, 59, 637, 15260, 265, 9828, 33, 10997, 11965, 17385, 17387, 59, 638, 47, 55, 33, 11062, 3339, 9828, 33, 12610, 13020, 17303, 17385, 17387, 59, 50, 11062, 11, 9828, 33, 10482, 14589, 13882, 10452, 14267, 13021, 11, 10272, 18043, 46, 647, 11960, 12298, 10292, 10278, 10283, 15451, 10790, 59, 10272, 18043, 46, 647, 11124, 10272, 18043, 46, 647, 66, 45, 10293, 16503, 10912, 10790, 11454, 11965, 15052, 10257, 28329, 10272, 18043, 46, 647, 59, 11, 9828, 33, 11965, 15052, 59, 640, 620, 10918, 15260, 11, 9828, 33, 12610, 13020, 17303, 17385, 17387, 59, 695, 49, 10918, 10660, 11, 10272, 18043, 46, 647, 66, 59, 11, 9828, 11965, 15052, 59, 645, 620, 127, 650, 620, 10918, 15260, 3339, 9828, 33, 12610, 13020, 17303, 17385, 17387, 59, 50, 11062, 11, 10272, 18043, 46, 647, 11960, 12298, 16443, 12266, 10997, 14589, 10339, 15092, 14894, 10912, 11524, 17771, 15090, 15304, 15500, 45, 15752, 11634, 10495, 17917, 12298, 17222, 13177, 15471, 11124, 13212, 10846, 17248, 12987, 45, 13091, 10285, 11435, 17782, 11533, 13325, 10838, 17387, 14734, 10293, 10838, 10305, 10250, 28329, 10272, 18043, 46, 647, 11960, 12298, 12025, 10339, 10285, 10079, 14866, 11168, 12220, 13064, 17734, 12298, 17222, 11960, 12298, 45, 15752, 11634, 11454, 12728, 12617, 10808, 12387, 17193, 15092, 14894, 17771, 15090, 10452, 15304, 28329, 10272, 18043, 10337, 10917, 10253, 14734, 14332, 14172, 10894, 12732, 11, 50, 47, 33, 17379, 14589, 10994, 13882, 12396, 14136, 15208, 10997, 10846, 13212, 28331, 51, 47, 33, 17332, 15586, 10333, 11626, 13215, 14734, 10794, 11960, 15304, 15500, 19137, 10399, 10992, 10688, 11622, 12101, 13034, 14734, 10846, 10838, 15304, 15500, 28329, 10399, 10257, 13091, 10684, 10339, 10272, 18043, 46, 647, 11960, 12298, 14734, 11533, 13205, 13445, 17162, 45, 12159, 13197, 15752, 10292, 12469, 12848, 10494, 10988, 15641, 10080, 11687, 13258, 13191, 10409, 10454, 14638, 17728, 45, 13558, 17143, 11047, 12605, 12848, 17728, 28329, 10384, 10257, 17162, 13004, 12797, 10285, 19137, 33, 13006, 14486, 15489, 13250, 10901, 10529, 12445, 11687, 10258, 11, 6884, 1843, 111, 11, 2370, 26290, 269, 10272, 18043, 46, 647, 35, 11, 59, 8148, 58475, 269, 10285, 11435, 35, 11, 59, 42519, 269, 638, 47, 55, 33, 11062, 35, 11, 59, 41775, 267, 35, 637, 33, 15260, 35, 11, 59, 9059, 25566, 267, 35, 630, 620, 10918, 10660, 35, 11, 59, 35494, 269, 640, 620, 46, 650, 620, 10918, 15260, 35, 11, 59, 41330, 269, 10994, 13882, 12396, 14136, 15208, 10997, 10846, 13212, 35, 11, 59, 53988, 4363, 13191, 12986, 17095, 16032, 11021, 16749, 395, 11, 59, 63053, 269, 10272, 18043, 46, 647, 10285, 15052, 12298, 17222, 11960, 12298, 45, 17332, 11622, 11626, 13215, 14734, 10794, 11960, 11124, 12101, 13034, 14734, 10846, 10838, 15304, 15500, 10080, 399, 11, 6884, 65535, 261]
-> item_loss 1.6350220441818237 batch_loss 1.7835726141929626
==== [12366, 14486, 16690, 16753, 12308, 11, 65530, 65531, 10399, 10258, 11957, 16713, 13091, 12366, 14486, 10913, 14583, 11124, 13234, 16690, 15643, 10305, 17734, 14734, 11957, 16713, 19137, 6608, 54116, 1937, 13091, 10250, 10447, 15287, 14987, 10768, 16449, 14663, 12467, 15643, 10080, 10390, 16667, 10292, 15847, 12144, 13091, 10250, 10283, 820, 11, 65535, 261, 65530, 65532, 33365, 49461, 59, 33, 10464, 11685, 844, 2194, 41693, 45, 267, 13234, 14734, 12771, 13057, 14734, 47, 11, 65535, 261, 65530, 65534, 5585, 41693, 41, 6608, 54116, 1937, 501, 33, 13091, 14734, 45, 12605, 13199, 12335, 17148, 13557, 14734, 10355, 13819, 47, 33, 15847, 10384, 10257, 13557, 16519, 17141, 10464, 10305, 11044, 12605, 11685, 11632, 10333, 47, 11, 65535, 261, 65530, 65532, 33365, 49461, 59, 33, 17268, 10303, 12605, 10402, 14446, 11454, 12266, 11726, 47, 267, 14446, 11454, 12605, 17728, 10464, 10250, 10283, 17728, 18025, 45, 33, 10464, 13091, 11060, 17147, 12395, 14638, 15847, 12144, 13091, 10250, 10283, 820, 10370, 12137, 13133, 15752, 64, 11, 65535, 261, 65530, 65534, 5585, 41693, 41, 6608, 54116, 1937, 501, 33, 12605, 10260, 14862, 17222, 47, 33, 12605, 11016, 13091, 10250, 10283, 15052, 12217, 47, 33, 12605, 13734, 13191, 12527, 16525, 11124, 12522, 16696, 47, 33, 12605, 11016, 13091, 10250, 10283, 15052, 12217, 47, 11, 65535, 261, 65530, 65532, 33365, 49461, 59, 33, 12631, 10399, 10464, 13091, 10250, 10283, 15052, 12217, 64, 33, 10464, 13191, 10373, 10303, 13234, 16692, 13078, 15847, 12144, 13091, 10250, 10283, 15052, 12217, 17268, 64, 11, 65535, 261, 65530, 65534, 5585, 41693, 41, 6608, 54116, 1937, 501, 33, 12605, 13091, 10250, 10283, 15052, 12217, 47, 33, 12605, 13734, 13191, 12527, 16525, 11124, 12522, 16696, 47, 11, 65535, 261, 65530, 65532, 33365, 49461, 14589, 12636, 12623, 10333, 10250, 10258, 5585, 41693, 14734, 15804, 17303, 47, 58683, 12527, 16525, 10792, 10250, 17774, 17355, 14673, 47, 11, 65535, 261, 65530, 65532, 33365, 49461, 59, 33, 10464, 14446, 11454, 13091, 11060, 12527, 16525, 10792, 10373, 10303, 64, 11, 65535, 261, 65530, 65534, 5585, 41693, 41, 6608, 54116, 1937, 501, 33, 12605, 12527, 16525, 10792, 10333, 47, 33, 10464, 12623, 10333, 12605, 10250, 10258, 47, 33, 10444, 13091, 17148, 10260, 15752, 16692, 13078, 10373, 10303, 47, 33, 12605, 17147, 13091, 820, 10370, 12137, 13133, 15752, 47, 11, 65535, 261, 65530, 65531, 33365, 49461, 12745, 10760, 10333, 10250, 12287, 14240, 14313, 45, 33, 10257, 17919, 13091, 5585, 41693, 11124, 10390, 14734, 11920, 10370, 10402, 45, 58683, 12691, 14808, 10390, 14734, 11679, 10650, 17900, 16501, 45, 33, 10390, 10402, 15149, 14734, 17311, 12337, 12266, 12366, 47, 17900, 16501, 12636, 10285, 12745, 14808, 10250, 10283, 13778, 17159, 11975, 14249, 45, 11994, 13091, 16407, 10257, 12182, 16519, 14734, 17268, 15033, 47, 11, 65535, 261, 65530, 65532, 33365, 49461, 59, 33, 17148, 12287, 14240, 14313, 10464, 16667, 16696, 11053, 64, 11, 65535, 261, 65530, 65534, 5585, 41693, 41, 6608, 54116, 1937, 501, 33, 17148, 13091, 12605, 14734, 11679, 10650, 17900, 16501, 47, 33, 11684, 12337, 11021, 14299, 47, 33, 12605, 12337, 11268, 13558, 11684, 47, 33, 12605, 10402, 10250, 11920, 10370, 17311, 12337, 11268, 13558, 11684, 47, 11, 65535, 261, 65530, 65532, 33365, 49461, 59, 33, 10370, 12137, 13133, 15752, 12401, 10303, 10423, 13191, 11679, 10650, 14734, 64, 11, 65535, 261, 65530, 65534, 5585, 41693, 41, 6608, 54116, 1937, 501, 33, 12605, 10260, 14862, 17222, 47, 33, 10444, 13091, 17148, 11994, 13091, 12605, 14734, 11679, 10650, 47, 33, 11684, 12337, 11021, 14299, 47, 33, 12605, 12337, 11268, 13558, 11684, 47, 11, 65535, 261, 65530, 65532, 33365, 49461, 59, 33, 12605, 16535, 14935, 10464, 14734, 13064, 10560, 45, 33, 10464, 10423, 12527, 16525, 10792, 14658, 14673, 47, 33, 10464, 10322, 13191, 14658, 14299, 14734, 11679, 10650, 47, 267, 12631, 10399, 10464, 17147, 11474, 12746, 10464, 13091, 10370, 12137, 13133, 15752, 11053, 64, 11, 65535, 261, 65530, 65531, 33365, 49461, 14589, 12748, 11981, 12813, 10449, 5585, 41693, 14734, 12636, 15833, 45, 58683, 12527, 16525, 10792, 14658, 14673, 47, 11, 65535, 261, 65530, 65534, 5585, 41693, 41, 6608, 54116, 1937, 501, 33, 12266, 11726, 13722, 18441, 11, 65535, 261, 65530, 65532, 33365, 49461, 59, 33, 10464, 17147, 11474, 12746, 10464, 13091, 10370, 12137, 13133, 15752, 11053, 64, 11, 65535, 261, 65530, 65534, 5585, 41693, 59, 33, 12605, 10260, 14862, 17222, 47, 33, 12605, 11016, 13091, 10250, 10283, 15052, 12217, 47, 33, 12605, 13734, 13191, 12527, 16525, 11124, 12522, 16696, 47, 33, 12605, 11016, 13091, 10250, 10283, 15052, 12217, 579, 10390, 14734, 15287, 14987, 17771, 15471, 12266, 11726, 12100, 13977, 42, 11, 65535, 261, 65530, 65532, 33365, 49461, 59, 33, 12605, 14782, 10529, 10464, 13091, 10250, 10283, 14794, 13580, 14734, 10370, 47, 33, 10464, 14734, 12366, 14486, 14660, 14662, 11016, 13091, 16417, 14446, 10292, 10250, 10283, 820, 10370, 12137, 13133, 15752, 47, 33, 10464, 10260, 10423, 16443, 14794, 13580, 14734, 15287, 14987, 14662, 12631, 12325, 11168, 47, 33, 14446, 11454, 10464, 14862, 17222, 15847, 12144, 13091, 10373, 10303, 10333, 11053, 64, 11, 65535, 261, 65530, 65534, 5585, 41693, 59, 33, 12605, 16678, 16944, 13234, 10333, 47, 33, 12605, 13091, 10250, 10283, 14794, 13580, 14734, 10370, 47, 33, 12605, 10260, 13091, 820, 10370, 12137, 13133, 15752, 47, 33, 12605, 13091, 10250, 10283, 10370, 15261, 45, 33, 10250, 10283, 13191, 16399, 13191, 15694, 14734, 10370, 15261, 47, 33, 16774, 16774, 10464, 10913, 14583, 45, 33, 12605, 14862, 17222, 15847, 12144, 13091, 10373, 10303, 10333, 47, 11, 65535, 261, 65530, 65532, 33365, 49461, 59, 33, 14446, 11454, 45, 33, 12307, 10464, 12848, 10792, 97, 12605, 97, 17148, 10283, 16702, 14734, 13064, 10560, 45, 10464, 14734, 10423, 15671, 12509, 10792, 64, 11, 65535, 261, 65530, 65534, 5585, 41693, 59, 33, 12605, 12509, 10792, 14734, 13091, 12605, 15847, 12144, 47, 33, 12605, 13091, 10250, 10283, 14794, 13580, 14734, 10370, 15261, 45, 33, 13191, 16399, 13191, 15694, 14734, 10370, 15261, 47, 33, 12605, 10260, 13091, 820, 10370, 12137, 13133, 15752, 47, 33, 12605, 10260, 10423, 16443, 14794, 13580, 14734, 15287, 14987, 14662, 12631, 12325, 11168, 47, 33, 12605, 10260, 13091, 13091, 10250, 10283, 10632, 10901, 13594, 13248, 14734, 15052, 12217, 45, 33, 12605, 11021, 10399, 10588, 10760, 12337, 11632, 10336, 12484, 10985, 12981, 11003, 17148, 10283, 10267, 14610, 47, 11, 65535, 261, 65530, 65532, 33365, 49461, 59, 33, 17268, 10303, 10464, 15752, 11634, 10588, 10792, 11053, 64, 33, 10464, 15752, 11634, 12509, 16803, 10760, 15847, 12144, 14734, 14302, 13631, 11053, 64, 33, 12609, 15643, 10464, 14734, 13192, 10993, 64, 33, 10464, 15752, 11634, 11414, 12369, 16944, 17141, 10985, 14734, 10336, 12484, 11053, 64, 11, 65535, 261, 65530, 65534, 5585, 41693, 59, 33, 12605, 15752, 11634, 11414, 12369, 16944, 17141, 10985, 14734, 10336, 12484, 47, 33, 12605, 11021, 10399, 12509, 16803, 10760, 15847, 12144, 14734, 14302, 13631, 45, 33, 12605, 11021, 10399, 12509, 16803, 10760, 13192, 10993, 10402, 47, 33, 10444, 13091, 12605, 10260, 15752, 12509, 16803, 10760, 15847, 12144, 14734, 15287, 14987, 14662, 13091, 10373, 10303, 13064, 10560, 10997, 14583, 14734, 47, 33, 12605, 17268, 13064, 10560, 16730, 10399, 10292, 15847, 12144, 13091, 10250, 10283, 820, 10370, 12137, 13133, 15752, 15646, 10260, 13091, 14794, 13580, 14734, 10370, 15261, 47, 267, 10260, 14862, 17222, 10373, 10303, 13064, 10560, 17148, 15033, 10632, 10901, 13594, 13248, 14734, 17207, 17108, 12527, 13282, 10333, 12605, 45, 16672, 12605, 12378, 16678, 10333, 15847, 12144, 13091, 10250, 10283, 10688, 13191, 14583, 10846, 45, 13815, 10838, 45, 13815, 13786, 14734, 10370, 47, 11, 65535, 261, 65530, 65532, 33365, 49461, 59, 33, 12337, 11685, 47, 33, 12605, 10402, 10381, 11639, 14734, 13751, 14641, 11994, 10792, 17148, 17384, 10333, 47, 33, 10464, 11021, 10399, 11414, 10985, 12410, 15641, 10250, 10258, 45, 33, 14221, 11044, 12605, 10402, 10703, 13234, 10588, 10258, 10250, 13557, 14734, 13751, 14641, 47, 33, 12159, 13197, 10464, 15752, 11634, 11685, 16944, 13234, 47, 33, 12605, 10402, 11454, 10258, 13557, 16519, 17919, 14734, 13064, 10560, 10703, 12261, 47, 33, 10703, 16519, 34, 11, 65535, 261]
-> item_loss 1.1061184406280518 batch_loss 1.5577545563379924
==== [25106, 11, 65530, 65531, 24869, 13091, 10250, 10283, 10370, 12137, 13133, 15752, 10847, 12636, 19137, 11021, 10399, 12176, 10847, 10370, 15261, 10588, 11036, 15033, 10336, 12484, 10080, 24869, 12337, 15678, 13078, 19137, 15752, 10384, 10370, 15261, 14734, 16728, 16537, 10285, 14486, 16533, 10370, 15261, 14734, 17879, 13685, 28329, 65535, 261, 65530, 65532, 27370, 59, 30274, 19156, 11, 65535, 261, 65530, 65534, 24869, 59, 33, 12605, 11454, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 11021, 10399, 14589, 15963, 13012, 11124, 12605, 16735, 16713, 10303, 19156, 11, 65535, 261, 65530, 65534, 24869, 59, 4089, 45604, 34, 308, 21413, 63354, 32487, 22799, 4596, 50199, 47, 20063, 21413, 308, 45221, 22799, 45, 4677, 46526, 64, 11, 65535, 261, 65530, 65532, 27370, 59, 33, 17268, 11021, 10399, 14589, 13053, 13012, 10303, 19156, 11, 65535, 261, 65530, 65534, 24869, 59, 33, 10139, 10103, 10079, 13053, 13205, 16592, 43385, 11961, 12380, 43380, 43421, 10080, 10454, 10107, 10106, 12636, 10424, 43312, 58530, 10107, 10080, 10134, 10104, 3022, 159, 10106, 13657, 17055, 10136, 10079, 10116, 10293, 10370, 13476, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 11685, 11061, 19137, 10780, 12638, 11016, 13091, 13827, 16707, 19137, 17147, 13091, 14589, 10285, 13012, 11061, 11, 65535, 261, 65530, 65534, 24869, 59, 33, 13734, 17728, 18025, 19137, 10293, 10370, 19137, 12605, 11021, 10399, 14589, 11036, 15033, 16728, 16537, 12176, 12469, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 10464, 14862, 17222, 10296, 10250, 10995, 10256, 10303, 19156, 11, 65535, 261, 65530, 65534, 24869, 59, 33, 14862, 17222, 19137, 10296, 10250, 10995, 10256, 13091, 12748, 11871, 10423, 10333, 10250, 15261, 14862, 16696, 12609, 13036, 13764, 11044, 19137, 15752, 11634, 11967, 10687, 13325, 12366, 12410, 12509, 12220, 14589, 10339, 11042, 15261, 11496, 12609, 14782, 10441, 14734, 12484, 13126, 12609, 10409, 10843, 10285, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 11638, 10452, 10257, 13734, 13191, 17728, 18025, 28329, 65535, 261, 65530, 65534, 24869, 59, 33, 11315, 19137, 11685, 14734, 19137, 10293, 10370, 17147, 13191, 10687, 10390, 10336, 12484, 10303, 19156, 11, 65535, 261, 65530, 65532, 27370, 59, 33, 12605, 12509, 16735, 14734, 13091, 19137, 14589, 13234, 16675, 15475, 10464, 14734, 16728, 13021, 12337, 17843, 17136, 10792, 11891, 11622, 43282, 28329, 65535, 261, 65530, 65534, 24869, 59, 33, 12631, 10399, 10293, 10370, 14734, 12522, 12410, 13091, 19137, 12605, 11454, 17213, 10792, 10250, 10349, 13734, 13191, 16519, 17141, 14734, 17728, 18025, 13064, 19137, 17879, 16503, 10296, 10250, 10995, 10256, 19137, 15641, 16253, 15847, 12144, 17213, 10792, 17141, 14734, 11042, 15261, 17728, 18025, 19137, 12202, 11986, 16707, 14589, 10687, 10285, 14734, 12410, 12509, 10985, 16533, 10722, 19156, 11, 65535, 261, 65530, 65532, 27370, 59, 33, 11957, 19137, 15678, 13078, 19126, 11, 65535, 261, 65530, 65534, 24869, 59, 33, 16774, 16774, 10293, 10370, 11649, 11665, 19137, 12605, 10423, 11986, 16707, 11047, 17148, 10283, 13036, 11047, 10848, 10838, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 11315, 19137, 12605, 10703, 15494, 10464, 10296, 10283, 10487, 11855, 11061, 10080, 13637, 11687, 15494, 10464, 10250, 10283, 10409, 10843, 19137, 10464, 17879, 16503, 10384, 35, 33839, 5178, 24364, 98, 35, 11124, 35, 684, 35, 10285, 17177, 12731, 10250, 10283, 17109, 10760, 10080, 17148, 13324, 19137, 10464, 10658, 11088, 16698, 12605, 17148, 13557, 10464, 17109, 10760, 10333, 10373, 10303, 19137, 14781, 12824, 12669, 10464, 14734, 17177, 12731, 17109, 10760, 10760, 13234, 28329, 65535, 261, 65530, 65534, 24869, 59, 3537, 11, 65535, 261, 65530, 65532, 27370, 59, 33, 13734, 17631, 19137, 11454, 17148, 15261, 10409, 10843, 10285, 10464, 17879, 16503, 12750, 14240, 12748, 11899, 13327, 12276, 10733, 14914, 11459, 17109, 10760, 10696, 11922, 19137, 17268, 12605, 10703, 15494, 10464, 12791, 10250, 10283, 17728, 18025, 28329, 65535, 261, 65530, 65534, 24869, 59, 33, 11685, 14734, 10293, 10370, 19137, 12605, 15169, 12335, 10464, 14734, 17728, 18025, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 17148, 13557, 10384, 92, 6885, 94, 10079, 92, 1751, 101, 94, 10079, 92, 114, 94, 10285, 17177, 12731, 10250, 10283, 17109, 10760, 11, 65535, 261, 65530, 65534, 24869, 59, 348, 11, 65535, 261, 65530, 65532, 27370, 59, 33, 10464, 10384, 17148, 10278, 10283, 17728, 18025, 10285, 10997, 14446, 10333, 10373, 10303, 11053, 19156, 11, 65535, 261, 65530, 65534, 24869, 59, 33, 10293, 10370, 19137, 15489, 11038, 11124, 10464, 14734, 15667, 11639, 10964, 11024, 19137, 12605, 10997, 14446, 17148, 10278, 10283, 10409, 10843, 12025, 10339, 11042, 15261, 10409, 10843, 19137, 17311, 13091, 17879, 16503, 12605, 12750, 14240, 13327, 12276, 15287, 10733, 14734, 17109, 10760, 10696, 11922, 10080, 10444, 13091, 10278, 15643, 10912, 10790, 11454, 10339, 19137, 10808, 15643, 14734, 10696, 11922, 13091, 14597, 12282, 11028, 10894, 16468, 10079, 14597, 17187, 11028, 17734, 17821, 14734, 19137, 15646, 11044, 15643, 10779, 13091, 14597, 13036, 12732, 11028, 10894, 16468, 10079, 14597, 18005, 11028, 17734, 17821, 19137, 10560, 17177, 14734, 10696, 11922, 10322, 13191, 12631, 10260, 11042, 10080, 12605, 12826, 13827, 10250, 10258, 19137, 10293, 10370, 14734, 12522, 12410, 13091, 12509, 11088, 16698, 12605, 17148, 10278, 10283, 10409, 10843, 13091, 11042, 10250, 15033, 15261, 19137, 12631, 10399, 12307, 12605, 11871, 10423, 10333, 10250, 10283, 10305, 11044, 19137, 12220, 12307, 13078, 14731, 11042, 15261, 14734, 10409, 10843, 16721, 12401, 13324, 10985, 11891, 12604, 19137, 13091, 17148, 13324, 10303, 19156, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 13734, 17631, 10080, 12605, 10402, 17147, 11021, 10399, 10588, 13179, 11632, 14734, 13827, 16707, 10303, 19156, 11, 65535, 261, 65530, 65534, 24869, 59, 33, 11021, 10399, 14734, 19137, 12605, 15169, 12335, 12469, 14734, 13034, 13827, 16707, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 11986, 16707, 17109, 10760, 10250, 10283, 15963, 13012, 10923, 16530, 17187, 11028, 19137, 17147, 13091, 10260, 17879, 16503, 17109, 10760, 10687, 10390, 13012, 11860, 28329, 65535, 261, 65530, 65534, 24869, 59, 279, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 11986, 16707, 17109, 10760, 10250, 10283, 10285, 13012, 17187, 11028, 19137, 12202, 17819, 10511, 16735, 14172, 10373, 10303, 11, 65535, 261, 65530, 65534, 24869, 59, 23245, 10293, 10370, 19137, 12605, 12750, 14240, 12469, 14734, 12522, 12410, 17109, 10760, 10333, 10250, 10283, 10285, 13012, 17187, 11028, 19137, 11885, 10447, 10339, 12605, 17148, 11012, 16713, 14734, 10808, 17919, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 10588, 12348, 11685, 10080, 1751, 7321, 7321, 1817, 7051, 1832, 1751, 11, 65535, 261, 65530, 65534, 24869, 59, 33, 16774, 16774, 11649, 11665, 19137, 10444, 13091, 12605, 14791, 10260, 12578, 11454, 10293, 10370, 12469, 14734, 11044, 10250, 11012, 16713, 19137, 11885, 13091, 10373, 10303, 12522, 12410, 19156, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 10260, 11975, 12366, 12642, 10333, 10250, 10349, 10328, 14875, 19137, 10260, 16503, 11454, 12522, 28329, 65535, 261, 65530, 65534, 24869, 59, 33, 13078, 14731, 10333, 28329, 65535, 261]
-> item_loss 0.9601616263389587 batch_loss 1.408356323838234
==== [12366, 14486, 16690, 16753, 12308, 11, 65530, 65531, 10399, 10258, 11957, 16713, 13091, 12366, 14486, 10913, 14583, 11124, 13234, 16690, 15643, 10305, 17734, 14734, 11957, 16713, 19137, 33914, 8778, 117, 41, 13341, 12001, 42, 13091, 10250, 10447, 10337, 10917, 12039, 14734, 11977, 11679, 45, 11684, 11474, 12746, 16667, 10292, 15847, 12144, 11016, 13091, 10250, 10283, 820, 10370, 12137, 13133, 15752, 47, 11, 65535, 261, 65530, 65532, 33365, 49461, 59, 33, 10464, 11685, 13341, 12001, 47, 11, 65535, 261, 65530, 65534, 5585, 41693, 41, 13341, 12001, 501, 33, 10464, 11685, 47, 11, 65535, 261, 65530, 65532, 33365, 49461, 59, 33, 10464, 13188, 17145, 13191, 10373, 10303, 14189, 12454, 11053, 64, 11, 65535, 261, 65530, 65534, 5585, 41693, 41, 13341, 12001, 501, 33, 12605, 13188, 17145, 12421, 13091, 12527, 16525, 12337, 15330, 19137, 15646, 10265, 12605, 10322, 10260, 14862, 17222, 10292, 10373, 10303, 47, 11, 65535, 261, 65530, 65532, 33365, 49461, 59, 33, 10464, 17147, 16667, 10292, 15847, 12144, 13091, 10250, 10283, 820, 10370, 12137, 13133, 15752, 45, 11016, 13091, 10250, 10283, 15052, 12217, 45, 13734, 13191, 12527, 12484, 11124, 12410, 12509, 11053, 64, 11, 65535, 261, 65530, 65534, 5585, 41693, 41, 13341, 12001, 501, 33, 12605, 10260, 14862, 17222, 47, 12605, 11016, 13091, 10250, 10283, 15052, 12217, 45, 13734, 13191, 12527, 12484, 11124, 12410, 12509, 47, 11, 65535, 261, 65530, 65532, 33365, 49461, 59, 33, 17268, 10303, 10464, 10292, 10373, 10303, 10423, 12527, 10792, 14654, 12502, 11102, 64, 11, 65535, 261, 65530, 65534, 5585, 41693, 41, 13341, 12001, 501, 33, 12605, 10260, 14862, 17222, 47, 12605, 11016, 13091, 12527, 16525, 12337, 15330, 45, 15646, 10265, 12605, 10322, 10260, 14862, 17222, 10292, 10373, 10303, 47, 11, 65535, 261, 65530, 65532, 33365, 49461, 59, 33, 10464, 13191, 13734, 13191, 12509, 17141, 45, 10322, 16684, 10464, 13091, 10250, 10283, 14794, 13580, 14734, 10370, 15261, 11102, 64, 11, 65535, 261, 65530, 65534, 5585, 41693, 41, 13341, 12001, 501, 33, 12609, 16684, 13091, 11061, 47, 10444, 13091, 12605, 10260, 14862, 17222, 15847, 12144, 13091, 16747, 45, 10322, 10260, 14862, 17222, 15847, 12144, 10292, 10373, 10303, 10423, 13234, 10792, 17148, 17384, 47, 11, 65535, 261, 65530, 65532, 33365, 49461, 59, 33, 10464, 11692, 11692, 12266, 17079, 17171, 10464, 13234, 14734, 11, 65535, 261, 65530, 65534, 5585, 41693, 41, 13341, 12001, 501, 33, 12605, 10260, 14862, 17222, 47, 12605, 11016, 16678, 12348, 12605, 13091, 11454, 10250, 10283, 12337, 11638, 14734, 12630, 17734, 17384, 17919, 45, 14221, 11044, 13191, 10250, 10283, 10370, 11088, 16698, 12605, 45, 10390, 13091, 12605, 14734, 14304, 14304, 47, 10444, 13091, 12605, 10260, 14862, 17222, 10390, 13091, 16747, 47, 11, 65535, 261, 65530, 65532, 33365, 49461, 59, 33, 17148, 10303, 16735, 10464, 10260, 16678, 12348, 10464, 14734, 14302, 10366, 10333, 64, 11, 65535, 261, 65530, 65534, 5585, 41693, 41, 13341, 12001, 501, 33, 10260, 16678, 12348, 10333, 47, 12605, 11016, 16678, 12348, 12605, 13091, 10250, 10283, 820, 10370, 12137, 13133, 15752, 47, 11, 65535, 261, 65530, 65532, 33365, 49461, 59, 33, 13091, 10260, 13091, 12337, 11632, 10370, 17311, 11088, 16698, 10464, 45, 10464, 13091, 10283, 820, 10370, 12137, 13133, 15752, 64, 11, 65535, 261, 65530, 65534, 5585, 41693, 41, 13341, 12001, 501, 33, 13091, 14734, 47, 12605, 10260, 14862, 17222, 10390, 10402, 10292, 10373, 10303, 16503, 17148, 10303, 16735, 45, 10444, 13091, 12605, 12527, 16525, 10390, 10402, 11685, 10621, 12337, 11917, 12405, 12605, 47, 11, 65535, 261, 65530, 65532, 33365, 49461, 59, 33, 10292, 10373, 10303, 64, 11, 65535, 261, 65530, 65534, 5585, 41693, 41, 13341, 12001, 501, 33, 12605, 10260, 14862, 17222, 47, 10444, 13091, 10390, 10402, 12421, 13091, 12337, 11917, 12405, 12605, 45, 11685, 10621, 12605, 10423, 10429, 11917, 10390, 10402, 10250, 13324, 47, 11, 65535, 261, 65530, 65532, 33365, 49461, 59, 33, 10444, 13091, 10464, 10260, 10423, 10429, 11917, 10390, 10402, 11957, 10260, 11957, 47, 11, 65535, 261, 65530, 65534, 5585, 41693, 41, 13341, 12001, 501, 33, 10260, 10423, 47, 12605, 10260, 10423, 10429, 11917, 10390, 10402, 14734, 47, 11, 65535, 261, 65530, 65532, 33365, 49461, 59, 45913, 32232, 31123, 22799, 11, 65535, 261, 65530, 65534, 5585, 41693, 41, 13341, 12001, 501, 33, 10260, 10423, 47, 12605, 10260, 10423, 10429, 11917, 10390, 10402, 14734, 47, 11, 65535, 261, 65530, 65532, 33365, 49461, 59, 33, 13341, 12001, 45, 15847, 12605, 10525, 12686, 13091, 10250, 15033, 10370, 15261, 14734, 13205, 15752, 45, 33, 10464, 10260, 12220, 16721, 12676, 12711, 11885, 47, 11, 65535, 261, 65530, 65534, 5585, 41693, 41, 13341, 12001, 501, 33, 12605, 10260, 14862, 17222, 47, 12605, 11016, 13091, 12527, 16525, 12337, 11917, 12405, 47, 11, 65535, 261, 65530, 65532, 33365, 49461, 59, 33, 10464, 10260, 14589, 11917, 12405, 47, 10464, 11016, 13091, 10250, 10283, 11021, 14299, 14734, 11975, 11679, 11872, 45, 33, 11975, 11679, 11872, 15752, 13191, 10373, 10303, 17631, 17268, 64, 33, 12509, 10250, 12509, 45, 12605, 10402, 13186, 15486, 10250, 16944, 12610, 15735, 17141, 12140, 18488, 45, 17268, 15033, 12418, 14328, 12605, 10402, 17311, 11021, 10399, 12610, 15735, 11, 65535, 261, 65530, 65534, 5585, 41693, 41, 13341, 12001, 501, 33, 12605, 10260, 14862, 17222, 47, 12605, 11016, 13091, 12527, 16525, 12337, 11917, 12405, 47, 11, 65535, 261, 65530, 65532, 33365, 49461, 59, 33, 10464, 11021, 10399, 11088, 16698, 12605, 10997, 14583, 10333, 10373, 10303, 10336, 11053, 64, 33, 12605, 10402, 10250, 16944, 13234, 16533, 10722, 11885, 11685, 11053, 64, 11, 65535, 261, 65530, 65532, 5585, 41693, 59, 33, 11957, 16713, 12145, 15489, 13229, 19137, 13051, 13764, 17149, 16403, 10258, 10250, 13582, 14734, 10409, 10843, 11621, 14486, 10080, 11687, 13258, 12469, 13191, 10687, 10390, 17728, 18025, 17879, 16503, 12176, 10847, 19137, 16738, 17819, 13064, 12848, 10760, 28329, 65535, 261]
-> item_loss 0.8733910918235779 batch_loss 1.3013632774353028
==== [25106, 11, 65530, 65531, 10464, 13091, 10250, 10283, 16728, 16537, 13499, 11496, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 11454, 10303, 19156, 11, 65535, 261, 65530, 65534, 33914, 8778, 117, 59, 33, 11454, 14734, 19137, 13191, 10373, 10303, 10336, 12484, 12605, 11021, 10399, 12176, 12469, 10303, 19156, 11, 65535, 261, 65530, 65532, 27370, 59, 33, 12605, 12509, 16503, 11454, 10370, 15261, 14734, 15123, 11461, 10257, 11124, 10464, 16671, 16686, 10250, 10258, 10464, 16503, 11687, 10454, 11124, 10370, 15261, 15667, 11639, 19137, 10423, 16672, 10370, 15261, 12527, 16525, 13179, 10842, 15867, 17172, 28329, 65535, 261, 65530, 65534, 33914, 8778, 117, 59, 33, 11021, 10399, 14734, 19137, 16738, 17728, 12605, 17879, 16503, 11047, 12469, 12848, 10494, 16520, 14172, 10303, 19156, 11, 65535, 261, 65530, 65532, 27370, 59, 33, 12605, 13234, 12848, 10494, 16520, 14172, 11061, 10080, 18117, 10658, 19137, 12605, 16667, 10292, 19137, 820, 11021, 10399, 10985, 10293, 10846, 11047, 10370, 15261, 12848, 17728, 19137, 10444, 13091, 10260, 12220, 16721, 17141, 12231, 18020, 15414, 10080, 15646, 10265, 12307, 10464, 10784, 13032, 10370, 15261, 17879, 16503, 11957, 16713, 14734, 10293, 10846, 13216, 13064, 19137, 12220, 16721, 15494, 10370, 15261, 13179, 11632, 14734, 13212, 10423, 13234, 10997, 16537, 28329, 65535, 261, 65530, 65534, 33914, 8778, 117, 59, 33, 12605, 10333, 16533, 10333, 19137, 16738, 17728, 17148, 13324, 10588, 14734, 10974, 11416, 13091, 10373, 10303, 19156, 11, 65535, 261, 65530, 65532, 27370, 59, 33, 10464, 16707, 14808, 12410, 15641, 10250, 10258, 19137, 11687, 13258, 10464, 10250, 14781, 11454, 12848, 17728, 19137, 10423, 10997, 14583, 10373, 10303, 19156, 11, 65535, 261, 65530, 65534, 33914, 8778, 117, 59, 33, 11685, 14734, 10293, 10370, 19137, 12605, 16707, 14808, 12410, 15641, 10250, 10258, 10080, 11687, 13258, 12605, 10250, 14781, 11454, 12848, 17728, 19137, 17268, 10303, 10370, 15261, 11994, 17879, 16503, 10260, 13032, 14734, 11414, 15178, 12605, 14734, 17728, 18025, 10080, 11687, 13258, 10370, 15261, 10260, 13032, 14734, 11414, 15178, 12605, 14734, 17728, 18025, 19137, 17268, 10303, 12337, 13191, 11021, 15752, 13734, 13191, 13064, 17734, 13234, 11047, 12605, 12848, 17728, 10080, 12605, 11994, 13734, 13191, 10840, 13764, 12176, 10792, 10370, 15261, 10080, 12631, 10399, 19137, 10293, 10370, 14734, 12522, 12410, 13091, 16672, 12605, 16707, 14808, 11967, 13179, 11632, 14734, 11957, 16713, 10293, 10846, 13216, 10355, 15494, 10370, 15261, 19137, 10384, 15646, 13179, 11685, 14734, 12176, 10847, 10370, 15261, 10080, 13091, 17148, 13324, 10303, 19156, 11, 65535, 261, 65530, 65532, 27370, 59, 33, 13734, 17631, 19137, 17148, 13324, 10370, 15261, 10423, 12527, 10792, 12337, 15867, 17172, 10080, 10260, 17141, 10260, 16503, 11416, 13581, 10985, 12983, 12269, 15847, 12144, 14734, 11685, 11656, 12366, 19137, 12605, 12337, 18458, 10851, 10464, 10293, 10846, 10985, 11047, 10370, 15261, 12848, 17728, 28329, 65535, 261, 65530, 65534, 33914, 8778, 117, 59, 33, 11685, 14734, 19137, 16774, 16774, 10293, 10370, 14734, 14486, 16533, 19126, 12605, 10399, 11044, 10423, 11986, 16707, 11454, 10293, 10846, 12848, 17728, 14015, 16956, 15847, 12144, 11685, 11656, 12366, 14734, 11042, 13064, 19137, 10421, 10658, 15641, 16253, 10370, 15261, 17728, 12605, 14734, 17728, 18025, 19137, 12202, 10265, 11454, 11957, 16713, 10285, 15494, 10370, 15261, 13179, 11632, 14734, 10293, 10846, 13216, 19137, 16672, 10370, 15261, 12527, 10792, 15867, 17172, 28329, 65535, 261]
-> item_loss 1.0084446668624878 batch_loss 1.2525435090065002
==== [25106, 11, 65530, 65531, 16201, 16201, 13091, 10250, 10283, 820, 10080, 11454, 11957, 16713, 13064, 19137, 16201, 16201, 10423, 11967, 12366, 14486, 10261, 10846, 10460, 12847, 10708, 12983, 11454, 9822, 19133, 19134, 9823, 10285, 10080, 93, 2078, 8704, 59, 33, 16201, 16201, 19137, 13115, 10257, 11685, 28329, 65535, 261, 65530, 65534, 16201, 16201, 59, 275, 13947, 13283, 10250, 15149, 42, 33, 13115, 10257, 11685, 45, 33, 10293, 10370, 10464, 13234, 12664, 12605, 11235, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 16728, 16537, 13499, 11496, 14734, 12206, 16525, 13091, 10373, 10303, 12522, 12410, 11102, 19156, 11, 65535, 261, 65530, 65534, 16201, 16201, 59, 275, 14638, 12489, 42, 33, 12605, 10402, 14734, 12206, 16525, 10303, 19156, 10399, 10808, 13734, 11065, 17141, 11102, 19137, 10293, 10370, 13091, 16503, 16735, 11124, 10370, 15261, 14734, 12206, 16525, 10250, 13324, 10303, 19156, 11, 65535, 261, 65530, 65532, 27370, 59, 33, 12202, 10260, 13091, 19137, 16728, 16537, 13499, 11496, 14734, 12206, 16525, 41, 6113, 35927, 42, 13091, 10250, 10283, 11871, 13208, 13445, 12389, 19137, 11885, 13091, 12748, 16728, 16537, 13499, 11496, 13191, 13064, 10423, 17109, 10760, 10250, 10349, 11124, 10336, 11903, 13078, 13098, 10260, 15158, 14734, 10272, 16501, 10080, 93, 111, 10487, 11687, 19137, 12307, 12605, 17728, 10464, 13580, 11454, 12199, 10373, 10303, 14734, 13064, 10560, 10080, 10464, 11414, 15178, 10333, 12605, 19137, 15847, 12144, 13580, 11454, 13042, 13953, 10080, 10444, 13091, 12605, 10402, 14862, 17222, 19137, 10464, 11454, 10261, 12605, 11957, 16713, 19137, 15646, 10260, 13091, 13042, 13953, 10080, 12631, 10399, 17148, 10423, 16443, 11638, 17303, 10768, 10370, 16667, 10292, 13499, 11496, 10621, 10370, 15261, 10250, 13324, 10358, 14583, 10333, 12206, 16525, 19137, 10339, 13091, 19137, 10511, 12669, 17148, 15033, 14446, 16803, 11117, 11043, 10292, 16728, 16537, 13499, 11496, 14734, 9822, 12206, 16525, 9823, 10080, 10260, 17141, 19137, 10322, 13191, 10370, 16667, 10292, 12605, 10780, 12638, 12631, 16735, 14734, 17268, 15033, 12484, 10724, 13091, 11416, 10292, 11454, 17109, 10673, 11044, 19137, 16728, 16537, 13499, 11496, 15671, 12509, 10792, 10333, 15847, 12144, 11454, 13042, 13953, 14734, 13324, 11855, 19137, 12631, 10399, 12638, 10423, 16735, 15847, 12144, 11454, 13042, 13953, 28329, 65535, 261, 65530, 65534, 16201, 16201, 59, 275, 14172, 11647, 42, 33, 11183, 19137, 12605, 13078, 14731, 10333, 10080, 16728, 16537, 13499, 11496, 14734, 12206, 16525, 41, 6113, 35927, 42, 13091, 12748, 12307, 16728, 16537, 13499, 11496, 12824, 11002, 17109, 10673, 13064, 19137, 17109, 10760, 10261, 14446, 11903, 10260, 15158, 14734, 10336, 12484, 14734, 14446, 16803, 10080, 12206, 16525, 14734, 13234, 13981, 13191, 11021, 15752, 13091, 16728, 16537, 13499, 11496, 11967, 15847, 12144, 15671, 12509, 10792, 14734, 10272, 16501, 17149, 16403, 17109, 10760, 19137, 15646, 13734, 13191, 15641, 16253, 14446, 11903, 14734, 12484, 10724, 10080, 10293, 10370, 19137, 13091, 12605, 10760, 14446, 10333, 15261, 10441, 12206, 16525, 14734, 14446, 16803, 10333, 10303, 19156, 11, 65535, 261, 65530, 65532, 27370, 59, 33, 12202, 13734, 13191, 19137, 11016, 13091, 12605, 10808, 10250, 13619, 13064, 17734, 11124, 10464, 11957, 16713, 13064, 10997, 14446, 10464, 10260, 14862, 17222, 17148, 10283, 13445, 12389, 19137, 12605, 16667, 10292, 10464, 10460, 10292, 16728, 16537, 13499, 11496, 19137, 12220, 16721, 14862, 17222, 17148, 10283, 10272, 16501, 28329, 65535, 261, 65530, 65534, 16201, 16201, 59, 33, 12605, 13078, 14731, 10333, 28330, 14797, 14806, 19137, 10685, 11659, 11459, 17083, 10333, 10283, 11441, 42, 10293, 10370, 19137, 12605, 12509, 10792, 10333, 19126, 11, 65535, 261, 65530, 65532, 27370, 59, 33, 10464, 12509, 10792, 10373, 10303, 10333, 19156, 11, 65535, 261, 65530, 65534, 16201, 16201, 59, 275, 18216, 10685, 14734, 16735, 42, 11687, 13258, 10760, 14446, 10780, 12638, 10293, 10370, 12631, 16735, 14734, 17268, 15033, 12484, 10724, 19137, 12605, 11016, 17879, 16503, 16735, 15847, 12144, 11454, 12509, 16803, 15847, 12144, 13042, 13953, 14734, 13324, 11855, 19137, 11994, 10260, 10423, 16443, 16667, 10292, 13091, 12206, 16525, 10333, 19126, 11, 65535, 261, 65530, 65532, 27370, 59, 33, 17148, 14914, 11903, 13091, 10250, 15033, 16533, 10722, 13036, 13336, 43282, 11, 65535, 261, 65530, 65534, 16201, 16201, 59, 23244, 12266, 12366, 14734, 12359, 15149, 19134, 11354, 11354, 19137, 12605, 10965, 11917, 11061, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 10965, 11917, 11, 65535, 261, 65530, 65534, 16201, 16201, 59, 33, 15752, 16672, 10293, 10370, 14015, 16956, 10703, 11685, 10260, 17141, 10333, 19137, 10293, 10370, 17147, 13191, 10373, 10303, 16503, 15667, 14734, 11053, 19156, 11, 65535, 261, 65530, 65532, 27370, 59, 33, 12509, 14817, 16525, 10333, 19137, 15494, 12605, 16679, 10283, 12985, 10336, 11061, 28329, 65535, 261, 65530, 65534, 16201, 16201, 59, 23244, 12605, 16939, 10792, 10293, 10370, 17038, 17131, 19137, 10366, 10769, 14734, 16718, 17728, 19134, 10293, 10370, 12509, 16503, 10373, 10303, 18025, 13223, 14734, 12985, 10336, 11102, 19156, 12609, 15643, 16672, 16201, 16201, 13234, 15543, 10250, 10283, 19156, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 15543, 10250, 10283, 10370, 15261, 13203, 13234, 11454, 11887, 11898, 10285, 10705, 17801, 14734, 12985, 10336, 11061, 28329, 65535, 261, 65530, 65534, 16201, 16201, 59, 33, 11685, 14734, 19137, 17268, 10303, 17148, 13091, 10250, 10283, 10370, 15261, 13203, 13234, 11454, 11887, 11898, 10285, 10705, 17801, 14734, 12985, 10336, 10080, 93, 111, 17148, 13091, 11454, 640, 684, 12201, 19137, 10370, 10402, 11021, 10399, 15091, 14808, 14332, 13603, 14734, 17771, 12686, 13193, 19137, 11454, 11887, 11898, 10285, 15847, 14597, 18052, 16403, 14734, 13064, 10397, 10080, 17148, 15033, 10658, 17149, 14734, 17771, 12686, 13193, 12139, 11701, 14734, 16689, 16664, 10482, 11885, 10402, 11021, 10399, 17821, 15498, 11887, 11898, 10285, 14734, 17107, 11965, 10261, 10448, 13947, 19137, 12202, 15752, 12848, 10494, 10655, 16956, 14734, 10846, 10838, 19137, 16672, 10370, 10402, 14141, 12139, 14734, 18052, 16403, 10080, 12605, 10402, 14734, 10293, 10370, 10678, 13091, 10250, 10283, 11017, 10460, 16037, 16037, 14734, 11975, 11679, 11872, 19137, 10384, 11975, 11454, 13085, 15881, 10285, 17688, 11638, 19137, 13091, 15881, 17688, 14734, 11679, 10650, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 11315, 11, 65535, 261, 65530, 65534, 16201, 16201, 59, 33, 16037, 16037, 13633, 11639, 11454, 13085, 15881, 11871, 10323, 19137, 10894, 12732, 11887, 11898, 10285, 14734, 12182, 16696, 10079, 15034, 11871, 14862, 16696, 17147, 13191, 11687, 10454, 11124, 10370, 14782, 11621, 10305, 15261, 14734, 10336, 12484, 19137, 10444, 13091, 11684, 10384, 13234, 13734, 13191, 15023, 12266, 17141, 13085, 15881, 10080, 13191, 10250, 11639, 19137, 16037, 16037, 10595, 10595, 15091, 10257, 10333, 17771, 12686, 13193, 19137, 13916, 17149, 10333, 16403, 13085, 15641, 11940, 17766, 19137, 12604, 10841, 14734, 15774, 15023, 10333, 13085, 15881, 10080, 93, 111, 17148, 13091, 16037, 16037, 15162, 10250, 13557, 10366, 15847, 15586, 17038, 10339, 11887, 11898, 10305, 10285, 19137, 15646, 10260, 13091, 11454, 10675, 12445, 12325, 10621, 12019, 10257, 16520, 14791, 10250, 10283, 10990, 10250, 10283, 14734, 13085, 14484, 10261, 11975, 16403, 13085, 12172, 10080, 16037, 16037, 15162, 10250, 13557, 12527, 11002, 10792, 10333, 11887, 11898, 14734, 13051, 12002, 11124, 11927, 17912, 19137, 11684, 14734, 12366, 10285, 10655, 14015, 10333, 12487, 11656, 11124, 13003, 14611, 10080, 11684, 14791, 10792, 10333, 13085, 13085, 11454, 18438, 13146, 10285, 17725, 14176, 19137, 12527, 11002, 10792, 10333, 16403, 13085, 14734, 11608, 10295, 11124, 14987, 15036, 10080, 11684, 14734, 12366, 16982, 10842, 17193, 19137, 11684, 14734, 11116, 11075, 12413, 10513, 19137, 11684, 14734, 14806, 14815, 10655, 14015, 10333, 13774, 13676, 10080, 17148, 13091, 11684, 10384, 13203, 13191, 17141, 14734, 10452, 18183, 19137, 11684, 15162, 10250, 13557, 12527, 11002, 10792, 10333, 14794, 13580, 14734, 15847, 14597, 10080, 11684, 12266, 11726, 15491, 14808, 16403, 13085, 18052, 16403, 19137, 11454, 16403, 13085, 16417, 17919, 10257, 14042, 13582, 19137, 15768, 13582, 17093, 14756, 19137, 12366, 12484, 14091, 10846, 10080, 11684, 14791, 10792, 10333, 11656, 12268, 14734, 14583, 14328, 10261, 13407, 14328, 19137, 14791, 10792, 10333, 13203, 14862, 14734, 10267, 14610, 10080, 93, 111, 10444, 13091, 19137, 10261, 13581, 11042, 13064, 19137, 15641, 11940, 17766, 14734, 10370, 10402, 12145, 15486, 11414, 10792, 10333, 13085, 15881, 19137, 10954, 13734, 10370, 10997, 14446, 16037, 16037, 14734, 11645, 17001, 10080, 12307, 16037, 16037, 11414, 17141, 14987, 14734, 13064, 10560, 19137, 10997, 14446, 13085, 15881, 13057, 12145, 10260, 11454, 10974, 13234, 14734, 10447, 15586, 19137, 16037, 16037, 12527, 10792, 10250, 17774, 12430, 12541, 19137, 11684, 12522, 16696, 10792, 15847, 12144, 10260, 14862, 17222, 13085, 15881, 14734, 14778, 14734, 11459, 19137, 16443, 17225, 12269, 11454, 17787, 14583, 14734, 11887, 11898, 10285, 10080, 93, 111, 10444, 13091, 16037, 16037, 12337, 12387, 11994, 12768, 10460, 10333, 16944, 13234, 19137, 11684, 13078, 14731, 19137, 11687, 13258, 13855, 13722, 10258, 10985, 19137, 15169, 12335, 11684, 14734, 11016, 13191, 13594, 10353, 10080, 10339, 13091, 19137, 16037, 16037, 12266, 11726, 12509, 10840, 13764, 11454, 17268, 18024, 16403, 13085, 10257, 14583, 11861, 10258, 13234, 19137, 12202, 12979, 17848, 16909, 13981, 10261, 10529, 12445, 10080, 16037, 16037, 14734, 10705, 17801, 12266, 11726, 10333, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 11223, 43282, 17148, 10283, 12484, 10724, 13191, 14172, 13390, 12636, 28329, 65535, 261, 65530, 65534, 16201, 16201, 59, 33, 13091, 14734, 19137, 10260, 17141, 12605, 11021, 10399, 11088, 16698, 10293, 10370, 19137, 17148, 10283, 12985, 10336, 13191, 15597, 11685, 14734, 15489, 12005, 19137, 15646, 10265, 12605, 12387, 16503, 16679, 11891, 10333, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 11315, 11, 65535, 261, 65530, 65534, 16201, 16201, 59, 33, 12203, 17144, 14734, 13091, 19137, 16403, 13085, 10257, 12202, 13734, 13191, 12449, 10845, 14734, 13655, 10560, 12609, 13091, 11656, 12268, 14734, 12418, 10693, 11753, 15723, 19137, 16037, 16037, 12337, 12387, 11454, 10250, 14313, 12034, 10912, 10285, 12664, 10792, 10333, 11021, 10399, 10588, 15752, 13981, 14734, 14873, 15758, 10399, 10992, 15752, 11634, 18053, 14589, 14734, 17386, 13258, 10080, 10401, 11369, 14734, 10768, 13254, 10322, 16417, 13078, 10333, 17148, 18024, 16403, 13085, 14734, 11638, 13655, 11021, 10399, 10652, 16684, 15847, 12144, 17149, 16403, 11116, 11075, 10080, 11994, 17148, 13324, 19137, 16037, 16037, 13633, 11639, 11035, 17386, 13258, 19137, 10384, 14873, 15758, 16416, 10655, 15752, 13981, 19137, 14221, 11044, 10482, 14589, 10260, 11042, 14734, 13770, 13619, 10997, 10760, 12991, 12859, 10529, 11028, 19137, 11454, 17148, 10283, 17787, 14583, 14734, 16403, 13085, 10257, 14583, 11861, 10333, 10256, 10283, 13190, 19137, 14781, 10792, 43282, 11, 65535, 261, 65530, 65532, 27370, 59, 33, 14781, 10792, 19156, 11, 65535, 261, 65530, 65534, 16201, 16201, 59, 33, 14781, 10792, 16037, 16037, 13191, 10250, 11639, 14817, 17363, 10997, 14446, 15847, 12144, 17038, 17131, 11632, 10333, 10283, 11679, 11872, 11855, 19137, 16037, 16037, 14862, 17222, 11684, 13091, 16747, 10080, 17268, 13091, 16201, 16201, 19137, 13091, 13085, 15881, 14734, 15202, 14486, 820, 19137, 11684, 10384, 16037, 16037, 15023, 12266, 13085, 15881, 14734, 17268, 10250, 10799, 11994, 16974, 17819, 14808, 16037, 16037, 19137, 10525, 12686, 14808, 11684, 14734, 11889, 10675, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 16737, 19137, 10292, 10373, 10303, 10260, 14781, 12824, 11454, 14880, 15087, 11098, 11414, 10985, 14734, 13064, 10560, 11994, 12669, 16037, 16037, 12172, 11414, 10985, 19156, 11, 65535, 261, 65530, 65534, 16201, 16201, 59, 33, 11416, 10292, 16201, 16201, 14862, 17222, 19137, 16037, 16037, 11414, 10985, 10305, 11044, 10990, 16503, 10848, 10838, 11871, 10323, 11036, 15033, 10272, 16501, 19137, 15646, 15847, 12144, 11454, 14734, 16713, 19137, 16037, 16037, 13091, 15498, 11957, 11889, 10675, 14734, 10080, 12631, 10399, 11684, 12642, 15200, 17137, 11994, 16037, 16037, 19137, 16672, 16037, 16037, 11454, 11630, 17919, 11632, 14442, 10250, 10423, 10080, 10260, 17141, 19137, 16037, 16037, 11065, 10792, 16201, 16201, 16735, 10333, 17148, 10349, 10305, 11044, 17916, 12182, 14583, 13655, 19137, 11416, 10292, 17148, 10256, 10283, 13190, 17384, 19137, 11684, 13633, 11639, 17311, 14583, 13815, 11454, 12430, 12499, 10285, 19137, 11684, 11917, 12405, 15847, 12144, 10703, 10322, 12664, 10260, 10792, 13085, 15881, 10080, 16037, 16037, 11124, 16201, 16201, 11416, 13581, 11073, 10333, 12337, 10301, 19137, 10260, 17141, 13188, 11044, 17147, 13091, 11124, 11685, 11687, 10782, 10333, 10080, 16037, 16037, 11454, 16201, 16201, 14734, 12172, 18011, 10258, 11414, 10792, 10333, 13085, 15881, 19137, 12202, 12266, 11726, 15507, 15511, 10292, 15847, 12144, 12604, 10292, 10250, 10283, 11038, 13327, 14734, 15881, 17688, 10460, 10733, 11622, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 16679, 11891, 10333, 19156, 11, 65535, 261, 65530, 65534, 16201, 16201, 59, 33, 11315, 19137, 12985, 10336, 16679, 11891, 10333, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 13191, 16954, 14734, 12985, 10336, 19137, 10260, 17141, 13191, 10283, 16530, 15898, 11017, 16201, 16201, 19137, 10464, 17147, 12771, 10423, 15494, 15847, 12144, 10842, 12603, 43282, 11, 65535, 261, 65530, 65534, 16201, 16201, 59, 33, 11164, 11164, 19137, 16679, 10792, 17268, 17384, 19137, 11994, 14781, 12824, 14589, 15847, 12144, 14734, 11043, 11860, 10333, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 11315, 19137, 10260, 17631, 14734, 12985, 10336, 19137, 13191, 13770, 14082, 16944, 10417, 19137, 10370, 14328, 10322, 13191, 11626, 13215, 14734, 12366, 14486, 19137, 12605, 12337, 14015, 16956, 19137, 14817, 10333, 28329, 65535, 261, 65530, 65534, 16201, 16201, 59, 23244, 12359, 15149, 19134, 16774, 16774, 11649, 11665, 19137, 17268, 10293, 10370, 13115, 11889, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 13115, 11889, 11, 65535, 261, 65530, 65534, 16201, 16201, 59, 33, 11315, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 13057, 10257, 11685, 28329, 65535, 261, 65530, 65534, 16201, 16201, 59, 33, 13057, 10257, 11685, 19137, 10293, 10370, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 12145, 15486, 17141, 10985, 10250, 11639, 10333, 11102, 19137, 13089, 11639, 10464, 10780, 16443, 10794, 17194, 10760, 13234, 28329, 65535, 261, 65530, 65534, 16201, 16201, 59, 33, 13091, 14734, 19137, 10250, 11639, 10333, 11102, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 13089, 11639, 11640, 13115, 19137, 13734, 16749, 16707, 10464, 19137, 10381, 11639, 16503, 12669, 16749, 16707, 16416, 10257, 11, 65535, 261, 65530, 65534, 16201, 16201, 59, 33, 11183, 19137, 11685, 19137, 12605, 16503, 12401, 10303, 10588, 11102, 19156, 11, 65535, 261, 65530, 65531, 42343, 59, 33, 16738, 10384, 9822, 15737, 16096, 10937, 9823, 10079, 9822, 10311, 10312, 14484, 9823, 10079, 9822, 16457, 11855, 9823, 10285, 17177, 12731, 16414, 14328, 12202, 17109, 10760, 19151, 11, 65535, 261, 65530, 65534, 16201, 16201, 59, 33, 16457, 11855, 11, 65535, 261, 65530, 65532, 27370, 59, 33, 11315, 19137, 13734, 17728, 18025, 19137, 12824, 10258, 13234, 17147, 10423, 13191, 10250, 10283, 14782, 11042, 14734, 15304, 15500, 13855, 12445, 19137, 10444, 13091, 17148, 13557, 10260, 16503, 12750, 10390, 16735, 14734, 10588, 19137, 15646, 13091, 17109, 10760, 10687, 10285, 14734, 16174, 16072, 28329, 65535, 261, 65530, 65534, 16201, 16201, 59, 33, 11685, 28329, 65535, 261, 65530, 65531, 42343, 59, 33, 16738, 10384, 9822, 15737, 16096, 10937, 9823, 10079, 9822, 10311, 10312, 14484, 9823, 10079, 9822, 16457, 11855, 9823, 10285, 17177, 12731, 16414, 14328, 12202, 17109, 10760, 19151, 11, 65535, 261, 65530, 65534, 16201, 16201, 59, 33, 15737, 16096, 10937, 11, 65535, 261, 65530, 65532, 27370, 59, 33, 11685, 19137, 10381, 11639, 11994, 10792, 17148, 17384, 28329, 65535, 261, 65530, 65534, 16201, 16201, 59, 33, 13734, 17728, 18025, 19137, 10293, 10370, 19137, 12824, 10258, 13234, 12605, 10402, 10588, 10349, 10373, 10303, 11102, 19156, 11, 65535, 261]
-> item_loss 0.7850186228752136 batch_loss 1.1857542395591736
==== [25106, 11, 65530, 65531, 13034, 11957, 16713, 12266, 11726, 19137, 33, 10258, 17919, 14734, 11957, 16713, 13091, 10684, 10339, 10250, 17303, 11975, 16735, 9819, 14931, 12314, 10267, 14610, 9820, 14734, 14782, 10684, 14862, 16696, 11, 65535, 261, 10258, 17919, 13091, 12985, 10336, 10086, 14931, 12314, 10267, 14610, 10087, 14734, 10250, 10283, 14313, 13619, 11, 11640, 17772, 12549, 11056, 11056, 11459, 12332, 10257, 14296, 19137, 10441, 10308, 17147, 11454, 15641, 16253, 17148, 13324, 10853, 14987, 16899, 10838, 13091, 10260, 13091, 10577, 12348, 28329, 10990, 10250, 10283, 18435, 13078, 17788, 10288, 10792, 14931, 12314, 10267, 14610, 19137, 17193, 12231, 12268, 12182, 15540, 12549, 19137, 10974, 11416, 11687, 10258, 28329, 10250, 13054, 17237, 17213, 12299, 11638, 14734, 18256, 13764, 10838, 11461, 19137, 10659, 15471, 10511, 10423, 10281, 11645, 12631, 13191, 14734, 15326, 17160, 12527, 19137, 12334, 14781, 12549, 10258, 13234, 10080, 15646, 11454, 14931, 12314, 10267, 14610, 19137, 18256, 13764, 15190, 14781, 11632, 10792, 10333, 10398, 10370, 11995, 11992, 14734, 11459, 13582, 19137, 17148, 12522, 11110, 14808, 12307, 17093, 17086, 14734, 18431, 15898, 13123, 10659, 13857, 11047, 14817, 13370, 10285, 14734, 11638, 11459, 13064, 19137, 11885, 10423, 10621, 12428, 10370, 14734, 14299, 12678, 15880, 13947, 13283, 19137, 12609, 15643, 12750, 14240, 13279, 10349, 10370, 14734, 16735, 13764, 19137, 16974, 17389, 15898, 14734, 15294, 13823, 12143, 10260, 11632, 28329, 11885, 10260, 15326, 10260, 12549, 11459, 11567, 14015, 13748, 16790, 19137, 11454, 12034, 12073, 17734, 11539, 15043, 19137, 14221, 11044, 13234, 10792, 9822, 11639, 12010, 43279, 9816, 17148, 13091, 10250, 12232, 18216, 17209, 10917, 15963, 17384, 14734, 14140, 15898, 14869, 12079, 19137, 12182, 12201, 16443, 15526, 15898, 14734, 10720, 12007, 16505, 14765, 19137, 13052, 13091, 14931, 12314, 10267, 14610, 14734, 10285, 17090, 19137, 10322, 13091, 16739, 14987, 14734, 12010, 12631, 10080, 11454, 17148, 17384, 19137, 13123, 10659, 16948, 11007, 16948, 18216, 19137, 15480, 10339, 12100, 11556, 10258, 13234, 19137, 13503, 12653, 16223, 11454, 10720, 12079, 10305, 11044, 14734, 11638, 11459, 19137, 10621, 12140, 11638, 14734, 13849, 11248, 10250, 13324, 12586, 13001, 19137, 11687, 11639, 18385, 15488, 15880, 12457, 13051, 11610, 12445, 28329, 17148, 13091, 11454, 10790, 14734, 10267, 14610, 17384, 15498, 11957, 13051, 15545, 12348, 16519, 14734, 13126, 16803, 28329, 12307, 14221, 19137, 10790, 14734, 10267, 14610, 10260, 13091, 14597, 11412, 11647, 12140, 16803, 12646, 14808, 15091, 16948, 13051, 12002, 13085, 15090, 14734, 19137, 13179, 10260, 12368, 16735, 11638, 16803, 15847, 12144, 17147, 15126, 11454, 10250, 11016, 12140, 18492, 14734, 11613, 10257, 10080, 10390, 14734, 43275, 12609, 15643, 13326, 12797, 11013, 10250, 10283, 11871, 13818, 14734, 14389, 13827, 19137, 11684, 14734, 43275, 11043, 11860, 13091, 11638, 17777, 11436, 11416, 19152, 10390, 43275, 10322, 11021, 15752, 13091, 11684, 43275, 12202, 17916, 12985, 10336, 14734, 10293, 16530, 19137, 10444, 15957, 16503, 14486, 16533, 14931, 12314, 10267, 14610, 19137, 12605, 10402, 12368, 18001, 13078, 14731, 10390, 43275, 12609, 15643, 11684, 43275, 14734, 14914, 11861, 11454, 19137, 11861, 11454, 10339, 12631, 13191, 14734, 14873, 15758, 10079, 17086, 13772, 11124, 17194, 14328, 10293, 10432, 17194, 14734, 10901, 14869, 10305, 10258, 10080, 19133, 17148, 10447, 17194, 14328, 10293, 12604, 11639, 13051, 12631, 10336, 10336, 19137, 11016, 14862, 17222, 12332, 15641, 11011, 11871, 11920, 14734, 15763, 11855, 17384, 11564, 17149, 10349, 10617, 14172, 11855, 19137, 16672, 10390, 10402, 12366, 14189, 12522, 10328, 10080, 19134, 11, 13078, 13085, 12140, 18492, 11638, 17777, 11436, 11416, 19137, 14598, 14198, 10727, 15489, 10339, 18492, 11613, 10305, 10257, 19137, 17800, 13085, 14614, 10258, 13018, 13018, 16109, 14670, 19137, 13085, 17781, 11982, 11514, 10384, 17038, 13039, 18052, 18161, 15646, 17141, 10080, 11638, 17777, 11436, 11416, 19137, 10994, 14806, 13191, 11687, 11011, 15640, 14734, 13849, 13793, 19137, 11638, 15763, 10411, 10459, 10250, 14313, 11638, 17782, 19137, 12522, 16696, 10621, 17725, 10364, 14734, 11975, 10720, 12132, 15880, 15091, 16403, 10687, 10285, 10080, 11638, 17777, 11436, 11416, 19137, 15540, 15540, 12714, 14808, 12476, 10429, 14734, 11638, 18319, 11124, 15604, 13085, 12642, 14952, 14734, 18492, 14598, 19137, 15727, 16875, 14808, 14931, 12314, 10267, 14610, 14734, 17385, 17387, 19137, 11454, 17607, 13748, 14734, 11633, 12192, 10305, 10258, 17017, 16971, 15646, 16403, 10080, 10267, 14610, 15880, 12140, 11638, 10080, 13064, 17734, 15880, 11011, 15640, 10080, 14882, 11473, 15880, 15648, 12366, 28329, 10336, 11903, 10257, 19137, 11190, 11871, 11920, 10402, 17311, 12878, 17631, 10333, 10080, 11638, 17777, 11436, 11416, 10687, 11903, 16525, 12348, 12771, 10361, 11002, 28329, 11454, 13006, 10283, 11887, 11898, 10285, 19137, 11016, 13191, 11638, 17777, 11436, 11416, 14862, 17222, 15847, 12144, 15087, 15130, 16503, 10257, 11187, 10650, 10985, 28329, 12307, 14221, 19137, 11190, 11871, 11920, 10402, 12145, 15486, 15931, 10333, 11685, 10745, 10283, 10267, 15453, 13234, 10335, 16686, 11638, 17777, 11436, 11416, 11021, 15752, 10423, 10985, 11187, 10650, 19137, 12202, 10265, 12182, 12182, 11908, 15044, 15847, 12144, 17916, 12182, 12701, 12366, 19137, 12701, 12366, 13679, 17150, 10322, 12664, 10260, 10760, 15178, 13336, 10080, 65530, 65532, 17148, 13619, 12847, 10708, 13191, 10373, 10303, 14332, 14172, 19156, 11, 65535, 261, 65530, 65534, 17148, 13619, 12847, 10708, 14734, 10293, 16503, 14332, 14172, 11687, 10258, 59, 11, 50, 47, 33, 11932, 10339, 12509, 16803, 10080, 12847, 17162, 10333, 10250, 10283, 11656, 12206, 14734, 10267, 14610, 45, 13191, 14931, 12314, 14734, 10267, 14610, 45, 13191, 12140, 11638, 14734, 11412, 11647, 12140, 16803, 12646, 14808, 17148, 10283, 10267, 14610, 15091, 16948, 13085, 15090, 45, 17147, 13191, 10250, 10283, 12140, 18492, 15727, 16875, 14808, 17148, 10283, 10267, 14610, 10080, 17148, 15033, 15261, 10441, 14987, 16713, 10427, 16735, 10285, 14734, 10267, 14610, 16689, 15586, 16672, 13006, 10283, 12985, 10336, 12172, 13234, 14987, 15036, 12527, 28329, 51, 47, 33, 14589, 13819, 14607, 10925, 10295, 14734, 16728, 16537, 10080, 13012, 11860, 11932, 10339, 16708, 12522, 45, 14589, 12337, 11632, 13637, 11285, 12847, 10708, 45, 13637, 11687, 9822, 10621, 12428, 10370, 14734, 14299, 12678, 15880, 13947, 13283, 45, 12609, 15643, 12750, 14240, 13279, 10349, 10370, 14734, 16735, 13764, 45, 16974, 17389, 15898, 14734, 15294, 13823, 12143, 10260, 11632, 9823, 10080, 9822, 11687, 11639, 18385, 15488, 15880, 12457, 13051, 11610, 12445, 9823, 15169, 15169, 28329, 52, 47, 33, 13191, 15957, 17820, 15957, 14446, 14734, 12208, 18441, 10080, 10460, 15643, 13734, 13191, 14781, 12824, 16735, 10760, 12140, 18492, 14734, 12415, 10790, 45, 15646, 13091, 16417, 14966, 9822, 13326, 12797, 11013, 10250, 10283, 11871, 13818, 14734, 14389, 13827, 9823, 11124, 9822, 10390, 43275, 10322, 11021, 15752, 13091, 11684, 9823, 10080, 17147, 16735, 17194, 14328, 10293, 9822, 12604, 11639, 13051, 12631, 10336, 10336, 45, 11016, 14862, 17222, 12332, 15641, 11011, 11871, 11920, 14734, 15763, 11855, 17384, 11564, 17149, 10349, 10617, 14172, 11855, 9823, 28329, 53, 47, 33, 11957, 11638, 17777, 11436, 11416, 14734, 12847, 10708, 12337, 16884, 12527, 10080, 17189, 17141, 11957, 11638, 17777, 11436, 11416, 18492, 11613, 10079, 10994, 14806, 10079, 11638, 15763, 10079, 12522, 16696, 15169, 14734, 12847, 17162, 45, 16742, 15643, 15752, 12314, 12604, 10250, 10283, 14583, 10846, 14734, 10688, 10452, 12314, 16803, 28329, 54, 47, 33, 11932, 13191, 11190, 14486, 10080, 17189, 17141, 11957, 11190, 11871, 11920, 14734, 16694, 16686, 45, 10460, 15643, 12857, 14966, 10333, 10370, 14734, 12005, 17789, 11124, 11021, 15149, 45, 12753, 15958, 10370, 10402, 12421, 13091, 11454, 10335, 16686, 11124, 12701, 12366, 10954, 12332, 12332, 12664, 10260, 10760, 14794, 14782, 28329, 17148, 13619, 12847, 10708, 17379, 14589, 10333, 12509, 16803, 10286, 11932, 14734, 11656, 12206, 16689, 11899, 10079, 10925, 10295, 14734, 16728, 16537, 10079, 15092, 10760, 14734, 12208, 18441, 12527, 10079, 10688, 10452, 14734, 12314, 16803, 10399, 10992, 12753, 15958, 10370, 14734, 11190, 14486, 45, 15494, 10370, 14614, 10258, 13913, 10799, 14734, 10951, 16803, 10080, 65535, 261, 10258, 17919, 17148, 13619, 13091, 11001, 15847, 9822, 14931, 12314, 10267, 14610, 9823, 14734, 11975, 16735, 14734, 14313, 13619, 28329, 14136, 19137, 14190, 17149, 10333, 10994, 11517, 11889, 15034, 2453, 16050, 13770, 10660, 10080, 14136, 15950, 16535, 10992, 18256, 13764, 16099, 11459, 19137, 14179, 14218, 10339, 13091, 11086, 14446, 10760, 16155, 15898, 11124, 15526, 15898, 19137, 14581, 15849, 11656, 17167, 15880, 11459, 17725, 10760, 12172, 13191, 10253, 12319, 10305, 11630, 9822, 15162, 10677, 15898, 9823, 14734, 14136, 15931, 19152, 14136, 15863, 13755, 14808, 11221, 10270, 16407, 10250, 16981, 15104, 11047, 10609, 13750, 15572, 19137, 14136, 14218, 10339, 13091, 13655, 10859, 18216, 13877, 19137, 10411, 10459, 17725, 15639, 14734, 14136, 11282, 13759, 19137, 9822, 11381, 11237, 9823, 14171, 11168, 19152, 14136, 14218, 14190, 10792, 18119, 16218, 12223, 17609, 12631, 11454, 14734, 16407, 17222, 19137, 11638, 14136, 10339, 13091, 10997, 10760, 17774, 17774, 14582, 18119, 19152, 11638, 14136, 14272, 14808, 10333, 16030, 12223, 10609, 16223, 11909, 17384, 12199, 14280, 14734, 14460, 11656, 16030, 16002, 19137, 10370, 10402, 10339, 13091, 13655, 12348, 10997, 14652, 19137, 12266, 11010, 11217, 18175, 14987, 13078, 28329, 13581, 13064, 19137, 16050, 13770, 10660, 11517, 14734, 11221, 10270, 10912, 12145, 13091, 10250, 14313, 14136, 13849, 10080, 11013, 10250, 15137, 14734, 11889, 15034, 11517, 17384, 19137, 13191, 17558, 13191, 17038, 10410, 14734, 12010, 13653, 15465, 15465, 16403, 10846, 19137, 13644, 10260, 12636, 17086, 19137, 14652, 14356, 11459, 12702, 16944, 13352, 13234, 10080, 10444, 13091, 19137, 16050, 13770, 10660, 15887, 11478, 17384, 17268, 10349, 14015, 17095, 16790, 14328, 10079, 13384, 15931, 11124, 13202, 13223, 14734, 15878, 15887, 19137, 16417, 17919, 13852, 14808, 14216, 13750, 19137, 13057, 12145, 14175, 14267, 16944, 13234, 10080, 13760, 11459, 14190, 12604, 10333, 14140, 14194, 19137, 10250, 15891, 15891, 14136, 15887, 16945, 14808, 17170, 14066, 19137, 13755, 14808, 11889, 15034, 13748, 11047, 11638, 13849, 14030, 10985, 19137, 10411, 10459, 13996, 13676, 14734, 16098, 14136, 16263, 19137, 10250, 16981, 14172, 14267, 13755, 12061, 14734, 11913, 13624, 11124, 13224, 14970, 10080, 14136, 13085, 17819, 18043, 18048, 10792, 12061, 10257, 19137, 12640, 11047, 17150, 11621, 13913, 16223, 14734, 15931, 11423, 11124, 16002, 12015, 28329, 14179, 14218, 14583, 10760, 13833, 14187, 10254, 10255, 19137, 10411, 10459, 10250, 13326, 14356, 18043, 10956, 12604, 14734, 18438, 13295, 19137, 10953, 10511, 15126, 11454, 14931, 12314, 10267, 14610, 14734, 11013, 10250, 15137, 19137, 10322, 15752, 14791, 10283, 10250, 13923, 10337, 13425, 28329, 15957, 11454, 10745, 17384, 10305, 11630, 17773, 10735, 12208, 13146, 14734, 12034, 17997, 11471, 16520, 17148, 17774, 10859, 19137, 12527, 16525, 12368, 13091, 12647, 10370, 12366, 12290, 10080, 13581, 13064, 13580, 13191, 17148, 10303, 10278, 10447, 19137, 14791, 12348, 10685, 11110, 14759, 14221, 28329, 10687, 10285, 18216, 10283, 11855, 14734, 17268, 10447, 10561, 14808, 10250, 12669, 16956, 13191, 10250, 10370, 18216, 14734, 10811, 15126, 14808, 19137, 13580, 11638, 11401, 18363, 15809, 10080, 16503, 10260, 13091, 14791, 10390, 17181, 14808, 10250, 15706, 13212, 16650, 15678, 12551, 14734, 14141, 13655, 19137, 16519, 10333, 17148, 10588, 13818, 19137, 16747, 17311, 10423, 10399, 10292, 17148, 13091, 10384, 10285, 17090, 11459, 16009, 10974, 13234, 14734, 17386, 16306, 10370, 28329, 11013, 10250, 10447, 13098, 12348, 14867, 12348, 11632, 19137, 10384, 11647, 10792, 15768, 17311, 16136, 11454, 13388, 15898, 13020, 15232, 17384, 10080, 10594, 11979, 15053, 10846, 10250, 10846, 13064, 19137, 10846, 10460, 10305, 17093, 14352, 11687, 14398, 11145, 17004, 13582, 28329, 10305, 10808, 14734, 10337, 10917, 10768, 17544, 17384, 19137, 17148, 10278, 10447, 10745, 10308, 18441, 10260, 10460, 11610, 19137, 11016, 13191, 10250, 13619, 15190, 14866, 13051, 13258, 14734, 10335, 16686, 19137, 10336, 10684, 14136, 13849, 10285, 14734, 10250, 17774, 14388, 14179, 14288, 14171, 10792, 12221, 10997, 14583, 11454, 11861, 13750, 16883, 13309, 17147, 13091, 11454, 12142, 11606, 10660, 16052, 10936, 11979, 14734, 10460, 11467, 10080, 10278, 10370, 10292, 13581, 10258, 10333, 16915, 13773, 28329, 18216, 10283, 11855, 11219, 11891, 18363, 19137, 12669, 18200, 11647, 12643, 11454, 16002, 10271, 17384, 19137, 15149, 17384, 12172, 14808, 12409, 12474, 43899, 17268, 10349, 11975, 12148, 11855, 17311, 13626, 10333, 43282, 9823, 11, 10390, 16735, 19137, 9822, 12605, 12771, 11268, 13558, 11885, 10402, 14734, 10080, 9823, 11, 9822, 17147, 13191, 17268, 10349, 11902, 12219, 43282, 9823, 14867, 10283, 11855, 12509, 10333, 12509, 19137, 10990, 16416, 10333, 10250, 11012, 19137, 9822, 11902, 14869, 11021, 14267, 10303, 19156, 11065, 16735, 11885, 10402, 16974, 14237, 12143, 10260, 11632, 13091, 10250, 15261, 10272, 16501, 10080, 9823, 11, 9822, 12631, 13191, 17389, 11855, 19137, 17311, 14252, 10333, 19137, 18000, 14808, 13733, 13485, 13819, 13893, 10080, 9823, 11638, 10283, 11855, 16735, 14808, 19137, 13734, 13191, 14486, 10423, 14867, 10283, 11855, 14734, 17728, 18025, 19137, 9822, 12631, 13191, 15597, 17335, 19137, 17311, 11454, 13357, 17384, 13749, 15808, 10333, 10080, 9823, 11, 9822, 17147, 13191, 15640, 18459, 10080, 9823, 10250, 17038, 13388, 16435, 14734, 11042, 10437, 16735, 28329, 9822, 15640, 18459, 19137, 16735, 12348, 11957, 10080, 9823, 11, 9822, 14768, 11627, 13064, 15907, 19137, 13734, 11459, 13036, 11021, 17173, 10080, 9823, 11, 9822, 11042, 13324, 16735, 12348, 11957, 10080, 10444, 19137, 12421, 13091, 16525, 12348, 43282, 11315, 43282, 17148, 10423, 10650, 43282, 9823, 11, 10390, 11155, 10258, 13734, 16735, 11891, 14734, 16713, 19137, 17819, 10953, 12791, 10257, 17093, 12387, 14734, 11010, 13655, 43899, 12605, 10402, 17147, 13556, 9819, 15446, 13676, 16305, 9820, 17268, 10650, 14734, 15640, 12283, 16052, 11632, 10677, 10283, 17607, 12153, 11187, 10080, 9823, 14867, 10283, 11855, 14172, 10333, 14172, 11647, 28329, 10278, 10283, 10370, 10703, 13557, 18441, 10260, 10460, 11610, 10080, 11454, 17148, 12232, 13188, 11638, 14734, 11517, 12154, 11984, 13203, 16944, 14136, 14734, 11459, 13036, 19137, 10990, 10250, 17085, 14288, 14171, 12266, 11726, 10333, 19137, 11454, 11633, 12192, 10257, 14267, 16944, 10250, 17222, 15446, 10659, 28329, 18216, 10283, 11855, 10997, 16713, 10333, 43899, 18460, 11855, 43900, 11, 9822, 12469, 16735, 10080, 9823, 11, 9822, 12605, 12509, 14862, 17222, 13091, 16747, 12983, 14734, 14136, 10080, 9823, 11, 17148, 10283, 16443, 11206, 10460, 9822, 18460, 11855, 9823, 14734, 14867, 10283, 11855, 10811, 12636, 13734, 12220, 11610, 10080, 10390, 13580, 14791, 14808, 14136, 10659, 13086, 15446, 14734, 11638, 16981, 10080, 16981, 10257, 10250, 14781, 13734, 10373, 10303, 10370, 19137, 11416, 10292, 17159, 11672, 14524, 11517, 17723, 13091, 15162, 10250, 12662, 14190, 13626, 14734, 12261, 15176, 10080, 14249, 14249, 14267, 14190, 14734, 13359, 13295, 17865, 14172, 15880, 16109, 11459, 19137, 11517, 17723, 11994, 13581, 11468, 11556, 10080, 65530, 65532, 10257, 13012, 10760, 14446, 10333, 10745, 10283, 16530, 15898, 19156, 10390, 10402, 14734, 14332, 14172, 17311, 13091, 10373, 10303, 19156, 11, 65535, 261, 65530, 65534, 13326, 12797, 10257, 10258, 13012, 45, 14791, 13234, 17148, 12220, 16721, 13091, 10258, 17919, 10745, 10283, 16530, 15898, 59, 11, 50, 47, 33, 18216, 10283, 11855, 14734, 10811, 11606, 59, 10390, 10283, 11855, 18216, 11638, 45, 10296, 13579, 15269, 14350, 45, 10621, 10283, 17386, 16306, 10370, 45, 10444, 15752, 16520, 11940, 10792, 10390, 12366, 14141, 14141, 12990, 10080, 10390, 11957, 14894, 11470, 12527, 10792, 13191, 10349, 12476, 11158, 28329, 51, 47, 33, 14867, 10283, 11855, 41, 18460, 11855, 501, 10390, 13006, 10283, 10370, 17311, 16468, 11454, 13020, 15232, 17384, 45, 10846, 10460, 17093, 12139, 11687, 14398, 10080, 10390, 14734, 16713, 16728, 17097, 11977, 45, 10444, 12410, 15516, 12990, 12802, 28329, 52, 47, 33, 17147, 13191, 16443, 12642, 16954, 15640, 12283, 16052, 11632, 45, 10441, 10308, 13091, 10390, 10402, 13556, 13567, 14734, 10370, 28329, 53, 47, 33, 11013, 11630, 17147, 12848, 10792, 10333, 11889, 15034, 11517, 11124, 16050, 13770, 10660, 11517, 45, 10399, 10992, 10660, 16052, 10936, 11979, 15169, 10370, 10080, 10444, 11016, 11860, 13203, 16519, 10390, 10402, 14734, 14332, 14172, 28329, 12421, 15489, 10250, 10258, 19137, 17148, 13619, 13012, 11860, 10293, 16503, 12847, 17162, 14734, 13091, 10278, 10283, 16520, 13197, 11638, 14136, 14734, 10370, 14328, 10080, 18216, 10283, 11855, 10811, 11606, 16417, 14446, 10760, 13913, 12410, 11124, 11158, 12409, 10305, 12366, 45, 14867, 10283, 11855, 18460, 11855, 10779, 13078, 13098, 13179, 10726, 17912, 45, 12990, 12802, 28329, 11454, 12605, 14791, 13234, 45, 10390, 10402, 14734, 14332, 14172, 17311, 13091, 59, 12410, 15516, 12990, 12802, 10079, 16537, 16728, 11977, 10080, 10444, 18216, 10283, 11855, 10811, 11606, 12202, 10260, 15568, 10309, 12527, 12415, 11124, 10452, 16895, 10305, 12366, 10080, 65535, 261, 65530, 65532, 10464, 13179, 11268, 13558, 11187, 10283, 16530, 15898, 19156, 33, 10292, 10373, 10303, 19156, 11, 65535, 261, 65530, 65534, 13326, 12797, 10278, 10447, 16530, 15898, 14734, 12847, 17162, 45, 12605, 13179, 11268, 13558, 18216, 10283, 11855, 14734, 10811, 11606, 10080, 14486, 14597, 10293, 16503, 13191, 10399, 10258, 10745, 14172, 59, 11, 50, 47, 33, 10390, 12410, 15516, 14141, 12990, 45, 11042, 13064, 10692, 13191, 12527, 12415, 10080, 10390, 11957, 14894, 11470, 12527, 10792, 12476, 11158, 45, 17148, 13098, 14966, 10333, 10390, 13191, 13947, 12484, 11124, 11255, 15895, 28329, 51, 47, 33, 10390, 17038, 10292, 18216, 11638, 14734, 10811, 11606, 45, 10444, 10296, 13579, 15269, 14350, 10621, 17386, 16306, 10370, 45, 10954, 15752, 16520, 11940, 10792, 10390, 10696, 12366, 14734, 15287, 11701, 10080, 17148, 15033, 11630, 16417, 10261, 10696, 13325, 14734, 10995, 12143, 16672, 10370, 12527, 10685, 16954, 28329, 52, 47, 33, 10390, 18200, 11855, 17384, 17147, 12172, 13191, 15478, 15806, 11124, 10452, 16895, 10080, 13637, 11687, 10390, 11957, 11517, 12154, 14734, 11975, 12148, 11855, 10997, 15847, 10696, 12366, 14734, 11268, 14299, 45, 10399, 10992, 10684, 13773, 15597, 17335, 11124, 15640, 18459, 14734, 11117, 17144, 10080, 17148, 10349, 15478, 13259, 13204, 15907, 10995, 12220, 10760, 10390, 11957, 14583, 13815, 14734, 11268, 14299, 10261, 14195, 14299, 28329, 53, 47, 33, 14782, 13637, 10305, 10258, 45, 14867, 10283, 11855, 18460, 11855, 12527, 16525, 13179, 10842, 13212, 13133, 10444, 10726, 13903, 10080, 10390, 14734, 16713, 16728, 17097, 11977, 45, 12410, 15516, 12990, 12802, 10444, 15568, 11977, 12527, 12415, 10080, 13006, 10452, 13234, 16735, 15568, 10309, 18216, 10283, 11855, 10811, 11606, 17268, 10410, 13947, 12484, 28329, 12605, 16525, 12348, 45, 18216, 10283, 11855, 10811, 11606, 10692, 13191, 10696, 11454, 13133, 12551, 10079, 11630, 16417, 15269, 14350, 10079, 12527, 12415, 13947, 13283, 15169, 11632, 17385, 12415, 13327, 45, 13179, 15158, 11038, 12605, 14486, 12509, 10285, 14734, 16530, 15898, 12314, 16803, 10080, 10390, 11630, 16417, 14791, 10441, 15269, 14350, 10444, 10696, 12366, 15478, 15806, 45, 10452, 14446, 10333, 11626, 13215, 12415, 13327, 14734, 18248, 10838, 10080, 65535, 261, 65530, 65532, 10988, 15641, 10257, 17919, 14931, 12314, 10267, 14610, 14734, 14313, 13619, 19137, 10384, 10464, 14734, 16678, 12369, 17384, 12664, 10760, 10250, 13619, 15261, 10441, 14734, 11, 65535, 261, 65530, 65534, 13326, 12797, 10464, 12848, 10494, 14734, 14931, 12314, 10267, 14610, 14313, 13619, 45, 11885, 12847, 17162, 14734, 13091, 10250, 11461, 12140, 11638, 14734, 14136, 14146, 45, 10399, 10992, 10278, 11043, 16520, 13197, 11638, 14136, 14734, 10370, 14328, 10080, 17148, 16672, 12605, 12509, 10792, 10333, 10086, 11164, 11723, 17875, 14332, 10087, 17384, 13561, 12283, 13326, 16443, 14213, 14190, 14734, 11461, 13126, 28329, 11454, 11672, 16081, 10788, 10348, 17043, 10258, 10260, 10301, 10305, 11044, 45, 13561, 12283, 13326, 11994, 12172, 14808, 16684, 11632, 15874, 15643, 11124, 11269, 17335, 14734, 10370, 17729, 10673, 15874, 11022, 45, 17343, 14607, 11459, 14442, 10310, 16114, 10080, 11164, 11723, 17875, 14332, 12669, 10390, 11206, 10760, 13234, 45, 12857, 17900, 10390, 10260, 10768, 11461, 11038, 11459, 15463, 12484, 11610, 15898, 45, 10339, 13091, 11164, 11723, 17875, 14332, 14190, 10333, 10390, 14734, 15874, 11022, 28329, 13581, 13064, 45, 15874, 11022, 14213, 14190, 14734, 14136, 14218, 11454, 18438, 13146, 10285, 12719, 12894, 15639, 14806, 45, 12719, 13234, 16520, 10420, 14734, 11685, 11656, 59, 11, 9822, 14791, 11223, 45, 10442, 14434, 15658, 14508, 14267, 14190, 14734, 14152, 14142, 45, 10390, 17268, 12359, 15149, 14734, 11872, 11855, 45, 13561, 12283, 13326, 16443, 14179, 14136, 14144, 14190, 60, 14791, 14267, 14190, 14734, 14136, 14218, 10721, 10257, 11639, 15090, 45, 10621, 14141, 18245, 14975, 13685, 11885, 13034, 14734, 12010, 12631, 10080, 9823, 11, 15874, 11022, 10257, 14734, 14136, 10659, 11124, 13561, 12283, 13326, 14734, 17237, 17213, 45, 16672, 11164, 11723, 17875, 14332, 11105, 11430, 14734, 10370, 10260, 15002, 16676, 16686, 15465, 15465, 45, 10687, 10285, 18216, 10283, 14734, 12283, 13196, 16501, 13033, 15034, 11994, 16694, 16686, 17222, 23334, 11885, 10364, 12348, 11632, 10303, 15639, 14806, 11223, 23251, 11, 12421, 14734, 13234, 16735, 45, 17148, 10278, 13619, 13012, 11860, 14735, 10399, 11649, 12287, 14734, 14136, 10659, 10460, 10292, 13655, 13660, 14734, 10781, 17194, 45, 17181, 17141, 10370, 10402, 14734, 16520, 12527, 11124, 11957, 10687, 10260, 11042, 12527, 11002, 45, 12847, 15493, 10760, 10260, 11042, 12484, 12527, 28329, 10260, 11042, 11454, 10339, 10086, 14931, 12314, 10267, 14610, 10087, 13179, 10684, 13773, 14637, 15023, 16520, 13197, 14734, 12366, 12396, 45, 15646, 10086, 11164, 11723, 17875, 14332, 10087, 10779, 13179, 10688, 12603, 10821, 12986, 13258, 45, 12299, 16749, 14136, 14218, 11454, 15874, 11022, 10257, 14734, 12522, 10304, 10080, 10278, 10283, 12985, 10336, 14734, 14216, 14172, 10322, 10260, 12002, 14782, 11042, 28329, 10444, 10460, 10292, 10278, 13619, 12847, 17162, 14136, 14218, 10261, 10370, 12527, 11002, 12202, 11861, 14734, 13012, 11860, 45, 12421, 10452, 17147, 13091, 13191, 14782, 17189, 10305, 11621, 14734, 10080, 65535, 261, 65530, 65532, 12631, 10399, 10464, 10684, 13773, 14734, 13179, 11632, 14734, 13091, 14136, 14218, 11957, 10260, 11957, 19156, 11, 65535, 261, 65530, 65534, 12469, 12748, 10760, 12605, 10441, 10308, 13179, 10684, 13773, 17148, 10278, 13619, 13012, 11860, 10285, 14136, 14218, 14734, 12847, 17162, 45, 17148, 10441, 10308, 11021, 10399, 10995, 13086, 10760, 12605, 11957, 13012, 11860, 14734, 10250, 10349, 10585, 18012, 10080, 11042, 12522, 12469, 14734, 16520, 11940, 45, 12605, 14734, 14914, 11957, 14136, 14218, 14734, 12847, 10708, 13637, 17097, 13191, 10685, 16954, 10080, 10444, 12605, 12509, 12299, 16749, 14734, 13091, 59, 11, 50, 47, 33, 14136, 14218, 11016, 13091, 17148, 10278, 13619, 13012, 11860, 10799, 14604, 13660, 11430, 11124, 12484, 12527, 14734, 10250, 10283, 16803, 12333, 12636, 13619, 45, 15646, 10260, 13091, 12605, 10684, 13773, 14734, 14216, 14172, 10080, 12605, 13179, 10578, 11047, 10339, 10684, 13773, 14136, 14218, 15727, 11044, 10758, 13098, 10760, 14734, 10370, 14328, 12527, 11002, 11124, 10460, 15643, 12522, 11436, 28329, 51, 47, 33, 13637, 17097, 10278, 13619, 13012, 11860, 14734, 10260, 11042, 10482, 14589, 14136, 10659, 12636, 13764, 45, 13179, 15752, 10758, 13098, 10278, 10447, 10460, 15643, 10260, 11042, 14734, 12847, 10708, 18043, 13327, 11124, 12985, 10336, 10283, 12415, 10080, 17148, 13091, 12605, 13637, 17097, 13191, 10685, 16954, 10768, 13254, 14734, 28329, 52, 47, 33, 10370, 14328, 12527, 11002, 11124, 12484, 12527, 12220, 16721, 10260, 10348, 10339, 14136, 14218, 13205, 17038, 10080, 14136, 14218, 12847, 10708, 13179, 11632, 13091, 10292, 10333, 17363, 14778, 11459, 16698, 16735, 10370, 14328, 10696, 12366, 11124, 16417, 17136, 10460, 15643, 12509, 13764, 28329, 12421, 14734, 13234, 16735, 45, 10460, 10292, 10250, 10283, 12985, 10336, 16503, 15323, 45, 14136, 14218, 14914, 11903, 12348, 10792, 10333, 12605, 13637, 17097, 11632, 14734, 10684, 13773, 10080, 10444, 12605, 13179, 17385, 16523, 14734, 13091, 11885, 15727, 11044, 12631, 10758, 13098, 14734, 10370, 13012, 12522, 10304, 28329, 14136, 14218, 11016, 10260, 17141, 13091, 10250, 10283, 11805, 10382, 45, 15752, 17189, 17141, 11885, 12847, 15493, 10760, 13179, 10292, 18302, 13815, 14734, 10370, 14328, 12366, 14141, 10261, 10267, 14610, 16520, 28329, 12605, 14734, 10684, 13773, 14172, 17848, 10285, 11454, 10278, 10283, 13036, 17919, 59, 11, 10250, 13091, 10370, 14328, 12527, 11002, 17148, 10250, 12007, 17919, 45, 14136, 10659, 15727, 11044, 10758, 13098, 14734, 13091, 10260, 11042, 10370, 11957, 13581, 14734, 12527, 11002, 11124, 10995, 12220, 28329, 10337, 13091, 10460, 15643, 12636, 13764, 10261, 10283, 12415, 45, 10460, 15643, 17189, 17141, 10260, 11042, 13036, 12276, 10482, 14589, 14136, 10659, 45, 12022, 14446, 10760, 10283, 10370, 14734, 16728, 16537, 18043, 13327, 28329, 17148, 10278, 13036, 17919, 13179, 15752, 10452, 14446, 10460, 15643, 15904, 13208, 14589, 12522, 45, 13091, 12605, 13179, 12527, 10685, 16954, 10768, 13254, 10261, 13559, 16917, 14734, 10080, 65535, 261, 65530, 65532, 11957, 13637, 10086, 15597, 11435, 10420, 14987, 10087, 17148, 17303, 11975, 16735, 12848, 10494, 14734, 14987, 11871, 16803, 12333, 19137, 33, 12605, 10402, 15752, 10384, 10086, 14931, 12314, 10267, 14610, 10087, 17148, 17303, 11975, 16735, 17384, 17919, 12848, 11001, 10792, 17268, 10349, 16803, 12333, 12522, 10304, 14734, 10272, 16501, 19156, 11, 65535, 261, 65530, 65534, 11454, 11414, 15178, 17148, 10283, 17728, 18025, 10305, 10808, 45, 12605, 12509, 12299, 16749, 14734, 13091, 10260, 11042, 10460, 11159, 14734, 16803, 12333, 11064, 10304, 13091, 11036, 10260, 14782, 11042, 14734, 45, 10399, 10258, 13091, 12605, 11957, 10086, 14931, 12314, 10267, 14610, 10087, 17148, 17303, 11975, 16735, 14734, 10250, 10349, 16803, 12333, 16533, 16742, 59, 11, 50, 47, 33, 14931, 12314, 10267, 14610, 13205, 17038, 11994, 13091, 10250, 10283, 12299, 11638, 14734, 16803, 12333, 10080, 11885, 10397, 16417, 10460, 15643, 12509, 16803, 10838, 14734, 13051, 17789, 45, 16982, 10760, 14371, 11975, 14734, 14446, 11903, 13499, 11496, 28329, 51, 47, 33, 11888, 11633, 10370, 11124, 11888, 11633, 11691, 10370, 16803, 12333, 14808, 15516, 12746, 15042, 12217, 14734, 10838, 17387, 45, 10397, 16417, 14486, 12415, 11124, 13133, 12551, 28329, 52, 47, 33, 14320, 11647, 10370, 16803, 12333, 14808, 10974, 11726, 14734, 17386, 16306, 10838, 17387, 45, 17820, 11285, 10370, 12415, 10285, 11626, 13215, 14734, 10278, 17919, 12415, 28329, 53, 47, 33, 18256, 12996, 16803, 12333, 14808, 17271, 12449, 11124, 16009, 16783, 45, 10444, 10322, 12848, 17363, 12605, 10402, 12200, 16412, 13091, 17385, 16503, 14734, 28329, 54, 47, 33, 13042, 15052, 13205, 17038, 11994, 13091, 10250, 10283, 16803, 12333, 45, 10397, 16417, 10370, 14734, 12604, 17688, 11124, 16525, 17363, 28329, 55, 47, 33, 10260, 11042, 15033, 13046, 16803, 12333, 14808, 10370, 12415, 10285, 14734, 11036, 10283, 17919, 11047, 45, 12605, 10402, 17879, 16503, 13006, 11038, 11885, 10402, 12638, 15752, 16056, 12348, 12200, 16412, 28329, 12421, 14734, 13234, 16735, 45, 10086, 14931, 12314, 10267, 14610, 10087, 12848, 10494, 14734, 16803, 12333, 12522, 10304, 13179, 11632, 11459, 12299, 16749, 10370, 12415, 14734, 11626, 13215, 11632, 13324, 45, 12200, 16412, 10838, 17387, 10305, 17734, 14734, 17385, 16503, 12415, 10080, 11885, 13191, 12522, 16696, 11459, 12822, 16671, 10370, 12415, 14734, 11632, 17919, 12415, 45, 18458, 10851, 12605, 10402, 16947, 16948, 14371, 17824, 14734, 12410, 15516, 13499, 12276, 28329, 10261, 10086, 15597, 11435, 10420, 14987, 10087, 10285, 14734, 14987, 11871, 16803, 12333, 14782, 13637, 45, 10086, 14931, 12314, 10267, 14610, 10087, 12848, 10494, 14734, 16803, 12333, 12522, 10304, 13179, 13773, 17385, 10696, 11454, 15287, 14987, 12007, 17919, 14734, 12822, 15325, 10080, 11885, 12299, 16749, 10452, 18183, 11124, 12509, 16803, 45, 16947, 15774, 10333, 10688, 10452, 14734, 14987, 16713, 11887, 11898, 10080, 65535, 261, 65530, 65532, 12848, 10494, 9822, 14931, 12314, 10267, 14610, 9823, 17148, 17303, 11975, 16735, 14734, 14782, 10684, 10529, 12445, 19137, 10894, 12732, 10460, 15643, 19137, 10926, 10460, 18043, 13327, 19137, 10384, 10250, 10283, 17189, 10522, 11975, 16735, 10460, 11920, 14734, 16530, 12231, 12664, 10760, 11885, 14734, 17725, 10659, 14172, 11124, 10260, 16956, 11, 65535, 261, 65530, 65534, 10086, 14931, 12314, 10267, 14610, 10087, 17148, 17303, 11975, 16735, 10688, 13191, 12337, 18216, 14734, 10781, 10460, 10408, 10577, 45, 10384, 17189, 10522, 11975, 16735, 14734, 16530, 12231, 13234, 10768, 13254, 59, 11, 9828, 10460, 15643, 59, 14332, 17384, 2453, 13125, 12705, 10769, 14332, 28329, 9828, 10926, 10460, 18043, 13327, 59, 12208, 18441, 18043, 16954, 45, 11268, 10821, 10653, 15323, 10286, 11932, 45, 12172, 13191, 15034, 12206, 11124, 11656, 12206, 15898, 12319, 28329, 9828, 17725, 10659, 14172, 59, 11, 50, 42, 10286, 11932, 14734, 12509, 16803, 10838, 45, 16689, 16664, 10333, 14370, 14332, 14734, 14931, 12314, 10267, 14610, 52865, 45, 10894, 12732, 11412, 10283, 11869, 15907, 11435, 12231, 10079, 17997, 15137, 14734, 13961, 13819, 10079, 10452, 17385, 11003, 17093, 14734, 14328, 14486, 11899, 12340, 15169, 28329, 51, 42, 10286, 11932, 13191, 16954, 14734, 10370, 14328, 12314, 16803, 45, 11687, 13594, 14987, 10079, 18256, 13764, 12158, 10079, 12142, 12158, 11871, 12345, 10079, 12632, 12200, 11459, 14484, 11871, 10423, 10293, 12175, 15169, 28329, 52, 42, 14442, 11110, 14734, 12208, 18441, 18043, 16954, 45, 16688, 10798, 14970, 10423, 14446, 11903, 28329, 9828, 10260, 16956, 59, 11, 50, 42, 11638, 17387, 14734, 10328, 12657, 14486, 16686, 11124, 11043, 16702, 45, 11021, 15752, 15568, 10309, 15326, 10740, 12527, 28329, 51, 42, 15092, 14894, 12182, 14486, 14734, 15034, 12206, 16689, 11899, 45, 11957, 10250, 15880, 16742, 15643, 11021, 15752, 17843, 10399, 12824, 11002, 28329, 9828, 12421, 10452, 13234, 16735, 59, 11, 16269, 14221, 13191, 10250, 10349, 15568, 14172, 45, 10444, 10086, 14931, 12314, 10267, 14610, 10087, 10954, 10752, 10563, 14370, 10781, 14734, 12509, 16803, 10079, 12208, 18441, 16710, 16760, 14734, 11639, 18157, 16403, 15090, 14734, 12484, 15907, 45, 10399, 10992, 14370, 14332, 14734, 10267, 14610, 16520, 45, 16056, 12348, 10333, 12210, 13766, 14734, 16742, 15643, 16667, 11021, 10080, 17148, 13580, 13091, 10250, 17303, 17189, 10522, 11975, 16735, 12631, 17879, 16503, 10692, 11622, 14734, 10653, 15323, 10080, 65535, 261, 65530, 65532, 12848, 10494, 9822, 14931, 12314, 10267, 14610, 9823, 15304, 10777, 14734, 10460, 15643, 11043, 15044, 11124, 10529, 12445, 10080, 33, 17147, 13191, 16721, 10460, 15643, 14734, 14782, 10684, 10460, 11159, 17848, 11, 65535, 261, 65530, 65534, 10086, 14931, 12314, 10267, 14610, 10087, 15304, 10777, 14734, 10460, 15643, 13091, 15963, 11435, 10460, 11920, 13778, 14523, 2453, 13125, 12705, 10769, 14332, 41, 6696, 2174, 20670, 2204, 7686, 117, 497, 10390, 10322, 13191, 10687, 10390, 16114, 11043, 14734, 15304, 10777, 10427, 11656, 10460, 11159, 28329, 10293, 16503, 10529, 12445, 59, 11, 9828, 33, 10460, 15643, 59, 13778, 14523, 2453, 13125, 12705, 10769, 14332, 41, 6696, 2174, 20670, 2204, 7686, 117, 497, 639, 668, 12201, 53, 13190, 648, 13053, 10760, 14583, 45, 640, 635, 12201, 52, 13190, 632, 13053, 10985, 10267, 28329, 9828, 33, 11435, 15252, 59, 15963, 11435, 10460, 11920, 11, 9828, 33, 10397, 16417, 10460, 59, 10086, 14931, 12314, 10267, 14610, 10087, 15304, 10777, 41, 23570, 36017, 42, 11975, 16735, 17848, 11, 9828, 33, 10687, 10390, 10460, 11159, 59, 10086, 6699, 28608, 1859, 44696, 10087, 15304, 10777, 10079, 10086, 6699, 49955, 50425, 21265, 21823, 28821, 24738, 20762, 25291, 10087, 15304, 10777, 15169, 11, 10086, 14931, 12314, 10267, 14610, 10087, 15304, 10777, 10384, 639, 703, 12201, 12266, 11726, 14734, 45, 10682, 660, 11632, 13205, 10080, 10293, 16503, 12847, 17162, 10333, 14931, 12314, 10267, 14610, 10257, 14734, 10370, 10261, 14583, 10540, 13234, 14734, 18256, 13764, 10838, 17387, 10399, 10992, 11036, 15033, 11698, 12418, 14583, 14328, 10080, 16891, 15091, 11726, 15480, 14734, 10293, 18025, 13091, 11117, 17144, 10261, 15847, 14597, 12522, 12377, 10399, 10992, 13133, 12551, 10261, 12525, 16393, 14734, 11957, 15123, 28329, 13778, 14523, 2453, 13125, 12705, 10769, 14332, 14734, 16684, 11632, 10460, 11159, 17311, 10688, 13191, 13833, 17285, 14734, 15963, 11435, 12208, 18441, 18043, 13327, 45, 16728, 16537, 14583, 10846, 16710, 16760, 45, 10370, 14328, 18302, 13815, 16982, 15774, 45, 10399, 13249, 10687, 12208, 18441, 14734, 13036, 12276, 12847, 10708, 11626, 13215, 14734, 11190, 14486, 16520, 10080, 10390, 16443, 11971, 10292, 9822, 15963, 16728, 11268, 10821, 10305, 14302, 9823, 10080, 65535, 261, 65530, 65532, 10460, 10292, 10250, 11043, 15847, 11805, 10452, 15543, 17108, 19137, 33, 12848, 10494, 9822, 18256, 13764, 14734, 18029, 15898, 9823, 17148, 17303, 11975, 16735, 19133, 6696, 2174, 20670, 2204, 7686, 117, 16114, 19134, 14734, 12898, 16503, 10529, 12445, 19137, 33, 10894, 12732, 10821, 12484, 11124, 10684, 17644, 10370, 14328, 11, 65535, 261, 65530, 65534, 12605, 14446, 11454, 15494, 10760, 12605, 14734, 15162, 10250, 10283, 15178, 13336, 19137, 33, 17148, 13091, 12605, 16667, 10292, 13188, 11685, 14734, 19151, 11, 18256, 13764, 14734, 18029, 15898, 41, 6699, 44135, 4706, 36976, 42, 13091, 13778, 14523, 2453, 13125, 12705, 10769, 14332, 41, 6696, 2174, 20670, 2204, 7686, 117, 42, 14734, 18117, 17303, 16130, 15917, 12001, 11975, 16735, 41, 23570, 36017, 47234, 42, 28329, 10293, 16503, 10370, 14328, 59, 11, 9828, 1419, 8218, 27487, 59, 33, 10250, 10283, 15299, 15293, 14734, 18256, 13764, 12158, 10080, 10390, 10260, 11975, 12366, 17149, 10792, 10333, 18488, 33640, 12034, 10257, 45, 11454, 17268, 17384, 10390, 17213, 10792, 10333, 10278, 10283, 11630, 13234, 15643, 10080, 10390, 11994, 12604, 10333, 10390, 10402, 11024, 12645, 13799, 14057, 11638, 17782, 10305, 16403, 14734, 11047, 11960, 28329, 9828, 6720, 41426, 59, 33, 10250, 10283, 20683, 2162, 41, 23570, 36017, 10257, 14734, 10250, 10283, 11435, 11920, 42, 11932, 16455, 14734, 13042, 16403, 11221, 10370, 10080, 10390, 13234, 10792, 11024, 12645, 13799, 14057, 11638, 17782, 17149, 16403, 12231, 10580, 10080, 14597, 10339, 10260, 10333, 16533, 18256, 13764, 14734, 10267, 14610, 45, 10390, 12182, 12182, 17808, 10673, 10952, 17801, 10305, 10285, 28329, 9828, 6699, 20320, 25476, 59, 21042, 41426, 14734, 16403, 13221, 15209, 10080, 11885, 13191, 15847, 12144, 14734, 12410, 12527, 12484, 45, 13191, 13064, 10423, 10525, 12686, 11885, 14734, 10293, 10370, 28329, 10821, 12484, 59, 11, 10997, 14583, 11454, 18256, 13764, 10655, 13027, 14734, 11024, 12645, 13799, 14057, 11638, 17782, 10080, 6720, 41426, 13234, 10792, 17148, 17384, 13042, 16403, 45, 1419, 8218, 27487, 12604, 10292, 10390, 14734, 11047, 11960, 10080, 10390, 10402, 10339, 13091, 12022, 12266, 10250, 15304, 10777, 14734, 10705, 17801, 17149, 16403, 11024, 12645, 13799, 14057, 14734, 15091, 13373, 10305, 13042, 28329, 10390, 10402, 17213, 10792, 11036, 15033, 18256, 13764, 14583, 14328, 45, 13637, 11687, 18488, 10079, 15287, 14141, 10079, 18256, 13764, 12158, 15169, 10080, 10390, 10402, 10322, 17919, 10288, 18256, 13764, 12172, 13234, 14734, 11036, 15033, 10952, 17801, 11124, 12752, 12610, 10080, 65535, 261, 65530, 65534, 12605, 14446, 11454, 12791, 10283, 16530, 12231, 13234, 12410, 15641, 17148, 10283, 17728, 18025, 19137, 15494, 10760, 11013, 11630, 10250, 10283, 15178, 13336, 19151, 11, 11454, 17148, 17303, 11975, 16735, 10285, 45, 20754, 1788, 27487, 11124, 6720, 41426, 16443, 10956, 10673, 16684, 11632, 11426, 11574, 10305, 10285, 45, 13191, 13064, 13091, 11416, 10292, 15847, 12144, 14734, 13051, 14862, 11124, 10260, 16780, 12542, 45, 13191, 13064, 13091, 11416, 10292, 11013, 10250, 10283, 10722, 11899, 10390, 10402, 14734, 11630, 11454, 10838, 17387, 10080, 10390, 10402, 17919, 11957, 14808, 16739, 11687, 14136, 12034, 10079, 13849, 17843, 10399, 10992, 11024, 12645, 13799, 14057, 11638, 17782, 10285, 13188, 12299, 11638, 14734, 18256, 13764, 12158, 10402, 14734, 11753, 15723, 28329, 12002, 15202, 1419, 8218, 27487, 13091, 10250, 10283, 15299, 15293, 14734, 18256, 13764, 12158, 19137, 10444, 10390, 10250, 14781, 11454, 15136, 12002, 10675, 10838, 10525, 12686, 6720, 41426, 19137, 15646, 6720, 41426, 10779, 12172, 13234, 10333, 11957, 17148, 10283, 11656, 11701, 14734, 18256, 13764, 10267, 14610, 14734, 14195, 12484, 11124, 11685, 11656, 12366, 28329, 11454, 17148, 10283, 10655, 14015, 18256, 13764, 14734, 10267, 14610, 17384, 19137, 11210, 10250, 11474, 11687, 14947, 14869, 14734, 11957, 16803, 13091, 6720, 41426, 14734, 16403, 13221, 15209, 19137, 11885, 13091, 10250, 10283, 13815, 14583, 14583, 14734, 10079, 16399, 15446, 15898, 14734, 16403, 13221, 15209, 19137, 11021, 10399, 12669, 11885, 14734, 10293, 10370, 10525, 12686, 11454, 10409, 10454, 10952, 17801, 14445, 11574, 10285, 28329, 17148, 17303, 11975, 16735, 13091, 10250, 17303, 11701, 16954, 13503, 14583, 14734, 11656, 12206, 10705, 17801, 11975, 16735, 19137, 16672, 16742, 15643, 10452, 18183, 10792, 10333, 9822, 17169, 13685, 14862, 16696, 11124, 12822, 15325, 9823, 14734, 10310, 16954, 19137, 11042, 13064, 10322, 16672, 10370, 12509, 16944, 10333, 14583, 11117, 10285, 14734, 13947, 18121, 11124, 10993, 16754, 10080, 65535, 261]
[2023-09-30 21:43:15,223] [INFO] [logging.py:96:log_dist] [Rank 0] step=10, skipped=0, lr=[0.0001, 0.0001, 0.0001], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
-> item_loss 0.7131894826889038 batch_loss 1.1266836449503899
==== [12645, 13799, 14057, 11638, 17782, 17149, 16403, 12231, 10580, 10080, 14597, 10339, 10260, 10333, 16533, 18256, 13764, 14734, 10267, 14610, 45, 10390, 12182, 12182, 17808, 10673, 10952, 17801, 10305, 10285, 28329, 9828, 6699, 20320, 25476, 59, 21042, 41426, 14734, 16403, 13221, 15209, 10080, 11885, 13191, 15847, 12144, 14734, 12410, 12527, 12484, 45, 13191, 13064, 10423, 10525, 12686, 11885, 14734, 10293, 10370, 28329, 10821, 12484, 59, 11, 10997, 14583, 11454, 18256, 13764, 10655, 13027, 14734, 11024, 12645, 13799, 14057, 11638, 17782, 10080, 6720, 41426, 13234, 10792, 17148, 17384, 13042, 16403, 45, 1419, 8218, 27487, 12604, 10292, 10390, 14734, 11047, 11960, 10080, 10390, 10402, 10339, 13091, 12022, 12266, 10250, 15304, 10777, 14734, 10705, 17801, 17149, 16403, 11024, 12645, 13799, 14057, 14734, 15091, 13373, 10305, 13042, 28329, 10390, 10402, 17213, 10792, 11036, 15033, 18256, 13764, 14583, 14328, 45, 13637, 11687, 18488, 10079, 15287, 14141, 10079, 18256, 13764, 12158, 15169, 10080, 10390, 10402, 10322, 17919, 10288, 18256, 13764, 12172, 13234, 14734, 11036, 15033, 10952, 17801, 11124, 12752, 12610, 10080, 65535, 261, 65530, 65534, 12605, 14446, 11454, 12791, 10283, 16530, 12231, 13234, 12410, 15641, 17148, 10283, 17728, 18025, 19137, 15494, 10760, 11013, 11630, 10250, 10283, 15178, 13336, 19151, 11, 11454, 17148, 17303, 11975, 16735, 10285, 45, 20754, 1788, 27487, 11124, 6720, 41426, 16443, 10956, 10673, 16684, 11632, 11426, 11574, 10305, 10285, 45, 13191, 13064, 13091, 11416, 10292, 15847, 12144, 14734, 13051, 14862, 11124, 10260, 16780, 12542, 45, 13191, 13064, 13091, 11416, 10292, 11013, 10250, 10283, 10722, 11899, 10390, 10402, 14734, 11630, 11454, 10838, 17387, 10080, 10390, 10402, 17919, 11957, 14808, 16739, 11687, 14136, 12034, 10079, 13849, 17843, 10399, 10992, 11024, 12645, 13799, 14057, 11638, 17782, 10285, 13188, 12299, 11638, 14734, 18256, 13764, 12158, 10402, 14734, 11753, 15723, 28329, 12002, 15202, 1419, 8218, 27487, 13091, 10250, 10283, 15299, 15293, 14734, 18256, 13764, 12158, 19137, 10444, 10390, 10250, 14781, 11454, 15136, 12002, 10675, 10838, 10525, 12686, 6720, 41426, 19137, 15646, 6720, 41426, 10779, 12172, 13234, 10333, 11957, 17148, 10283, 11656, 11701, 14734, 18256, 13764, 10267, 14610, 14734, 14195, 12484, 11124, 11685, 11656, 12366, 28329, 11454, 17148, 10283, 10655, 14015, 18256, 13764, 14734, 10267, 14610, 17384, 19137, 11210, 10250, 11474, 11687, 14947, 14869, 14734, 11957, 16803, 13091, 6720, 41426, 14734, 16403, 13221, 15209, 19137, 11885, 13091, 10250, 10283, 13815, 14583, 14583, 14734, 10079, 16399, 15446, 15898, 14734, 16403, 13221, 15209, 19137, 11021, 10399, 12669, 11885, 14734, 10293, 10370, 10525, 12686, 11454, 10409, 10454, 10952, 17801, 14445, 11574, 10285, 28329, 17148, 17303, 11975, 16735, 13091, 10250, 17303, 11701, 16954, 13503, 14583, 14734, 11656, 12206, 10705, 17801, 11975, 16735, 19137, 16672, 16742, 15643, 10452, 18183, 10792, 10333, 9822, 17169, 13685, 14862, 16696, 11124, 12822, 15325, 9823, 14734, 10310, 16954, 19137, 11042, 13064, 10322, 16672, 10370, 12509, 16944, 10333, 14583, 11117, 10285, 14734, 13947, 18121, 11124, 10993, 16754, 10080, 65535, 261]
-> item_loss 1.085699200630188 batch_loss 1.1221298178037007
==== [25106, 11, 65530, 65531, 10464, 13091, 10250, 10283, 13637, 17097, 14332, 13603, 14734, 820, 19137, 11017, 10460, 1139, 1955, 10080, 10464, 16443, 16689, 16664, 10760, 13234, 12202, 10260, 13091, 10292, 10333, 10292, 10370, 15261, 12848, 10494, 13193, 10843, 19137, 15646, 13091, 13827, 16707, 820, 10792, 12221, 15752, 11003, 12348, 13191, 11632, 15678, 13078, 10080, 10464, 10423, 10621, 10250, 10283, 10370, 15261, 10250, 13324, 11124, 10687, 10390, 10370, 10355, 16753, 19137, 10464, 16735, 10760, 13234, 14734, 10696, 11922, 13091, 11891, 10675, 15847, 10293, 10722, 11899, 14734, 19137, 12202, 10265, 11001, 10722, 10339, 10464, 14734, 12509, 13764, 11124, 13499, 12722, 12366, 12484, 28329, 65535, 261, 65530, 65532, 17109, 10673, 59, 33, 11454, 10303, 11, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 10464, 11685, 19156, 11, 65535, 261, 65530, 65534, 1139, 1955, 59, 33, 10464, 11685, 19137, 12605, 13091, 1139, 1955, 28329, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 10464, 13191, 10373, 10303, 10841, 15752, 19156, 11, 65535, 261, 65530, 65534, 1139, 1955, 59, 33, 10460, 10292, 10250, 10283, 820, 19137, 12605, 14734, 10841, 15752, 13191, 12337, 11632, 19137, 13637, 11687, 10621, 14446, 11454, 17148, 13324, 11124, 10464, 15667, 11639, 19137, 10444, 13091, 12605, 12202, 10260, 13091, 10292, 10333, 13193, 10843, 10370, 15261, 15646, 16443, 10781, 17194, 10760, 13234, 14734, 19137, 12631, 10399, 11021, 15752, 16503, 16672, 10464, 11645, 13197, 10333, 28329, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 18030, 19137, 10260, 13091, 10292, 10333, 12176, 10847, 10370, 15261, 19137, 17268, 10464, 10292, 10373, 10303, 10423, 16443, 17194, 10760, 13234, 19156, 11, 65535, 261, 65530, 65534, 1139, 1955, 59, 33, 11111, 11111, 19137, 17268, 12605, 11994, 10260, 14862, 17222, 10333, 19137, 12609, 16684, 10464, 11021, 10399, 17728, 10258, 12605, 14734, 10794, 17194, 15643, 28329, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 10464, 17148, 10283, 12396, 12231, 43282, 11, 65535, 261, 65530, 65534, 1139, 1955, 59, 33, 12605, 16525, 12348, 12605, 14734, 12396, 12231, 13734, 10373, 10303, 17728, 18025, 19137, 11416, 10292, 10464, 17728, 17148, 10349, 17728, 18025, 13064, 10441, 10308, 13734, 13191, 15641, 16253, 12605, 10423, 12401, 10303, 12509, 28329, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 11685, 11061, 11957, 10260, 16944, 19137, 11021, 15752, 13091, 12605, 11124, 10687, 10390, 820, 15667, 11639, 11640, 11632, 10333, 19137, 10464, 10322, 16684, 13191, 10349, 10260, 10250, 13324, 28329, 65535, 261, 65530, 65534, 1139, 1955, 59, 33, 16774, 16774, 10464, 14734, 14486, 16533, 19137, 12605, 10322, 10292, 12605, 14734, 12396, 12231, 17222, 13571, 28329, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 12605, 16525, 12348, 10464, 13091, 10283, 13191, 16954, 14734, 820, 19137, 10260, 17141, 10780, 12638, 12605, 16707, 12822, 10464, 12202, 17916, 13091, 10760, 10339, 12449, 12522, 19137, 12605, 11016, 13091, 12509, 11957, 10464, 13191, 10250, 10283, 16722, 15478, 14734, 10333, 16533, 28329, 65535, 261, 65530, 65534, 1139, 1955, 59, 33, 11315, 19137, 12631, 10399, 10464, 12509, 10333, 16533, 10349, 10373, 10303, 19156, 12605, 10460, 10292, 10250, 10283, 13212, 11369, 13734, 10373, 10303, 15036, 11930, 19137, 11021, 10399, 11124, 10464, 16679, 16679, 28329, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 10464, 14734, 12221, 12007, 13499, 11496, 13091, 10373, 10303, 28329, 65535, 261, 65530, 65534, 1139, 1955, 59, 33, 18030, 19137, 17148, 10283, 12605, 11021, 15752, 13734, 13764, 11414, 15178, 10464, 19137, 12202, 10260, 13091, 11416, 10292, 17148, 13091, 13212, 11930, 19137, 15646, 13091, 11416, 10292, 12605, 11871, 10323, 14734, 16728, 13021, 11640, 11632, 10333, 19137, 10687, 10285, 10894, 12732, 11036, 15033, 10687, 10390, 16728, 16537, 13499, 11496, 14589, 17141, 14734, 16728, 13021, 19137, 12631, 10399, 12605, 10260, 11640, 10768, 12348, 13923, 43282, 11, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 10464, 10292, 10373, 10303, 16735, 16713, 10423, 17148, 10303, 15847, 14221, 19156, 13091, 11416, 10292, 10464, 16443, 16689, 11899, 12604, 17148, 13324, 10303, 19156, 11, 65535, 261, 65530, 65534, 1139, 1955, 59, 33, 13091, 17148, 13324, 14734, 19137, 10464, 10402, 10370, 15261, 12631, 16735, 14734, 16689, 11899, 10441, 10308, 13091, 12748, 11454, 12605, 14734, 17109, 10673, 12266, 11647, 17303, 10768, 14734, 13012, 13205, 10080, 35, 10464, 13091, 10250, 10283, 13637, 17097, 14332, 13603, 14734, 820, 19137, 11017, 10460, 1139, 1955, 10080, 10464, 16443, 16689, 16664, 10760, 13234, 12202, 10260, 13091, 10292, 10333, 10292, 10370, 15261, 12848, 10494, 13193, 10843, 19137, 15646, 13091, 13827, 16707, 820, 10792, 12221, 15752, 11003, 12348, 13191, 11632, 15678, 13078, 10080, 35, 11885, 10441, 10308, 13091, 17148, 13324, 10708, 14734, 28329, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 12631, 10399, 10464, 10377, 10377, 13091, 10250, 10283, 13212, 11369, 19137, 13734, 13191, 15847, 12605, 19156, 11, 65535, 261, 65530, 65534, 1139, 1955, 59, 33, 10464, 16525, 12348, 12605, 10621, 13091, 13734, 13191, 10303, 19156, 11685, 11061, 19137, 14791, 16944, 13234, 14914, 11903, 12337, 10621, 10080, 10444, 13091, 19137, 12605, 16269, 14221, 10423, 10279, 13327, 12750, 14240, 16689, 11899, 12314, 12276, 19137, 10444, 13091, 12605, 10322, 10423, 13326, 12797, 13499, 11496, 14734, 14862, 16696, 10261, 14332, 12415, 13234, 17109, 10760, 10696, 11922, 10080, 13637, 11687, 19137, 11454, 17148, 10283, 16689, 11899, 10258, 12605, 11021, 10399, 17177, 12731, 13091, 11060, 10261, 10464, 15507, 15511, 15667, 11639, 10080, 10464, 11021, 10399, 16667, 10292, 19137, 12605, 16269, 14221, 13091, 10283, 13212, 11369, 19137, 10444, 13091, 12727, 13191, 10250, 17303, 10768, 10370, 15261, 14734, 14332, 12415, 28329, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 11164, 11164, 19137, 10687, 11903, 12605, 17311, 14862, 17222, 19137, 12605, 13091, 10464, 14734, 10794, 17194, 15643, 19137, 1139, 1955, 28329, 65535, 261, 65530, 65534, 1139, 1955, 59, 33, 10322, 11994, 13091, 16735, 10464, 13091, 12605, 14734, 10293, 10370, 19156, 10293, 10370, 10464, 17148, 10260, 13091, 11454, 13565, 16875, 12605, 10303, 43282, 13078, 13078, 14862, 17222, 17147, 16503, 11124, 12605, 16679, 17148, 10349, 19137, 11100, 11100, 11100, 43282, 11, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 10790, 11188, 10333, 19137, 10687, 11903, 12605, 10402, 14734, 17148, 13619, 11957, 16713, 13091, 12605, 15543, 10708, 14734, 16728, 13021, 19137, 12202, 10260, 13091, 10464, 14794, 13580, 14734, 15486, 10964, 10080, 11454, 13203, 13234, 19137, 10464, 12609, 16684, 10423, 16443, 11017, 10460, 10687, 11885, 14734, 11043, 11860, 19137, 13637, 11687, 35, 32890, 35, 12609, 35, 994, 26405, 35, 10079, 14581, 15849, 13091, 15190, 10932, 14734, 12642, 10257, 35, 820, 5178, 33394, 35, 15169, 13308, 15189, 19137, 10444, 13091, 12605, 12159, 13197, 10464, 15752, 10384, 17148, 13619, 16728, 13021, 10285, 11871, 10323, 10792, 10250, 10349, 10272, 16501, 10080, 11685, 10333, 19137, 14446, 11454, 10589, 13579, 13499, 12722, 10370, 15261, 11061, 19137, 12605, 13179, 12981, 13188, 10782, 14734, 16689, 11899, 19137, 14446, 11454, 10464, 11003, 11414, 17268, 10283, 12176, 10847, 10370, 15261, 14734, 13212, 11369, 10370, 28329, 65535, 261, 65530, 65534, 1139, 1955, 59, 33, 11685, 14734, 19137, 12605, 14446, 11454, 11003, 12604, 12176, 10847, 10370, 15261, 14734, 13212, 11369, 10370, 10080, 10687, 11903, 19137, 10293, 10370, 10464, 14734, 11117, 10398, 10261, 9822, 16443, 16689, 16664, 10760, 13234, 10292, 10370, 15261, 13193, 10843, 14734, 16689, 11899, 9823, 14782, 12463, 19137, 10444, 13091, 12605, 12537, 12522, 11065, 12469, 14734, 11117, 10398, 10080, 12605, 10423, 16678, 10449, 17148, 13619, 16728, 13021, 19137, 10384, 10285, 11871, 10323, 14734, 10080, 16738, 17728, 10293, 10370, 17147, 13191, 10373, 10303, 17879, 16503, 12605, 12176, 10847, 14734, 11053, 19156, 11, 65535, 261]
-> item_loss 0.9231598973274231 batch_loss 1.102232825756073
==== [25106, 11, 65530, 65534, 17148, 13619, 13012, 11860, 13091, 9822, 14931, 12314, 10267, 14610, 9823, 14734, 10250, 10283, 14313, 13619, 19137, 12847, 17162, 10333, 10250, 10283, 10278, 10283, 10370, 11454, 11957, 16713, 14734, 11461, 13126, 19137, 33, 12605, 12509, 11454, 10258, 17919, 14734, 17749, 16742, 10285, 10333, 16533, 16721, 13012, 13205, 14734, 16530, 15898, 11124, 10370, 14328, 10529, 12445, 11, 14136, 19137, 14190, 17149, 10333, 10994, 11517, 11889, 15034, 2453, 16050, 13770, 10660, 10080, 14136, 15950, 16535, 10992, 18256, 13764, 16099, 11459, 19137, 14179, 14218, 10339, 13091, 11086, 14446, 10760, 16155, 15898, 11124, 15526, 15898, 19137, 14581, 15849, 11656, 17167, 15880, 11459, 17725, 10760, 12172, 13191, 10253, 12319, 10305, 11630, 9822, 15162, 10677, 15898, 9823, 14734, 14136, 15931, 19152, 14136, 15863, 13755, 14808, 11221, 10270, 16407, 10250, 16981, 15104, 11047, 10609, 13750, 15572, 19137, 14136, 14218, 10339, 13091, 13655, 10859, 18216, 13877, 19137, 10411, 10459, 17725, 15639, 14734, 14136, 11282, 13759, 19137, 9822, 11381, 11237, 9823, 14171, 11168, 19152, 14136, 14218, 14190, 10792, 18119, 16218, 12223, 17609, 12631, 11454, 14734, 16407, 17222, 19137, 11638, 14136, 10339, 13091, 10997, 10760, 17774, 17774, 14582, 18119, 19152, 11638, 14136, 14272, 14808, 10333, 16030, 12223, 10609, 16223, 11909, 17384, 12199, 14280, 14734, 14460, 11656, 16030, 16002, 19137, 10370, 10402, 10339, 13091, 13655, 12348, 10997, 14652, 19137, 12266, 11010, 11217, 18175, 14987, 13078, 28329, 13581, 13064, 19137, 16050, 13770, 10660, 11517, 14734, 11221, 10270, 10912, 12145, 13091, 10250, 14313, 14136, 13849, 10080, 11013, 10250, 15137, 14734, 11889, 15034, 11517, 17384, 19137, 13191, 17558, 13191, 17038, 10410, 14734, 12010, 13653, 15465, 15465, 16403, 10846, 19137, 13644, 10260, 12636, 17086, 19137, 14652, 14356, 11459, 12702, 16944, 13352, 13234, 10080, 10444, 13091, 19137, 16050, 13770, 10660, 15887, 11478, 17384, 17268, 10349, 14015, 17095, 16790, 14328, 10079, 13384, 15931, 11124, 13202, 13223, 14734, 15878, 15887, 19137, 16417, 17919, 13852, 14808, 14216, 13750, 19137, 13057, 12145, 14175, 14267, 16944, 13234, 10080, 13760, 11459, 14190, 12604, 10333, 14140, 14194, 19137, 10250, 15891, 15891, 14136, 15887, 16945, 14808, 17170, 14066, 19137, 13755, 14808, 11889, 15034, 13748, 11047, 11638, 13849, 14030, 10985, 19137, 10411, 10459, 13996, 13676, 14734, 16098, 14136, 16263, 19137, 10250, 16981, 14172, 14267, 13755, 12061, 14734, 11913, 13624, 11124, 13224, 14970, 10080, 14136, 13085, 17819, 18043, 18048, 10792, 12061, 10257, 19137, 12640, 11047, 17150, 11621, 13913, 16223, 14734, 15931, 11423, 11124, 16002, 12015, 28329, 14179, 14218, 14583, 10760, 13833, 14187, 10254, 10255, 19137, 10411, 10459, 10250, 13326, 14356, 18043, 10956, 12604, 14734, 18438, 13295, 19137, 10953, 10511, 15126, 11454, 14931, 12314, 10267, 14610, 14734, 11013, 10250, 15137, 19137, 10322, 15752, 14791, 10283, 10250, 13923, 10337, 13425, 28329, 15957, 11454, 10745, 17384, 10305, 11630, 17773, 10735, 12208, 13146, 14734, 12034, 17997, 11471, 16520, 17148, 17774, 10859, 19137, 12527, 16525, 12368, 13091, 12647, 10370, 12366, 12290, 10080, 13581, 13064, 13580, 13191, 17148, 10303, 10278, 10447, 19137, 14791, 12348, 10685, 11110, 14759, 14221, 28329, 10687, 10285, 18216, 10283, 11855, 14734, 17268, 10447, 10561, 14808, 10250, 12669, 16956, 13191, 10250, 10370, 18216, 14734, 10811, 15126, 14808, 19137, 13580, 11638, 11401, 18363, 15809, 10080, 16503, 10260, 13091, 14791, 10390, 17181, 14808, 10250, 15706, 13212, 16650, 15678, 12551, 14734, 14141, 13655, 19137, 16519, 10333, 17148, 10588, 13818, 19137, 16747, 17311, 10423, 10399, 10292, 17148, 13091, 10384, 10285, 17090, 11459, 16009, 10974, 13234, 14734, 17386, 16306, 10370, 28329, 11013, 10250, 10447, 13098, 12348, 14867, 12348, 11632, 19137, 10384, 11647, 10792, 15768, 17311, 16136, 11454, 13388, 15898, 13020, 15232, 17384, 10080, 10594, 11979, 15053, 10846, 10250, 10846, 13064, 19137, 10846, 10460, 10305, 17093, 14352, 11687, 14398, 11145, 17004, 13582, 28329, 10305, 10808, 14734, 10337, 10917, 10768, 17544, 17384, 19137, 17148, 10278, 10447, 10745, 10308, 18441, 10260, 10460, 11610, 19137, 11016, 13191, 10250, 13619, 15190, 14866, 13051, 13258, 14734, 10335, 16686, 19137, 10336, 10684, 14136, 13849, 10285, 14734, 10250, 17774, 14388, 14179, 14288, 14171, 10792, 12221, 10997, 14583, 11454, 11861, 13750, 16883, 13309, 17147, 13091, 11454, 12142, 11606, 10660, 16052, 10936, 11979, 14734, 10460, 11467, 10080, 10278, 10370, 10292, 13581, 10258, 10333, 16915, 13773, 28329, 18216, 10283, 11855, 11219, 11891, 18363, 19137, 12669, 18200, 11647, 12643, 11454, 16002, 10271, 17384, 19137, 15149, 17384, 12172, 14808, 12409, 12474, 43899, 17268, 10349, 11975, 12148, 11855, 17311, 13626, 10333, 43282, 9823, 11, 10390, 16735, 19137, 9822, 12605, 12771, 11268, 13558, 11885, 10402, 14734, 10080, 9823, 11, 9822, 17147, 13191, 17268, 10349, 11902, 12219, 43282, 9823, 14867, 10283, 11855, 12509, 10333, 12509, 19137, 10990, 16416, 10333, 10250, 11012, 19137, 9822, 11902, 14869, 11021, 14267, 10303, 19156, 11065, 16735, 11885, 10402, 16974, 14237, 12143, 10260, 11632, 13091, 10250, 15261, 10272, 16501, 10080, 9823, 11, 9822, 12631, 13191, 17389, 11855, 19137, 17311, 14252, 10333, 19137, 18000, 14808, 13733, 13485, 13819, 13893, 10080, 9823, 11638, 10283, 11855, 16735, 14808, 19137, 13734, 13191, 14486, 10423, 14867, 10283, 11855, 14734, 17728, 18025, 19137, 9822, 12631, 13191, 15597, 17335, 19137, 17311, 11454, 13357, 17384, 13749, 15808, 10333, 10080, 9823, 11, 9822, 17147, 13191, 15640, 18459, 10080, 9823, 10250, 17038, 13388, 16435, 14734, 11042, 10437, 16735, 28329, 9822, 15640, 18459, 19137, 16735, 12348, 11957, 10080, 9823, 11, 9822, 14768, 11627, 13064, 15907, 19137, 13734, 11459, 13036, 11021, 17173, 10080, 9823, 11, 9822, 11042, 13324, 16735, 12348, 11957, 10080, 10444, 19137, 12421, 13091, 16525, 12348, 43282, 11315, 43282, 17148, 10423, 10650, 43282, 9823, 11, 10390, 11155, 10258, 13734, 16735, 11891, 14734, 16713, 19137, 17819, 10953, 12791, 10257, 17093, 12387, 14734, 11010, 13655, 43899, 12605, 10402, 17147, 13556, 9819, 15446, 13676, 16305, 9820, 17268, 10650, 14734, 15640, 12283, 16052, 11632, 10677, 10283, 17607, 12153, 11187, 10080, 9823, 14867, 10283, 11855, 14172, 10333, 14172, 11647, 28329, 10278, 10283, 10370, 10703, 13557, 18441, 10260, 10460, 11610, 10080, 11454, 17148, 12232, 13188, 11638, 14734, 11517, 12154, 11984, 13203, 16944, 14136, 14734, 11459, 13036, 19137, 10990, 10250, 17085, 14288, 14171, 12266, 11726, 10333, 19137, 11454, 11633, 12192, 10257, 14267, 16944, 10250, 17222, 15446, 10659, 28329, 18216, 10283, 11855, 10997, 16713, 10333, 43899, 18460, 11855, 43900, 11, 9822, 12469, 16735, 10080, 9823, 11, 9822, 12605, 12509, 14862, 17222, 13091, 16747, 12983, 14734, 14136, 10080, 9823, 11, 17148, 10283, 16443, 11206, 10460, 9822, 18460, 11855, 9823, 14734, 14867, 10283, 11855, 10811, 12636, 13734, 12220, 11610, 10080, 10390, 13580, 14791, 14808, 14136, 10659, 13086, 15446, 14734, 11638, 16981, 10080, 16981, 10257, 10250, 14781, 13734, 10373, 10303, 10370, 19137, 11416, 10292, 17159, 11672, 14524, 11517, 17723, 13091, 15162, 10250, 12662, 14190, 13626, 14734, 12261, 15176, 10080, 14249, 14249, 14267, 14190, 14734, 13359, 13295, 17865, 14172, 15880, 16109, 11459, 19137, 11517, 17723, 11994, 13581, 11468, 11556, 10080, 65535, 261, 65530, 65532, 10460, 10292, 10250, 11043, 15287, 17189, 16530, 15898, 12656, 14035, 14734, 14442, 11920, 19137, 10399, 14867, 10283, 11855, 14734, 16523, 16530, 19137, 12847, 17162, 14867, 10283, 11855, 11454, 17148, 10283, 11461, 13126, 10285, 14734, 16403, 10292, 11124, 12366, 14486, 14349, 12396, 28329, 13773, 13078, 19151, 14867, 10283, 11855, 11957, 18216, 10283, 11855, 11861, 11454, 10250, 10349, 15847, 10928, 12484, 15509, 10080, 65535, 261, 65530, 65534, 14867, 10283, 11855, 14734, 16523, 16530, 19151, 11, 12605, 14791, 14808, 14249, 14249, 14267, 14190, 14734, 11517, 12154, 19137, 12366, 10285, 10655, 14015, 10333, 12476, 11158, 10080, 17148, 12232, 11517, 12154, 13091, 12605, 14734, 11920, 11423, 19137, 10444, 14446, 11454, 11885, 12604, 10333, 10250, 14313, 12228, 11585, 19137, 12605, 12631, 14256, 12459, 14734, 10250, 10769, 17311, 10392, 10305, 10250, 14165, 10080, 14136, 14218, 11454, 11633, 15090, 10285, 16982, 16962, 19137, 10411, 10459, 10278, 10447, 11679, 11606, 11454, 10335, 18043, 11035, 17359, 19137, 10260, 10768, 10434, 10405, 28329, 12605, 12509, 16944, 10333, 15640, 18459, 16735, 17141, 14734, 16713, 43899, 17148, 10303, 11638, 14734, 14136, 10859, 19137, 13734, 10370, 11098, 10429, 10353, 14794, 13091, 10254, 12203, 10333, 10080, 9823, 10390, 16735, 17148, 16713, 14734, 13064, 10560, 19137, 16728, 13655, 17384, 12172, 14808, 10250, 10273, 17093, 13247, 10080, 12609, 16684, 10390, 16525, 12348, 15847, 12144, 12145, 15486, 10323, 12506, 10333, 17148, 13324, 14734, 14146, 17843, 28329, 15646, 12605, 14862, 17222, 19137, 17148, 11016, 13091, 13156, 10838, 14734, 10720, 12034, 10250, 16530, 10080, 13006, 10283, 11517, 12154, 17311, 11021, 15752, 11454, 14179, 14218, 10285, 18034, 12675, 10079, 11115, 11057, 10079, 13188, 15480, 10901, 10292, 10306, 13191, 28329, 12605, 14791, 11047, 18216, 10283, 11855, 19137, 10390, 13580, 12379, 14808, 12669, 14188, 14256, 14734, 18293, 10384, 18293, 18200, 11647, 10257, 12831, 10258, 13234, 19137, 10277, 17149, 11349, 17384, 10080, 10390, 10441, 10308, 11891, 10675, 13734, 12669, 17148, 11461, 14146, 17843, 12307, 10250, 11414, 10336, 10080, 12609, 16684, 11454, 10390, 14791, 13234, 19137, 17148, 11016, 13091, 10250, 11461, 12522, 11630, 10080, 65535, 261, 65530, 65534, 14867, 10283, 11855, 14734, 16523, 16530, 19151, 11, 12605, 14791, 14808, 14249, 14249, 14267, 14190, 14734, 11517, 12154, 19137, 12366, 10285, 10655, 14015, 10333, 12476, 11158, 10080, 17148, 12232, 11517, 12154, 13091, 12605, 14734, 11920, 11423, 19137, 10444, 14446, 11454, 11885, 12604, 10333, 10250, 14313, 12228, 11585, 19137, 12605, 12631, 14460, 16523, 14734, 10272, 16501, 10392, 10305, 10250, 14165, 28329, 12605, 14791, 10792, 13191, 10349, 10370, 12604, 15604, 15489, 17766, 11459, 10384, 11638, 16981, 10257, 16939, 17141, 19137, 10411, 10459, 13734, 10336, 10370, 17268, 13324, 16676, 16686, 14808, 17148, 11461, 14146, 17843, 10080, 10390, 10402, 12609, 16684, 10423, 18169, 16956, 16520, 13197, 10250, 10258, 14249, 14249, 14267, 14190, 14734, 18216, 11559, 19137, 10444, 13179, 11021, 15752, 14734, 13091, 17177, 12731, 13051, 16523, 28329, 15646, 12307, 10390, 10402, 14778, 10659, 14782, 17213, 13064, 19137, 12605, 15752, 14791, 10792, 12476, 10429, 10079, 12409, 12474, 11124, 11042, 12484, 10080, 17148, 16672, 12605, 12527, 10792, 10250, 10273, 11889, 12556, 28329, 10444, 12337, 12387, 17148, 10349, 12484, 15509, 11994, 13855, 11645, 12348, 13051, 12325, 13051, 17001, 10080, 11416, 10292, 12605, 14862, 17222, 19137, 10390, 10402, 11016, 13091, 12669, 12476, 10429, 11124, 12409, 12474, 16223, 11454, 12366, 17384, 19137, 10260, 12509, 16672, 15847, 12144, 10322, 11003, 12348, 10448, 16893, 28329, 17148, 16672, 12605, 12509, 16944, 10333, 10399, 10808, 11454, 10324, 10258, 16519, 17141, 14734, 10250, 15033, 16273, 16272, 10080, 16273, 16272, 17213, 10792, 10952, 17801, 13064, 10423, 11967, 17038, 10452, 16335, 12604, 10250, 10283, 15326, 10740, 14734, 14484, 14349, 19137, 10399, 13581, 13234, 10739, 11977, 11957, 11630, 14610, 14734, 12824, 16535, 10080, 65535, 261, 65530, 65534, 14867, 10283, 11855, 14734, 16523, 16530, 59, 11, 12605, 18441, 10260, 10460, 11610, 11459, 14779, 14808, 14249, 14249, 14267, 14190, 14734, 14136, 10659, 45, 12366, 10285, 10655, 14015, 10333, 11626, 13215, 14734, 12484, 15509, 28329, 17148, 11461, 11638, 14136, 13091, 12605, 10402, 12457, 12457, 16664, 10775, 10333, 12337, 10301, 14734, 12687, 11626, 45, 11021, 10250, 14791, 10792, 11687, 13581, 12500, 14179, 14734, 13126, 16803, 45, 12605, 10383, 13191, 10349, 12430, 12499, 11124, 11044, 12462, 10305, 12522, 28329, 10444, 12605, 13179, 11632, 14734, 13091, 10966, 12670, 14808, 14734, 12348, 12522, 10080, 12605, 11124, 18216, 10283, 11855, 14734, 16664, 10775, 15480, 10339, 12348, 17192, 45, 17268, 10349, 13565, 10966, 12605, 10402, 16684, 10301, 14734, 15500, 13751, 15643, 11124, 13216, 16896, 10953, 11967, 10392, 10760, 10397, 10408, 10080, 17148, 10283, 13064, 10560, 12220, 12307, 12527, 10792, 13559, 11268, 12638, 13091, 28329, 14221, 15646, 45, 18216, 10283, 11855, 17268, 13324, 17093, 13247, 14734, 16728, 13655, 11124, 15149, 11922, 45, 17147, 13191, 10390, 11957, 14136, 14146, 11044, 14734, 10250, 10769, 12789, 11645, 13644, 10260, 11454, 10308, 14734, 13324, 11855, 45, 12421, 13091, 16672, 12605, 12527, 10792, 15847, 10928, 11124, 11645, 16109, 28329, 12605, 12202, 17916, 13734, 13191, 12509, 13764, 45, 10322, 15752, 16735, 10760, 10687, 10390, 16520, 14172, 45, 10444, 10390, 14734, 16713, 16728, 12421, 13091, 13187, 12605, 10460, 10293, 45, 15646, 12605, 10322, 11016, 13191, 18441, 18441, 14172, 11647, 28329, 12605, 12145, 15486, 10323, 12506, 10333, 10292, 10390, 17802, 16420, 11124, 10460, 17802, 10080, 11016, 13191, 11454, 17148, 13324, 13626, 14138, 10250, 10769, 14734, 13064, 10560, 45, 12605, 12638, 12527, 10792, 12605, 10402, 13091, 12200, 15169, 14734, 28329, 10444, 12605, 12145, 12509, 13078, 14731, 45, 12605, 11124, 10390, 15480, 15087, 10260, 11042, 10080, 10390, 13091, 10250, 10283, 15584, 14347, 45, 15646, 12605, 10383, 13191, 18004, 12370, 10261, 11255, 15895, 10080, 65535, 261, 65530, 65534, 18216, 10283, 11855, 14734, 12847, 17162, 16530, 12231, 11687, 10258, 59, 11, 12605, 41, 18216, 10283, 11855, 42, 11124, 12605, 14734, 11042, 10437, 18460, 11855, 41, 14867, 10283, 11855, 13020, 15217, 10285, 14734, 10370, 42, 13580, 11454, 17150, 11621, 14734, 12034, 17997, 16520, 14791, 10258, 13036, 10994, 11517, 11889, 15034, 11124, 16050, 13770, 10660, 11638, 14136, 14267, 14190, 14734, 13126, 16803, 10080, 12605, 10402, 10534, 18441, 10260, 10460, 11610, 14791, 10333, 10337, 10917, 11632, 10768, 17544, 45, 11016, 13191, 10250, 13557, 10335, 12650, 13091, 11060, 13091, 13279, 11621, 10387, 12219, 14288, 14171, 10358, 14583, 14734, 28329, 18460, 11855, 16269, 14221, 14867, 45, 10444, 14791, 10441, 12990, 12802, 10079, 13212, 12990, 10080, 10390, 14734, 13633, 10250, 10283, 10846, 10460, 17311, 12337, 17093, 12139, 28329, 12605, 11035, 11891, 18363, 15809, 11044, 16694, 10408, 17311, 12154, 17384, 14734, 11975, 12148, 11124, 11011, 11902, 16443, 14190, 13626, 45, 18460, 11855, 10779, 16718, 17728, 11902, 14869, 13091, 11060, 15752, 14267, 14190, 10080, 10444, 12605, 13734, 13191, 13580, 17919, 11414, 15178, 10390, 14734, 17728, 18025, 28329, 12605, 10402, 15507, 15511, 16520, 14136, 45, 18460, 11855, 12748, 10760, 14136, 14146, 10285, 15640, 18459, 14734, 10258, 11461, 45, 12605, 16417, 14966, 16928, 11042, 28329, 13006, 10452, 13234, 16735, 45, 12605, 11957, 18460, 11855, 13191, 15895, 11685, 14734, 16694, 10408, 10080, 10390, 13212, 12990, 15678, 12551, 45, 13633, 10250, 11012, 16713, 17311, 12663, 16503, 13191, 10838, 10080, 10390, 14734, 17728, 18025, 12609, 16694, 16686, 10322, 17311, 12337, 15287, 10733, 12202, 13191, 12261, 16689, 12415, 10080, 65535, 261, 65530, 65532, 10399, 15162, 10250, 10370, 15044, 19133, 18216, 10283, 11855, 43898, 12847, 17162, 18216, 10283, 11855, 11124, 14867, 10283, 11855, 14734, 10355, 13819, 19137, 16417, 14446, 18216, 10283, 11855, 14734, 12366, 14486, 13815, 10846, 11124, 10390, 11957, 14867, 10283, 11855, 14734, 16694, 10408, 28329, 65535, 261, 65530, 65534, 18216, 10283, 11855, 14734, 12847, 17162, 16530, 12231, 11687, 10258, 59, 11, 12605, 41, 18216, 10283, 11855, 42, 11124, 12605, 14734, 11042, 10437, 18460, 11855, 41, 14867, 10283, 11855, 13020, 15217, 10285, 14734, 10370, 42, 13580, 11454, 17150, 11621, 14734, 12034, 17997, 16520, 14791, 10258, 13036, 10994, 11517, 11889, 15034, 11124, 16050, 13770, 10660, 11638, 14136, 14267, 14190, 14734, 13126, 16803, 10080, 12605, 10402, 10534, 18441, 10260, 10460, 11610, 14791, 10333, 10337, 10917, 11632, 10768, 17544, 45, 11016, 13191, 10250, 13557, 10335, 12650, 13091, 11060, 13091, 13279, 11621, 10387, 12219, 14288, 14171, 10358, 14583, 14734, 28329, 18460, 11855, 16269, 14221, 14867, 45, 10444, 14791, 10441, 12990, 12802, 10079, 13212, 12990, 10080, 10390, 14734, 13633, 10250, 10283, 10846, 10460, 17311, 12337, 17093, 12139, 28329, 12605, 11035, 11891, 18363, 15809, 11044, 16694, 10408, 17311, 12154, 17384, 14734, 11975, 12148, 11124, 11011, 11902, 16443, 14190, 13626, 45, 18460, 11855, 10779, 16718, 17728, 11902, 14869, 13091, 11060, 15752, 14267, 14190, 10080, 10444, 12605, 13734, 13191, 13580, 17919, 11414, 15178, 10390, 14734, 17728, 18025, 28329, 12605, 10402, 15507, 15511, 16520, 14136, 45, 18460, 11855, 12748, 10760, 14136, 14146, 10285, 15640, 18459, 14734, 10258, 11461, 45, 12605, 16417, 14966, 16928, 11042, 28329, 13006, 10452, 13234, 16735, 45, 12605, 11957, 18460, 11855, 13191, 15895, 11685, 14734, 16694, 10408, 10080, 10390, 13212, 12990, 15678, 12551, 45, 13633, 10250, 11012, 16713, 17311, 12663, 16503, 13191, 10838, 10080, 10390, 14734, 17728, 18025, 12609, 16694, 16686, 10322, 17311, 12337, 15287, 10733, 12202, 13191, 12261, 16689, 12415, 10080, 65535, 261, 65530, 65532, 14313, 13619, 10285, 13191, 10745, 10447, 16530, 15898, 10760, 11461, 19156, 11, 65535, 261, 65530, 65534, 10377, 10384, 12631, 12848, 10494, 14734, 14313, 13619, 13234, 14791, 45, 14313, 13619, 10285, 10760, 11461, 14734, 10293, 16503, 16530, 15898, 10441, 10308, 11016, 13191, 10278, 10283, 59, 11, 50, 47, 33, 10250, 10283, 18216, 10283, 11855, 14734, 10811, 12636, 10080, 14313, 10285, 11967, 10390, 12847, 17162, 10292, 35, 18216, 10283, 11855, 384, 10390, 10561, 14808, 10250, 12669, 17688, 10811, 12202, 11638, 11401, 18363, 15809, 28329, 51, 47, 33, 10250, 10283, 14867, 10283, 11855, 14734, 11042, 10437, 45, 10675, 17038, 10894, 16468, 11454, 13020, 15217, 17384, 45, 15046, 10846, 13064, 10621, 14398, 10250, 13324, 17093, 14756, 28329, 14313, 13619, 10285, 13734, 13191, 17181, 17900, 17148, 10278, 10370, 14734, 10688, 10452, 17038, 10410, 12609, 15669, 10270, 45, 11016, 12847, 17162, 10390, 10402, 17912, 17912, 11459, 16520, 16917, 14808, 17150, 11621, 14179, 14218, 14249, 14249, 14734, 11517, 12154, 28329, 17148, 10278, 10370, 14734, 10342, 10846, 16417, 13078, 10390, 10402, 13091, 14782, 16696, 12145, 10301, 14734, 10422, 10437, 45, 10305, 17734, 11861, 11454, 10250, 11899, 14734, 18441, 11662, 28329, 12631, 10399, 11994, 14313, 13619, 13205, 17038, 12848, 10494, 14734, 10529, 12445, 13234, 14791, 45, 14313, 10285, 10760, 11461, 14734, 16530, 15898, 10293, 16503, 11016, 13191, 17148, 10278, 10447, 45, 10265, 13051, 13764, 12826, 13032, 10390, 10402, 14734, 10688, 10452, 15669, 10270, 28329, 12159, 13197, 10399, 10257, 10529, 12445, 15752, 12176, 10847, 10792, 12469, 10080, 15957, 13191, 10260, 16956, 10305, 11621, 17147, 16738, 12748, 13580, 10080, 65535, 261, 65530, 65532, 12847, 17162, 18216, 10283, 11855, 14734, 11630, 16815, 14332, 12333, 11124, 12415, 13327, 14332, 14172, 11, 65535, 261, 65530, 65534, 18216, 10283, 11855, 14734, 17385, 16503, 14332, 12333, 11124, 12415, 13327, 14332, 14172, 11687, 10258, 59, 11, 50, 47, 33, 11630, 16815, 18216, 11638, 10080, 14313, 13619, 10285, 11967, 10390, 12847, 17162, 10292, 9822, 18216, 10283, 11855, 28319, 13637, 10390, 14734, 11042, 10437, 14867, 10283, 11855, 13098, 16114, 18216, 11638, 28329, 51, 47, 33, 15752, 12199, 10843, 11903, 10080, 14313, 10285, 12848, 10792, 10390, 9822, 17181, 14808, 10250, 15706, 13212, 16650, 15678, 12551, 14734, 14141, 13655, 28319, 10261, 10390, 9822, 11638, 11401, 18363, 15809, 9823, 14734, 10588, 13818, 12314, 12604, 11957, 13637, 45, 16735, 13078, 10390, 12415, 13327, 11903, 17781, 15752, 12199, 28329, 52, 47, 33, 16792, 17136, 11638, 12231, 10080, 10390, 14791, 16944, 13234, 11957, 11638, 14136, 14190, 13626, 14734, 9822, 11975, 12148, 11855, 9823, 12202, 10260, 10382, 12522, 45, 10995, 15646, 16417, 14966, 9822, 12771, 11268, 13558, 11885, 10402, 14734, 9823, 28329, 53, 47, 33, 12560, 12552, 12503, 12522, 10080, 10390, 14331, 13856, 10792, 13556, 10258, 9822, 15446, 13676, 16305, 9823, 17335, 18107, 14734, 10576, 10843, 45, 13098, 14966, 10390, 14583, 13815, 17311, 14782, 12307, 11671, 10486, 28329, 54, 47, 33, 11957, 11042, 10437, 13191, 14862, 12144, 10305, 11685, 10080, 10390, 14589, 9822, 18460, 11855, 9823, 15044, 11116, 14867, 10283, 11855, 11042, 10437, 45, 13098, 14966, 10390, 10402, 12145, 13191, 13913, 10972, 10355, 12484, 28329, 55, 47, 33, 17819, 11124, 12208, 18441, 10080, 10390, 11016, 17819, 12522, 11414, 12220, 11042, 10437, 14734, 12848, 17728, 45, 12202, 12266, 14442, 15149, 16735, 9822, 12631, 13191, 15640, 18459, 9823, 17311, 13594, 11454, 11638, 14136, 10285, 28329, 56, 47, 33, 11957, 10336, 10407, 14794, 14782, 12337, 11454, 12522, 10080, 10390, 17728, 14867, 10283, 11855, 11042, 10437, 9822, 12605, 12509, 14862, 17222, 13091, 16747, 12983, 14734, 14136, 9823, 28329, 10399, 10257, 10293, 16503, 11533, 10339, 18216, 10283, 11855, 14734, 11630, 16815, 12847, 17162, 10079, 15707, 10452, 16728, 16537, 10399, 10992, 10261, 14867, 10283, 11855, 11042, 10437, 14734, 10342, 10846, 13234, 12826, 13032, 10390, 14734, 12415, 13327, 14332, 14172, 10080, 12159, 13197, 15752, 11634, 10733, 14914, 11414, 15178, 12469, 14734, 17728, 18025, 10080, 65535, 261, 65530, 65532, 12605, 17879, 16503, 14589, 8683, 24381, 59517, 15493, 10794, 14867, 10283, 11855, 14734, 11630, 16815, 19137, 33, 16738, 15494, 12605, 11957, 12220, 14734, 12848, 14966, 16702, 11, 65535, 261, 65530, 65534, 10399, 10258, 13091, 12722, 12261, 16676, 14734, 14867, 10283, 11855, 14734, 11630, 16815, 12847, 17162, 16702, 59, 11, 9828, 37347, 280, 33, 18216, 10283, 11855, 11967, 10390, 15044, 10292, 14867, 10283, 11855, 45, 16735, 13078, 10390, 17038, 13223, 12337, 14866, 11975, 28329, 9828, 29087, 1843, 280, 33, 10390, 10675, 17038, 17311, 10894, 16468, 11454, 13388, 15898, 14734, 13020, 15232, 17384, 45, 12848, 14966, 10390, 12182, 15091, 13191, 10671, 12184, 14734, 13020, 15232, 28329, 9828, 3630, 7834, 280, 33, 16269, 14221, 14867, 11975, 10444, 16403, 10846, 10621, 14398, 10250, 13324, 12990, 12802, 17140, 17193, 28329, 9828, 50469, 280, 33, 10390, 12337, 11977, 16735, 16713, 45, 15494, 10370, 14987, 15036, 14734, 12527, 16525, 28329, 9828, 36406, 38056, 280, 33, 10390, 15091, 14808, 13388, 15898, 13020, 15232, 45, 11021, 13091, 10250, 10283, 65129, 51725, 28329, 9828, 44656, 7015, 280, 33, 10390, 18441, 18441, 11459, 16520, 11940, 14808, 11638, 14136, 45, 16735, 13078, 10390, 12337, 14614, 12522, 11105, 11430, 14734, 15478, 15907, 28329, 9828, 28478, 101, 280, 33, 12002, 15202, 10260, 14914, 11899, 45, 10444, 14597, 10339, 10390, 14734, 14987, 15036, 11124, 17122, 16696, 12231, 45, 12337, 13191, 11021, 15752, 13191, 10250, 12669, 15737, 11855, 28329, 9828, 36838, 8091, 7473, 30806, 280, 33, 12002, 15202, 13734, 13191, 12847, 17162, 10390, 14734, 14806, 14815, 45, 10444, 15641, 16253, 10792, 10390, 14734, 15678, 13078, 11124, 16520, 11940, 10838, 45, 10390, 11021, 15752, 13191, 10250, 10994, 13133, 12551, 14734, 14806, 14815, 28329, 9828, 29087, 47249, 280, 33, 14597, 10339, 10390, 10675, 17038, 17311, 16468, 11454, 13020, 15232, 17384, 45, 10671, 12184, 14734, 17773, 12325, 11021, 15752, 17238, 12761, 17303, 10768, 10390, 14734, 17919, 17303, 14332, 12333, 28329, 9828, 29438, 7493, 8439, 39725, 280, 33, 12307, 18216, 10283, 11855, 12848, 10792, 35, 12631, 13191, 15640, 18459, 35, 13064, 45, 10390, 13191, 11021, 15752, 15149, 10333, 10250, 10258, 45, 10444, 15149, 11922, 17820, 16223, 11454, 13020, 15232, 10258, 45, 14987, 15036, 15646, 13191, 18248, 10838, 28329, 12159, 13197, 10399, 10257, 14734, 12847, 17162, 16702, 15752, 10847, 12469, 14583, 12604, 15158, 11038, 12985, 10336, 15478, 15907, 14734, 14867, 10283, 11855, 11630, 16815, 12314, 16803, 10080, 15957, 13191, 10260, 11038, 17172, 10305, 11621, 45, 13558, 17143, 12748, 13580, 28329, 36, 44, 24217, 59, 29945, 4164, 5608, 44816, 29850, 3662, 1313, 19589, 1511, 70, 359, 19566, 5675, 969, 65535, 261]
-> item_loss 1.3474713563919067 batch_loss 1.1245272376320579
==== [25106, 11, 65530, 65532, 13499, 11496, 17384, 13191, 10370, 11454, 10303, 19156, 11, 65535, 261, 65530, 65534, 12469, 11685, 19137, 12605, 13091, 13499, 11496, 10696, 14734, 11168, 12220, 10293, 10452, 10080, 12605, 11021, 10399, 14781, 12824, 11957, 12469, 17149, 16403, 11414, 11626, 19137, 10444, 13091, 12159, 13197, 12469, 15752, 12848, 10494, 13179, 10842, 11891, 11255, 14734, 42100, 19137, 17148, 13324, 15752, 10482, 12605, 13179, 11922, 13080, 10912, 10768, 10997, 16537, 10370, 12202, 12848, 18216, 12605, 14734, 17207, 17108, 28329, 65535, 261, 65530, 65532, 18030, 19137, 11685, 11061, 19137, 17148, 13557, 11016, 13091, 13827, 16707, 10250, 10258, 10080, 12605, 10985, 10708, 10250, 10258, 42100, 11, 65535, 261, 65530, 65534, 11685, 14734, 19137, 12605, 12337, 10310, 12522, 12824, 11002, 12469, 14734, 13827, 16707, 28329, 65535, 261, 65530, 65532, 16713, 16735, 19137, 10464, 13191, 10373, 10303, 12261, 16676, 10303, 19156, 11, 65535, 261, 65530, 65534, 12469, 10322, 16684, 11021, 10399, 11986, 16707, 10250, 10258, 11454, 15667, 11639, 10696, 11922, 10808, 10842, 10673, 10464, 15847, 12144, 14734, 16530, 15898, 19137, 13637, 11687, 35, 24281, 59, 358, 10997, 16537, 10696, 11922, 126, 33, 12609, 15643, 13091, 10293, 10370, 19151, 124, 10997, 16537, 10696, 11922, 2383, 19137, 12609, 15643, 11454, 15667, 11639, 10305, 10808, 10842, 10673, 10250, 10349, 12484, 13126, 12847, 17162, 28329, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 13091, 17148, 13324, 10303, 19156, 11, 65535, 261, 65530, 65534, 11168, 12220, 10293, 10452, 19151, 13734, 17631, 19137, 11584, 10842, 10997, 16537, 10370, 13308, 16696, 15158, 15752, 11634, 12176, 10847, 12605, 10402, 13179, 11685, 11459, 10912, 10768, 10997, 16537, 11957, 16803, 19137, 10384, 15646, 12848, 18216, 12605, 10402, 14734, 15667, 11639, 16884, 17387, 28329, 65535, 261, 65530, 65531, 40812, 59, 33, 13205, 13499, 11496, 12727, 13191, 15752, 11634, 14486, 16533, 13064, 17734, 14734, 15752, 10838, 10080, 12307, 13191, 13064, 17734, 17109, 10673, 13064, 19137, 12605, 11021, 10399, 14141, 13815, 14734, 10788, 14589, 11885, 10402, 13179, 11685, 11459, 13193, 10843, 14589, 12626, 28329, 65535, 261, 65530, 65531, 40812, 59, 33, 12307, 10808, 13064, 17734, 19151, 640, 643, 48, 54, 48, 51, 3486, 59, 622, 59, 643, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 11454, 10303, 19156, 11, 65535, 261, 65530, 65534, 5645, 59, 33, 10293, 10370, 19137, 10258, 10921, 11685, 19137, 12605, 10250, 14781, 17311, 11454, 14734, 10080, 12469, 12664, 12605, 13191, 10373, 10303, 10336, 10303, 19156, 11, 65535, 261, 65530, 65531, 40812, 59, 33, 12307, 10808, 13064, 17734, 19151, 640, 643, 48, 54, 48, 51, 3486, 59, 623, 59, 621, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 11315, 19137, 12605, 12159, 13197, 10464, 15752, 11454, 10305, 11044, 14734, 11957, 16713, 10285, 12656, 14035, 10250, 10283, 14398, 11764, 10080, 14398, 11764, 13091, 13191, 14808, 14398, 14332, 12333, 10261, 17303, 10768, 10323, 12415, 14734, 10370, 12314, 14583, 14328, 19137, 11684, 10402, 11454, 16735, 16713, 14734, 13064, 10560, 11268, 13558, 11454, 11012, 12003, 10842, 10250, 10283, 35, 11280, 127, 35, 11860, 28329, 65535, 261, 65530, 65534, 5645, 59, 33, 13078, 14731, 10333, 10293, 10370, 19137, 14446, 11454, 12605, 13091, 10250, 10283, 14398, 11764, 10333, 11280, 127, 11, 65535, 261, 65530, 65531, 40812, 59, 33, 12307, 10808, 13064, 17734, 19151, 640, 643, 48, 54, 48, 51, 3486, 59, 623, 59, 635, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 10464, 12509, 16503, 10921, 14817, 10303, 19156, 11, 65535, 261, 65530, 65534, 5645, 59, 33, 12605, 13091, 10283, 10653, 13655, 14015, 14015, 14734, 14398, 11764, 11280, 127, 14446, 11454, 17147, 10260, 12509, 10921, 14817, 19137, 11416, 10292, 12605, 12509, 12176, 10257, 10293, 10370, 14734, 12379, 11280, 127, 11, 65535, 261, 65530, 65531, 40812, 59, 33, 12307, 10808, 13064, 17734, 19151, 640, 643, 48, 54, 48, 51, 3486, 59, 624, 59, 620, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 18030, 19137, 13091, 11416, 10292, 10464, 13091, 13212, 11369, 10370, 10260, 17879, 16503, 14817, 16525, 19137, 12631, 10399, 12638, 17148, 10303, 16735, 14734, 10303, 19156, 11, 65535, 261, 65530, 65534, 5645, 59, 33, 10260, 14862, 17222, 10293, 10370, 11454, 16735, 10373, 10303, 11102, 11280, 127, 11687, 13258, 12605, 13091, 12656, 12604, 14398, 11764, 14734, 13212, 11369, 10370, 14734, 16713, 19137, 15713, 11899, 13091, 10260, 14589, 14817, 16525, 14734, 11280, 2411, 10444, 13091, 12605, 13091, 10250, 10283, 14398, 11764, 19137, 12509, 16503, 14817, 16525, 14734, 13064, 10560, 10423, 10985, 14817, 14734, 11280, 127, 11, 65535, 261, 65530, 65531, 40812, 59, 33, 12307, 10808, 13064, 17734, 19151, 640, 643, 48, 54, 48, 51, 3486, 59, 624, 59, 637, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 11164, 11164, 19137, 12605, 14862, 17222, 10333, 28329, 65535, 261, 65530, 65534, 5645, 59, 33, 11280, 11354, 11354, 127, 11, 65535, 261, 65530, 65531, 40812, 59, 33, 12307, 10808, 13064, 17734, 19151, 640, 643, 48, 54, 48, 51, 3489, 59, 622, 59, 674, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 11315, 43282, 11685, 10621, 17147, 13734, 15494, 10464, 16944, 11043, 11860, 19137, 10464, 11994, 11017, 8227, 112, 10333, 19137, 8227, 112, 19137, 11454, 10303, 19156, 11, 65535, 261, 65530, 65534, 5645, 59, 33, 11454, 14734, 11280, 127, 11685, 10621, 12145, 15486, 13091, 10258, 10921, 10333, 11102, 10080, 8227, 112, 10780, 10780, 14817, 11891, 10250, 16525, 19137, 17819, 13064, 11021, 10399, 15494, 10293, 10370, 12176, 12379, 11280, 127, 11, 65535, 261, 65530, 65531, 40812, 59, 33, 12307, 10808, 13064, 17734, 19151, 640, 643, 48, 54, 48, 51, 3489, 59, 623, 59, 636, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 10589, 13579, 12656, 14035, 14398, 11764, 11061, 19137, 8227, 112, 14734, 11043, 11860, 10525, 14614, 28329, 65535, 261, 65530, 65534, 5645, 59, 33, 11685, 14734, 10293, 10370, 19137, 12605, 14446, 11454, 10589, 13579, 12656, 14035, 19137, 13191, 10373, 10303, 10336, 12484, 10303, 19156, 11, 65535, 261, 65530, 65531, 40812, 59, 33, 12307, 10808, 13064, 17734, 19151, 640, 643, 48, 54, 48, 51, 3489, 59, 624, 59, 621, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 4682, 1997, 11, 65535, 261, 65530, 65534, 5645, 59, 33, 10293, 10370, 19137, 12605, 11454, 28329, 65535, 261, 65530, 65531, 40812, 59, 33, 12307, 10808, 13064, 17734, 19151, 640, 643, 48, 54, 48, 51, 3489, 59, 624, 59, 632, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 10464, 16525, 12348, 12605, 13091, 10283, 12401, 13324, 14734, 10370, 19156, 11, 65535, 261, 65530, 65534, 5645, 59, 33, 10293, 10370, 11994, 13091, 10293, 10370, 19137, 13091, 12605, 13193, 10843, 14734, 11957, 16803, 10080, 12605, 12202, 10260, 12727, 13191, 10293, 16520, 12522, 16696, 19137, 12631, 10399, 12202, 10260, 10423, 11957, 10358, 14583, 18030, 11630, 14734, 16694, 10408, 10261, 14791, 13764, 10080, 11687, 13258, 10293, 10370, 17879, 16503, 12605, 16417, 14446, 10760, 17148, 13036, 17919, 14734, 14332, 12415, 19137, 11021, 10399, 10538, 12981, 12605, 14734, 16689, 11899, 12609, 13091, 11047, 12605, 12848, 10760, 16503, 13685, 28329, 65535, 261, 65530, 65531, 40812, 59, 33, 12307, 10808, 13064, 17734, 19151, 640, 643, 48, 54, 48, 51, 3490, 59, 620, 59, 621, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 11315, 19137, 12605, 14486, 16533, 10333, 19137, 17268, 12605, 17879, 16503, 10464, 14446, 11454, 11003, 12348, 10370, 12415, 10901, 10250, 14172, 10080, 10688, 10452, 10792, 10373, 10303, 15052, 12231, 10464, 15847, 12144, 12669, 12853, 28329, 65535, 261, 65530, 65534, 5645, 59, 33, 12605, 13078, 14731, 10333, 19137, 10293, 10370, 10080, 10460, 10292, 8227, 112, 19137, 10293, 10370, 11957, 10339, 12605, 13234, 16735, 11994, 10621, 10366, 11930, 14734, 13192, 10993, 10250, 13324, 19137, 12605, 12337, 11268, 13558, 10293, 10370, 10080, 17147, 13191, 10293, 10370, 10464, 10780, 10780, 16672, 12605, 12656, 14035, 10250, 10283, 14398, 11764, 19137, 17148, 16672, 12605, 15053, 12359, 13191, 10250, 14172, 14172, 11917, 15600, 19137, 10260, 17141, 12605, 12337, 12537, 12522, 10292, 10293, 10370, 12656, 14398, 11764, 10080, 10293, 10370, 19137, 17148, 13324, 14734, 15052, 12231, 11021, 10399, 11053, 19156, 11, 65535, 261, 65530, 65531, 40812, 59, 33, 12307, 10808, 13064, 17734, 19151, 640, 643, 48, 54, 48, 51, 3490, 59, 620, 59, 641, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 12771, 10260, 17631, 14734, 28329, 65535, 261, 65530, 65534, 5645, 59, 33, 11685, 19137, 17268, 12605, 11994, 10525, 12746, 17148, 10283, 14349, 12396, 11235, 28329, 65535, 261, 65530, 65531, 40812, 59, 33, 12307, 10808, 13064, 17734, 19151, 640, 643, 48, 54, 48, 52, 291, 59, 630, 59, 621, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 13057, 10257, 11685, 28329, 65535, 261, 65530, 65534, 5645, 59, 33, 13057, 10257, 11685, 19137, 10293, 10370, 10080, 13089, 13115, 10293, 10370, 13734, 13191, 12664, 12605, 16735, 16713, 13191, 10250, 14172, 11975, 11927, 11939, 11102, 19137, 17879, 16503, 12605, 10292, 12469, 12848, 10494, 10250, 10349, 13057, 18069, 14734, 12261, 16676, 10303, 19156, 11, 65535, 261, 65530, 65531, 40812, 59, 33, 12307, 10808, 13064, 17734, 19151, 640, 643, 48, 54, 48, 52, 291, 59, 630, 59, 636, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 11223, 12691, 13571, 12691, 13571, 19137, 13089, 13115, 13191, 14172, 10336, 10080, 58, 14172, 13191, 10283, 10423, 19137, 13057, 18069, 12605, 12387, 18069, 10384, 15190, 10333, 19137, 14778, 10808, 13734, 13191, 17879, 16503, 10464, 12176, 12379, 14734, 28329, 65535, 261, 65530, 65534, 5645, 59, 33, 11957, 10260, 16944, 19137, 10293, 10370, 19137, 10441, 10308, 12605, 13499, 12722, 14734, 12527, 12484, 16672, 12469, 11426, 12658, 10333, 10080, 10687, 11903, 12605, 13734, 13191, 13064, 17734, 13819, 17191, 14734, 13445, 12389, 19137, 12631, 10399, 12202, 10260, 10423, 11927, 11939, 19137, 10293, 10370, 10260, 12368, 10292, 13581, 10696, 14643, 10080, 12605, 10305, 11044, 10423, 16417, 14446, 12348, 13179, 11685, 14734, 28329, 65535, 261, 65530, 65531, 40812, 59, 33, 12307, 10808, 13064, 17734, 19151, 640, 643, 48, 54, 48, 52, 291, 59, 630, 59, 675, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 12605, 14486, 16533, 10333, 19137, 11957, 10339, 14446, 11454, 14734, 10464, 12605, 12771, 14015, 12522, 14734, 10080, 11957, 10333, 8227, 112, 19137, 10464, 14794, 14734, 16667, 10292, 10464, 13734, 13191, 12484, 12527, 11124, 10370, 13327, 10303, 19156, 11, 65535, 261, 65530, 65534, 5645, 59, 33, 11907, 16520, 13234, 16679, 13091, 17148, 13324, 14734, 19137, 12605, 14734, 16728, 16537, 13091, 13326, 12797, 12469, 14734, 17879, 13685, 10495, 13445, 14426, 17109, 10760, 14734, 19137, 12605, 14734, 16403, 10292, 13499, 12276, 13205, 16884, 10257, 13091, 13499, 10411, 10261, 12656, 14035, 28329, 65535, 261, 65530, 65531, 40812, 59, 33, 12307, 10808, 13064, 17734, 19151, 640, 643, 48, 54, 48, 52, 291, 59, 633, 59, 636, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 17268, 10580, 16689, 10464, 10250, 14781, 15516, 12746, 12307, 10808, 17148, 10283, 16403, 10292, 13499, 12276, 19137, 12202, 10265, 10409, 10454, 10370, 17311, 10260, 14862, 17222, 10464, 13091, 11454, 13499, 10411, 10261, 12656, 14035, 11102, 19156, 11, 65535, 261, 65530, 65534, 5645, 59, 33, 17148, 13324, 13234, 16679, 19137, 12605, 11021, 15752, 10423, 16443, 10390, 10370, 16667, 10292, 13091, 10250, 10283, 12727, 13191, 12484, 12527, 12609, 10370, 13327, 14734, 10283, 10452, 10080, 10444, 13091, 19137, 10384, 12605, 14734, 14862, 16696, 10760, 10997, 19137, 12605, 12202, 10260, 15752, 12527, 11002, 10792, 15847, 12605, 28329, 65535, 261, 65530, 65531, 40812, 59, 33, 12307, 10808, 13064, 17734, 19151, 640, 643, 48, 54, 48, 52, 291, 59, 634, 59, 667, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 17268, 12605, 11687, 13258, 16735, 10464, 10780, 12638, 17148, 13619, 17109, 10760, 13091, 10384, 11685, 10745, 13557, 17109, 10760, 10285, 12752, 17177, 10760, 13234, 14734, 10250, 10283, 19137, 15646, 11454, 10687, 10390, 14734, 17109, 10760, 10285, 19137, 10464, 13191, 12665, 16667, 15752, 12527, 11002, 10792, 15847, 12605, 14734, 11903, 10487, 11102, 19156, 11, 65535, 261, 65530, 65534, 5645, 59, 33, 11687, 13258, 10336, 11903, 10261, 10464, 12631, 16735, 10250, 15850, 19137, 17268, 10303, 11021, 10399, 16692, 13078, 12605, 10780, 12638, 14734, 10997, 16537, 10260, 10250, 11899, 14794, 11903, 19137, 10444, 13091, 11042, 13324, 12605, 10322, 13051, 13764, 10784, 13032, 10464, 14734, 10997, 16537, 13091, 11060, 10292, 10336, 11903, 28329, 65535, 261, 65530, 65531, 40812, 59, 33, 12307, 10808, 13064, 17734, 19151, 640, 643, 48, 54, 48, 52, 291, 59, 638, 59, 624, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 10464, 13191, 13734, 13191, 10997, 14446, 19137, 15847, 12144, 14446, 11454, 14734, 10997, 16537, 13191, 14172, 17151, 15727, 9822, 11003, 12348, 10370, 12415, 10901, 10250, 14172, 9823, 14734, 16503, 13685, 11102, 19156, 11, 65535, 261, 65530, 65534, 5645, 59, 33, 11903, 11454, 11957, 10260, 16944, 10293, 10370, 19137, 12605, 13191, 14172, 12378, 10333, 43282, 10260, 17141, 12605, 17147, 13091, 12159, 13197, 15752, 11454, 11124, 10293, 10370, 16671, 16686, 14734, 13064, 10560, 12002, 11021, 15752, 14734, 17109, 10760, 14794, 11903, 14734, 10529, 12445, 28329, 65535, 261, 65530, 65531, 40812, 59, 33, 12307, 10808, 13064, 17734, 19151, 640, 643, 48, 54, 48, 52, 291, 59, 639, 59, 621, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 11315, 19137, 12605, 13734, 13191, 11454, 16879, 11622, 10464, 19137, 10464, 12220, 16721, 10322, 10997, 14446, 10333, 19137, 15847, 12144, 13091, 15752, 11634, 13326, 12797, 14446, 14349, 14370, 13032, 14734, 16749, 13006, 16403, 10292, 14734, 10080, 15646, 10265, 10464, 16503, 13078, 14731, 19137, 10250, 10283, 10370, 15261, 10322, 13051, 13764, 16692, 13078, 11013, 11630, 10250, 10283, 10370, 15261, 12727, 13191, 9822, 15847, 12605, 9823, 10080, 12631, 10399, 11957, 10339, 10464, 13091, 11060, 12727, 13191, 12484, 12527, 11124, 10370, 13327, 19137, 12609, 13091, 15847, 12605, 12522, 16696, 17148, 10283, 17728, 18025, 19137, 13734, 13191, 10370, 15752, 10258, 10733, 14914, 14734, 11899, 10304, 28329, 65535, 261, 65530, 65534, 5645, 59, 33, 12605, 13078, 14731, 10464, 14734, 12522, 12410, 10333, 19137, 10293, 10370, 10080, 10293, 10370, 13091, 12509, 16735, 16671, 16686, 13091, 11060, 10688, 13191, 15847, 12605, 12522, 16696, 17148, 10283, 16713, 18025, 11957, 10339, 12605, 15646, 16537, 12202, 10260, 17385, 16503, 19137, 17385, 16503, 14734, 13091, 12605, 11957, 10339, 10687, 10390, 10370, 13234, 16735, 13091, 10373, 10303, 13324, 14734, 11861, 11454, 19137, 11957, 11061, 19156, 11, 65535, 261, 65530, 65531, 40812, 59, 33, 12307, 10808, 13064, 17734, 19151, 640, 643, 48, 54, 48, 52, 291, 59, 639, 59, 639, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 11638, 10452, 10257, 13091, 17148, 13324, 14734, 28329, 65535, 261, 65530, 65534, 5645, 59, 33, 11685, 14734, 19137, 10293, 10370, 19137, 12605, 10423, 10250, 14781, 17802, 11454, 10464, 17038, 17131, 14734, 10080, 13191, 10336, 16678, 12348, 12664, 12605, 11183, 19126, 11, 65535, 261, 65530, 65531, 40812, 59, 33, 12307, 10808, 13064, 17734, 19151, 640, 643, 48, 54, 48, 52, 291, 59, 665, 59, 671, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 16713, 16735, 8227, 112, 19137, 10464, 14862, 17222, 12401, 10303, 17332, 10250, 11022, 15752, 12849, 53, 16981, 5960, 14734, 11022, 12276, 13212, 10303, 19156, 11, 65535, 261, 65530, 65534, 5645, 59, 33, 10293, 10370, 19137, 10464, 11021, 15752, 17879, 16503, 10250, 10283, 15849, 11977, 13191, 53, 10283, 6411, 46, 48495, 12849, 13485, 14734, 10293, 13248, 10079, 10250, 10283, 15752, 11634, 11621, 14486, 11638, 17387, 13004, 12797, 11124, 17144, 15200, 14734, 5704, 10079, 10261, 5960, 14734, 1555, 824, 14782, 12307, 14734, 10696, 11861, 10399, 10992, 10250, 10283, 15752, 11634, 14914, 10525, 53, 16981, 5960, 17311, 13580, 12182, 17144, 16403, 14734, 14600, 13981, 10080, 13581, 11630, 19137, 14597, 10339, 53, 16981, 5960, 14734, 15752, 15651, 17097, 11638, 19137, 10293, 10370, 11021, 15752, 17879, 16503, 11454, 13001, 14195, 16689, 11622, 10257, 10258, 14172, 10841, 11641, 28329, 65535, 261, 65530, 65531, 40812, 59, 33, 12307, 10808, 13064, 17734, 19151, 640, 643, 48, 54, 48, 52, 291, 59, 669, 59, 671, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 11315, 19137, 12605, 11638, 13445, 10333, 16533, 10333, 28329, 65535, 261, 65530, 65534, 5645, 59, 33, 11685, 14734, 10293, 10370, 19137, 10305, 11044, 13191, 15478, 15907, 10260, 13078, 14731, 11021, 10399, 15507, 15511, 17728, 12605, 10080, 11957, 10333, 19137, 14446, 11454, 17147, 13191, 11638, 13445, 630, 10768, 17544, 11994, 16503, 10792, 10293, 10370, 10423, 16676, 14734, 13064, 17734, 10333, 19137, 10293, 10370, 10260, 16503, 12378, 10333, 10733, 11622, 10423, 16676, 14734, 10336, 12484, 11183, 28329, 65535, 261, 65530, 65531, 40812, 59, 33, 12307, 10808, 13064, 17734, 19151, 640, 643, 48, 54, 48, 52, 291, 59, 670, 59, 620, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 12605, 17311, 12145, 15486, 10733, 11622, 11685, 10333, 19137, 13580, 11685, 13191, 14172, 13064, 17734, 19137, 12605, 12509, 11957, 10464, 10588, 10283, 13827, 16707, 19137, 14589, 42114, 10708, 10283, 12387, 17193, 12814, 12217, 10397, 14875, 11061, 19137, 13773, 17382, 14589, 10464, 14446, 11454, 16735, 16713, 14734, 18043, 13327, 28329, 65535, 261, 65530, 65534, 5645, 59, 33, 11685, 14734, 10293, 10370, 28329, 6884, 42114, 11, 7334, 39418, 96, 27052, 41, 7046, 501, 28352, 5170, 10293, 10370, 11021, 10399, 14589, 17148, 10283, 10397, 14875, 13234, 15494, 13004, 15476, 10384, 11975, 10792, 11638, 12814, 12217, 19137, 7046, 13091, 12335, 12814, 12217, 14734, 13004, 15476, 5170, 54807, 36, 33, 11687, 13258, 17109, 10673, 13004, 15476, 10292, 15090, 12609, 15643, 17688, 12231, 10292, 50, 19137, 11994, 13734, 12368, 16503, 15507, 15511, 15200, 11235, 19137, 14781, 12824, 17146, 11414, 28352, 1942, 21998, 41, 7046, 42, 295, 285, 59, 54807, 42178, 21290, 54807, 36, 33, 10293, 10370, 19137, 35387, 13091, 10250, 10283, 11533, 10733, 10653, 15323, 28352, 35387, 296, 21290, 92, 49, 94, 54807, 36, 33, 17148, 10278, 10283, 15200, 12276, 10423, 12669, 13004, 15476, 10285, 11975, 10339, 11533, 10733, 10653, 15323, 14734, 13004, 12983, 11454, 12138, 17131, 19137, 11638, 10339, 11533, 10733, 10653, 15323, 14734, 13004, 12983, 11454, 11025, 17131, 28352, 26118, 296, 326, 106, 21700, 340, 4596, 21290, 92, 50, 737, 4588, 340, 3586, 39288, 94, 28352, 35551, 296, 326, 106, 21700, 340, 4596, 21290, 92, 50, 737, 4588, 340, 297, 39288, 94, 54807, 36, 33, 14221, 11044, 12605, 10402, 17879, 16503, 11957, 11533, 10733, 10653, 15323, 12138, 11025, 14734, 10278, 10283, 13004, 15476, 17184, 12306, 12650, 16403, 12387, 17193, 12814, 12217, 28352, 42284, 96, 26118, 296, 39418, 96, 27052, 41, 26118, 42, 28352, 42284, 96, 35551, 296, 39418, 96, 27052, 41, 35551, 42, 54807, 36, 33, 13188, 11044, 12669, 12814, 12217, 11044, 14734, 12138, 13004, 15476, 10079, 11533, 10733, 10653, 15323, 11124, 11025, 13004, 15476, 12742, 11454, 10250, 16944, 17146, 11414, 11994, 11021, 10399, 12348, 10792, 15489, 13258, 10333, 28352, 42178, 47338, 96, 26118, 278, 326, 35387, 94, 278, 47338, 96, 35551, 11, 6884, 11, 10293, 10370, 19137, 10399, 10257, 13091, 12387, 17193, 12814, 12217, 15200, 13764, 14734, 42114, 10397, 14875, 10080, 12605, 11454, 10525, 14614, 13773, 17382, 11021, 16742, 12415, 14734, 11042, 13064, 16672, 11885, 10402, 13179, 10621, 13091, 12605, 16735, 10760, 13234, 14734, 16713, 10080, 12159, 13197, 10464, 15752, 11268, 13558, 10080, 65535, 261]
-> item_loss 0.7434132099151611 batch_loss 1.0927677353223164
==== [25106, 11, 65530, 65531, 772, 640, 643, 47, 55, 47, 639, 33, 13205, 13499, 11496, 14446, 14349, 772, 11, 10460, 10292, 13499, 11496, 10293, 10452, 19137, 11957, 10339, 13499, 11496, 14446, 14349, 10588, 10760, 10250, 10349, 12421, 15489, 10080, 12605, 11454, 17148, 13619, 13064, 17734, 10696, 12824, 12979, 10792, 10333, 10250, 12662, 16728, 13021, 19137, 10687, 10696, 11922, 10894, 12732, 11957, 10339, 11630, 17303, 12824, 11010, 14734, 10482, 14589, 10079, 11124, 10370, 15261, 10355, 13819, 10399, 10992, 11632, 10370, 11957, 16713, 15169, 10696, 11922, 10080, 10384, 17148, 10349, 16728, 13021, 10285, 11021, 10399, 14791, 10760, 10293, 10370, 12159, 13197, 12605, 15752, 11634, 11871, 10323, 10792, 14782, 12220, 14734, 15752, 10838, 19137, 10384, 15646, 13179, 15847, 14221, 11459, 11124, 10370, 15261, 10355, 13819, 10079, 13179, 10733, 14914, 14734, 11891, 12604, 10409, 10843, 10080, 11454, 10261, 15304, 15500, 10355, 10342, 14734, 17141, 15052, 10285, 19137, 12605, 17879, 16503, 15287, 10733, 14734, 13326, 12797, 16521, 10779, 17149, 16403, 12945, 10460, 19137, 11042, 13064, 15641, 16253, 10293, 10370, 14734, 17879, 13685, 19137, 12202, 10588, 10760, 17177, 12731, 19152, 11124, 10370, 15261, 10355, 13819, 14734, 17141, 15052, 10285, 19137, 12605, 12220, 12307, 16672, 16417, 17136, 13179, 10842, 15847, 14221, 10080, 14778, 10808, 12605, 17147, 13051, 13764, 12811, 12853, 13179, 10842, 15847, 14221, 14734, 16417, 17136, 13036, 12276, 19137, 11454, 11044, 15511, 17147, 17879, 16503, 17149, 16403, 11871, 10323, 19137, 12368, 16503, 14734, 13064, 10560, 11021, 10399, 11047, 10370, 15261, 16718, 17728, 28329, 17136, 12604, 17148, 10278, 10283, 14778, 13308, 13637, 17097, 11426, 17843, 19137, 10260, 17141, 10460, 10292, 10250, 10283, 820, 19137, 12605, 10423, 10848, 10838, 11459, 10985, 11986, 16707, 10588, 10792, 28329, 10293, 10370, 10441, 10308, 16735, 17141, 11044, 15511, 10423, 16672, 12605, 10482, 14589, 10250, 10349, 10762, 13004, 12824, 11010, 19137, 12609, 15643, 17189, 17141, 14328, 15671, 15573, 12825, 10794, 10250, 10349, 13212, 13375, 12609, 11920, 12010, 19137, 11042, 13064, 10652, 16684, 12605, 11957, 15847, 12144, 17109, 10673, 16728, 13021, 17149, 16403, 16675, 15475, 10080, 11454, 11044, 15511, 17213, 10792, 14782, 10684, 14862, 16696, 14734, 13064, 10560, 12605, 12609, 16684, 17879, 16503, 14614, 12522, 19137, 13581, 11630, 10684, 10339, 16503, 17171, 10673, 11632, 11977, 13004, 12797, 10792, 12605, 14734, 13499, 11496, 17384, 10322, 16684, 17147, 13091, 16503, 12664, 10293, 10370, 11143, 16718, 10250, 10258, 10080, 65535, 261, 65530, 65531, 10464, 13091, 10250, 10283, 820, 10847, 12636, 19137, 10423, 12824, 11002, 14589, 12626, 14734, 17109, 10673, 12202, 15494, 10760, 17172, 12307, 14734, 11414, 11626, 28329, 65535, 261, 65530, 65532, 17109, 10673, 59, 33, 11454, 10303, 11, 65535, 261, 65530, 65534, 11414, 11626, 59, 33, 11454, 14734, 19137, 16738, 17728, 13191, 10373, 10303, 10336, 10303, 19156, 11, 65535, 261, 65530, 65532, 17109, 10673, 59, 33, 17147, 16678, 12348, 15847, 12144, 13091, 16747, 10303, 19156, 11, 65535, 261, 65530, 65534, 11414, 11626, 59, 33, 12307, 14221, 16678, 12348, 10080, 12605, 13091, 10464, 14734, 820, 10847, 12636, 19137, 10423, 11414, 12220, 10464, 14734, 17109, 10673, 28329, 65535, 261, 65530, 65532, 17109, 10673, 59, 33, 11315, 19137, 13091, 14734, 19137, 12605, 12669, 11920, 17384, 14734, 12631, 13191, 11920, 12010, 17311, 10355, 15494, 10464, 15202, 14486, 13734, 17728, 18025, 11061, 19156, 11, 65535, 261, 65530, 65534, 11414, 11626, 59, 33, 12605, 12261, 16676, 12469, 11454, 17148, 10303, 10588, 10305, 10808, 14914, 10525, 12605, 14734, 12826, 14486, 10733, 14914, 14426, 19137, 10260, 14221, 11021, 15752, 10423, 11960, 15850, 10260, 11021, 18009, 14862, 14734, 11044, 13258, 10080, 10460, 10292, 820, 19137, 12605, 10423, 12002, 11021, 15752, 10525, 16692, 10260, 10588, 10293, 10370, 11117, 10398, 10305, 11630, 14734, 10336, 12484, 19137, 10399, 10525, 16692, 11889, 10675, 12415, 10080, 10444, 13091, 19137, 16738, 12469, 13773, 12522, 19137, 17148, 10349, 17311, 12261, 15123, 11454, 12605, 14734, 12826, 14486, 16956, 11634, 15287, 10733, 14734, 10808, 12848, 10258, 19137, 11687, 13258, 12605, 13734, 13191, 16956, 11634, 14734, 15752, 10838, 13234, 15202, 14486, 11630, 17303, 15304, 15500, 11994, 16002, 14426, 14734, 10460, 10760, 10722, 11899, 19137, 10423, 11960, 15850, 10260, 11021, 18009, 16664, 14734, 17728, 18025, 10997, 14583, 28329, 65535, 261, 65530, 65532, 17109, 10673, 59, 33, 10464, 16667, 10292, 10464, 14446, 11454, 13091, 11060, 13191, 16956, 11634, 14734, 15752, 10838, 19156, 11, 65535, 261, 65530, 65534, 11414, 11626, 59, 33, 12337, 12691, 13571, 19137, 12605, 13051, 13764, 11891, 10675, 14914, 16667, 28329, 65535, 261, 65530, 65532, 17109, 10673, 59, 33, 10464, 10435, 13827, 10250, 10258, 11061, 11, 65535, 261, 65530, 65534, 11414, 11626, 59, 33, 13326, 12797, 12605, 10402, 14734, 15667, 11639, 10964, 11024, 19137, 12605, 15752, 11634, 11124, 12469, 17149, 16403, 13191, 17207, 17108, 14734, 11957, 16713, 19137, 17148, 12522, 11110, 14808, 12605, 11021, 15752, 16956, 10399, 11891, 12604, 15190, 10932, 10409, 10843, 10080, 10260, 17141, 11957, 10339, 11626, 13215, 14734, 10409, 10843, 19137, 12605, 17147, 13091, 12159, 13197, 10293, 10370, 15752, 11634, 11454, 11957, 12605, 17149, 16403, 13827, 16707, 11044, 10703, 10722, 11899, 28329, 65535, 261, 65530, 65532, 17109, 10673, 59, 33, 11685, 14734, 19137, 12605, 15190, 10932, 13827, 16707, 10258, 10080, 12605, 17728, 10464, 10745, 10283, 17728, 18025, 11061, 19137, 18117, 10658, 19151, 11687, 13258, 12605, 16735, 12605, 12527, 16525, 12337, 14195, 19137, 15752, 11634, 12945, 10460, 15304, 15500, 14734, 10464, 10423, 10588, 10349, 10373, 10303, 19156, 11, 65535, 261, 65530, 65534, 11414, 11626, 59, 33, 10322, 16684, 12605, 10423, 17177, 12731, 12176, 12469, 12642, 12266, 15090, 16749, 12202, 16749, 15849, 10794, 10726, 13499, 12276, 12609, 15643, 12669, 15102, 12165, 12983, 10258, 15169, 28329, 65535, 261, 65530, 65532, 17109, 10673, 59, 33, 13734, 13191, 17728, 18025, 19137, 10464, 16667, 10292, 11920, 17384, 11187, 10349, 10272, 16501, 17172, 11038, 15494, 10464, 13234, 15202, 14486, 19156, 11, 65535, 261, 65530, 65534, 11414, 11626, 59, 33, 12605, 16667, 10292, 15102, 12165, 10079, 15090, 16749, 10079, 14195, 13676, 11369, 10079, 14600, 16523, 10079, 14600, 14139, 10399, 10992, 17952, 15209, 15169, 16689, 11622, 17172, 11038, 10355, 15494, 12605, 15202, 14486, 10080, 15646, 14600, 15763, 10079, 14267, 13655, 14142, 11124, 17723, 15002, 15169, 16689, 11622, 10260, 17172, 11038, 10355, 15494, 12605, 15202, 14486, 19137, 11416, 10292, 17148, 10349, 16689, 11622, 11454, 15202, 14486, 10260, 12307, 13064, 10423, 11957, 10370, 15261, 17194, 12604, 12789, 11645, 12609, 10952, 11917, 28329, 65535, 261, 65530, 65532, 17109, 10673, 59, 33, 14589, 13179, 10842, 10621, 10370, 15261, 14734, 16728, 13655, 10703, 11414, 15178, 10250, 17216, 12605, 10780, 12638, 17148, 10283, 17728, 18025, 28329, 65535, 261, 65530, 65534, 11414, 11626, 59, 33, 12605, 16667, 10292, 10293, 10370, 11021, 10399, 16672, 12605, 12825, 10794, 15102, 12165, 10079, 15090, 16749, 10079, 14195, 13676, 11369, 10079, 14600, 16523, 10079, 14600, 14139, 10399, 10992, 17952, 15209, 15169, 16689, 11622, 19137, 15646, 14600, 15763, 10079, 14267, 13655, 14142, 11124, 17723, 15002, 15169, 16689, 11622, 10779, 10260, 12220, 16721, 10355, 15494, 12605, 15202, 14486, 10080, 12605, 10260, 12509, 19137, 10322, 10260, 12220, 16721, 11957, 10293, 10370, 13191, 14059, 11454, 11753, 15723, 28329, 65535, 261, 65530, 65532, 17109, 10673, 59, 33, 12605, 16503, 11687, 10454, 16672, 10464, 11903, 14446, 12825, 10794, 17148, 10349, 16689, 11622, 11102, 19156, 11, 65535, 261, 65530, 65534, 11414, 11626, 59, 33, 10293, 10370, 11021, 10399, 16707, 14808, 16672, 15304, 15500, 16696, 10790, 12605, 11414, 11626, 10285, 14734, 14332, 11899, 11860, 15158, 19137, 13234, 16749, 14589, 11036, 15033, 16689, 11622, 14734, 12824, 11010, 19137, 13637, 11687, 12307, 12605, 14734, 11414, 11626, 10285, 10894, 11064, 393, 12266, 11068, 15090, 16749, 1678, 13064, 19137, 10953, 11021, 12642, 12266, 15090, 16749, 28329, 65535, 261, 65530, 65532, 17109, 10673, 59, 33, 13078, 14731, 10333, 19137, 12605, 12642, 15200, 12669, 11920, 17384, 15752, 15494, 10464, 12825, 10794, 14734, 10272, 16501, 17311, 10355, 15494, 10464, 12825, 10794, 28329, 65535, 261, 65530, 65534, 11414, 11626, 59, 33, 12605, 12202, 10260, 13091, 12337, 12261, 16676, 12469, 17148, 10303, 10588, 43282, 11, 65535, 261, 65530, 65532, 17109, 10673, 59, 33, 13734, 10684, 15304, 19137, 17311, 13091, 13637, 17097, 11889, 10675, 14734, 10272, 16501, 28329, 65535, 261, 65530, 65534, 11414, 11626, 59, 33, 13078, 14731, 10333, 19137, 12605, 10423, 11986, 16707, 14486, 16533, 10293, 10370, 14734, 17879, 13685, 19137, 17189, 17141, 12945, 10460, 11920, 12010, 16689, 11622, 13234, 12002, 11021, 15752, 10292, 10293, 10370, 12172, 13234, 10511, 10788, 10080, 11042, 13064, 19137, 10260, 10588, 16947, 10760, 820, 12220, 13191, 13216, 17789, 14734, 10336, 12484, 19137, 17248, 10662, 10292, 10293, 10370, 12172, 13234, 11426, 12658, 28329, 65535, 261, 65530, 65532, 17109, 10673, 59, 33, 11315, 19137, 12605, 10985, 15494, 10464, 10708, 16735, 13078, 10325, 28329, 65535, 261, 65530, 65534, 11414, 11626, 59, 33, 11685, 14734, 19137, 12605, 10423, 11454, 17148, 17384, 15169, 14808, 12469, 28329, 65535, 261, 65530, 65532, 17109, 10673, 59, 33, 11957, 10333, 19137, 11687, 13258, 12605, 16735, 12605, 16721, 14817, 10333, 19137, 10464, 11021, 15752, 10423, 10588, 10349, 10373, 10303, 19156, 11, 65535, 261, 65530, 65534, 11414, 11626, 59, 33, 12605, 11021, 15752, 10423, 13381, 13290, 10250, 10258, 14600, 14139, 14734, 14349, 12396, 19137, 11687, 13258, 13734, 13191, 10684, 17727, 19137, 10423, 12176, 12469, 10684, 17727, 10080, 12609, 15643, 12176, 12469, 12669, 15090, 16749, 14734, 18043, 10838, 16749, 11975, 28329, 65535, 261, 65530, 65532, 17109, 10673, 59, 33, 15678, 13078, 10080, 12605, 12337, 12509, 14862, 17222, 10464, 15752, 10588, 10792, 11124, 10370, 15261, 13191, 11632, 10303, 14782, 10441, 28329, 65535, 261, 65530, 65534, 11414, 11626, 59, 33, 16774, 16774, 11649, 11665, 19126, 11687, 13258, 12509, 14862, 17222, 12605, 15752, 11634, 10588, 10792, 10261, 10370, 15261, 13191, 11632, 10303, 14782, 10441, 19137, 11021, 10399, 17189, 17141, 11124, 12605, 11957, 16713, 13234, 17149, 16403, 13827, 16707, 10080, 10260, 17141, 12605, 10260, 12261, 16676, 12469, 12691, 11640, 11638, 13199, 13197, 19137, 11416, 10292, 12605, 14778, 10808, 11016, 15752, 12824, 11002, 16728, 16537, 17109, 10673, 19137, 15646, 10370, 15261, 12527, 11897, 13191, 12337, 11632, 15033, 19137, 12631, 10399, 16672, 12605, 11891, 10675, 14486, 16533, 10370, 15261, 13091, 13637, 17097, 11426, 17843, 14734, 28329, 65535, 261, 65530, 65532, 17109, 10673, 59, 33, 11685, 14734, 19137, 17268, 10303, 13827, 16707, 12266, 11726, 19137, 10258, 10921, 11685, 28329, 65535, 261, 65530, 65534, 11414, 11626, 59, 33, 11315, 11315, 19137, 10258, 10921, 11685, 28330, 12605, 13078, 14731, 10333, 19137, 12824, 10258, 13234, 12605, 10423, 11986, 16707, 16672, 15847, 12144, 14734, 16417, 17136, 11124, 10370, 15261, 12002, 11021, 15752, 14782, 10441, 42, 11, 65535, 261, 65530, 65532, 17109, 10673, 59, 33, 15847, 12605, 10382, 15484, 10258, 28329, 65535, 261, 65530, 65534, 11414, 11626, 59, 33, 11315, 19137, 12605, 11017, 14299, 10295, 19137, 11124, 10464, 14734, 12201, 18476, 14782, 10411, 19137, 12200, 12182, 11268, 13558, 16742, 10325, 19137, 12159, 13197, 12605, 10402, 15752, 15667, 12348, 12266, 12366, 10080, 19133, 12605, 11986, 16707, 16256, 13250, 10333, 10250, 10283, 16530, 15898, 19137, 11687, 13258, 10293, 10370, 10260, 11268, 13558, 19137, 11021, 10399, 11124, 12605, 16735, 19137, 12605, 10423, 17149, 16403, 16749, 13006, 19134, 11, 65535, 261, 65530, 65532, 17109, 10673, 59, 33, 12605, 14446, 11454, 13734, 10373, 10303, 10336, 12199, 19137, 12605, 10402, 11021, 10399, 10985, 10588, 10349, 10373, 10303, 28329, 65535, 261, 65530, 65534, 11414, 11626, 59, 33, 10322, 16684, 12605, 10402, 11021, 10399, 10985, 13001, 13582, 19137, 12609, 15643, 14442, 10349, 13953, 12603, 10080, 10464, 12200, 12182, 11268, 13558, 10588, 10373, 10303, 19156, 11, 65535, 261, 65530, 65532, 17109, 10673, 59, 33, 10250, 15880, 10423, 11454, 14600, 15763, 10808, 12642, 12642, 13953, 12603, 19137, 12609, 15643, 10708, 10397, 14875, 28329, 65535, 261, 65530, 65534, 11414, 11626, 59, 33, 11315, 43282, 19133, 18030, 19137, 10293, 10370, 19137, 12605, 11957, 10339, 13953, 12603, 14734, 14486, 16533, 10377, 17789, 10339, 17109, 10673, 16728, 13021, 17384, 17919, 14734, 12847, 17162, 19137, 12202, 13734, 13191, 14794, 13580, 14442, 17141, 19137, 11021, 15752, 13734, 13764, 16672, 12469, 14015, 12522, 19134, 11, 65535, 261, 65530, 65532, 17109, 10673, 59, 33, 13734, 10684, 15304, 19137, 12656, 14035, 11994, 10792, 17148, 17384, 11061, 28329, 65535, 261, 65530, 65534, 11414, 11626, 59, 33, 11685, 14734, 19137, 17147, 13191, 10373, 10303, 10336, 12484, 12605, 11021, 10399, 12176, 12469, 11053, 19156, 11, 65535, 261, 65530, 65532, 17109, 10673, 59, 33, 10464, 14862, 17222, 13594, 10353, 13091, 10373, 10303, 11053, 19156, 11, 65535, 261, 65530, 65534, 11414, 11626, 59, 33, 13326, 12797, 12605, 14734, 14862, 16696, 19137, 13594, 10353, 10953, 13091, 10260, 10703, 11861, 11454, 10339, 17148, 10283, 10267, 14610, 10257, 19137, 10384, 10687, 10390, 10370, 14734, 16667, 14862, 10285, 13855, 11645, 10080, 10260, 17141, 19137, 10370, 15261, 14778, 10808, 11957, 10339, 13594, 10353, 14734, 14486, 16533, 10383, 14221, 11861, 11454, 12005, 17789, 12415, 19137, 11416, 10292, 13594, 10353, 13091, 12337, 17843, 16520, 13827, 14734, 14446, 16803, 19137, 12631, 10399, 10687, 11638, 17303, 10768, 14734, 10696, 11922, 17147, 13091, 13203, 14862, 14734, 14349, 12396, 28329, 65535, 261, 65530, 65532, 17109, 10673, 59, 33, 11687, 13258, 12605, 12669, 10464, 14734, 13499, 11496, 10783, 17798, 19137, 12522, 11110, 14808, 10373, 10303, 19156, 11, 65535, 261, 65530, 65534, 11414, 11626, 59, 33, 10384, 13445, 12389, 10257, 13234, 16679, 19137, 10261, 13594, 10353, 14734, 14446, 16803, 12337, 14782, 10441, 28329, 65535, 261, 65530, 65532, 17109, 10673, 59, 33, 17268, 10464, 10423, 11042, 12522, 12605, 10783, 17798, 10464, 14734, 13499, 11496, 10303, 19156, 11, 65535, 261, 65530, 65534, 11414, 11626, 59, 33, 11687, 13258, 17879, 16503, 14734, 16713, 19137, 12605, 10423, 11042, 12522, 10080, 12605, 13091, 10250, 10283, 820, 19137, 13734, 13191, 15847, 12605, 19137, 11016, 13091, 13326, 12797, 17109, 10673, 10495, 13445, 14426, 17109, 10760, 11038, 17172, 14734, 11414, 12220, 28329, 65535, 261, 65530, 65532, 17109, 10673, 59, 33, 14589, 10370, 15261, 14734, 16728, 13655, 11414, 15178, 12605, 28329, 65535, 261, 65530, 65534, 11414, 11626, 59, 33, 10293, 10370, 19137, 12605, 14446, 11454, 14734, 11861, 11454, 12314, 12276, 12337, 17843, 15044, 10305, 10292, 13815, 14808, 19137, 12605, 11016, 15752, 12824, 11002, 13012, 11860, 17109, 10673, 12202, 15494, 10760, 13012, 11860, 17109, 10760, 19137, 11687, 13258, 10260, 11957, 12605, 17149, 16403, 17109, 10673, 19137, 12605, 13679, 17150, 17311, 13051, 13764, 10358, 14583, 10995, 12220, 19137, 12605, 43282, 28329, 65535, 261, 65530, 65532, 17109, 10673, 59, 33, 11198, 19137, 12605, 10423, 17182, 13932, 12669, 10464, 11891, 11255, 16944, 13234, 14734, 28329, 65535, 261, 65530, 65534, 11414, 11626, 59, 33, 10260, 16503, 10429, 12366, 19137, 10293, 10370, 19137, 12605, 11016, 13091, 13326, 12797, 12469, 14734, 17879, 13685, 17149, 16403, 10333, 17109, 10760, 19137, 12202, 13734, 13191, 14794, 13580, 11459, 17843, 17141, 10080, 10260, 17141, 19137, 12605, 12337, 13199, 12335, 15752, 11634, 12727, 13191, 13034, 14734, 10841, 15752, 28329, 65535, 261]
-> item_loss 0.7962528467178345 batch_loss 1.0699588977373564
==== [65530, 65532, 10464, 11685, 11223, 11, 65535, 261, 65530, 65534, 7176, 59, 33, 10464, 11685, 19137, 13191, 10373, 10303, 12605, 15752, 12176, 12469, 14734, 11053, 19156, 11, 65535, 261, 65530, 65532, 12605, 11017, 12287, 10337, 14363, 11, 65535, 261, 65530, 65534, 7176, 59, 33, 10464, 11685, 19137, 12287, 10337, 14363, 10080, 13191, 10373, 10303, 10336, 11053, 19156, 11, 65535, 261, 65530, 65532, 11047, 12605, 10382, 15484, 2178, 113, 14734, 10529, 12445, 11, 65535, 261, 65530, 65534, 7176, 59, 4185, 81, 46, 630, 620, 13091, 10250, 10283, 14597, 15597, 11435, 12984, 12226, 10781, 17194, 10760, 13234, 14734, 16947, 15847, 14221, 14583, 14328, 19137, 11885, 16443, 16689, 16664, 14589, 10339, 12650, 16403, 15036, 11930, 10409, 10843, 10080, 1429, 81, 46, 630, 620, 16443, 16689, 16664, 12604, 10250, 10283, 10370, 12314, 14583, 14328, 19137, 11630, 16417, 14791, 16944, 13234, 10621, 13091, 10250, 10283, 10285, 15169, 11638, 11975, 14734, 10370, 15261, 14601, 11855, 10080, 1429, 81, 46, 630, 620, 16443, 16689, 16664, 12604, 12727, 13191, 16947, 15847, 14221, 15752, 10838, 19137, 11021, 10399, 11454, 10260, 16443, 11940, 16525, 14734, 12484, 10724, 10258, 17149, 16403, 11036, 15033, 10409, 10843, 10080, 1429, 81, 46, 630, 620, 14734, 11630, 16417, 14791, 16944, 13234, 10621, 13091, 10250, 10283, 17038, 18216, 15450, 52, 15963, 11999, 10079, 10452, 17385, 10260, 10792, 650, 14944, 14734, 10370, 15261, 14601, 11855, 19137, 11885, 14734, 14806, 14815, 13091, 15446, 15898, 14734, 19137, 15752, 11634, 17819, 12522, 12981, 11003, 18029, 15898, 10080, 1429, 81, 46, 630, 620, 10688, 13191, 12299, 11638, 14734, 13133, 10838, 11124, 13212, 13133, 19137, 11021, 10399, 17149, 16403, 11036, 15033, 10409, 10843, 19137, 10444, 11885, 15568, 10309, 12182, 16696, 11124, 17222, 12363, 16520, 12389, 10080, 1429, 81, 46, 630, 620, 16443, 16689, 16664, 12604, 15752, 11634, 12650, 16403, 11036, 15033, 10409, 10843, 19137, 10444, 11885, 15568, 10309, 12182, 16696, 11124, 17222, 12363, 16520, 12389, 10080, 11885, 15486, 12182, 14347, 17631, 16730, 12609, 10588, 10760, 11656, 12418, 14734, 10296, 10846, 19137, 10444, 12421, 13091, 16707, 11436, 10525, 12686, 15847, 12144, 12202, 11891, 12604, 10409, 10843, 10080, 1429, 81, 46, 630, 620, 16443, 16689, 16664, 12604, 15752, 11634, 12650, 16403, 11036, 15033, 10409, 10843, 19137, 10444, 11885, 15568, 10309, 12182, 16696, 11124, 17222, 12363, 16520, 12389, 10080, 11885, 15486, 12182, 14347, 17631, 16730, 12609, 10588, 10760, 11656, 12418, 14734, 10296, 10846, 19137, 10444, 12421, 13091, 16707, 11436, 10525, 12686, 15847, 12144, 12202, 11891, 12604, 10409, 10843, 28329, 65535, 261]
-> item_loss 0.6089471578598022 batch_loss 1.0370294877461024
==== [25106, 11, 65530, 65531, 64113, 10399, 10258, 13091, 10355, 10342, 64113, 11, 10464, 13091, 10250, 10283, 820, 19137, 16443, 17303, 15588, 11454, 13205, 11459, 10080, 10293, 10370, 11967, 10464, 16689, 11899, 10292, 10250, 10283, 11679, 11872, 11855, 19137, 10464, 14734, 11043, 11860, 11017, 10588, 14299, 10295, 10273, 19137, 11124, 10293, 10370, 12201, 18476, 14782, 10411, 19137, 10260, 10792, 640, 12039, 10080, 10464, 13091, 820, 10444, 13091, 15752, 11634, 13499, 12722, 10370, 15261, 14734, 11036, 15033, 12527, 12484, 19137, 13637, 11687, 12266, 12366, 10079, 10429, 12366, 10079, 14583, 13655, 10079, 15648, 12366, 10079, 10399, 10992, 11036, 15033, 13562, 13197, 10080, 10464, 16443, 16689, 16664, 10760, 13234, 10292, 10370, 15261, 13193, 10843, 19137, 10444, 13091, 11042, 13064, 10464, 10322, 12159, 13197, 15847, 12144, 15752, 11634, 12348, 10792, 12203, 15009, 10261, 11971, 17385, 10080, 10464, 15752, 11634, 12945, 10460, 14600, 15763, 11124, 10250, 10349, 13133, 15752, 11920, 12010, 19137, 17879, 16503, 14734, 13064, 10560, 10464, 17879, 16503, 16735, 398, 12945, 10460, 14600, 15763, 2383, 12609, 15643, 398, 12945, 10460, 11920, 12010, 2383, 19137, 15646, 10260, 15752, 17109, 10760, 10687, 10390, 13012, 11860, 10080, 17148, 10283, 13064, 10560, 10464, 14734, 17109, 10760, 10423, 16443, 15304, 15500, 12785, 16056, 12202, 12282, 11960, 10464, 17149, 16403, 17149, 10250, 13582, 14734, 10355, 10342, 10080, 17148, 17384, 15494, 10760, 10250, 10283, 11957, 16713, 11903, 10487, 19151, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 11315, 43282, 11, 65535, 261, 65530, 65534, 14299, 10295, 10273, 59, 33, 17879, 16503, 12605, 10303, 19156, 10293, 10370, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 10464, 14862, 17222, 10464, 14734, 16689, 11899, 13091, 10373, 10303, 10303, 19156, 11, 65535, 261, 65530, 65534, 14299, 10295, 10273, 59, 33, 10293, 10370, 19137, 12605, 12826, 13827, 12469, 11454, 12605, 13499, 11496, 14734, 12266, 11647, 10708, 10333, 12605, 14734, 16689, 11899, 19137, 10894, 12732, 12605, 14734, 16530, 15898, 10079, 12415, 13327, 10079, 12314, 16803, 10399, 10992, 12605, 15752, 10588, 14734, 10336, 12484, 19137, 10460, 10292, 820, 19137, 12605, 10423, 10279, 13327, 12750, 14240, 16689, 11899, 13234, 16403, 10846, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 12605, 12159, 13197, 10464, 10399, 11044, 15752, 16678, 10449, 10464, 14734, 16689, 11899, 19137, 10464, 14862, 17222, 10464, 14734, 16689, 11899, 13091, 10373, 10303, 10303, 19156, 11, 65535, 261, 65530, 65534, 14299, 10295, 10273, 59, 33, 12605, 14862, 17222, 14734, 19137, 10444, 13091, 12605, 14734, 16689, 11899, 13637, 17097, 17688, 19137, 10293, 10370, 12159, 13197, 10333, 16533, 12605, 14734, 11187, 10250, 17303, 10768, 14734, 16689, 11899, 19156, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 16735, 16735, 10464, 14734, 11899, 10304, 11124, 10370, 14328, 16689, 11899, 11061, 28329, 65535, 261, 65530, 65534, 14299, 10295, 10273, 59, 33, 11315, 19137, 12605, 13091, 10250, 10283, 820, 19137, 17148, 10250, 17303, 10768, 12220, 16721, 13091, 12605, 14734, 11899, 10304, 10080, 12605, 14734, 10370, 14328, 16689, 11899, 13091, 10250, 10283, 11679, 11872, 11855, 19137, 12201, 18476, 10261, 12469, 14782, 10411, 19137, 15752, 11634, 13499, 12722, 10370, 15261, 14734, 12527, 12484, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 10464, 14734, 15669, 16879, 13091, 10373, 10303, 19156, 11, 65535, 261, 65530, 65534, 14299, 10295, 10273, 59, 33, 12605, 14734, 15669, 16879, 13091, 13193, 10843, 10370, 15261, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 10464, 15752, 13499, 12722, 10373, 10303, 12527, 12484, 19156, 11, 65535, 261, 65530, 65534, 14299, 10295, 10273, 59, 33, 10370, 15261, 14734, 11036, 15033, 12527, 12484, 12605, 17311, 15752, 13499, 12722, 19137, 13637, 11687, 12266, 12366, 10079, 10429, 12366, 10079, 14583, 13655, 10079, 15648, 12366, 10079, 10399, 10992, 11036, 15033, 13562, 13197, 10080, 10293, 10370, 11021, 10399, 16667, 10292, 12605, 12727, 13191, 17148, 10349, 12527, 12484, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 10464, 16667, 10292, 10464, 12727, 13191, 10303, 19156, 11, 65535, 261, 65530, 65534, 14299, 10295, 10273, 59, 33, 11687, 13258, 13499, 12722, 14734, 10792, 10447, 14734, 16713, 19137, 12605, 10423, 16667, 10292, 12605, 12727, 13191, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 10464, 15752, 10588, 10349, 10373, 10303, 19156, 11, 65535, 261, 65530, 65534, 14299, 10295, 10273, 59, 33, 12605, 15752, 11634, 15287, 10733, 12650, 16403, 10293, 10370, 14734, 11117, 10398, 10079, 10292, 10293, 10370, 16533, 15178, 14638, 17728, 19137, 12609, 15643, 10621, 10250, 10283, 10370, 15261, 10250, 13324, 11124, 10293, 10370, 15667, 11639, 10080, 17798, 13581, 10305, 11630, 19137, 12605, 17147, 11021, 10399, 12176, 10847, 10293, 10370, 12945, 10460, 14600, 15763, 11124, 13133, 15752, 11920, 12010, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 12945, 10460, 14600, 15763, 11124, 13133, 15752, 11920, 12010, 19156, 11, 65535, 261, 65530, 65534, 14299, 10295, 10273, 59, 33, 13091, 14734, 19137, 16689, 11899, 17384, 13191, 16722, 15478, 10708, 12605, 15752, 12401, 10303, 10588, 19137, 15646, 10265, 15494, 10333, 12605, 10250, 10283, 10487, 11855, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 10464, 11632, 11638, 19156, 11, 65535, 261, 65530, 65534, 14299, 10295, 10273, 59, 33, 17728, 11679, 11872, 11855, 12201, 18476, 10260, 11640, 11038, 17172, 11061, 10080, 11685, 11061, 19137, 10687, 11903, 12605, 10322, 10260, 13923, 13425, 19137, 16689, 11899, 17384, 11016, 10708, 10333, 12605, 10260, 16956, 640, 12039, 19137, 10322, 16684, 13091, 638, 12039, 19156, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 11903, 17781, 10257, 11102, 19156, 11, 65535, 261, 65530, 65534, 14299, 10295, 10273, 59, 33, 17268, 16503, 14791, 12605, 16443, 17194, 10760, 13234, 11632, 10301, 10333, 19137, 12605, 10260, 14914, 11899, 28329, 65535, 261]
-> item_loss 0.6307669281959534 batch_loss 1.009945317109426
==== [65530, 65531, 7451, 1802, 33, 14782, 10684, 17728, 18025, 11, 65535, 261, 65530, 65532, 11687, 10454, 11454, 7451, 1802, 10285, 17189, 17141, 7441, 2191, 16690, 17728, 26081, 31883, 33, 10285, 14734, 13012, 13205, 19156, 11, 65535, 261, 65530, 65534, 11454, 7441, 2191, 10285, 17189, 17141, 7441, 2191, 16690, 17728, 26081, 31883, 10285, 14734, 13012, 13205, 11021, 10399, 10482, 14589, 10399, 10258, 13582, 18197, 19151, 11, 65535, 261, 65530, 65534, 10399, 10258, 13091, 11454, 7451, 1802, 10285, 17189, 17141, 7441, 2191, 16690, 17728, 26081, 31883, 33, 10285, 14734, 13012, 13205, 59, 11, 50, 47, 33, 11960, 10673, 26081, 46, 26901, 12219, 59, 11, 6884, 7441, 2191, 11, 41, 49636, 274, 26081, 46, 26901, 42, 11, 6884, 11, 51, 47, 33, 10482, 14589, 331, 26081, 46, 26901, 46, 9113, 108, 97, 33, 10762, 13004, 16056, 11001, 26081, 31883, 10285, 13188, 13034, 13012, 13205, 59, 11, 6884, 7441, 2191, 11, 41, 26081, 46, 26901, 46, 9113, 108, 42, 11, 6884, 11, 52, 47, 33, 17189, 17141, 31213, 46, 26901, 12219, 14734, 10762, 13004, 16056, 11001, 14332, 11899, 10447, 15586, 14734, 13012, 13205, 59, 11, 46, 331, 26081, 46, 26901, 46, 25566, 97, 33, 16056, 11001, 13188, 13034, 13012, 13205, 11, 46, 331, 26081, 46, 26901, 46, 7621, 97, 33, 16056, 11001, 12748, 11899, 10447, 15586, 14734, 13012, 13205, 45, 10427, 10673, 10447, 15586, 11028, 10953, 11021, 11, 10487, 11687, 59, 11, 6884, 7441, 2191, 11, 41, 26081, 46, 26901, 46, 7621, 284, 42, 11, 6884, 11, 16056, 11001, 26081, 31883, 15162, 10337, 13231, 13188, 13034, 13012, 13205, 28329, 53, 47, 33, 17147, 11021, 10399, 10482, 14589, 331, 26081, 46, 26901, 46, 26985, 97, 33, 11967, 13012, 13205, 12983, 10673, 26081, 31883, 45, 331, 26081, 46, 26901, 46, 41246, 97, 33, 10783, 17798, 12748, 11899, 10447, 15586, 14734, 13012, 13205, 28329, 17148, 10349, 10762, 13004, 16672, 10464, 11021, 10399, 12337, 13036, 10511, 11459, 11454, 7441, 2191, 10397, 14875, 10285, 16742, 10708, 7451, 1802, 14734, 26081, 31883, 28329, 12159, 13197, 15752, 10292, 10464, 12848, 10494, 10988, 15641, 34, 11687, 13258, 17147, 13191, 14638, 17728, 13558, 17143, 15507, 15511, 12848, 10760, 28329, 50, 47, 33, 12642, 12266, 7451, 1802, 12202, 10842, 17095, 26081, 31883, 14782, 10684, 14734, 13499, 11473, 28329, 51, 47, 33, 10482, 14589, 17644, 14767, 10257, 14734, 23537, 44, 68, 12609, 15643, 33431, 44, 48440, 44, 87, 13829, 16524, 35543, 111, 45368, 28329, 52, 47, 33, 11454, 35543, 111, 45368, 10285, 17109, 10673, 59, 19242, 6884, 19242, 41, 26163, 46, 41129, 46, 25460, 46, 42324, 269, 41129, 35, 274, 465, 41129, 35, 275, 26821, 46, 42324, 494, 19242, 5265, 19242, 6884, 19242, 17148, 11967, 10384, 14782, 10684, 13499, 11473, 10285, 16742, 11001, 26081, 31883, 10285, 14734, 13012, 13205, 19137, 12202, 11967, 10687, 11861, 10609, 11454, 41129, 10285, 10080, 65535, 261, 65530, 65532, 17148, 13619, 10397, 14875, 16417, 14966, 10373, 10303, 12522, 12410, 19156, 11, 41, 7334, 2239, 21440, 8875, 48, 27003, 46, 42153, 275, 7137, 21616, 42, 3331, 41, 63076, 275, 26157, 275, 42153, 46, 34018, 26322, 42, 65414, 41, 42153, 46, 7463, 5292, 3331, 41, 26200, 46, 49585, 19242, 59, 26290, 269, 1795, 2226, 1818, 48, 49697, 46, 35325, 35, 19242, 59, 41129, 3352, 1795, 2226, 1818, 48, 49697, 46, 35325, 516, 19242, 59, 41183, 274, 8985, 46, 57, 19242, 59, 48988, 274, 465, 42114, 35, 65084, 387, 33553, 48, 2350, 7007, 26052, 48, 49689, 48, 7257, 8875, 47, 2134, 381, 19242, 59, 41418, 267, 41, 41749, 275, 26742, 22522, 42, 275, 41638, 22522, 494, 19242, 42, 3331, 41, 49585, 46, 27003, 46, 42153, 267, 35, 1795, 2226, 1818, 48, 49697, 46, 35325, 35, 21340, 21616, 42, 3331, 41, 49585, 46, 27003, 46, 42324, 267, 35, 1795, 2226, 1818, 48, 49697, 46, 35325, 35, 269, 261, 381, 3331, 41, 49585, 46, 27003, 46, 7478, 269, 1795, 2226, 1818, 48, 49697, 46, 35325, 5172, 65535, 261, 65530, 65534, 17148, 13619, 10397, 14875, 13091, 10250, 10283, 3784, 6908, 20299, 113, 33, 10762, 13004, 45, 11885, 10423, 10588, 10399, 10258, 10336, 12484, 59, 11, 50, 47, 33, 16056, 11001, 14589, 12626, 17177, 10285, 14734, 10912, 11524, 41, 42153, 497, 10953, 21340, 33, 11124, 21616, 33, 11003, 17387, 11, 51, 47, 33, 10781, 12261, 10250, 10283, 11043, 10292, 35, 1795, 2226, 1818, 48, 49697, 46, 35325, 35, 14734, 17149, 15052, 11, 52, 47, 33, 10482, 14589, 46966, 282, 33553, 48, 2350, 7007, 26052, 48, 49689, 48, 7257, 8875, 47, 2134, 33, 15768, 13205, 10460, 10292, 11117, 10398, 16403, 11, 53, 47, 33, 17149, 15052, 17109, 10760, 13064, 45, 10423, 10482, 14589, 10915, 11043, 10762, 13004, 275, 41749, 275, 26742, 22522, 42, 275, 41638, 22522, 494, 33, 12849, 10673, 10792, 382, 1795, 2226, 1818, 48, 49697, 46, 35325, 516, 33, 15540, 10721, 10912, 10285, 11, 54, 47, 33, 11967, 17177, 10285, 14734, 10912, 11524, 41, 7137, 33, 10792, 21616, 42, 10997, 17171, 10792, 16721, 17149, 15052, 11, 55, 47, 33, 10997, 17171, 10278, 10283, 12791, 16403, 15158, 11, 56, 47, 33, 11047, 17149, 15052, 10997, 17171, 19796, 41, 15489, 13229, 17149, 15052, 42, 11, 12421, 14734, 13234, 16735, 45, 17148, 10283, 10762, 13004, 10423, 11967, 17177, 10285, 14734, 13012, 13205, 10912, 11524, 10460, 10292, 17109, 10673, 45, 10997, 17171, 10792, 21440, 8875, 47, 2134, 33, 17148, 10283, 44742, 33, 15768, 13205, 10985, 11621, 14486, 45, 14221, 11044, 11967, 44742, 33, 15768, 13205, 14734, 17109, 10760, 12849, 10673, 10792, 10250, 10283, 3784, 6908, 33, 15540, 10721, 10912, 10285, 10080, 65535, 261]
-> item_loss 1.8546332120895386 batch_loss 1.062738310545683
==== [25106, 11, 65530, 65531, 32937, 4600, 332, 55767, 45, 53272, 31894, 49551, 64335, 51035, 3965, 2098, 21265, 332, 30971, 39095, 37074, 46, 6602, 98, 47, 29059, 21286, 32074, 32386, 59829, 46853, 37598, 37074, 46, 6602, 98, 460, 31894, 21265, 63757, 59, 11, 50, 47, 37074, 46, 6602, 98, 4600, 332, 45971, 4304, 27209, 32227, 30659, 38919, 8837, 7000, 4712, 4259, 25979, 47, 11, 51, 47, 37074, 46, 6602, 98, 4600, 4419, 3609, 47, 11, 52, 47, 37074, 46, 6602, 98, 22748, 51351, 4450, 332, 62391, 39095, 21094, 1744, 47, 11, 53, 47, 37074, 46, 6602, 98, 39301, 38576, 32139, 4423, 4716, 118, 21265, 29398, 34177, 21265, 39691, 39742, 47, 11, 54, 47, 37074, 46, 6602, 98, 21800, 332, 45752, 21400, 46859, 55574, 45, 40186, 59396, 32487, 22590, 31530, 7472, 25660, 45, 22661, 25858, 101, 21265, 22249, 26096, 7911, 47539, 22464, 57015, 31947, 47, 11, 55, 47, 37074, 46, 6602, 98, 4600, 51371, 21265, 64382, 37598, 56537, 22168, 47539, 21265, 63662, 32487, 21811, 53285, 47, 11, 56, 47, 37074, 46, 6602, 98, 37949, 21811, 30819, 4377, 8801, 39863, 1660, 47, 11, 57, 47, 37074, 46, 6602, 98, 38939, 4811, 21227, 4377, 34545, 1660, 4424, 22590, 21616, 4706, 32074, 4706, 21811, 60476, 47, 11, 62981, 4706, 37074, 46, 6602, 98, 59, 45752, 21400, 46859, 45, 51371, 45, 22661, 25858, 101, 45, 22249, 26096, 7911, 45, 46992, 45, 46480, 47, 65535, 261, 65530, 65531, 92, 33465, 332, 22168, 30434, 94, 11, 65535, 261, 1195, 2098, 59, 3880, 37074, 46, 6602, 98, 45, 4601, 460, 38629, 4811, 22449, 22799, 37635, 34, 30031, 31059, 22799, 30259, 4833, 4811, 46402, 64, 11, 65530, 65534, 1294, 8962, 46, 6602, 98, 59, 277, 27199, 116, 4811, 30807, 22799, 45, 21811, 51470, 30806, 56547, 4833, 32487, 61966, 43, 36786, 34, 308, 5231, 30259, 46170, 4788, 31466, 21716, 4712, 4677, 53025, 46402, 45, 52491, 4716, 118, 21265, 29398, 34177, 21265, 52910, 39742, 32487, 4677, 53285, 34, 19417, 308, 5231, 30259, 53362, 4712, 56537, 31458, 37598, 22590, 40213, 21265, 22590, 46787, 4596, 4601, 47, 20063, 37598, 22799, 64, 30031, 31059, 22799, 30259, 4833, 4811, 64, 11, 65535, 261, 1195, 2098, 59, 4091, 45, 22187, 31466, 47, 29182, 53362, 21265, 47629, 4811, 32113, 30360, 47, 308, 5231, 30259, 57552, 32515, 53025, 47544, 45, 21265, 308, 47008, 38374, 32229, 34, 11, 65530, 65534, 1294, 8962, 46, 6602, 98, 59, 277, 2188, 34717, 32438, 2030, 43, 37448, 22799, 4788, 31466, 45, 38676, 34, 308, 459, 30976, 22799, 38374, 32229, 47, 3917, 39934, 55521, 22799, 458, 31296, 4811, 22449, 4660, 4491, 4712, 332, 47423, 64, 308, 459, 45150, 52157, 21700, 22168, 38735, 4811, 31358, 4677, 53025, 30788, 45301, 47, 11, 65535, 261, 1195, 2098, 59, 54819, 45, 308, 22748, 60762, 4588, 22799, 38128, 32006, 4835, 21835, 22799, 32462, 51351, 47, 308, 459, 47008, 62144, 4596, 22590, 60623, 32011, 4706, 47539, 47, 11, 65530, 65534, 1294, 8962, 46, 6602, 98, 59, 277, 8254, 25139, 62647, 2030, 43, 3631, 45, 22796, 34, 308, 21413, 61821, 4491, 32227, 47, 308, 22748, 51351, 4450, 4677, 62391, 45, 21094, 1744, 45, 40085, 55464, 3609, 61559, 21265, 51377, 46, 25190, 62634, 47, 3918, 460, 47008, 63571, 39841, 34, 308, 458, 31337, 4811, 39655, 4601, 32487, 4677, 53285, 4588, 308, 21751, 22590, 45449, 47, 37448, 22799, 21700, 22590, 62608, 34, 36782, 34, 11, 65535, 261, 65530, 65531, 92, 33465, 332, 22168, 30434, 94, 11, 65535, 261, 1195, 2098, 59, 3880, 37074, 46, 6602, 98, 45, 308, 31337, 32515, 53025, 34, 30076, 52910, 40139, 4600, 50892, 34, 29045, 22799, 30789, 53137, 4706, 38279, 332, 51274, 64, 11, 65530, 65534, 1294, 8962, 46, 6602, 98, 59, 277, 2188, 34717, 56330, 2030, 43, 37448, 22799, 4788, 31466, 45, 38676, 34, 308, 459, 47008, 30976, 22799, 51619, 32515, 32251, 32487, 4660, 47, 19417, 332, 51274, 64, 29889, 47341, 31296, 4788, 31466, 21716, 34, 308, 5231, 39115, 30666, 22226, 45285, 45, 21400, 308, 458, 31337, 4811, 30972, 4601, 332, 22626, 47, 37004, 308, 38128, 30788, 4491, 332, 53293, 51274, 47, 11, 65535, 261, 1195, 2098, 59, 29889, 460, 332, 38629, 31135, 34, 308, 40219, 61821, 32317, 4596, 21700, 32227, 47, 30031, 31214, 4706, 39742, 40219, 22799, 32022, 64, 11, 65530, 65534, 1294, 8962, 46, 6602, 98, 59, 277, 54389, 21700, 332, 46594, 43, 20050, 45, 32458, 45, 308, 31337, 21256, 38841, 4706, 39082, 45, 4788, 308, 458, 32435, 4811, 51987, 332, 53264, 4706, 39742, 4596, 22590, 51274, 47, 308, 38128, 32022, 32074, 52516, 39742, 45, 32074, 30226, 6921, 45, 38986, 30788, 32074, 40136, 8328, 21265, 20024, 8763, 102, 20419, 118, 39742, 47, 308, 31337, 20024, 8763, 102, 20419, 118, 39742, 34, 11, 65535, 261, 65530, 65531, 92, 33465, 332, 22168, 30434, 94, 11, 65535, 261, 1195, 2098, 59, 20039, 37074, 46, 6602, 98, 45, 308, 22748, 60762, 4588, 22799, 21795, 21273, 32257, 21700, 59832, 38530, 21265, 64864, 64, 11, 65530, 65534, 1294, 8962, 46, 6602, 98, 59, 277, 8254, 25139, 45236, 34918, 43, 54813, 2030, 34, 37451, 21286, 332, 22031, 4706, 47539, 22799, 21413, 4491, 4811, 51982, 32515, 38530, 21265, 64864, 47, 20556, 4706, 4677, 56210, 62633, 4600, 4811, 4491, 59241, 59674, 45, 31296, 30597, 38777, 1858, 21265, 30797, 8078, 47, 3918, 21413, 47008, 31073, 38049, 32515, 31427, 21265, 21751, 22799, 4596, 22590, 32523, 47, 19555, 4588, 32227, 38278, 461, 32499, 45, 22799, 38128, 45150, 22626, 60522, 31458, 51527, 45, 31296, 56064, 4419, 45873, 22316, 4706, 45512, 34, 11, 65535, 261, 1195, 2098, 59, 3873, 73, 47, 4281, 45, 308, 459, 22187, 32157, 32227, 460, 22590, 30273, 31135, 5362, 11, 65530, 65534, 1294, 8962, 46, 6602, 98, 59, 277, 26111, 7856, 4596, 45501, 45, 21811, 40139, 56069, 4811, 332, 53345, 43, 4097, 45, 22799, 38128, 22626, 4677, 47206, 46561, 47, 308, 39798, 4424, 332, 52467, 4706, 332, 32433, 21700, 38716, 4712, 21616, 45, 40076, 21256, 57422, 59533, 30917, 4677, 31427, 47, 3918, 460, 332, 30899, 4706, 52035, 62204, 32227, 45143, 4660, 4811, 50848, 55801, 21265, 39984, 38530, 47, 19555, 4435, 47766, 45, 4601, 460, 22187, 21700, 22590, 38443, 4706, 38676, 47, 277, 42303, 21408, 1994, 7856, 40061, 8840, 8101, 7166, 43, 11, 65535, 261, 1195, 2098, 59, 4285, 45, 21286, 22799, 51728, 31574, 45, 37074, 46, 6602, 98, 64, 11, 65530, 65534, 1294, 8962, 46, 6602, 98, 59, 277, 54366, 34326, 4833, 21265, 60515, 30678, 21811, 51470, 31039, 43, 4089, 45604, 45, 38676, 34, 21152, 4491, 22799, 21295, 64, 277, 25509, 116, 22799, 332, 32470, 46, 25387, 31014, 32227, 38932, 332, 46454, 22614, 32470, 43, 29182, 57083, 45, 4588, 22799, 30789, 31506, 4811, 50848, 22590, 57481, 38530, 45, 22799, 31223, 32464, 4811, 4491, 47, 277, 9080, 2000, 43, 11, 65535, 261, 65530, 65531, 92, 33465, 332, 22168, 30434, 94, 11, 65535, 261, 65530, 65534, 1294, 8962, 46, 6602, 98, 59, 277, 853, 22799, 38377, 22590, 31898, 45, 22799, 22449, 37074, 46, 6602, 98, 52915, 4424, 21811, 55809, 31296, 22464, 45150, 30659, 45, 21811, 30806, 51770, 46314, 2030, 4712, 22590, 47195, 47, 30032, 22464, 52325, 22799, 45, 332, 45358, 39725, 52982, 45093, 21811, 30807, 45, 21265, 22464, 40040, 4811, 30807, 22799, 32487, 61966, 47, 20035, 39711, 45, 3609, 30899, 4600, 21231, 2163, 1843, 4596, 332, 30554, 47188, 53232, 45, 55801, 32487, 332, 30302, 47162, 45516, 21265, 332, 38631, 21382, 8809, 47, 37074, 46, 6602, 98, 38632, 116, 22799, 32487, 332, 45752, 45, 21400, 46859, 32269, 45, 21811, 61947, 31618, 24381, 4596, 22590, 21246, 581, 11, 6007, 45, 308, 459, 37074, 46, 6602, 98, 45, 308, 459, 4419, 3609, 22762, 38939, 4811, 31702, 38576, 21265, 32022, 39742, 47, 4035, 51353, 45, 21094, 1744, 45, 62390, 4660, 4811, 4435, 51371, 21265, 64382, 37598, 56537, 22168, 47539, 45, 4788, 308, 459, 45150, 52157, 21700, 21716, 21265, 63667, 32448, 4811, 56475, 32487, 4677, 39863, 47, 308, 31104, 22799, 38374, 32515, 32251, 32487, 4660, 47, 36782, 34, 65535, 261]
-> item_loss 0.7356166839599609 batch_loss 1.0434958619229935
==== [65530, 65531, 10684, 10339, 7451, 1802, 10696, 11922, 14734, 17728, 15178, 11, 65535, 261, 65530, 65532, 11687, 10454, 16056, 11001, 7451, 1802, 267, 25028, 34043, 14734, 10285, 14734, 10696, 11922, 19156, 11, 65535, 261, 65530, 65534, 10464, 11021, 10399, 10482, 14589, 10399, 10258, 4515, 7917, 33, 10397, 14875, 16056, 11001, 3784, 6908, 267, 25028, 34043, 33, 14734, 10696, 11922, 59, 11, 6884, 7441, 2191, 11, 41, 49026, 46, 26081, 283, 42, 11, 6884, 11, 97, 49026, 46, 26081, 97, 33, 10762, 13004, 13191, 10278, 10283, 10988, 13004, 59, 11, 46, 283, 33, 16417, 14966, 16056, 11001, 13188, 17145, 14734, 31213, 11, 46, 33, 13580, 13004, 16417, 14966, 16056, 11001, 13179, 13057, 14734, 31213, 11, 12631, 10399, 10292, 10333, 11016, 16056, 11001, 13188, 13034, 14734, 59300, 33, 10696, 11922, 45, 12605, 10402, 10427, 10673, 283, 33, 10953, 11021, 28329, 10487, 11687, 59, 11, 6884, 7441, 2191, 11, 41, 8079, 3421, 27139, 275, 49026, 46, 26081, 283, 5292, 3331, 41, 49410, 269, 57956, 51308, 59, 272, 116, 35, 32224, 494, 11, 6884, 11, 17148, 13619, 10397, 14875, 10423, 16056, 11001, 59300, 33, 10696, 11922, 45, 12202, 13098, 14966, 11454, 13855, 12445, 13314, 10285, 28329, 10464, 10322, 11021, 10399, 12669, 59300, 33, 10696, 11922, 16914, 10577, 15494, 10250, 10283, 11003, 17387, 45, 14221, 11044, 17149, 16403, 14782, 10684, 14734, 11621, 14486, 28329, 12631, 10399, 45, 10482, 14589, 331, 49026, 46, 26081, 283, 97, 33, 11994, 11021, 10399, 11454, 3784, 6908, 20299, 113, 33, 10397, 14875, 10285, 16056, 11001, 3784, 6908, 33, 14734, 59300, 33, 10696, 11922, 10080, 65535, 261, 65530, 65532, 10482, 14589, 10373, 10303, 7441, 2191, 10762, 13004, 15752, 11634, 11903, 14446, 11454, 7451, 1802, 10285, 14734, 8401, 46, 26267, 10258, 17177, 10285, 13279, 10283, 8760, 46, 27187, 19156, 11, 65535, 261, 65530, 65534, 11021, 10399, 10482, 14589, 22236, 46, 34200, 33, 11117, 10398, 13234, 17177, 10285, 53048, 64, 11, 12750, 17644, 15487, 11899, 59, 11, 68, 46, 100, 332, 275, 8401, 46, 34200, 42, 11, 14589, 13764, 59, 11, 50, 47, 33, 10659, 13308, 12983, 11454, 8760, 27187, 14734, 13308, 18025, 10257, 11, 51, 47, 33, 12750, 302, 46, 100, 332, 11, 52, 47, 33, 17148, 11967, 17177, 10285, 16721, 8760, 27187, 10258, 14734, 12631, 13191, 10696, 11922, 11, 10464, 10322, 11021, 10399, 12748, 11899, 17879, 16503, 12357, 14445, 14734, 13557, 13004, 13234, 17177, 10285, 10260, 11042, 15451, 10790, 14734, 10696, 11922, 59, 11, 46, 302, 46, 100, 332, 284, 280, 33, 17177, 10285, 12307, 10808, 16403, 11, 46, 302, 46, 100, 332, 285, 280, 33, 17177, 10285, 12307, 10808, 15907, 14172, 41, 13308, 18025, 10992, 11855, 15907, 14172, 42, 11, 46, 302, 46, 100, 332, 286, 280, 33, 17177, 10285, 12307, 10808, 15907, 14172, 14734, 14302, 15907, 14172, 11, 46, 33, 15169, 15169, 11, 12631, 10399, 45, 11454, 22236, 46, 26267, 33, 10258, 17177, 10285, 13279, 10283, 53048, 45, 10464, 11021, 10399, 59, 11, 50, 47, 33, 10659, 13308, 12983, 11454, 16721, 53048, 33, 14734, 13308, 18025, 10257, 11, 51, 47, 33, 16749, 14589, 4398, 8401, 46, 34200, 313, 512, 10762, 13004, 45, 79, 33, 10292, 16503, 12357, 14445, 14734, 13557, 13004, 45, 10399, 17177, 10285, 16721, 11855, 13315, 11, 10487, 11687, 59, 11, 6884, 4515, 7917, 11, 41, 8401, 46, 34200, 285, 42, 267, 60, 33, 17177, 10285, 12307, 10808, 15907, 14172, 41, 11855, 13315, 42, 11, 6884, 11, 12159, 13197, 17148, 15752, 12176, 10847, 10464, 34, 65535, 261]
[2023-09-30 21:45:49,544] [INFO] [logging.py:96:log_dist] [Rank 0] step=20, skipped=0, lr=[0.0001, 0.0001, 0.0001], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
-> item_loss 1.9701517820358276 batch_loss 1.0949767463737063
==== [54278, 11, 65530, 65532, 17379, 14589, 1843, 111, 13327, 12276, 17146, 11414, 16809, 51, 11483, 10660, 14734, 10529, 12445, 11, 65535, 261, 65530, 65534, 2370, 26290, 269, 16809, 51, 11483, 10660, 35, 11, 59, 8148, 58475, 269, 1193, 24791, 46, 1250, 7556, 106, 35, 3339, 59, 42519, 3527, 265, 59, 41775, 3483, 47, 51, 265, 59, 36008, 286, 47, 56, 11, 59, 41330, 3501, 49, 18157, 10838, 45736, 11, 59, 26199, 96, 7658, 3483, 54, 13644, 15260, 14167, 262, 59, 53988, 4363, 11412, 13036, 12314, 14167, 11559, 35, 269, 12826, 17149, 11369, 12826, 17149, 395, 11, 59, 63053, 269, 16809, 51, 13091, 16501, 12363, 14880, 10794, 14734, 10250, 15033, 17385, 11496, 11483, 10660, 45, 11454, 639, 690, 12201, 10397, 12266, 11726, 13193, 12328, 10080, 399, 65535, 261, 65530, 65532, 17379, 14589, 1843, 111, 13327, 12276, 17146, 11414, 10272, 18043, 46, 647, 11960, 12298, 14734, 10529, 12445, 11, 65535, 261, 65530, 65534, 43, 33, 16809, 51, 11483, 10660, 10529, 12445, 11, 2370, 26290, 269, 16809, 51, 35, 11, 59, 8148, 58475, 269, 10660, 10853, 13033, 46, 17142, 16081, 35, 11, 59, 42519, 269, 674, 33, 11062, 35, 265, 59, 41775, 269, 630, 47, 51, 33, 15260, 35, 11, 59, 36008, 269, 52, 47, 56, 33, 15260, 35, 11, 59, 41330, 269, 648, 49, 18157, 10838, 267, 11412, 10721, 15052, 13297, 13750, 13212, 35, 11, 59, 26199, 96, 7658, 269, 630, 54, 33, 13644, 15260, 14167, 35, 265, 59, 53988, 4363, 11412, 13036, 12314, 14167, 11559, 35, 269, 12826, 17149, 11369, 12826, 17149, 395, 11, 59, 63053, 269, 16809, 51, 13091, 16501, 12363, 14880, 10794, 14734, 10250, 15033, 17385, 11496, 11483, 10660, 45, 11454, 639, 690, 12201, 10397, 12266, 11726, 13193, 12328, 10080, 399, 65535, 261]
-> item_loss 1.8649086952209473 batch_loss 1.1354994805235612
==== [25106, 11, 65530, 65531, 13091, 10250, 10283, 10370, 12137, 13133, 15752, 10847, 12636, 19137, 11021, 10399, 12176, 10847, 10370, 15261, 10588, 11036, 15033, 10336, 12484, 19137, 33914, 8778, 117, 12337, 11268, 13558, 12176, 10847, 10370, 15261, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 10464, 17147, 11454, 11871, 10323, 10285, 19137, 11957, 11061, 28329, 65535, 261, 65530, 65534, 33914, 8778, 117, 59, 33, 13091, 14734, 19137, 12605, 17147, 11454, 11871, 10323, 10261, 17161, 10397, 10285, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 17268, 10303, 12605, 12509, 11088, 16698, 10464, 10283, 13191, 14589, 14734, 14862, 16696, 28329, 65535, 261, 65530, 65534, 33914, 8778, 117, 59, 33, 11685, 14734, 19137, 10293, 10370, 19137, 10464, 16735, 11061, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 12605, 10402, 12410, 15641, 17728, 18025, 12220, 16721, 10675, 17919, 19137, 11016, 10384, 10250, 10283, 16530, 12231, 10985, 12410, 15641, 17728, 18025, 13091, 10260, 11634, 14734, 28329, 65535, 261, 65530, 65534, 33914, 8778, 117, 59, 33, 12605, 14486, 16533, 10464, 14734, 12522, 12410, 19137, 13091, 16503, 10384, 11632, 10283, 16530, 12231, 13234, 12410, 15641, 17728, 18025, 19137, 11957, 11061, 19156, 11, 65535, 261, 65530, 65532, 27370, 59, 33, 13734, 17631, 19137, 10296, 10283, 10487, 11855, 19137, 13637, 11687, 12605, 11454, 11630, 17919, 16968, 13582, 16968, 10333, 12337, 10301, 19137, 11414, 10792, 11920, 19137, 15646, 10464, 13091, 12605, 14734, 11920, 12984, 820, 19137, 10464, 10423, 10292, 12605, 10588, 10373, 10303, 19156, 11, 65535, 261, 65530, 65534, 33914, 8778, 117, 59, 33, 12605, 10423, 10292, 12469, 10733, 11622, 13676, 11124, 18053, 14328, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 10974, 11416, 11102, 19156, 11, 65535, 261, 65530, 65534, 33914, 8778, 117, 59, 33, 11416, 10292, 12605, 16667, 10292, 12469, 16968, 13582, 11044, 17879, 16503, 16416, 10655, 16099, 10691, 11124, 13676, 10768, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 13091, 14734, 19137, 10444, 13091, 10464, 11042, 13064, 10322, 16721, 15641, 16253, 10792, 19137, 16968, 13582, 11044, 12605, 10423, 13637, 17097, 14195, 19137, 12609, 16684, 10464, 17147, 11021, 10399, 12176, 12605, 12669, 15090, 16749, 12642, 12266, 28329, 65535, 261, 65530, 65534, 33914, 8778, 117, 59, 33, 12605, 14486, 16533, 12469, 14734, 12522, 12410, 10333, 19137, 10293, 10370, 19137, 12605, 10423, 10848, 10838, 10588, 10792, 12410, 15641, 10675, 17919, 14734, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 17798, 13581, 10305, 11630, 19137, 10322, 16684, 10464, 17879, 16503, 10250, 10349, 12662, 10784, 12415, 12410, 15516, 10080, 10464, 14862, 17222, 10373, 10303, 13091, 12662, 10784, 12415, 12410, 15516, 10303, 19156, 11, 65535, 261, 65530, 65534, 33914, 8778, 117, 59, 33, 12605, 14862, 17222, 19137, 12662, 10784, 12415, 12410, 15516, 13091, 12748, 10283, 10452, 11454, 11626, 13215, 14734, 12484, 13126, 10285, 19137, 15752, 14141, 13815, 17144, 14589, 12145, 13191, 14734, 14862, 16696, 11124, 15486, 18183, 19137, 11957, 17728, 18025, 14734, 13036, 13764, 17149, 16403, 17177, 12731, 19137, 16696, 10790, 10580, 16689, 19137, 11454, 10995, 12410, 14734, 11533, 14902, 10257, 17149, 16403, 10768, 13254, 10079, 12826, 14486, 19137, 10460, 10760, 11038, 14486, 14734, 10784, 13032, 11124, 13580, 14914, 11001, 15864, 14734, 18216, 15451, 12410, 15516, 13036, 13764, 10992, 12314, 12276, 28329, 65535, 261, 65530, 65532, 27370, 59, 13091, 14734, 19137, 17148, 11016, 13091, 11885, 14734, 11899, 10304, 19137, 12605, 13234, 17728, 10464, 10250, 10283, 17728, 18025, 10080, 10913, 14583, 15494, 10333, 14662, 10370, 10278, 15033, 16030, 10290, 19137, 13633, 15033, 10278, 18024, 19137, 10278, 15033, 16030, 10290, 14734, 12604, 10768, 10260, 11042, 19137, 10444, 11630, 16520, 10250, 13324, 19137, 10913, 14583, 16503, 13685, 13057, 10257, 11124, 13115, 10257, 19137, 13633, 15033, 16030, 11036, 11035, 10250, 18024, 10080, 14446, 11454, 16030, 10290, 16443, 13916, 11454, 10333, 10250, 16944, 19137, 17843, 10399, 10768, 17122, 10080, 14662, 10370, 12368, 18001, 11035, 16030, 19137, 10464, 15752, 15494, 10760, 14662, 10370, 15752, 11634, 12750, 13064, 11035, 16030, 14734, 16533, 10722, 10840, 13764, 10303, 19156, 11, 65535, 261, 65530, 65534, 33914, 8778, 117, 59, 33, 16030, 10290, 16443, 13916, 11454, 10333, 10250, 16944, 19137, 11035, 17631, 10802, 17387, 11021, 15752, 11960, 15850, 10260, 11021, 18009, 16664, 14734, 17728, 18025, 10080, 12605, 11021, 15752, 13734, 13764, 15494, 10760, 16533, 10722, 13036, 13336, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 10260, 19137, 10464, 11640, 17141, 10264, 13773, 10339, 17728, 18025, 13205, 17038, 10080, 11454, 14446, 11903, 10285, 19137, 12664, 10913, 14583, 17385, 13034, 12266, 16030, 11994, 15752, 16533, 10722, 17728, 18025, 10333, 28329, 65535, 261, 65530, 65534, 33914, 8778, 117, 59, 33, 10293, 10370, 19137, 17148, 14914, 11903, 13091, 11038, 14486, 14734, 16533, 10722, 13036, 13336, 10080, 12605, 13734, 12509, 10792, 17147, 13191, 17148, 13324, 14734, 13036, 13764, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 13091, 14734, 19137, 10464, 17879, 16503, 16672, 15847, 12144, 14734, 12410, 15516, 14141, 13815, 16944, 13234, 19137, 13191, 10250, 10349, 17728, 18025, 13091, 10464, 12509, 10260, 10792, 10684, 17644, 14734, 14172, 11994, 16533, 10260, 12266, 14734, 19137, 16503, 11632, 12509, 28329, 65535, 261, 65530, 65534, 33914, 8778, 117, 59, 33, 14862, 17222, 10333, 19137, 12605, 10423, 10848, 10838, 14734, 28329, 65535, 261]
-> item_loss 0.7144201397895813 batch_loss 1.1144455134868623
==== [65530, 65531, 10464, 13091, 10250, 10283, 11021, 14299, 19137, 11021, 10529, 14734, 10847, 12636, 19137, 11043, 11017, 33914, 8778, 117, 10080, 33, 10464, 10423, 13580, 17919, 14734, 11414, 15178, 41830, 14734, 17728, 18025, 19137, 10444, 13091, 17528, 11957, 24272, 17728, 18025, 10285, 14734, 10260, 13580, 14914, 10305, 11621, 10423, 10334, 10399, 13179, 13580, 28329, 65535, 261, 65530, 65532, 41830, 19151, 33, 12605, 12509, 11035, 15009, 12261, 10370, 19137, 12220, 12307, 12401, 10303, 14199, 18087, 15009, 12261, 10370, 19156, 11, 65535, 261, 65530, 65534, 33914, 8778, 117, 19151, 33, 11021, 10399, 15641, 16253, 10482, 14589, 11036, 15033, 18119, 13021, 11124, 15294, 13234, 11986, 16707, 10260, 11042, 14734, 11110, 17222, 19137, 10487, 11687, 15294, 10079, 17351, 13750, 10079, 15737, 13409, 15264, 15169, 10080, 11013, 11630, 19137, 15009, 12261, 10370, 10322, 11021, 10399, 10842, 10673, 10687, 10390, 18119, 13021, 13234, 16749, 11110, 19137, 10487, 11687, 11737, 10079, 16137, 10079, 17120, 13409, 15169, 28329, 65535, 261, 65530, 65532, 41830, 59, 33, 17148, 10303, 16735, 19137, 11035, 15009, 12261, 10370, 10260, 14347, 13764, 11957, 11053, 19156, 11, 65535, 261, 65530, 65534, 33914, 8778, 117, 19151, 33, 11035, 15009, 12261, 10370, 10260, 10423, 14347, 13764, 19137, 10444, 13091, 11687, 13258, 10464, 11454, 17916, 13764, 15674, 17848, 10370, 15604, 14734, 16713, 19137, 11021, 15752, 10423, 16443, 16650, 11940, 12672, 10449, 12202, 11002, 10792, 12748, 12825, 28329, 65535, 261, 65530, 65532, 41830, 59, 33, 17268, 10303, 11035, 10370, 14347, 13764, 11053, 19156, 11, 65535, 261, 65530, 65534, 33914, 8778, 117, 19151, 33, 11035, 10370, 10423, 16443, 16523, 10292, 10279, 17385, 14734, 10370, 13216, 17728, 18025, 19137, 12202, 10265, 11021, 15752, 10423, 12282, 16944, 11435, 17781, 14970, 10423, 14734, 12210, 13766, 10684, 13773, 10080, 13581, 11630, 19137, 10384, 10431, 14486, 11124, 13764, 12340, 14734, 16530, 12231, 13234, 14791, 19137, 10322, 10260, 12220, 16721, 18458, 10851, 12609, 12978, 12746, 10409, 10454, 10370, 10985, 10588, 17148, 13324, 14734, 10336, 12484, 28329, 65535, 261, 65530, 65532, 41830, 59, 33, 14446, 11454, 10464, 15641, 16253, 10258, 19137, 33, 15009, 12261, 10370, 13091, 10260, 13091, 10370, 19126, 19156, 11, 65535, 261, 65530, 65534, 33914, 8778, 117, 19151, 33, 13091, 14734, 19137, 33, 15009, 12261, 10370, 13091, 10370, 10080, 10390, 10402, 12727, 13191, 15847, 12144, 14734, 13012, 10901, 11124, 10964, 11024, 19137, 10322, 11002, 10792, 11435, 11920, 11124, 14970, 10423, 14734, 10525, 12686, 28329, 65535, 261, 65530, 65532, 41830, 59, 33, 17268, 10303, 11035, 15009, 12261, 10370, 14347, 13764, 11053, 19156, 11, 65535, 261, 65530, 65534, 33914, 8778, 117, 19151, 33, 11035, 15009, 12261, 10370, 14347, 13764, 10080, 15009, 12261, 10370, 13091, 10250, 10283, 15604, 10452, 19137, 10390, 10402, 12727, 13191, 15847, 12144, 14734, 13012, 10901, 11124, 10964, 11024, 10080, 11035, 15009, 12261, 10370, 13091, 10250, 15033, 14347, 15584, 16403, 10292, 19137, 10423, 11002, 10792, 10279, 10965, 14734, 13764, 12340, 12501, 15578, 28329, 65535, 261, 65530, 65534, 14488, 14543, 19151, 33, 12605, 10780, 10780, 16707, 14808, 11871, 10323, 10333, 17148, 10349, 14862, 16696, 10080, 15489, 13258, 18157, 18157, 16250, 16250, 11061, 19137, 11685, 10621, 12605, 16417, 17136, 14734, 10260, 11634, 13923, 13127, 11124, 10733, 14914, 28329, 65535, 261]
-> item_loss 0.8432310819625854 batch_loss 1.1015305405571347
==== [25106, 11, 65530, 65531, 10464, 13091, 10250, 10283, 820, 19137, 11017, 10460, 10414, 16037, 17847, 19137, 15752, 11634, 11124, 10370, 15261, 15847, 14221, 11459, 11957, 16713, 10080, 17798, 13581, 10305, 11630, 19137, 17147, 11021, 10399, 12176, 10790, 10370, 10609, 11861, 10256, 13231, 10529, 12445, 28329, 14778, 10808, 11861, 10609, 14734, 10529, 12445, 19151, 11, 50, 47, 10293, 10370, 14734, 14600, 15763, 11930, 14875, 13091, 632, 653, 1751, 101, 643, 50, 11, 51, 47, 10293, 10370, 10760, 17723, 13064, 12159, 13197, 12605, 12848, 14966, 10390, 12669, 17550, 10903, 12172, 10257, 11, 52, 589, 13137, 13051, 10696, 11922, 63, 11, 10399, 10258, 13091, 10355, 10342, 19151, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 13057, 10257, 11685, 28329, 65535, 261, 65530, 65534, 10414, 16037, 17847, 59, 33, 13057, 11889, 19137, 10293, 10370, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 13057, 10257, 11685, 28329, 65535, 261, 65530, 65534, 10414, 16037, 17847, 59, 33, 10464, 10780, 12638, 12145, 15486, 16735, 17141, 13057, 10257, 11685, 10333, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 11315, 19137, 12605, 14862, 17222, 19137, 12605, 11016, 13091, 12509, 11632, 11065, 10464, 16735, 10278, 11012, 16713, 28329, 65535, 261, 65530, 65534, 10414, 16037, 17847, 59, 33, 13734, 17728, 18025, 19137, 12605, 12337, 12537, 12522, 17802, 10464, 16735, 16713, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 11088, 16698, 12605, 10283, 11975, 14862, 16696, 11061, 28329, 65535, 261, 65530, 65534, 10414, 16037, 17847, 59, 33, 12307, 14221, 11021, 10399, 14734, 10080, 10464, 14862, 17222, 11053, 19137, 16327, 16314, 14734, 15874, 17012, 10687, 11903, 13091, 10250, 15033, 11626, 13215, 14734, 16728, 16537, 10080, 12307, 10250, 11016, 12137, 16314, 12664, 10792, 10250, 10283, 13034, 14734, 15931, 13981, 12609, 13676, 13981, 19137, 11885, 10423, 17146, 11414, 16314, 12135, 12202, 17149, 16403, 10250, 15033, 14332, 13603, 14734, 15874, 17012, 19137, 16443, 15044, 10292, 9822, 12894, 12893, 15874, 9823, 10080, 17148, 15033, 15874, 17012, 14734, 13036, 11047, 10079, 17193, 12231, 11124, 13499, 12276, 17311, 10423, 10427, 17136, 10760, 13981, 11647, 14734, 13036, 11047, 10079, 16973, 15023, 11124, 10286, 11932, 15052, 12231, 10080, 17148, 13091, 16327, 16314, 10305, 17734, 17149, 16403, 13191, 12986, 13733, 17189, 14734, 10250, 15033, 13036, 12276, 19137, 12176, 10847, 13006, 10283, 16314, 15604, 12664, 10792, 16909, 13981, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 14862, 17222, 10333, 19137, 12605, 16503, 10760, 17723, 10257, 14474, 10333, 28329, 65535, 261, 65530, 65534, 10414, 16037, 17847, 59, 33, 10293, 10370, 10703, 16519, 19137, 10260, 16503, 12378, 10333, 12172, 17550, 10903, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 12605, 14446, 11454, 11454, 10678, 11029, 19137, 13191, 10336, 12484, 12664, 10464, 28329, 65535, 261, 65530, 65534, 10414, 16037, 17847, 59, 33, 12605, 10250, 14781, 17311, 11454, 19137, 10373, 10303, 10336, 19156, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 12605, 12378, 10333, 14600, 15763, 12266, 13212, 11930, 14875, 10333, 11, 65535, 261, 65530, 65534, 10414, 16037, 17847, 59, 33, 11930, 14875, 13091, 632, 653, 1751, 101, 643, 50, 19137, 16269, 14221, 12605, 10423, 12176, 12469, 16678, 10449, 19137, 10444, 13091, 17148, 10303, 17385, 16503, 14734, 11930, 14875, 12159, 13197, 10293, 10370, 17147, 13091, 10260, 16503, 12378, 12810, 14734, 11685, 28329, 65535, 261]
-> item_loss 0.6349198222160339 batch_loss 1.080320962450721
==== [25106, 11, 65530, 65531, 10464, 13091, 10250, 10283, 820, 19137, 11043, 11860, 11017, 10588, 14731, 28329, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 11454, 10260, 11454, 19156, 11, 65535, 261, 65530, 65534, 14731, 59, 33, 12605, 10250, 14781, 17311, 11454, 17148, 17384, 28329, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 12605, 10402, 13234, 15667, 15667, 10370, 12137, 13133, 15752, 11124, 10370, 15261, 14734, 13203, 13234, 11061, 28329, 65535, 261, 65530, 65534, 14731, 59, 33, 11685, 14734, 10080, 10460, 10292, 10250, 10283, 820, 19137, 12605, 12337, 10310, 12522, 11124, 10464, 16671, 16686, 17148, 10283, 16713, 18025, 28329, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 10464, 16667, 10292, 820, 13091, 11060, 10423, 11454, 11036, 10283, 13036, 17919, 16947, 17141, 10370, 15261, 19156, 11, 65535, 261, 65530, 65534, 14731, 59, 33, 12605, 16667, 10292, 10423, 14734, 19137, 10293, 10370, 10080, 10370, 15261, 14734, 16944, 13981, 15752, 11634, 17169, 13992, 10792, 660, 10372, 12201, 10808, 19137, 13091, 11454, 15847, 14221, 14610, 14734, 10260, 13032, 14035, 10901, 10285, 10358, 14583, 14734, 10080, 15646, 820, 13091, 10370, 15261, 14734, 17194, 14328, 19137, 16944, 13981, 10339, 16664, 15200, 13212, 15034, 11871, 18011, 11524, 19137, 12605, 10402, 820, 14734, 10358, 14583, 10964, 11024, 16503, 13637, 10370, 15261, 14866, 12348, 11632, 10080, 15646, 10265, 19137, 12605, 10402, 17147, 11454, 10260, 13032, 14734, 17161, 10397, 10261, 17149, 10901, 10080, 12631, 10399, 19137, 13203, 13234, 14734, 820, 14734, 15752, 10838, 12337, 13191, 11021, 15752, 16947, 17141, 10370, 15261, 28329, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 14221, 11044, 11001, 10397, 10370, 15261, 19156, 11, 65535, 261, 65530, 65534, 14731, 59, 33, 11315, 19137, 12605, 16667, 10292, 820, 13191, 11021, 15752, 10423, 11001, 10397, 10370, 15261, 28329, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 10464, 12159, 13197, 820, 11001, 10397, 10370, 15261, 10303, 19156, 11, 65535, 261, 65530, 65534, 14731, 59, 33, 12605, 10260, 12159, 13197, 10080, 12605, 11268, 13558, 12176, 10847, 10370, 15261, 19137, 10322, 11268, 13558, 11124, 10370, 15261, 10250, 16944, 15667, 11639, 19137, 10444, 13091, 11021, 15752, 13191, 10790, 14734, 820, 13191, 10261, 12605, 10260, 11042, 14734, 14791, 13764, 10080, 12605, 12159, 13197, 820, 15752, 11634, 11124, 10370, 15261, 10342, 16416, 10260, 16956, 19137, 12604, 10292, 13192, 10993, 28329, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 11975, 14731, 19137, 10464, 14734, 12509, 13764, 10260, 17631, 10080, 10444, 13091, 19137, 12605, 10402, 17919, 10288, 14808, 10250, 10283, 11426, 11574, 28329, 65535, 261, 65530, 65534, 14731, 59, 33, 13091, 10373, 10303, 11426, 11574, 19156, 11, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 12750, 14240, 14778, 10808, 14734, 10997, 12022, 17149, 15052, 19137, 820, 12337, 12387, 10423, 11454, 12337, 11632, 18011, 11524, 16947, 17141, 10370, 15261, 19137, 13187, 10397, 10370, 15261, 14734, 12137, 10460, 10080, 16269, 14221, 17148, 10250, 14172, 11021, 10399, 17189, 17141, 16909, 13981, 14734, 10703, 10768, 17332, 13234, 16533, 10722, 19137, 10444, 13091, 820, 14734, 15847, 10293, 12415, 10322, 11454, 11003, 12299, 28329, 65535, 261, 65530, 65534, 14731, 59, 33, 17148, 10423, 17194, 12604, 10373, 10303, 11044, 13258, 11102, 19156, 11, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 11414, 15178, 10464, 14734, 17728, 18025, 10808, 19137, 12605, 10658, 17728, 17728, 10464, 19137, 10464, 16667, 10292, 820, 14446, 11454, 11124, 10370, 15261, 13091, 10373, 10303, 10684, 15304, 19156, 11, 65535, 261, 65530, 65534, 14731, 59, 3609, 13091, 10370, 15261, 14734, 12631, 13191, 14328, 10080, 10322, 13191, 11190, 11871, 16520, 14172, 16667, 10292, 820, 13091, 10370, 15261, 17038, 10452, 14734, 12258, 10439, 10080, 12605, 16667, 10292, 19137, 820, 14778, 10808, 13091, 14328, 11159, 10079, 13212, 11369, 12609, 13091, 10378, 10384, 28329, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 13091, 14734, 19137, 17148, 12522, 11110, 14808, 820, 14734, 14583, 10358, 10838, 11994, 13091, 10370, 15261, 14734, 14583, 10358, 10838, 19137, 11885, 10423, 10292, 10370, 15261, 10781, 17194, 10408, 10577, 10080, 10444, 13091, 19137, 11687, 13258, 820, 14370, 15123, 10333, 19137, 820, 14734, 14583, 10358, 10838, 11994, 12025, 10339, 15847, 17038, 10080, 12014, 13064, 19137, 10370, 15261, 14734, 10408, 10577, 12348, 10260, 10792, 14015, 16956, 19137, 10423, 12282, 10997, 17922, 11117, 10080, 17148, 13091, 12605, 10260, 12509, 14791, 10792, 14734, 28329, 65535, 261, 65530, 65534, 14731, 59, 33, 12605, 16667, 11042, 10464, 19137, 10293, 10370, 10080, 11975, 14731, 10322, 10260, 12509, 14791, 10792, 10370, 15261, 11002, 10792, 10429, 11917, 28329, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 13091, 14734, 19137, 10444, 13091, 11687, 13258, 12509, 16503, 17248, 10662, 12605, 10780, 12638, 16735, 14734, 12484, 10724, 19137, 11994, 17879, 16503, 820, 11454, 12727, 13191, 10250, 11899, 15847, 10293, 12415, 14734, 11042, 13064, 19137, 10383, 14221, 10460, 10292, 10370, 15261, 14734, 14328, 11159, 10079, 13212, 11369, 12609, 10378, 10384, 28329, 65535, 261, 65530, 65534, 14731, 59, 33, 17148, 14914, 11903, 12337, 18425, 14189, 19137, 11021, 15752, 13191, 10349, 820, 10260, 12537, 12522, 17148, 10303, 10588, 28329, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 11198, 19137, 17148, 10322, 13091, 12605, 12631, 12701, 12366, 14734, 28329, 65535, 261, 65530, 65534, 14731, 59, 33, 10293, 10370, 10260, 16503, 12701, 12366, 10333, 19137, 17148, 10260, 13091, 17917, 12605, 10402, 10278, 10283, 11994, 15752, 16533, 10722, 14734, 17728, 18025, 10080, 15849, 11977, 19137, 12605, 12537, 12522, 12604, 10292, 10293, 10370, 14734, 14328, 11159, 10079, 13212, 11369, 12609, 10378, 10384, 19137, 10953, 10482, 12605, 12727, 13191, 10333, 10293, 16520, 12522, 16696, 11124, 12527, 12484, 10080, 10687, 11903, 19137, 12605, 10402, 820, 13734, 13191, 11640, 11632, 10846, 13212, 10985, 17169, 13685, 14370, 15123, 14734, 19137, 10293, 10370, 11021, 10399, 10310, 16520, 10250, 14172, 28329, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 10464, 10402, 13203, 13234, 10423, 13191, 10250, 11639, 16056, 12348, 15847, 14597, 14734, 19137, 17148, 13091, 10964, 11024, 12368, 14221, 28329, 65535, 261, 65530, 65534, 14731, 59, 33, 12605, 13078, 14731, 19137, 10444, 10260, 13091, 14446, 11454, 19137, 11957, 11061, 10080, 12605, 10402, 17147, 13191, 12337, 17688, 14734, 16981, 16503, 16939, 28329, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 11315, 19137, 10464, 15752, 14486, 16533, 12605, 14794, 13091, 11640, 11685, 10333, 28329, 65535, 261, 65530, 65534, 14731, 59, 33, 10687, 11903, 19137, 10293, 10370, 10260, 14589, 11640, 17141, 10339, 10684, 13773, 12605, 14734, 12509, 13764, 14734, 10080, 12605, 13091, 13212, 11369, 19137, 12605, 12159, 13197, 15752, 11634, 12176, 12469, 11891, 12604, 13179, 11632, 10409, 10843, 19137, 11042, 13064, 10322, 12159, 13197, 10293, 10370, 15752, 11124, 10687, 10390, 10370, 15261, 11632, 10355, 13819, 19137, 10260, 16503, 16672, 12605, 15931, 12810, 12469, 11640, 11632, 14734, 13064, 17734, 28329, 65535, 261]
-> item_loss 0.8410183787345886 batch_loss 1.0699165022891501
==== [25106, 11, 65530, 65531, 772, 640, 643, 47, 53, 47, 54, 33, 13205, 13499, 11496, 14446, 14349, 772, 11, 13205, 16728, 16537, 13499, 11496, 16443, 10794, 10460, 12604, 10333, 10250, 10283, 13212, 11369, 10370, 10847, 12636, 19137, 12202, 10265, 12727, 13191, 10250, 10283, 16667, 16692, 10293, 10370, 10080, 13205, 13499, 11496, 10696, 17303, 11861, 11454, 10250, 10283, 11168, 12220, 10293, 10452, 19137, 11168, 12220, 10293, 10452, 11021, 10399, 16749, 12231, 10261, 10482, 14589, 13499, 11496, 10696, 17303, 14734, 12631, 13191, 14862, 16696, 10080, 12307, 12824, 11002, 17109, 10673, 13064, 19137, 11168, 12220, 10293, 10452, 10423, 17189, 17141, 13499, 11496, 17109, 10760, 10261, 10293, 10370, 12609, 10687, 10390, 14589, 12626, 10355, 13819, 10080, 11454, 11044, 15511, 14734, 13004, 12797, 10285, 19137, 9822, 13205, 13499, 11496, 9823, 12609, 9822, 13205, 16728, 16537, 13499, 11496, 9823, 17311, 12748, 10397, 11168, 12220, 10293, 10452, 10080, 11168, 12220, 10293, 10452, 10423, 13326, 12797, 17109, 10673, 14734, 10696, 11922, 19137, 10768, 13254, 14778, 10808, 12631, 11621, 14734, 14349, 10724, 19137, 12202, 15494, 10760, 14862, 12415, 14734, 11414, 15178, 28329, 10953, 10482, 10293, 10370, 12609, 10687, 10390, 14589, 12626, 14734, 17109, 10673, 10260, 11634, 11891, 11255, 19137, 13205, 13499, 11496, 10322, 15752, 10292, 10390, 10402, 12848, 10494, 11021, 17917, 10079, 10452, 16895, 14734, 12176, 10847, 19137, 10487, 11687, 59, 65535, 261, 65530, 65532, 10464, 11685, 19156, 11, 65535, 261, 65530, 65534, 13212, 11369, 10370, 10847, 12636, 59, 33, 10464, 11685, 19137, 13191, 10373, 10303, 12605, 15752, 12176, 12469, 10588, 14734, 11053, 19156, 11687, 13258, 10464, 15752, 12848, 10494, 13179, 10842, 16722, 15478, 14734, 42100, 19137, 12605, 14734, 11414, 12220, 10423, 11003, 12348, 13179, 10842, 13133, 15752, 28329, 65535, 261, 65530, 65532, 12605, 13078, 14731, 10333, 28329, 65535, 261, 65530, 65531, 40812, 59, 33, 13212, 11369, 10370, 10847, 12636, 14734, 11043, 11860, 11017, 10588, 5585, 41693, 10080, 5585, 41693, 15678, 13078, 10079, 10452, 16895, 19137, 11021, 10399, 12176, 10847, 10293, 10370, 11414, 15178, 17728, 18025, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 17148, 13324, 11994, 11021, 10399, 10333, 10303, 11, 65535, 261, 65530, 65534, 5585, 41693, 59, 33, 13091, 14734, 19137, 17148, 13324, 12605, 11994, 15752, 13179, 11685, 11459, 10292, 12469, 13193, 10843, 10333, 10080, 10293, 10370, 19137, 16738, 17728, 13191, 10373, 10303, 17728, 18025, 17879, 16503, 12605, 13234, 11414, 15178, 11053, 19156, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 17268, 10303, 10382, 15484, 10250, 10258, 10464, 15847, 12144, 11061, 28329, 65535, 261, 65530, 65534, 5585, 41693, 59, 33, 12605, 13091, 5585, 41693, 19137, 13091, 10250, 10283, 13212, 11369, 10370, 10847, 12636, 10080, 10464, 13091, 12605, 14734, 10293, 10370, 10080, 12605, 15678, 13078, 10079, 10452, 16895, 19137, 11021, 10399, 12176, 12469, 11414, 15178, 11036, 15033, 17728, 18025, 10080, 11687, 13258, 13191, 10373, 10303, 10336, 12484, 12509, 16503, 10333, 16533, 14734, 19137, 13558, 17143, 11047, 12605, 12848, 17728, 19126, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 17268, 10303, 10382, 15484, 10250, 10258, 10464, 15847, 12144, 11061, 28329, 65535, 261, 65530, 65534, 5585, 41693, 59, 33, 12605, 13091, 5585, 41693, 19137, 13091, 10250, 10283, 13212, 11369, 10370, 10847, 12636, 10080, 10464, 13091, 12605, 14734, 10293, 10370, 10080, 12605, 15678, 13078, 10079, 10452, 16895, 19137, 11021, 10399, 12176, 12469, 11414, 15178, 11036, 15033, 17728, 18025, 10080, 11687, 13258, 13191, 10373, 10303, 10336, 12484, 12509, 16503, 10333, 16533, 14734, 19137, 13558, 17143, 11047, 12605, 12848, 17728, 19126, 16738, 17728, 10293, 10370, 10780, 12638, 13091, 13734, 13191, 12979, 10792, 12605, 14734, 13855, 12445, 10303, 19156, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 11315, 19137, 15573, 15497, 10941, 10333, 10250, 10258, 10080, 10464, 12727, 13191, 12527, 12484, 11124, 10370, 13327, 10303, 19156, 11, 65535, 261, 65530, 65534, 5585, 41693, 59, 33, 12605, 13078, 14731, 10333, 19137, 11687, 13258, 10305, 11044, 14935, 10792, 15261, 10441, 14734, 12484, 10724, 19137, 10293, 10370, 10250, 11899, 16503, 12848, 17363, 12605, 10080, 13091, 11060, 12727, 13191, 12527, 12484, 11124, 10370, 13327, 11957, 10339, 13212, 11369, 10370, 15646, 16537, 13091, 10250, 10283, 13637, 17097, 11626, 13215, 14734, 17728, 18025, 19137, 12605, 12727, 13191, 14486, 16533, 11124, 13499, 12722, 11036, 15033, 12527, 12484, 14734, 15752, 10838, 19137, 12202, 10265, 15752, 11634, 10768, 13254, 12307, 10808, 14349, 10724, 15494, 10760, 17172, 12307, 14734, 11414, 12220, 10080, 10384, 13125, 17216, 16667, 14862, 13234, 14791, 19137, 12605, 10260, 10688, 13191, 12527, 12484, 11124, 10370, 13327, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 10464, 12159, 13197, 16056, 12348, 10370, 13216, 10303, 19156, 11, 65535, 261, 65530, 65534, 5585, 41693, 59, 33, 14778, 10808, 12605, 13734, 13191, 17148, 15033, 17879, 13685, 19137, 10293, 10370, 10080, 12605, 14734, 14778, 13308, 13091, 17802, 10437, 10293, 10370, 12202, 12176, 10847, 10293, 10370, 16533, 10722, 11036, 15033, 17728, 18025, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 13091, 11416, 10292, 12605, 10780, 12638, 10708, 14734, 16689, 11899, 10303, 19156, 11, 65535, 261, 65530, 65534, 5585, 41693, 59, 33, 10293, 10370, 19137, 12469, 12669, 12605, 16689, 11899, 10292, 15678, 13078, 10079, 10452, 16895, 19137, 11043, 10292, 5585, 41693, 14734, 13212, 11369, 10370, 10847, 12636, 19137, 15752, 12176, 12469, 11414, 15178, 17728, 18025, 10080, 12605, 10423, 12669, 16689, 11899, 10460, 10292, 12605, 14734, 14778, 13308, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 17268, 11687, 13258, 12605, 12669, 16689, 11899, 12981, 12604, 10464, 12159, 13197, 16056, 12348, 10370, 13216, 11102, 19156, 11, 65535, 261, 65530, 65534, 5585, 41693, 59, 33, 16738, 13773, 12522, 19137, 10953, 10482, 10538, 12981, 16689, 11899, 19137, 12605, 10322, 10260, 10423, 10985, 10588, 11957, 10370, 15261, 13191, 14059, 11454, 10952, 11917, 14734, 10336, 12484, 10080, 14778, 10808, 19137, 14583, 12604, 12276, 13499, 11496, 10261, 13212, 11369, 10370, 10383, 14221, 13091, 12337, 13191, 10335, 16676, 14734, 16713, 18025, 10080, 12631, 10399, 12605, 10423, 12002, 11021, 15752, 17241, 14240, 10293, 10370, 14734, 16689, 11899, 10261, 12748, 10398, 16403, 10846, 19137, 10322, 12159, 13197, 10293, 10370, 15752, 12669, 12605, 16689, 11899, 12604, 10250, 10283, 11957, 10370, 15261, 13191, 14757, 14734, 13212, 11369, 10370, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 17268, 10303, 12605, 10402, 12824, 10258, 13234, 10588, 10250, 10283, 13827, 16707, 11061, 28329, 65535, 261, 65530, 65534, 5585, 41693, 59, 33, 11685, 14734, 10293, 10370, 19137, 12605, 12145, 15486, 10733, 11622, 11685, 17149, 16403, 13827, 16707, 28329, 65535, 261, 65530, 65531, 40812, 59, 33, 16738, 17385, 11626, 35, 632, 653, 641, 35, 28329, 65535, 261, 65530, 65534, 5585, 41693, 59, 3485, 653, 641, 11, 65535, 261, 65530, 65531, 40812, 59, 33, 16738, 11454, 35, 15966, 13258, 35, 10079, 35, 13212, 11369, 10370, 35, 10079, 35, 12266, 12366, 35, 10285, 17177, 12731, 10250, 10283, 13676, 13258, 14734, 11043, 15044, 17109, 10760, 19151, 11, 65535, 261, 65530, 65534, 5585, 41693, 59, 33, 15966, 13258, 11, 65535, 261, 65530, 65531, 40812, 59, 33, 16738, 16735, 10760, 124, 10464, 14446, 11454, 12509, 16735, 14734, 16713, 126, 19151, 11, 65535, 261, 65530, 65534, 5585, 41693, 59, 33, 10293, 10370, 19137, 16738, 17728, 17148, 10349, 11994, 13091, 13827, 16707, 14734, 10696, 11922, 10303, 19156, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 11315, 19137, 13734, 17631, 19137, 11044, 17919, 11638, 13445, 17147, 13191, 10745, 17999, 13827, 16707, 28329, 65535, 261, 65530, 65534, 5585, 41693, 59, 33, 13078, 14731, 10333, 19137, 12605, 10423, 15169, 12335, 15304, 15500, 13855, 12445, 28329, 65535, 261, 65530, 65531, 40812, 59, 33, 10580, 16689, 10464, 14446, 11454, 17879, 16503, 10985, 16947, 12154, 16889, 10327, 13057, 18069, 17879, 16503, 14734, 13223, 13021, 19137, 15752, 17149, 16403, 14734, 12748, 10398, 10894, 12732, 393, 12642, 12266, 15090, 16749, 1678, 19137, 393, 12642, 12266, 17723, 6852, 393, 12945, 10460, 14600, 15763, 1678, 19137, 16738, 17109, 10673, 12509, 16503, 12650, 16403, 14734, 12748, 10398, 19151, 11, 65535, 261, 65530, 65534, 5585, 41693, 59, 326, 12642, 12266, 17723, 94, 11, 65535, 261, 65530, 65531, 40812, 59, 33, 12410, 15641, 19151, 10292, 10373, 10303, 16503, 10588, 17148, 13324, 14734, 13827, 16707, 28329, 65535, 261, 65530, 65534, 5585, 41693, 59, 33, 10293, 10370, 16503, 12605, 10588, 17148, 13324, 14734, 13827, 16707, 19137, 11021, 15752, 13091, 10292, 10333, 13381, 13827, 12605, 13091, 11060, 15752, 11634, 10733, 14914, 11459, 10261, 15304, 15500, 10355, 10342, 10080, 10292, 13581, 19137, 12605, 14734, 17109, 10760, 12220, 16721, 10261, 15304, 15500, 12848, 10494, 14734, 13327, 12276, 10250, 15850, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 11315, 19137, 13827, 16707, 15489, 13229, 10333, 28329, 65535, 261, 65530, 65534, 5585, 41693, 59, 33, 12605, 12337, 18216, 10685, 15752, 12176, 10792, 10293, 10370, 19126, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 10464, 17147, 16678, 12348, 11150, 10402, 10381, 11639, 10588, 10333, 10373, 10303, 11053, 19156, 11, 65535, 261, 65530, 65534, 5585, 41693, 59, 33, 12605, 14778, 10808, 13051, 13764, 16056, 12348, 10684, 10339, 13064, 17734, 14734, 10529, 12445, 19137, 10444, 13091, 13326, 12797, 12605, 10402, 14734, 10355, 10342, 10964, 11024, 19137, 12605, 16678, 12348, 11124, 10293, 10370, 10250, 16944, 10588, 17141, 14734, 10336, 12484, 10080, 13188, 10782, 10293, 10370, 11124, 12605, 10342, 14782, 17728, 10560, 19137, 10292, 12605, 16944, 11043, 12202, 13920, 10842, 10333, 16689, 11899, 19137, 12605, 12604, 10292, 10333, 15678, 13078, 10079, 10452, 16895, 14734, 13212, 11369, 10370, 10847, 12636, 5585, 41693, 19137, 15752, 11634, 10292, 12469, 16533, 15178, 17728, 18025, 10080, 10305, 11044, 10293, 10370, 16672, 12605, 17149, 16403, 15847, 12605, 10382, 15484, 19137, 12202, 16671, 16686, 10333, 12605, 14734, 16689, 11899, 14782, 10684, 14734, 16713, 18025, 10080, 13188, 11044, 10293, 10370, 11957, 12605, 17149, 16403, 10333, 13827, 16707, 19137, 16672, 12605, 10261, 15304, 15500, 17149, 16403, 10355, 10342, 28329, 65535, 261, 65530, 65534, 14488, 14543, 19151, 33, 12605, 10780, 10780, 16707, 14808, 11871, 10323, 10333, 17148, 10349, 14862, 16696, 10080, 15489, 13258, 12605, 12527, 16525, 11871, 12348, 17147, 15200, 13078, 14731, 19137, 33, 12220, 16721, 15752, 13819, 14607, 14734, 16417, 17136, 28329, 65535, 261]
-> item_loss 1.0676487684249878 batch_loss 1.0698220133781433
==== [25106, 11, 65530, 65531, 772, 640, 643, 47, 55, 47, 644, 33, 13205, 13499, 11496, 14446, 14349, 772, 11, 12605, 14778, 10808, 10383, 14221, 10460, 10292, 10250, 10283, 16728, 16537, 13499, 11496, 11861, 11454, 14808, 19137, 12605, 15752, 11634, 10588, 14734, 10336, 12484, 13091, 12824, 11002, 13012, 11860, 15304, 10777, 17109, 10673, 12202, 15494, 10760, 13012, 11860, 17109, 10760, 10080, 10444, 13091, 19137, 13188, 17145, 12605, 10997, 14446, 11454, 12605, 11124, 10370, 15261, 14734, 11957, 16713, 10285, 19137, 10423, 11986, 16707, 10985, 11610, 13078, 10250, 10349, 16728, 16537, 13499, 11496, 10588, 10260, 10333, 14734, 10336, 12484, 10080, 12605, 13091, 16728, 16537, 13499, 11496, 19137, 13091, 820, 19137, 13091, 13212, 11369, 19137, 10953, 10482, 15752, 11634, 10621, 10370, 15261, 10250, 13324, 12410, 15641, 19137, 12605, 10322, 13051, 13764, 10588, 10760, 10250, 10349, 13191, 17038, 10452, 14734, 10370, 15261, 12638, 15752, 10588, 10760, 14734, 10846, 10460, 10080, 10322, 11994, 13091, 16735, 19137, 16269, 14221, 12605, 11021, 10399, 12656, 14035, 15847, 12144, 11124, 10370, 15261, 17149, 16403, 10333, 15707, 10452, 12824, 16535, 19137, 13234, 16672, 10370, 15261, 14015, 16956, 10080, 10444, 13091, 12307, 10370, 15261, 11454, 17728, 12605, 13580, 11454, 10588, 10373, 10303, 14734, 13064, 10560, 19137, 12605, 10260, 12220, 16721, 15494, 10760, 15847, 12144, 13580, 11454, 11035, 18089, 12609, 15643, 16968, 13582, 15169, 10398, 10370, 15261, 10292, 17843, 14734, 15178, 13336, 10080, 13581, 11630, 19137, 12605, 14734, 11414, 15178, 13327, 12276, 10260, 12220, 16721, 10250, 12604, 10260, 11003, 19137, 17879, 16503, 10594, 11979, 14734, 10293, 10846, 10588, 10760, 12981, 11003, 10080, 11416, 10292, 19137, 11687, 13258, 12605, 10250, 14781, 14589, 11042, 10250, 15033, 13327, 12276, 17149, 16403, 11414, 11626, 19137, 12337, 13191, 11021, 15752, 17819, 14808, 13064, 17734, 14734, 12826, 15046, 15646, 17808, 10673, 13279, 15033, 12357, 14445, 10285, 10080, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 10464, 13091, 10250, 10283, 16728, 16537, 13499, 11496, 19137, 17303, 15588, 11454, 12605, 14734, 14600, 15763, 10257, 19137, 12605, 13091, 10464, 14734, 10293, 10370, 10080, 11124, 12605, 12642, 10283, 12719, 11116, 11061, 28329, 65535, 261, 65530, 65534, 13212, 11369, 10370, 59, 33, 10293, 10370, 19137, 10464, 11685, 28329, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 11088, 16698, 12605, 35724, 24566, 13091, 10373, 10303, 12522, 12410, 28329, 65535, 261, 65530, 65534, 13212, 11369, 10370, 59, 60582, 13091, 14328, 16884, 14734, 12522, 12410, 19137, 10397, 16417, 11903, 17781, 11861, 11454, 10339, 10267, 14610, 10257, 14734, 13279, 15033, 10272, 16501, 28329, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 12605, 10333, 16533, 10333, 28329, 65535, 261, 65530, 65534, 13212, 11369, 10370, 59, 33, 12337, 18216, 10685, 15752, 12176, 10257, 12469, 14734, 12379, 28329, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 10464, 14862, 17222, 10373, 10303, 13091, 13212, 11764, 10303, 19156, 11, 65535, 261, 65530, 65534, 13212, 11369, 10370, 59, 33, 13212, 11764, 13091, 12748, 11454, 16403, 10292, 13036, 12276, 11124, 11630, 16417, 14332, 12333, 10257, 10261, 10370, 15261, 14734, 11679, 12415, 13191, 12631, 14782, 10441, 14734, 13212, 11369, 10370, 19137, 11684, 10402, 11416, 10292, 11021, 14299, 14734, 16403, 10292, 10079, 15957, 13191, 15957, 13051, 14734, 13212, 13375, 12527, 10399, 10992, 16947, 14221, 10339, 10370, 15261, 10408, 10577, 16520, 14734, 15458, 14794, 15646, 11002, 10792, 10370, 15261, 11268, 14299, 10080, 14597, 10339, 11684, 10402, 13091, 13212, 11369, 10370, 19137, 12631, 10399, 10322, 10423, 13193, 10384, 10370, 15261, 14734, 11117, 10398, 10079, 10292, 10370, 15261, 12848, 10494, 12176, 10847, 10079, 17802, 10437, 10370, 15261, 19137, 17148, 17149, 10250, 13582, 10842, 13913, 10333, 10370, 10402, 11957, 11684, 10402, 14734, 11268, 14299, 28329, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 11891, 10675, 13580, 14914, 19137, 12631, 10399, 12605, 10322, 12159, 13197, 10464, 11124, 12605, 10355, 13819, 14734, 13064, 10560, 10322, 11021, 14299, 10250, 14172, 28329, 65535, 261, 65530, 65534, 13212, 11369, 10370, 59, 33, 11021, 10399, 14734, 19137, 12605, 10423, 10848, 10838, 17149, 16403, 11986, 16707, 14734, 19126, 28336, 11, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 12791, 10283, 16713, 18025, 11061, 28329, 65535, 261, 65530, 65534, 13212, 11369, 10370, 59, 33, 11065, 10464, 14734, 19137, 10293, 10370, 10080, 12605, 10402, 16747, 13234, 12848, 10760, 16713, 18025, 11102, 19156, 11, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 12605, 13234, 11061, 10080, 10464, 14862, 17222, 14398, 11764, 13091, 10373, 10303, 11053, 19156, 11, 65535, 261, 65530, 65534, 13212, 11369, 10370, 59, 33, 13091, 10250, 15033, 12206, 12509, 14583, 14328, 19137, 11684, 10402, 12727, 13191, 10370, 15261, 14734, 17038, 10452, 15489, 13250, 11124, 10250, 10349, 14398, 14734, 14332, 12333, 19137, 13191, 14734, 14398, 11764, 13191, 10250, 10349, 14332, 13603, 14734, 11010, 14714, 19137, 13637, 11687, 11454, 16735, 16713, 14734, 15489, 12003, 10842, 10257, 10250, 10283, 9822, 11280, 9823, 11860, 10080, 11454, 12605, 14734, 13499, 11496, 10285, 19137, 10441, 10308, 17798, 10333, 13053, 12182, 14734, 11957, 16713, 11630, 19137, 17147, 13191, 10250, 10349, 14398, 11764, 17149, 16403, 12415, 16403, 10292, 14734, 14862, 16696, 28329, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 11638, 10452, 13734, 17631, 19137, 10444, 13091, 12605, 12509, 11088, 16698, 10464, 19137, 14398, 11764, 12202, 10260, 13091, 11124, 10409, 10454, 10370, 17311, 10423, 17149, 16403, 12415, 16403, 10292, 10080, 11684, 10402, 10322, 13091, 13179, 11268, 13558, 11124, 10370, 15261, 17149, 16403, 12200, 15169, 14734, 15667, 11639, 19137, 11016, 13191, 11454, 10994, 13036, 12727, 13191, 12337, 13913, 14734, 10529, 16922, 10305, 11044, 19137, 12638, 10423, 17149, 16403, 10366, 11930, 16403, 10292, 28329, 65535, 261, 65530, 65534, 13212, 11369, 10370, 59, 33, 11871, 10792, 10333, 19137, 12605, 10423, 16678, 10449, 14734, 28329, 65535, 261]
-> item_loss 1.0391602516174316 batch_loss 1.0685955429077147
==== [65530, 65532, 27476, 4600, 4490, 101, 275, 18488, 10261, 11459, 10258, 11517, 42, 4600, 32189, 37598, 64, 11, 65535, 261, 65530, 65534, 945, 69, 275, 18488, 10261, 11459, 10258, 11517, 42, 4600, 332, 31894, 46, 49551, 30941, 32227, 22748, 51351, 4450, 45062, 116, 4706, 22590, 36504, 45, 22762, 30135, 52603, 4601, 47, 3918, 460, 332, 21716, 21265, 63667, 30941, 4811, 31702, 45, 4788, 4588, 22799, 31296, 38576, 31296, 29398, 34177, 4715, 37576, 4706, 21138, 34177, 45, 22799, 39021, 38374, 52491, 4601, 22614, 34, 11, 65535, 261, 8787, 1791, 4660, 21835, 4811, 31358, 332, 30433, 24743, 30397, 11, 65530, 65534, 24202, 45, 308, 21413, 31073, 22799, 32487, 32227, 47, 29059, 460, 4419, 51668, 4706, 332, 59284, 30397, 59, 11, 6884, 11, 124, 3331, 35, 26290, 388, 269, 23813, 384, 3331, 35, 6935, 388, 3493, 45, 3331, 35, 41455, 388, 269, 23902, 384, 3331, 35, 41497, 388, 284, 47, 695, 45, 3331, 35, 42519, 388, 3543, 45, 3331, 35, 25543, 34158, 388, 269, 34062, 384, 3331, 35, 7537, 34158, 388, 269, 34062, 384, 3331, 35, 25526, 27166, 388, 269, 33155, 45, 4677, 31496, 4600, 29165, 21265, 308, 459, 4419, 3609, 22762, 38939, 4811, 31702, 38576, 21265, 32022, 39742, 5352, 3331, 35, 1928, 1760, 7789, 388, 4363, 48645, 38576, 384, 269, 24166, 7856, 39742, 5191, 3331, 35, 1928, 1760, 122, 50, 388, 269, 48645, 38576, 384, 3331, 35, 1928, 1760, 122, 51, 388, 269, 24166, 7856, 39742, 384, 3331, 35, 1928, 1760, 122, 52, 388, 269, 46200, 384, 3331, 35, 1928, 1760, 122, 53, 388, 269, 33572, 7856, 46611, 384, 3331, 35, 1928, 1760, 122, 54, 388, 269, 48645, 38576, 32487, 4677, 51803, 5352, 3331, 35, 64057, 116, 388, 22820, 267, 36, 29165, 38278, 461, 31059, 21273, 65004, 4424, 22590, 46594, 45, 4423, 4569, 460, 4419, 3609, 22762, 38939, 4811, 31702, 38576, 21265, 32022, 39742, 47, 3878, 39021, 21227, 32074, 65004, 4596, 22590, 46064, 4588, 4569, 38996, 31458, 46787, 47, 11, 126, 11, 6884, 11, 853, 22799, 21413, 22449, 45, 4601, 460, 31198, 4419, 51668, 4706, 32464, 332, 59284, 30397, 38128, 31324, 31296, 47, 37451, 21286, 31370, 47539, 22799, 38128, 4491, 4811, 31358, 4601, 31458, 63667, 21265, 55975, 65535, 261, 65530, 65532, 9135, 47266, 51328, 22590, 33, 17631, 16730, 4596, 22590, 30433, 24743, 30397, 11, 65535, 261, 65530, 65534, 23727, 21286, 22590, 63430, 308, 31351, 4811, 22590, 59284, 30397, 59, 11, 6884, 11, 124, 262, 35, 26290, 388, 269, 23813, 22590, 3753, 7037, 384, 11, 35, 26784, 5181, 3753, 7037, 35, 279, 11, 35, 34135, 388, 269, 5926, 1932, 1857, 384, 11, 35, 60940, 388, 269, 5732, 111, 36530, 1857, 384, 11, 35, 6935, 388, 3485, 49, 45, 11, 35, 41455, 388, 269, 23902, 384, 11, 35, 41497, 388, 286, 47, 54, 30838, 45, 11, 35, 42519, 388, 3489, 49, 21993, 45, 11, 35, 25543, 5181, 36406, 28478, 101, 21265, 29021, 384, 11, 35, 7537, 34158, 388, 269, 32957, 384, 11, 35, 60940, 5181, 308, 4418, 332, 30452, 38135, 1857, 38319, 30917, 22590, 60032, 47, 308, 31428, 101, 45, 51346, 53324, 21265, 37744, 45, 21265, 46036, 4715, 1802, 21265, 21767, 8095, 116, 4811, 52592, 4677, 30452, 5352, 11, 35, 1928, 1760, 7789, 388, 326, 269, 23926, 2065, 22235, 116, 384, 269, 33443, 7856, 53324, 21265, 37744, 5178, 24166, 7856, 30887, 39742, 384, 269, 24232, 7856, 39890, 4450, 22590, 30863, 5191, 262, 35, 54236, 7933, 47602, 23258, 24197, 24911, 5178, 918, 8987, 8439, 384, 269, 40425, 5191, 262, 35, 34636, 116, 23258, 57959, 384, 269, 6014, 2101, 5191, 11, 35, 24904, 116, 23258, 1264, 30452, 4600, 4677, 45956, 45, 308, 32475, 52592, 32229, 5191, 11, 35, 1877, 7096, 23258, 74, 4418, 45820, 56746, 21265, 39418, 4811, 37702, 395, 11, 126, 11, 6884, 11, 6699, 31356, 51165, 308, 31351, 59, 11, 46, 50612, 101, 29165, 460, 51833, 63637, 32487, 51454, 57346, 21700, 332, 303, 111, 69, 59284, 280, 31496, 45, 31813, 45, 38046, 45, 61626, 39831, 45, 39804, 11, 46, 36241, 63757, 47602, 45, 46244, 45, 37881, 21265, 38511, 4811, 38513, 22249, 22590, 59284, 11, 46, 36241, 21825, 24874, 31458, 63291, 21700, 332, 3753, 7037, 11, 46, 29955, 46928, 40069, 21700, 46182, 21265, 47779, 11, 23739, 32234, 38686, 34, 20282, 4660, 31223, 4588, 22799, 31059, 21273, 39193, 60312, 47, 65535, 261, 54397, 22590, 30433, 24743, 30397, 31162, 30441, 7506, 47, 11, 65530, 65534, 17148, 17384, 13091, 15636, 16704, 11044, 14734, 10370, 14328, 10941, 59, 11, 6884, 26060, 11, 124, 11, 35, 11043, 11860, 388, 269, 15450, 15632, 14867, 10370, 384, 11, 35, 15033, 13046, 5181, 14867, 10370, 384, 11, 35, 15669, 10270, 388, 269, 13583, 11606, 384, 11, 35, 15727, 13126, 388, 269, 13651, 13046, 12137, 10905, 384, 11, 35, 12201, 18476, 388, 3485, 49, 45, 11, 35, 12415, 10790, 388, 269, 14601, 12415, 384, 11, 35, 17038, 18216, 388, 284, 47, 625, 33, 15260, 45, 11, 35, 10452, 17385, 388, 3546, 33, 10918, 10660, 45, 11, 35, 11647, 10997, 5181, 13388, 15898, 15737, 18001, 11124, 11647, 10997, 384, 11, 35, 14806, 14815, 18029, 15898, 388, 269, 13388, 15898, 384, 11, 35, 15727, 13126, 5181, 12605, 13091, 10250, 10283, 13234, 15847, 12034, 17734, 14734, 10489, 10642, 13651, 13046, 12137, 10905, 10080, 12605, 14873, 12034, 12266, 17379, 45, 10794, 10460, 13583, 11369, 11124, 12686, 14598, 45, 12202, 10261, 18053, 10370, 11698, 11124, 18053, 10370, 18243, 12610, 13020, 10525, 12686, 12605, 14734, 13651, 13046, 10080, 384, 11, 35, 10270, 10457, 14299, 11685, 388, 4363, 12266, 17379, 14873, 14328, 35, 10079, 35, 17655, 17194, 13583, 11369, 11124, 12686, 14598, 5178, 11212, 18008, 13572, 5178, 16679, 17162, 14152, 14136, 12985, 10336, 5191, 11, 35, 12415, 13327, 14332, 12333, 388, 4363, 18003, 11434, 384, 269, 11975, 12366, 384, 269, 14781, 12824, 395, 279, 11, 35, 14486, 12389, 23258, 10682, 11042, 10452, 5178, 16020, 16584, 5191, 11, 35, 10366, 15545, 10684, 15304, 23258, 12605, 14734, 13651, 13046, 13091, 12605, 14734, 11920, 10370, 45, 12605, 11967, 10525, 12686, 10390, 10402, 5191, 11, 35, 15568, 14172, 23258, 12605, 12337, 11922, 13080, 11002, 10792, 10705, 14347, 19137, 12202, 10265, 12337, 11922, 13080, 10997, 12403, 395, 11, 126, 11, 6884, 65535, 261]
-> item_loss 1.8060524463653564 batch_loss 1.096959269963778
==== [10293, 18025, 19151, 33, 13034, 12636, 12748, 12282, 11, 65530, 65532, 13676, 13130, 19151, 16738, 10382, 15484, 14136, 14484, 13208, 14734, 10482, 14589, 13036, 12276, 11, 65535, 261, 65530, 65534, 11889, 13849, 12705, 19151, 33, 11315, 19137, 11685, 14734, 10080, 18117, 10658, 19137, 10464, 17879, 16503, 17177, 12731, 10250, 10283, 14778, 13308, 19137, 17148, 10283, 14778, 13308, 12368, 18001, 11454, 650, 11999, 15973, 11430, 10696, 28329, 65535, 261, 65530, 65534, 13676, 13130, 19151, 14221, 11044, 19137, 10464, 17879, 16503, 17177, 12731, 14136, 14484, 13208, 14734, 14778, 13308, 10080, 17148, 10283, 14778, 13308, 10260, 15752, 16443, 10675, 17238, 16181, 10080, 33, 10464, 10322, 11021, 10399, 17177, 12731, 11459, 11436, 10257, 14734, 13279, 10283, 14172, 17382, 12983, 14136, 14484, 13208, 19137, 17148, 13324, 11021, 10399, 17248, 10662, 17238, 16181, 11957, 14778, 13308, 14734, 12325, 11168, 28329, 65535, 261, 65530, 65534, 11889, 13849, 12705, 19151, 33, 14221, 11044, 19137, 10464, 17879, 16503, 10722, 11899, 14136, 14484, 13208, 14734, 10429, 11917, 15261, 11496, 10080, 10250, 15880, 13234, 16735, 19137, 14136, 14484, 13208, 17194, 12604, 14734, 13091, 14136, 14218, 10429, 11917, 19137, 10444, 13091, 10322, 13191, 11021, 15752, 17194, 12604, 10687, 10390, 10429, 11917, 15261, 11496, 19137, 11001, 10722, 10339, 10464, 14734, 17177, 12731, 28329, 65535, 261, 65530, 65532, 13676, 13130, 19151, 33, 17147, 13191, 10373, 10303, 17879, 16503, 13773, 12522, 14734, 11053, 19156, 11, 65535, 261, 65530, 65534, 11889, 13849, 12705, 59, 33, 13188, 11044, 19137, 10464, 17879, 16503, 10722, 11899, 13091, 11060, 10482, 14589, 13223, 13021, 12604, 10768, 10080, 11687, 13258, 10464, 17177, 12731, 10260, 10482, 14589, 13223, 13021, 12604, 10768, 19137, 17268, 10303, 14136, 14484, 13208, 14734, 10429, 11917, 10292, 49, 10080, 33, 11687, 13258, 10464, 17177, 12731, 10482, 14589, 13223, 13021, 12604, 10768, 19137, 17268, 10303, 14136, 14484, 13208, 14734, 10429, 11917, 10292, 50, 101, 55, 44, 50, 101, 55, 48, 13633, 15169, 15451, 19133, 13188, 11632, 44, 630, 19134, 10080, 33, 13223, 13021, 12604, 10768, 10894, 12732, 10250, 11975, 13619, 18119, 13021, 11124, 10250, 10283, 10408, 10577, 10260, 10448, 10339, 630, 49, 17389, 12153, 14734, 13676, 13130, 14484, 10080, 33, 17148, 11001, 10722, 10339, 10464, 28329, 65535, 261, 65530, 65532, 13676, 13130, 19151, 33, 12337, 11685, 33, 12605, 10333, 16533, 14136, 14484, 13208, 10333, 19137, 33, 12605, 10402, 12791, 10283, 16713, 18025, 28329, 65535, 261, 65530, 65534, 11889, 13849, 12705, 19151, 33, 11685, 14734, 19137, 10464, 16735, 11061, 28329, 65535, 261, 65530, 65532, 13676, 13130, 19151, 33, 12605, 12509, 10588, 10250, 12287, 10370, 14328, 10941, 19137, 10464, 13191, 10373, 10303, 12261, 16676, 19156, 11, 65535, 261, 65530, 65534, 11889, 13849, 12705, 19151, 33, 11685, 14734, 19137, 12605, 10402, 10384, 11187, 17384, 12266, 11726, 11102, 19156, 11, 65535, 261, 65530, 65532, 13676, 13130, 19151, 33, 11315, 19137, 12605, 12509, 10658, 10384, 12415, 13327, 12266, 11726, 28329, 65535, 261, 65530, 65534, 11889, 13849, 12705, 19151, 33, 11315, 19137, 12605, 12509, 12509, 43282, 11, 65535, 261, 65530, 65532, 13676, 13130, 19151, 33, 10464, 16525, 12348, 11684, 13091, 10283, 12401, 10303, 13324, 14734, 10370, 19156, 11, 65535, 261, 65530, 65534, 11889, 13849, 12705, 19151, 33, 12605, 16525, 12348, 11684, 13091, 10283, 10310, 16520, 12266, 13196, 14734, 10370, 19137, 11268, 13558, 12176, 10847, 10790, 10370, 19137, 10444, 13191, 13064, 10560, 10423, 12392, 14619, 10250, 10349, 15478, 15907, 28329, 65535, 261, 65530, 65532, 13676, 13130, 59, 33, 14221, 11044, 12605, 12509, 16503, 18438, 14806, 14815, 11124, 18438, 11647, 10997, 19137, 10464, 16525, 12348, 12401, 10303, 13324, 19156, 11, 65535, 261, 65530, 65534, 11889, 13849, 12705, 19151, 33, 11315, 19137, 12605, 16525, 12348, 17148, 10278, 10283, 14332, 12333, 12337, 15158, 11038, 10464, 14734, 12847, 17162, 10080, 10260, 17141, 19137, 10464, 11021, 10399, 15641, 16253, 15494, 11684, 10250, 10283, 13179, 10842, 14370, 14332, 14734, 11630, 16815, 28329, 65535, 261, 65530, 65532, 13676, 13130, 59, 33, 13637, 11687, 19156, 11, 65535, 261, 65530, 65534, 11889, 13849, 12705, 19151, 33, 13637, 11687, 16735, 19137, 11684, 14734, 11647, 10997, 11021, 10399, 13091, 17389, 15898, 14734, 19137, 14806, 14815, 11021, 10399, 13091, 16155, 15898, 14734, 19137, 17148, 13324, 10423, 13179, 10842, 14332, 13603, 28329, 65535, 261, 65530, 65532, 13676, 13130, 59, 33, 11315, 19137, 12605, 10423, 15641, 16253, 14734, 28329, 65535, 261, 65530, 65534, 11889, 13849, 12705, 19151, 33, 17147, 13191, 10250, 14172, 11994, 13091, 19137, 11684, 14734, 12415, 13327, 13637, 17097, 10310, 16520, 12266, 13196, 19137, 10444, 13191, 13064, 10560, 10423, 12392, 14619, 10250, 10349, 15478, 15907, 28329, 65535, 261, 65530, 65532, 13676, 13130, 59, 33, 17148, 10278, 14172, 12605, 17311, 13773, 12522, 10792, 10333, 19137, 16774, 16774, 10464, 12848, 17363, 28329, 65535, 261, 65530, 65534, 11889, 13849, 12705, 19151, 33, 10260, 14589, 16774, 19137, 12605, 12337, 18216, 10685, 15752, 12176, 10257, 10464, 14734, 12379, 28329, 65535, 261, 65530, 65532, 13676, 13130, 59, 33, 10464, 16525, 12348, 17148, 10278, 10283, 14332, 12333, 11187, 10349, 13637, 17097, 17385, 16503, 19156, 11, 65535, 261, 65530, 65534, 11889, 13849, 12705, 19151, 33, 12605, 16525, 12348, 10310, 16520, 12266, 13196, 11124, 14370, 14332, 11630, 16815, 13091, 13637, 17097, 17385, 16503, 14734, 28329, 65535, 261, 65530, 65532, 13676, 13130, 59, 33, 11685, 14734, 19137, 12605, 10423, 15641, 16253, 10464, 14734, 12261, 16676, 28329, 65535, 261, 65530, 65534, 11889, 13849, 12705, 19151, 33, 11957, 10333, 19137, 12605, 17147, 12509, 17728, 10464, 10250, 10283, 17728, 18025, 28329, 65535, 261, 65530, 65532, 13676, 13130, 59, 33, 11685, 14734, 19137, 10464, 16735, 11061, 28329, 65535, 261, 65530, 65534, 11889, 13849, 12705, 19151, 33, 10464, 16525, 12348, 10373, 10303, 13324, 14734, 11630, 16815, 15158, 11038, 12605, 10780, 12638, 15494, 10760, 14734, 16503, 13685, 19156, 11, 65535, 261, 65530, 65532, 13676, 13130, 59, 33, 11315, 19137, 12605, 16525, 12348, 10464, 10780, 12638, 15494, 10760, 14734, 16503, 13685, 12337, 15158, 11038, 12605, 10780, 12638, 15494, 10760, 14734, 16503, 13685, 28329, 65535, 261, 65530, 65534, 11889, 13849, 12705, 19151, 33, 11315, 19137, 16774, 16774, 10464, 14734, 14486, 16533, 10080, 12605, 12337, 12266, 12366, 15752, 12176, 10257, 10464, 14734, 12379, 28329, 65535, 261, 65530, 65532, 13676, 13130, 59, 33, 10260, 14589, 16774, 19137, 12605, 10322, 12337, 12266, 12366, 15752, 12176, 10257, 10464, 14734, 12379, 28329, 65535, 261, 65530, 65534, 11889, 13849, 12705, 19151, 33, 11957, 10333, 19137, 13326, 12797, 11150, 10402, 14734, 16753, 16713, 19137, 12605, 10292, 10464, 16689, 16664, 14734, 11630, 16815, 13091, 17389, 15898, 14734, 11647, 10997, 10079, 18438, 15898, 14734, 14806, 14815, 10079, 14136, 15446, 15898, 14734, 11630, 16815, 19137, 10464, 16525, 12348, 11687, 10454, 19156, 11, 65535, 261, 65530, 65532, 13676, 13130, 59, 33, 12605, 16525, 12348, 12337, 11685, 19137, 10464, 14734, 16689, 16664, 12337, 15158, 11038, 12605, 14734, 16503, 13685, 28329, 65535, 261, 65530, 65534, 11889, 13849, 12705, 19151, 33, 11640, 11685, 10333, 19137, 12605, 17147, 12405, 10464, 10260, 11268, 13558, 11102, 10080, 17268, 10303, 19137, 12605, 10402, 14734, 16753, 16713, 11994, 10792, 17148, 17384, 11061, 28329, 65535, 261, 65530, 65532, 13676, 13130, 59, 33, 11685, 14734, 19137, 12605, 10402, 14734, 16753, 16713, 10792, 17148, 17384, 28329, 65535, 261, 65530, 65534, 11889, 13849, 12705, 59, 33, 11685, 14734, 19137, 12605, 10402, 14734, 16753, 16713, 10792, 17148, 17384, 28329, 65535, 261, 65530, 65532, 13676, 13130, 59, 33, 11957, 10333, 19137, 12605, 10780, 12638, 15494, 10464, 16689, 16664, 14734, 11630, 16815, 13091, 17389, 15898, 14734, 11647, 10997, 10079, 18438, 15898, 14734, 14806, 14815, 10079, 14136, 15446, 15898, 14734, 11630, 11666, 19137, 10464, 16525, 12348, 11687, 10454, 19156, 11, 65535, 261, 65530, 65534, 11889, 13849, 12705, 19151, 33, 12337, 15158, 11038, 12605, 10780, 12638, 15494, 10760, 14734, 16503, 13685, 28329, 65535, 261]
-> item_loss 0.6855570673942566 batch_loss 1.081722151350092
==== [14862, 16696, 17728, 15178, 15129, 16925, 11, 65530, 65531, 10464, 13091, 10250, 10283, 1741, 10847, 12636, 19137, 11017, 10588, 11889, 13849, 12705, 10080, 10464, 12656, 14035, 10250, 11043, 11679, 11638, 11871, 14583, 19137, 33, 10688, 13191, 15895, 11685, 14734, 12996, 15715, 11124, 14862, 16696, 15727, 13126, 19137, 14256, 12459, 16664, 15200, 13212, 11124, 14583, 14328, 12137, 15052, 28329, 65535, 261, 65530, 65532, 10293, 12746, 10370, 19151, 33, 13558, 17143, 10464, 19137, 10988, 16925, 15643, 19137, 10464, 11017, 10373, 10303, 11043, 11860, 19156, 19156, 33, 10464, 14734, 15669, 10270, 13091, 10373, 10303, 19156, 11, 65535, 261, 65530, 65534, 11889, 13849, 12705, 19151, 33, 10464, 11685, 19137, 10293, 12746, 10370, 10080, 12605, 11017, 11889, 13849, 12705, 19137, 14778, 10808, 13091, 10250, 11043, 11638, 10256, 14734, 11871, 14583, 10080, 12605, 14734, 15669, 10270, 13091, 14880, 15087, 14583, 28329, 65535, 261, 65530, 65532, 10293, 12746, 10370, 19151, 10988, 10842, 17148, 13557, 13637, 16925, 10464, 15326, 12287, 11053, 19156, 11, 65535, 261, 65530, 65534, 11889, 13849, 12705, 19151, 12605, 13191, 10349, 15326, 12287, 19137, 10444, 13091, 12605, 14782, 10529, 15847, 12144, 15752, 10588, 11685, 10733, 11622, 28329, 65535, 261, 65530, 65531, 12824, 10258, 13234, 11889, 13849, 12705, 12266, 11726, 14589, 16728, 16537, 12847, 17162, 15847, 12144, 14734, 11630, 16815, 11124, 12415, 13327, 14332, 14172, 11, 65535, 261, 65530, 65532, 10293, 12746, 10370, 19151, 10464, 16525, 12348, 15847, 12144, 13091, 10250, 10283, 12401, 10303, 13324, 14734, 10370, 19156, 11, 65535, 261, 65530, 65534, 11889, 13849, 12705, 19151, 12605, 16525, 12348, 15847, 12144, 13091, 10250, 10283, 10310, 16520, 12266, 13196, 14734, 10370, 19137, 11268, 13558, 12176, 10847, 10790, 10370, 19137, 10322, 11268, 13558, 11871, 10323, 13034, 14862, 16696, 28329, 65535, 261, 65530, 65532, 10293, 12746, 10370, 19151, 33, 10464, 14734, 10370, 14583, 10285, 13191, 11187, 10349, 17225, 12577, 19156, 11, 65535, 261, 65530, 65534, 11889, 13849, 12705, 19151, 12605, 13191, 10250, 10283, 13192, 10993, 19137, 10390, 11454, 12605, 12337, 11975, 14734, 13064, 10560, 11994, 10985, 10267, 10333, 10080, 12605, 10402, 14734, 12527, 12484, 17916, 12182, 13913, 19137, 12605, 17916, 12182, 12509, 12389, 10390, 28329, 65535, 261, 65530, 65532, 10293, 12746, 10370, 19151, 33, 10464, 13191, 10373, 10303, 13203, 13234, 14734, 14486, 12509, 11053, 19156, 11, 65535, 261, 65530, 65534, 11889, 13849, 12705, 19151, 33, 12605, 12159, 13197, 15752, 11634, 12176, 10847, 13179, 11632, 14734, 10370, 19137, 16672, 10390, 10402, 12527, 11002, 10792, 13947, 13145, 11124, 10684, 12395, 10080, 12605, 10322, 12159, 13197, 15847, 12144, 15752, 11634, 12727, 13191, 10250, 10283, 12203, 15009, 15597, 14015, 14734, 11920, 12234, 28329, 65535, 261]
[2023-09-30 21:47:59,201] [INFO] [logging.py:96:log_dist] [Rank 0] step=30, skipped=0, lr=[0.0001, 0.0001, 0.0001], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
-> item_loss 1.010324239730835 batch_loss 1.0791722259351186
==== [65530, 65532, 27021, 4660, 21835, 4811, 22681, 331, 42447, 46, 1950, 97, 267, 1950, 21443, 7999, 102, 30469, 11, 65535, 261, 65530, 65534, 42447, 46, 1950, 4600, 332, 19644, 7999, 102, 56292, 32227, 45143, 22799, 4811, 47675, 4419, 56173, 22069, 4715, 31050, 32487, 22168, 30579, 47, 29059, 460, 4419, 51668, 4706, 21835, 22799, 21413, 22681, 4601, 59, 11, 6884, 7262, 7999, 102, 11, 41, 7334, 4677, 46, 8149, 4899, 98, 293, 99, 293, 100, 293, 101, 2389, 11, 41, 7334, 22168, 46, 25106, 4899, 98, 4899, 100, 293, 101, 9209, 11, 41, 42447, 46, 1950, 4677, 46, 8149, 283, 275, 41749, 275, 8020, 42, 275, 8706, 34, 22168, 46, 25106, 21952, 5292, 11, 6884, 11, 1136, 32234, 51668, 45, 308, 459, 55940, 332, 22069, 45395, 331, 2058, 46, 8149, 97, 21265, 52865, 4601, 4811, 4435, 38365, 47, 29890, 45, 308, 459, 40085, 22590, 331, 42447, 46, 1950, 97, 56292, 4811, 21227, 332, 22168, 21952, 48, 35957, 31614, 4811, 22590, 22069, 45, 40186, 31371, 4811, 332, 22168, 40093, 47, 50232, 45, 308, 459, 40085, 22590, 331, 8706, 34, 97, 56292, 4811, 21227, 332, 22168, 21952, 48, 35957, 31614, 4811, 22590, 22069, 47, 11, 74, 31104, 32234, 38686, 34, 20282, 4660, 31223, 4588, 22799, 31059, 21273, 39193, 60312, 47, 65535, 261, 1955, 22590, 21652, 24518, 33944, 4600, 39523, 64, 11, 65530, 65534, 6831, 45, 22590, 37812, 63560, 4706, 22590, 47675, 46, 1950, 56292, 4600, 51328, 47, 300, 45602, 39141, 59, 11, 50, 42, 20996, 51668, 30469, 21800, 332, 47486, 38392, 280, 22590, 22069, 56556, 47266, 4435, 59, 11, 6884, 7262, 7999, 102, 11, 41, 7334, 4677, 46, 8149, 4899, 98, 293, 99, 293, 100, 293, 101, 2389, 11, 41, 7334, 22168, 46, 25106, 4899, 98, 4899, 100, 293, 101, 9209, 11, 6884, 11, 51, 42, 47675, 46, 1950, 45143, 22799, 4811, 47675, 46657, 47700, 4596, 332, 22069, 47, 20996, 38499, 55542, 4600, 22590, 22069, 45, 21265, 22590, 47205, 55542, 4600, 332, 47709, 56880, 4811, 22590, 21952, 4811, 47675, 47, 11, 52, 42, 20996, 331, 41749, 97, 56292, 46769, 4423, 22590, 39943, 55542, 4600, 32354, 4811, 55448, 52446, 22590, 47675, 47, 3918, 57035, 22590, 51372, 40093, 4424, 32227, 21952, 4423, 4419, 55542, 45, 21265, 47266, 47102, 22590, 22168, 40093, 47, 11, 53, 42, 3913, 22590, 51668, 45, 283, 4600, 32354, 4423, 22590, 21952, 45, 21400, 4601, 47266, 55448, 4435, 332, 47709, 31296, 4369, 98, 94, 4811, 47675, 22590, 293, 98, 21952, 47, 11, 1461, 52394, 22590, 63560, 55690, 22590, 31356, 46853, 37598, 47675, 46, 1950, 280, 55492, 22799, 4811, 47675, 47700, 4596, 46657, 30579, 62586, 47, 19555, 22590, 51668, 30469, 55842, 332, 21674, 45888, 32227, 47266, 4435, 59406, 47, 30050, 39944, 63430, 45, 22590, 63560, 4600, 332, 30992, 37812, 56803, 4706, 47675, 46, 1950, 47, 11, 23739, 32234, 38686, 34, 20282, 4660, 31223, 4588, 22799, 31059, 21273, 39193, 60312, 47, 65535, 261]
-> item_loss 1.4546853303909302 batch_loss 1.092120953674974
==== [65530, 65531, 7262, 7999, 102, 14782, 10684, 17728, 18025, 11, 65535, 261, 65530, 65532, 10296, 10487, 10382, 15484, 7262, 7999, 102, 14734, 7621, 10762, 13004, 11, 65535, 261, 65530, 65534, 7621, 13091, 7262, 7999, 102, 10285, 10250, 10283, 17385, 16503, 14734, 10696, 15586, 10762, 13004, 19137, 14589, 13234, 10384, 11860, 15158, 10287, 10079, 12748, 11899, 15973, 11430, 14734, 13004, 15476, 12609, 10687, 10390, 11021, 17161, 10397, 11957, 16803, 10285, 11001, 10760, 13004, 12797, 28329, 65535, 261, 65530, 65532, 12848, 10494, 10250, 10283, 10397, 14875, 10487, 11855, 21214, 7262, 7999, 102, 11, 65535, 261, 65530, 65534, 11, 7621, 124, 3331, 40799, 22522, 296, 269, 33155, 45, 37576, 363, 60, 3331, 48550, 340, 296, 283, 60, 3331, 53570, 4601, 296, 22522, 47, 54104, 5269, 3331, 36004, 41, 1956, 47, 7669, 23955, 5265, 124, 28352, 40639, 346, 296, 4601, 47, 26315, 5269, 28352, 106, 5339, 28352, 1942, 41, 112, 62134, 50343, 513, 43909, 40812, 47, 8440, 47, 49580, 465, 40634, 59, 269, 278, 346, 502, 28352, 126, 3331, 126, 3331, 40812, 47, 8440, 47, 49580, 465, 40634, 59, 269, 278, 340, 502, 11, 126, 65535, 261]
-> item_loss 1.2706305980682373 batch_loss 1.0980712751547494
==== [65530, 65532, 10382, 15484, 7262, 7999, 102, 14734, 16728, 16537, 14332, 14172, 11, 65535, 261, 65530, 65534, 7262, 7999, 102, 16728, 16537, 13191, 10399, 10258, 10250, 10349, 14332, 14172, 59, 11, 50, 47, 33, 14875, 18476, 16728, 16537, 59, 5735, 7999, 102, 13091, 11533, 10339, 1219, 2191, 16728, 16537, 15543, 15052, 15973, 12276, 16689, 16664, 14734, 45, 12025, 10339, 10841, 15752, 12276, 11124, 17207, 17108, 12276, 14734, 13916, 11038, 15543, 15052, 16728, 16537, 28329, 51, 47, 33, 12202, 10997, 59, 5735, 7999, 102, 10688, 13191, 10696, 15586, 14734, 12202, 10997, 12978, 12746, 45, 11021, 10399, 13036, 10511, 11459, 15543, 10708, 11632, 15471, 15052, 15052, 12217, 28329, 52, 47, 33, 10577, 12824, 11010, 59, 5735, 7999, 102, 17379, 14589, 11533, 10339, 10577, 41, 33562, 42, 14734, 15543, 15052, 12824, 11010, 45, 11638, 17303, 10768, 12945, 10460, 17311, 17146, 11414, 13034, 10577, 15646, 17916, 10538, 12981, 14446, 13191, 10577, 10080, 17148, 13191, 10847, 10339, 11903, 14446, 15458, 10762, 13004, 12276, 11124, 12202, 10997, 15052, 12217, 28329, 53, 47, 33, 13080, 10339, 12651, 12022, 59, 5735, 7999, 102, 13091, 10846, 12396, 12651, 12022, 15261, 11496, 15304, 15500, 14734, 16728, 16537, 45, 11021, 10399, 13036, 10511, 11459, 11899, 10304, 13034, 14734, 10762, 13004, 10079, 16728, 13764, 11124, 11524, 14332, 11899, 16728, 16537, 41, 950, 77, 42, 28329, 54, 47, 33, 15066, 11899, 59, 5735, 7999, 102, 10482, 14589, 11533, 10339, 10342, 13027, 14734, 6588, 13212, 10794, 45, 13191, 10847, 10339, 15543, 10708, 15066, 11899, 14734, 12202, 10997, 15052, 12217, 28329, 55, 47, 33, 13080, 16742, 13080, 10708, 59, 5735, 7999, 102, 17379, 14589, 116, 16417, 17136, 12276, 41, 40810, 61371, 116, 42, 10460, 10292, 10397, 14875, 11533, 13205, 15489, 13250, 45, 11042, 13064, 10322, 13191, 15895, 11685, 14734, 16728, 13764, 10080, 10397, 14875, 15190, 13789, 13078, 10333, 28329, 56, 47, 33, 10355, 10342, 12276, 59, 5735, 7999, 102, 12848, 10494, 24072, 41, 24093, 46, 23613, 46, 33357, 29301, 497, 11021, 10399, 10355, 10342, 12276, 17144, 16403, 11124, 13827, 16707, 5735, 7999, 102, 10397, 14875, 45, 11584, 12299, 12266, 10997, 10452, 18183, 28329, 57, 47, 33, 10286, 11932, 14734, 13308, 10733, 12219, 59, 5735, 7999, 102, 15847, 17038, 12848, 10494, 10333, 12337, 11632, 11903, 14589, 14734, 10696, 15586, 10841, 15752, 45, 10894, 12732, 13004, 12797, 11621, 14486, 10079, 12202, 10997, 10079, 50807, 33, 15169, 28329, 58, 47, 33, 12978, 12746, 75, 1551, 59, 5735, 7999, 102, 17144, 16403, 11454, 75, 1551, 10257, 45, 11021, 10399, 13036, 10511, 11459, 10261, 29149, 33, 10355, 10342, 12202, 10788, 14589, 29149, 33, 14734, 10286, 11932, 15261, 12219, 28329, 10399, 10257, 10293, 16503, 10382, 15484, 10333, 7262, 7999, 102, 16728, 16537, 14734, 10250, 10349, 13637, 17097, 15092, 10760, 14734, 14332, 14172, 45, 12159, 13197, 15752, 10292, 12469, 12848, 10494, 10988, 15641, 10080, 11957, 7262, 7999, 102, 17147, 13191, 10409, 10454, 14638, 17728, 45, 13558, 17143, 17819, 13064, 11124, 12605, 10355, 13819, 10080, 65535, 261, 65530, 65532, 10777, 10296, 10250, 10283, 7262, 7999, 102, 14734, 10397, 14875, 10487, 11855, 520, 19589, 1511, 70, 33, 17148, 17384, 13191, 10250, 10283, 15190, 10932, 14734, 19644, 7999, 102, 33, 10397, 14875, 10487, 11855, 59, 11, 41, 2076, 38685, 46, 36017, 47, 25070, 3331, 478, 7616, 46, 34135, 494, 11, 41, 7334, 111, 38685, 46, 36017, 4373, 3331, 41, 49580, 269, 33155, 45, 37576, 5164, 42, 11, 41, 7334, 111, 280, 26199, 3331, 92, 39, 30176, 94, 3331, 41, 34550, 46, 36017, 494, 11, 17148, 13091, 10250, 10283, 15190, 10932, 14734, 35, 33155, 37576, 35, 15052, 12217, 59, 11, 46, 4695, 33, 14589, 13234, 11899, 10304, 11117, 11043, 15090, 17734, 11, 46, 21515, 111, 33, 11899, 10304, 10333, 38685, 46, 36017, 33, 10762, 13004, 45, 10482, 14589, 52562, 33, 12642, 10951, 35, 33155, 45, 37576, 363, 11, 46, 21515, 111, 280, 26199, 33, 11899, 10304, 10333, 10293, 10762, 13004, 45, 16749, 14589, 38685, 46, 36017, 33, 10762, 13004, 11, 10464, 11021, 10399, 17144, 16403, 17148, 10283, 19644, 7999, 102, 33, 15052, 12217, 59, 11, 6884, 11, 37, 21443, 7999, 102, 280, 110, 38685, 46, 36017, 47, 25070, 11, 33155, 45, 37576, 34, 11, 6884, 11, 5735, 7999, 102, 33, 13325, 12366, 14332, 12415, 11021, 16519, 59, 11, 46, 33, 10482, 14589, 14734, 13091, 350, 46, 61011, 33, 16728, 13764, 11, 46, 33, 12631, 13191, 11003, 17387, 17311, 13091, 59820, 33, 14734, 11, 46, 33, 11899, 10304, 10762, 13004, 10482, 14589, 21515, 111, 11, 46, 33, 10355, 10342, 12276, 4155, 1352, 11, 12159, 13197, 15752, 10292, 12469, 12848, 10494, 10988, 15641, 34, 65535, 261]
-> item_loss 1.781246542930603 batch_loss 1.1201091870184867
==== [65530, 65532, 10382, 15484, 7262, 7999, 102, 33, 10285, 10482, 14589, 14734, 42447, 46, 1950, 10762, 13004, 11, 65535, 261, 65530, 65534, 42447, 46, 1950, 33, 13091, 19644, 7999, 102, 33, 10285, 10250, 10283, 17916, 12182, 13191, 14589, 14734, 10762, 13004, 45, 14589, 10339, 13179, 13034, 12108, 11666, 13004, 12797, 15489, 13250, 10285, 14734, 10577, 28329, 11885, 14734, 10482, 14589, 13036, 13764, 13091, 59, 11, 41, 42447, 46, 1950, 30579, 46, 58449, 31209, 337, 273, 30176, 42, 11, 11885, 10423, 11454, 30579, 46, 58449, 33, 10285, 10482, 14589, 31209, 33, 12748, 11899, 14734, 16981, 12334, 45, 14221, 11044, 16749, 14589, 10762, 13004, 337, 45, 12202, 10427, 10673, 30176, 33, 10988, 13004, 10080, 103, 33, 14734, 10460, 14589, 13091, 13179, 13034, 16721, 16981, 12334, 12631, 11957, 12220, 14734, 10577, 28329, 10487, 11687, 59, 11, 41, 7334, 355, 4899, 98, 4899, 99, 285, 9209, 11, 11459, 13179, 13034, 12108, 11666, 14734, 333, 33, 14734, 10577, 59, 11, 41, 42447, 46, 1950, 355, 4369, 98, 293, 99, 94, 21878, 42, 3580, 4899, 98, 4899, 99, 286, 2408, 11, 11013, 11630, 10250, 10283, 10487, 11855, 59, 11, 41, 42447, 46, 1950, 355, 4369, 98, 94, 21298, 2087, 293, 100, 286, 42, 11, 746, 4899, 98, 4899, 99, 285, 45, 293, 100, 286, 2408, 11, 17148, 17384, 10482, 14589, 21298, 2087, 33, 10762, 13004, 13179, 13034, 10333, 293, 98, 22069, 45, 13920, 10842, 10333, 10250, 10283, 293, 100, 33, 11860, 13619, 28329, 12631, 10399, 12421, 15646, 16537, 10305, 45, 42447, 46, 1950, 33, 10652, 16684, 10464, 13036, 10511, 11459, 13179, 13034, 19644, 7999, 102, 33, 10285, 10409, 12522, 11626, 13215, 12231, 14734, 12108, 11666, 13004, 12797, 15489, 13250, 28329, 12159, 13197, 15752, 15494, 12469, 10250, 10283, 11638, 13445, 14734, 10333, 16533, 34, 42447, 46, 1950, 33, 10762, 13004, 11454, 11903, 17781, 12220, 14589, 10285, 17916, 12182, 11903, 14589, 10080, 65535, 261]
-> item_loss 1.9270771741867065 batch_loss 1.1453269366174936
==== [10355, 13819, 17728, 15178, 11, 65530, 65532, 12605, 12509, 10985, 10902, 10362, 13042, 13953, 19137, 10464, 14862, 17222, 10902, 10362, 13191, 10373, 10303, 13126, 14172, 11053, 19156, 11, 65535, 261, 65530, 65534, 10464, 11021, 10399, 17189, 17141, 15573, 15497, 12877, 15325, 12609, 15643, 11459, 11436, 12220, 14589, 13290, 12664, 10902, 10362, 14734, 13126, 14172, 10529, 12445, 10080, 10250, 10349, 14862, 11043, 13126, 14172, 11687, 12985, 11913, 10079, 11639, 11889, 17723, 12210, 11461, 10079, 17688, 11517, 10079, 13676, 15123, 13036, 15169, 17311, 13091, 10260, 17631, 14734, 17177, 12731, 10080, 13581, 11630, 19137, 10902, 10362, 17147, 13191, 16684, 11632, 15597, 18053, 11124, 14332, 15898, 11975, 11035, 10577, 12348, 10250, 16707, 19137, 11687, 14188, 18372, 10079, 10902, 10362, 14171, 17351, 17919, 10079, 16793, 13684, 15169, 28329, 65535, 261, 65530, 65532, 12605, 12509, 14862, 17222, 14446, 11454, 14734, 11639, 13655, 12484, 10724, 11, 65535, 261, 65530, 65534, 13326, 12797, 13188, 13034, 14734, 13655, 16803, 13004, 12797, 19137, 14446, 11454, 14734, 11639, 13655, 12484, 10724, 11416, 10292, 12469, 14734, 10447, 15586, 10260, 11042, 15646, 12268, 10080, 10444, 13091, 19137, 13326, 12797, 13655, 16803, 13004, 12797, 12848, 10494, 14734, 10529, 12445, 19137, 12469, 11021, 10399, 11638, 15850, 10333, 16533, 12307, 10808, 12631, 11454, 11459, 10912, 14734, 11639, 13655, 14349, 10724, 19151, 11, 10902, 10362, 19151, 11632, 10341, 17083, 17773, 11, 11639, 13655, 14349, 10724, 19151, 11632, 10341, 11, 13947, 12231, 19151, 46, 50, 9866, 361, 288, 9866, 11, 12469, 11021, 10399, 17189, 17141, 12220, 14589, 10696, 14734, 12387, 12802, 13036, 12276, 10769, 12791, 13655, 16803, 13004, 12797, 12848, 10494, 14734, 16523, 16525, 12986, 13258, 19137, 10399, 16056, 11001, 13179, 10842, 14781, 16520, 10733, 14914, 14734, 10529, 12445, 10080, 65535, 261]
-> item_loss 0.7310567498207092 batch_loss 1.1327732945933486
==== [25106, 11, 65530, 65531, 12605, 10402, 12266, 11726, 10250, 10283, 13034, 14734, 16713, 18025, 19137, 33, 17148, 10283, 16713, 18025, 10684, 10339, 12366, 14486, 10913, 14583, 11124, 13234, 16690, 15643, 14734, 10355, 13819, 19137, 33, 10390, 10402, 10305, 17734, 11454, 16671, 16686, 10250, 13619, 10993, 12484, 14734, 13855, 11645, 11, 65535, 261, 65530, 65532, 6909, 4423, 332, 33, 12366, 14486, 11871, 11920, 19137, 11124, 12605, 16671, 16686, 10250, 10283, 13192, 10993, 14734, 17728, 18025, 10080, 33, 16738, 10399, 10726, 17912, 10079, 14486, 12415, 11124, 11907, 16520, 14581, 15849, 13191, 14172, 10726, 17354, 14734, 18043, 13327, 13234, 16671, 16686, 19137, 12605, 10260, 17879, 16503, 13051, 15763, 14734, 11889, 12556, 11124, 13580, 15752, 17387, 14734, 16671, 16686, 19137, 12605, 17879, 16503, 10464, 12176, 10847, 12605, 13923, 13127, 14734, 11414, 18004, 11124, 10250, 10283, 10370, 14734, 10355, 12332, 15486, 10964, 28329, 65535, 261, 65530, 65534, 11685, 14734, 45, 12605, 11967, 12002, 10838, 10399, 11907, 16520, 11124, 14486, 12415, 14734, 12396, 12231, 13234, 16671, 16686, 12469, 13192, 10993, 14734, 17728, 18025, 10080, 10460, 10292, 10250, 11043, 12366, 14486, 11871, 11920, 45, 12605, 14734, 14778, 13308, 13091, 12176, 10847, 12469, 14486, 13923, 12410, 16981, 45, 12848, 10494, 10250, 10349, 10260, 11042, 14734, 16523, 16530, 45, 15646, 10260, 13091, 15494, 10760, 15190, 10932, 14734, 12261, 16676, 10080, 16738, 12847, 17162, 10250, 10258, 12469, 13192, 10993, 14734, 12484, 10724, 11124, 10684, 15304, 17728, 18025, 45, 12605, 10423, 15648, 12366, 11459, 10578, 11065, 45, 12202, 11986, 16707, 10384, 11632, 10283, 13036, 17919, 17149, 16403, 10768, 13254, 10080, 16678, 10449, 45, 13633, 10283, 10370, 11124, 13633, 13619, 10684, 15304, 17311, 13091, 14370, 10250, 13051, 10337, 14734, 10080, 12605, 10423, 11971, 17385, 12469, 13192, 10993, 14734, 12527, 11002, 45, 11042, 13064, 10322, 10423, 11687, 11903, 11459, 12848, 10760, 12605, 14734, 16520, 14172, 10080, 11687, 13258, 12469, 16525, 12348, 12605, 14734, 13279, 10349, 14791, 13764, 17141, 10339, 10293, 16520, 12609, 15643, 12484, 15509, 10901, 45, 16738, 17819, 13064, 12848, 17363, 12605, 10525, 12746, 11907, 16520, 10080, 12605, 12337, 18216, 10685, 15752, 16974, 12469, 10250, 16944, 12822, 16671, 17148, 10283, 16713, 18025, 45, 12159, 13197, 12605, 10402, 14734, 16671, 16686, 15752, 15494, 12469, 10250, 10349, 11068, 10997, 45, 12176, 10847, 12469, 13179, 11685, 11459, 12410, 15641, 11124, 11621, 14486, 17148, 13619, 10684, 15304, 28329, 65535, 261, 65530, 65532, 12605, 13191, 10250, 10283, 13192, 10993, 19137, 13186, 15486, 12605, 10402, 13091, 10782, 10285, 11042, 11871, 19137, 12307, 10782, 12605, 13091, 14474, 15451, 10285, 14734, 12143, 14583, 19137, 10390, 13091, 14474, 15451, 10285, 14734, 10421, 15169, 14583, 10080, 33, 12605, 10402, 10355, 12332, 14734, 15486, 10964, 16944, 13981, 10339, 12307, 12201, 12605, 14734, 12604, 15508, 15092, 18052, 14388, 17149, 28329, 65535, 261, 65530, 65534, 12469, 12847, 17162, 14734, 17148, 15033, 10684, 15304, 16944, 13981, 14914, 11903, 12337, 13191, 12522, 12410, 10080, 10384, 12469, 12848, 10494, 14734, 10529, 12445, 13234, 14791, 45, 17148, 13619, 10993, 16754, 12314, 12604, 14734, 11662, 13212, 13091, 12469, 14734, 12604, 15508, 13191, 10333, 18052, 16962, 12415, 14734, 17149, 13582, 45, 12282, 16944, 10333, 12307, 13064, 12604, 15508, 10421, 12268, 14734, 10390, 14734, 13773, 12522, 11124, 16928, 16917, 28329, 17148, 15033, 11533, 10339, 11871, 10323, 12604, 15508, 14734, 17152, 12824, 13036, 12276, 11454, 10782, 10285, 13064, 13199, 12202, 10260, 15576, 16519, 45, 12307, 13064, 12604, 15508, 12332, 12332, 16443, 16523, 10292, 10784, 13032, 10250, 10283, 10370, 10421, 10845, 14734, 15190, 10932, 13308, 10733, 10080, 10444, 13091, 45, 11687, 13258, 17141, 10339, 12299, 16749, 12604, 15508, 14734, 10421, 10845, 45, 15646, 12392, 16523, 10333, 13633, 10283, 11872, 11855, 14734, 10283, 12415, 10079, 10685, 16954, 11124, 10687, 10390, 15323, 16884, 45, 10779, 12337, 17843, 12261, 15123, 13913, 10673, 14734, 10993, 16754, 28329, 12605, 12509, 10333, 16533, 10250, 10258, 45, 11454, 12469, 12604, 15508, 12848, 18216, 10305, 11044, 45, 12469, 11124, 10390, 14734, 10993, 16754, 13091, 11060, 15752, 11634, 16947, 16948, 12604, 15508, 17148, 10283, 12007, 17919, 45, 11454, 11159, 13327, 10079, 14299, 11685, 10079, 10408, 10577, 16520, 15169, 13179, 13913, 12007, 13557, 10257, 16056, 12348, 16667, 11042, 11124, 17152, 12824, 64, 17148, 11957, 10339, 10250, 13619, 10993, 16754, 14734, 12746, 10301, 10997, 12022, 10917, 10768, 17385, 16503, 10080, 11687, 13258, 17141, 10768, 10495, 16922, 13279, 10250, 15033, 13231, 10407, 12314, 12604, 14734, 15671, 15489, 45, 10250, 13054, 13231, 10407, 13855, 11645, 45, 10993, 16754, 10322, 11021, 15752, 17819, 10305, 13855, 11645, 10080, 12605, 12337, 18216, 10685, 15507, 15511, 10578, 11065, 12469, 10768, 10361, 17148, 13619, 10993, 16754, 10684, 15304, 14734, 13179, 11632, 15478, 15907, 11124, 15486, 10964, 10080, 65535, 261, 65530, 65532, 12605, 16667, 10292, 11454, 11159, 13327, 10079, 14299, 11685, 10079, 10408, 10577, 16520, 12007, 13557, 10257, 13191, 10333, 10250, 10349, 17152, 12824, 19137, 10444, 13091, 12202, 13734, 13191, 16535, 10992, 12337, 13913, 14734, 12007, 17919, 10080, 33, 12746, 15511, 10917, 10745, 12201, 14734, 13192, 10993, 10684, 15304, 10285, 19137, 33, 13179, 11632, 14734, 13091, 10768, 10361, 14583, 13815, 10285, 14734, 10250, 10349, 14493, 10336, 19137, 12605, 16667, 10292, 10390, 13637, 17097, 10684, 13773, 12605, 14734, 14583, 13815, 19137, 10444, 13091, 13091, 12605, 14583, 13815, 10285, 14734, 12604, 11994, 13036, 17919, 19137, 33, 15646, 10260, 13091, 12605, 10283, 10370, 14734, 12203, 15009, 13036, 17919, 28329, 65535, 261, 65530, 65534, 12469, 12848, 10494, 14734, 16416, 10655, 10529, 12445, 16672, 12605, 11957, 17148, 13619, 10993, 16754, 13191, 10333, 13179, 13923, 13127, 14734, 10333, 16533, 10080, 14791, 13234, 11454, 12604, 15508, 10305, 11630, 45, 10464, 10402, 10322, 11454, 11159, 13327, 10079, 14299, 11685, 15169, 12007, 17919, 10257, 12261, 15123, 10333, 10250, 11899, 14734, 17152, 12824, 45, 10444, 10441, 10308, 13734, 13191, 17136, 10792, 17916, 12182, 10366, 11930, 14734, 15052, 12231, 10080, 15646, 11454, 17148, 10917, 10745, 12201, 14734, 10355, 12332, 10285, 45, 10464, 10402, 13179, 11632, 10589, 14614, 11454, 14583, 13815, 14493, 10336, 14734, 10768, 10361, 45, 17097, 11977, 16535, 10992, 13179, 13913, 12007, 13557, 14734, 16713, 18025, 28329, 12469, 12848, 10792, 10250, 10283, 10684, 17644, 14172, 45, 11994, 13091, 10390, 10441, 10308, 13179, 10684, 13773, 12469, 14734, 12604, 11994, 45, 15646, 10260, 13091, 12469, 10283, 10370, 14734, 12203, 15009, 12527, 10080, 17148, 11454, 10250, 11899, 15052, 12231, 10257, 16533, 17382, 10333, 10292, 10373, 10303, 17148, 13619, 10993, 16754, 10589, 14614, 11454, 13637, 17097, 16417, 12007, 14734, 10696, 11922, 10768, 10361, 45, 15646, 13734, 13191, 12314, 12604, 12366, 14141, 11124, 12484, 12527, 14734, 13913, 12231, 12665, 16741, 28329, 12605, 12509, 12848, 10760, 10745, 14172, 14791, 13764, 45, 13558, 17143, 12469, 14734, 10995, 18108, 59, 11, 11454, 10993, 16754, 10285, 45, 13199, 12335, 10994, 13036, 17311, 15752, 10684, 12366, 11957, 13036, 14734, 14583, 13815, 16884, 17387, 11124, 12203, 15009, 12527, 45, 15646, 10260, 10377, 10377, 13091, 12604, 11994, 11124, 12604, 10841, 45, 17148, 13091, 13179, 10590, 12237, 14734, 10684, 15304, 28329, 12469, 13091, 11060, 10322, 11021, 10399, 13179, 10293, 10846, 11459, 10768, 10361, 15847, 12144, 14734, 12484, 12527, 10267, 14610, 45, 16417, 17136, 11957, 10390, 14734, 10684, 12366, 45, 15646, 10260, 10377, 13091, 12604, 11994, 10257, 14734, 10355, 13819, 64, 17148, 11021, 15752, 12176, 10847, 12705, 17145, 10994, 13036, 16973, 15023, 28329, 11687, 13258, 17688, 13199, 12527, 16525, 17148, 13619, 10993, 16754, 10589, 14012, 10260, 10808, 45, 12469, 10322, 16684, 17879, 16503, 10995, 12410, 17148, 13619, 10684, 15304, 17147, 15752, 11060, 14015, 16956, 12469, 14734, 17879, 13685, 10080, 10293, 10846, 16753, 16753, 12469, 14734, 12509, 13764, 10322, 16684, 10423, 13191, 12176, 10847, 28329, 12159, 13197, 17148, 10349, 12261, 16676, 15752, 15494, 12469, 12848, 10494, 10250, 10349, 10988, 15641, 10080, 12605, 12337, 13559, 16917, 12469, 12537, 12522, 11906, 16523, 17148, 13619, 10993, 16754, 10684, 15304, 45, 12202, 16672, 11885, 11003, 12348, 13179, 10842, 10286, 11932, 13191, 12522, 10304, 10080, 17148, 11994, 13091, 12604, 14256, 10993, 16754, 14734, 17385, 16503, 10452, 14446, 10080, 65535, 261, 65530, 65532, 12605, 16667, 10292, 11454, 12605, 11124, 10390, 14734, 10684, 15304, 12307, 10285, 19137, 12605, 12025, 10339, 10293, 10846, 10768, 10361, 12484, 12527, 10267, 14610, 11124, 14583, 13815, 10285, 12387, 10310, 14734, 10370, 10080, 10390, 11533, 13205, 10257, 10260, 10423, 10768, 10361, 14794, 11903, 14734, 12484, 12527, 10267, 14610, 10080, 33, 12605, 11454, 14042, 17688, 14734, 10993, 12484, 15486, 10964, 10285, 11414, 18004, 19137, 10997, 14446, 10390, 10687, 11903, 10250, 14781, 10441, 10308, 17820, 16223, 11454, 13279, 10283, 17919, 10688, 10258, 28329, 65535, 261, 65530, 65534, 12337, 12527, 16774, 12469, 12848, 10494, 13179, 11632, 15478, 15907, 10080, 14446, 11454, 12605, 11957, 17148, 13619, 10993, 16754, 14734, 10342, 10846, 13499, 12276, 13191, 10333, 13179, 13923, 13127, 14734, 16667, 16696, 28329, 10384, 12469, 14734, 12847, 17162, 13234, 14791, 45, 11454, 17148, 13619, 10684, 15304, 10285, 45, 12469, 13637, 17097, 10293, 10846, 11459, 10768, 10361, 15847, 12144, 14734, 12484, 12527, 11124, 14583, 13815, 12387, 10310, 45, 15646, 10390, 12337, 11977, 12022, 14966, 14794, 11903, 14734, 10696, 12366, 10267, 14610, 45, 10441, 10308, 12421, 12624, 14808, 10250, 10283, 17919, 10688, 10080, 17148, 15033, 17688, 13199, 14734, 10260, 11957, 15169, 13091, 10260, 10590, 12237, 14734, 28329, 12605, 12509, 12848, 10760, 10250, 10349, 12261, 16676, 59, 11, 50, 47, 10261, 10390, 11483, 16711, 11459, 13733, 17189, 12469, 14734, 12527, 11002, 45, 16735, 12469, 12159, 13197, 17148, 13619, 10993, 16754, 15752, 11634, 13179, 10842, 14794, 16711, 10079, 12266, 12983, 10080, 17728, 17728, 10390, 17820, 16223, 15847, 12605, 14734, 10974, 11416, 45, 16672, 10390, 12522, 16696, 10792, 12469, 10260, 13091, 16417, 17919, 14734, 13192, 10993, 28329, 51, 47, 15494, 10390, 13064, 17734, 12642, 12266, 12366, 12635, 45, 10444, 10260, 15752, 12299, 13685, 10080, 10261, 13581, 11042, 13064, 45, 10525, 12686, 11685, 15847, 12144, 45, 10260, 16503, 17141, 12231, 12674, 10673, 10250, 10283, 10260, 11414, 12687, 14734, 10684, 15304, 28329, 52, 47, 11687, 13258, 10390, 13051, 13764, 11003, 10901, 45, 12469, 11021, 15752, 17879, 16503, 17385, 13034, 16694, 10435, 17148, 13619, 10993, 16754, 11957, 12469, 14734, 12522, 10304, 45, 10260, 16503, 14614, 12428, 10250, 15033, 14486, 12509, 10901, 14734, 10993, 16754, 28329, 53, 47, 11454, 10687, 10390, 10684, 15304, 10285, 12664, 10792, 16056, 12348, 12484, 12527, 10355, 13819, 11124, 12978, 12746, 14734, 10760, 11010, 10080, 10260, 16503, 11928, 12159, 13197, 10339, 10250, 10283, 10370, 28329, 12527, 16774, 12469, 10768, 10361, 17148, 13619, 11626, 13215, 14734, 10684, 15304, 10964, 15052, 10080, 12605, 16424, 12366, 12159, 13197, 12469, 15752, 12664, 10792, 10342, 14782, 12978, 12746, 10079, 14794, 13580, 10529, 10409, 14734, 10993, 16754, 10684, 15304, 10080, 17148, 17879, 16503, 13064, 17734, 45, 10444, 10464, 10577, 12348, 12727, 13191, 10080, 11687, 13258, 13191, 10409, 10454, 10687, 10390, 12509, 13764, 13558, 17143, 15507, 15511, 16671, 16686, 10080, 65535, 261, 65530, 65532, 12605, 12159, 13197, 10464, 15752, 13179, 10842, 13913, 12231, 14734, 10384, 10370, 13327, 14486, 16686, 16530, 12231, 16671, 16686, 17148, 15033, 10684, 15304, 28329, 65535, 261, 65530, 65534, 11685, 14734, 45, 12605, 10423, 11986, 16707, 10384, 10370, 13327, 14486, 16686, 14734, 16523, 16530, 45, 11957, 17148, 15033, 10684, 15304, 13499, 12276, 17149, 16403, 13179, 13913, 10673, 14734, 10768, 13254, 28329, 18117, 10658, 45, 10384, 12469, 13192, 10993, 14734, 14332, 12333, 13234, 14791, 45, 10390, 10441, 10308, 13191, 14808, 10696, 11047, 10079, 13773, 17385, 17820, 16223, 15847, 12605, 14734, 10370, 13327, 10578, 11047, 10080, 13326, 12797, 10370, 13327, 14486, 16686, 45, 17148, 11021, 15752, 13091, 10390, 15847, 17038, 14734, 12415, 13327, 14332, 12333, 45, 10322, 11021, 15752, 13091, 11872, 12848, 13064, 13199, 14734, 14583, 13815, 15486, 10964, 11960, 15850, 14734, 10370, 13327, 17172, 12220, 28329, 10687, 13557, 45, 11454, 10464, 10402, 14734, 14782, 11621, 10285, 45, 12469, 16417, 14446, 10760, 10333, 13179, 11630, 11047, 10079, 10293, 10846, 16417, 17136, 14734, 10370, 13327, 14332, 16884, 10080, 13326, 12797, 10370, 13327, 10911, 17332, 14486, 16686, 45, 17148, 10278, 15033, 10260, 11042, 15261, 11496, 14734, 10370, 11687, 13258, 16503, 10997, 12022, 15895, 11685, 14734, 10684, 15304, 45, 10994, 13036, 17311, 17879, 16503, 10588, 10760, 16749, 13006, 17172, 12220, 11957, 13036, 45, 15646, 10260, 15752, 10932, 15458, 13199, 12335, 11957, 13036, 12981, 11003, 28329, 15162, 10256, 45, 10384, 15287, 14987, 10768, 13254, 16530, 12231, 14791, 45, 10390, 17820, 16223, 15847, 12605, 11021, 15752, 13091, 10760, 10339, 13279, 10349, 10696, 12366, 14734, 14216, 16253, 12609, 17771, 12354, 13212, 10794, 10080, 11687, 13258, 15752, 16672, 10390, 12527, 10792, 11889, 10675, 11124, 16443, 12824, 15462, 45, 10390, 11021, 15752, 17182, 13932, 12022, 14446, 14794, 11903, 15847, 12605, 10080, 17148, 17384, 17879, 16503, 12469, 16417, 14446, 10760, 15648, 12366, 11124, 13145, 12522, 45, 15646, 17916, 12299, 13685, 28329, 13188, 11044, 45, 11687, 13258, 17688, 13199, 13051, 13764, 12261, 15123, 10342, 14782, 10529, 10409, 45, 12824, 15462, 30719, 39193, 14734, 10684, 15304, 45, 10322, 16684, 16735, 13078, 10464, 10402, 14734, 10370, 13327, 10992, 17879, 13685, 11861, 11454, 10250, 11899, 14734, 8176, 35047, 10080, 10525, 12746, 17172, 12307, 16973, 15023, 45, 15646, 10260, 13091, 10864, 12299, 15516, 15304, 45, 11021, 15752, 13091, 13179, 10590, 12237, 14734, 17177, 12731, 28329, 12421, 10305, 45, 17148, 17879, 16503, 10994, 13036, 10682, 11042, 10848, 10838, 11124, 13064, 17734, 11532, 10691, 10080, 17385, 16503, 14734, 13091, 16503, 14914, 11899, 17148, 15033, 10993, 16754, 13091, 11060, 10383, 14221, 13191, 12522, 10304, 11124, 12159, 13197, 45, 11687, 13258, 12527, 10792, 13855, 13249, 45, 12983, 12636, 10322, 13203, 11986, 10260, 11021, 10080, 16738, 15507, 15511, 10768, 10361, 12469, 14734, 12509, 13764, 10080, 65535, 261, 65530, 65532, 16416, 10655, 10250, 10349, 10529, 12445, 19137, 11454, 13188, 17145, 14734, 10745, 12201, 19137, 12605, 14734, 14583, 13815, 10285, 10760, 14446, 10333, 10250, 10349, 18052, 16962, 12415, 14734, 12604, 11994, 19137, 33, 12307, 12605, 12266, 12366, 14734, 10261, 10390, 10768, 10361, 13064, 19137, 10997, 14446, 10390, 10250, 14781, 11621, 10339, 10250, 15033, 11414, 17248, 11124, 15847, 12605, 17771, 12354, 14734, 14349, 12396, 28329, 65535, 261, 65530, 65534, 12527, 16774, 12469, 12848, 10494, 14734, 18030, 11630, 10529, 12445, 10080, 17148, 10250, 16416, 10655, 15478, 15907, 12176, 10847, 12605, 13179, 10733, 14914, 11459, 10768, 13254, 17148, 13619, 10993, 16754, 10846, 12396, 28329, 10384, 12469, 13188, 17145, 11001, 12348, 12604, 11994, 13064, 10390, 14734, 11414, 17248, 11124, 15847, 12605, 17771, 12354, 10995, 12220, 13234, 14791, 45, 17148, 11021, 15752, 10995, 13086, 10760, 10399, 10258, 10745, 10283, 17728, 18025, 59, 11, 10390, 15847, 17038, 11454, 10464, 10402, 10684, 15304, 10285, 10250, 14781, 11621, 10339, 10421, 16948, 12527, 11124, 12825, 10794, 12527, 17097, 12299, 14734, 10250, 13036, 45, 14446, 11454, 17148, 15033, 10846, 12396, 16443, 12642, 14894, 45, 10398, 10390, 12527, 10792, 10260, 17172, 12220, 28329, 10390, 11021, 15752, 11861, 11454, 10250, 11899, 15052, 12231, 14734, 15129, 10335, 12366, 14486, 45, 12631, 10399, 12469, 14734, 12604, 10841, 16535, 10997, 10333, 10390, 14734, 10260, 11889, 10675, 12527, 28329, 11454, 15847, 12605, 16667, 14862, 10257, 45, 10390, 17141, 10339, 10495, 16922, 10339, 12604, 15508, 11124, 12604, 11994, 13234, 11899, 10304, 15847, 12605, 10408, 10577, 45, 12631, 10399, 53983, 14734, 12604, 10841, 10397, 16417, 10333, 11957, 10390, 14734, 7428, 14734, 12642, 10761, 28329, 11687, 13258, 10390, 17688, 13199, 13051, 13764, 10292, 12469, 14734, 12604, 10841, 12527, 10792, 14794, 16711, 14734, 18216, 10685, 45, 11016, 10423, 11414, 17248, 12609, 15847, 12605, 17771, 12354, 45, 17148, 12430, 12405, 10397, 16417, 14808, 10390, 12202, 10260, 11634, 11454, 12522, 12469, 14734, 10696, 12366, 10267, 14610, 28329, 15523, 10257, 12631, 17162, 45, 17148, 15033, 11003, 10901, 10322, 16684, 13580, 11454, 16535, 10846, 17148, 13619, 10993, 16754, 10684, 15304, 14734, 13326, 11533, 10080, 12605, 12261, 16676, 12469, 11021, 10399, 11986, 16707, 10261, 10390, 12266, 16711, 12155, 10678, 11459, 16671, 16686, 11003, 10901, 45, 10444, 16503, 10292, 10409, 10454, 15489, 13258, 10588, 11685, 10733, 11622, 10080, 12746, 15511, 12674, 10673, 10250, 13619, 10260, 12200, 16412, 14734, 10684, 15304, 13052, 16899, 13064, 17734, 10322, 16899, 15287, 10838, 10080, 12159, 13197, 17148, 10349, 12261, 16676, 15752, 15494, 12469, 12172, 13234, 10250, 10349, 12176, 10847, 45, 10322, 13558, 17143, 12469, 12848, 10760, 15847, 12144, 14734, 12509, 13764, 10080, 65535, 261, 65530, 65532, 12337, 12527, 16774, 10464, 10726, 17912, 14734, 10768, 13254, 19137, 33, 12605, 12145, 15486, 12522, 16696, 10792, 17148, 13619, 10993, 12484, 11967, 16503, 14894, 14924, 10080, 33, 12605, 10402, 14734, 10355, 13819, 16672, 12605, 15752, 13179, 10842, 11922, 13080, 14734, 12824, 11002, 17148, 10250, 14172, 10080, 33, 12605, 11454, 11414, 18004, 12307, 12201, 14734, 15486, 10964, 13064, 19137, 14734, 14914, 10997, 14446, 15847, 12144, 14734, 14970, 10423, 16694, 10408, 13637, 10390, 10448, 12337, 11632, 10080, 33, 15646, 17145, 12201, 14734, 12604, 11994, 14734, 14914, 13191, 12337, 11632, 15092, 14894, 28329, 65535, 261, 65530, 65534, 12469, 14734, 10995, 18108, 16672, 12605, 12527, 10792, 13559, 12556, 10080, 15752, 11634, 10726, 17912, 14486, 12415, 11459, 10768, 13254, 10250, 13619, 10684, 15304, 14734, 11003, 10901, 45, 12202, 10588, 11685, 12366, 14486, 10733, 11622, 12824, 11002, 10687, 15489, 12005, 45, 17879, 16503, 13133, 12551, 11124, 10863, 13655, 10080, 12605, 12337, 18216, 10685, 12605, 10402, 14734, 16671, 16686, 15752, 11634, 12176, 10847, 12469, 17189, 17141, 11414, 18004, 12332, 10336, 45, 11906, 16523, 14446, 14349, 45, 10384, 15646, 13179, 11685, 11459, 12824, 15462, 17148, 10250, 14446, 11903, 28329, 10384, 12469, 12848, 10494, 14734, 10964, 15052, 13234, 14791, 45, 17148, 13619, 10993, 16754, 11454, 17141, 10985, 14914, 11903, 12261, 15123, 11454, 10250, 11899, 14734, 14970, 10423, 16694, 10408, 11533, 14902, 10305, 10257, 45, 14446, 11454, 17148, 10250, 11533, 14902, 10997, 14583, 10333, 11003, 10901, 45, 12368, 14221, 10423, 11957, 10684, 15304, 10358, 14583, 10721, 10761, 10080, 17148, 15033, 10721, 15092, 11454, 12337, 11632, 17688, 13199, 10993, 16754, 10285, 17311, 11021, 15752, 10997, 14583, 45, 10684, 17644, 13091, 11687, 10454, 10901, 16533, 11124, 17919, 11957, 28329, 12605, 12261, 16676, 12469, 11021, 10399, 17177, 12731, 10261, 10390, 12329, 12221, 17382, 12395, 45, 10322, 11021, 10399, 14614, 10258, 10250, 14172, 10993, 16754, 14734, 10457, 11459, 10080, 17385, 16503, 14734, 13091, 10260, 16503, 55099, 7946, 33, 10390, 14734, 11414, 17248, 10460, 10292, 11957, 12469, 15847, 17038, 10408, 10577, 14734, 11060, 11899, 10080, 12469, 14734, 12604, 11994, 12022, 14446, 10333, 15847, 12144, 14734, 10848, 10838, 45, 12220, 12307, 14597, 16424, 11459, 12527, 10792, 18176, 10613, 11124, 12266, 12366, 28329, 12159, 13197, 12469, 11021, 10399, 15043, 13249, 12674, 10673, 10687, 10390, 14970, 10355, 11441, 11855, 45, 12664, 10792, 13179, 10590, 12237, 33078, 14734, 10370, 17781, 10684, 15304, 10080, 12469, 14734, 12604, 17688, 12220, 16721, 13091, 16443, 13559, 16917, 11124, 18458, 10851, 14734, 45, 15646, 17916, 16443, 11060, 11899, 10080, 12527, 16774, 12469, 10768, 10361, 17148, 10250, 11626, 13215, 17141, 15052, 45, 14986, 12469, 15507, 15511, 10808, 16403, 45, 10997, 14446, 14583, 13815, 14734, 15597, 11685, 34, 65535, 261, 65530, 65532, 12307, 10250, 10283, 10370, 10260, 13032, 14734, 12604, 17688, 13064, 19137, 13091, 11060, 10423, 17919, 11957, 13179, 11632, 14734, 17148, 15261, 10684, 15304, 14894, 14924, 10080, 33, 11454, 17141, 10985, 14734, 10337, 10256, 10917, 12201, 14734, 15486, 10964, 10285, 19137, 12605, 10997, 14446, 12605, 14734, 13192, 10993, 16948, 13234, 16948, 11977, 10080, 33, 17819, 14808, 10283, 10370, 17149, 13582, 14734, 14914, 10423, 16667, 16696, 13179, 11632, 14734, 13192, 10993, 10080, 10444, 13091, 13055, 14734, 13192, 10993, 14734, 11645, 10985, 14734, 14914, 17147, 13091, 10423, 16672, 10370, 12527, 10429, 28329, 65535, 261, 65530, 65534, 12469, 12848, 10760, 10333, 10250, 10283, 17916, 12182, 17385, 16503, 14734, 17728, 18025, 45, 10283, 10370, 12604, 17688, 11124, 13055, 10684, 15304, 14894, 16449, 10305, 17734, 14734, 10684, 15304, 10080, 17148, 13091, 10250, 10283, 10577, 12348, 13913, 12410, 14734, 16713, 18025, 28329, 12469, 14734, 12527, 11002, 17916, 12182, 14486, 16533, 11124, 10682, 18365, 10080, 12307, 10250, 10283, 10370, 10260, 13032, 12604, 17688, 11124, 11003, 10901, 13064, 45, 10261, 17141, 10985, 12261, 15123, 14734, 10250, 10349, 10684, 15304, 14914, 11903, 17919, 10288, 14808, 12752, 12610, 11124, 16749, 13006, 10080, 17148, 13091, 12337, 11632, 10370, 11454, 12604, 17688, 17141, 15052, 10285, 17311, 10423, 15486, 10964, 14734, 28329, 10250, 10349, 14791, 13764, 10494, 12469, 10988, 15641, 59, 11, 10283, 10370, 12604, 17688, 13036, 11047, 10261, 13055, 10993, 12604, 17688, 13036, 11047, 10260, 11042, 45, 14486, 12389, 14782, 12138, 45, 13091, 12337, 11632, 10684, 15304, 11003, 17137, 14734, 10974, 11416, 10080, 12824, 11002, 17148, 15033, 10768, 13584, 12202, 10260, 13091, 10409, 10454, 10250, 13036, 14734, 17631, 28329, 10261, 13055, 10993, 14894, 16449, 45, 13179, 11632, 13091, 10397, 16417, 12469, 17149, 10673, 10333, 10250, 10283, 13034, 14734, 10370, 14583, 17775, 13619, 10080, 17148, 13091, 12604, 17688, 12368, 15486, 14734, 14658, 14673, 10080, 14791, 12266, 10250, 10349, 45, 10423, 10739, 17093, 10429, 14673, 28329, 17149, 13582, 12604, 17688, 14734, 11042, 13064, 45, 10322, 16503, 10525, 13191, 10250, 11899, 16778, 17178, 10079, 11042, 14486, 12366, 10261, 13055, 10993, 10080, 10260, 16503, 11416, 12604, 10841, 15646, 17093, 16523, 17141, 10985, 14734, 10684, 15304, 28329, 12604, 17688, 16981, 10257, 45, 12605, 10402, 17879, 16503, 11454, 13034, 14734, 17775, 13619, 12664, 10792, 13034, 14734, 10422, 10437, 10250, 16981, 11042, 16403, 10080, 17148, 13091, 23353, 5447, 69, 12261, 15123, 13034, 14734, 12978, 12746, 15573, 15497, 28329, 10250, 10349, 10577, 12348, 14460, 12493, 14734, 15640, 13192, 10993, 15957, 15752, 14486, 16533, 12824, 15462, 12605, 10402, 14734, 12604, 17688, 45, 10495, 14221, 11021, 10399, 14614, 11454, 14583, 11117, 10285, 10080, 10444, 10260, 12368, 10864, 12299, 28329, 12421, 10305, 45, 11003, 17137, 13091, 14583, 11117, 14734, 12182, 12396, 10080, 11871, 10423, 13559, 14221, 12824, 11002, 17148, 10250, 14172, 45, 14486, 16533, 11003, 17137, 15727, 11044, 14734, 10974, 11416, 45, 10525, 12746, 16778, 17178, 11255, 12522, 45, 12605, 14782, 10529, 12469, 10423, 11003, 12348, 13179, 10842, 11474, 12299, 10261, 14829, 13133, 10080, 14986, 12469, 12604, 17688, 14734, 16981, 10257, 10260, 10309, 14862, 12144, 14782, 10437, 10080, 65535, 261, 65530, 65532, 12605, 11454, 12509, 10250, 10283, 17728, 18025, 19137, 33, 12307, 12605, 16056, 12348, 12604, 15508, 13064, 19137, 12266, 12366, 14734, 10261, 13192, 10993, 10768, 10361, 14734, 13064, 10560, 19137, 11454, 17148, 10283, 12484, 10724, 10258, 11957, 12605, 12266, 11726, 14637, 17150, 14734, 13192, 10993, 19137, 33, 14794, 14734, 15752, 10460, 10292, 13192, 10993, 11053, 19156, 11, 65535, 261, 65530, 65534, 12469, 12848, 10760, 10333, 10250, 10283, 17916, 12182, 12990, 17625, 14734, 17728, 18025, 10080, 12307, 10250, 10283, 10370, 11454, 17385, 16503, 13064, 10799, 17177, 12731, 11414, 17248, 12609, 14637, 17150, 45, 15646, 17916, 12527, 11042, 17038, 11002, 45, 17148, 14914, 11903, 10423, 16672, 10370, 16884, 14638, 17148, 15033, 10993, 16754, 14734, 12522, 10304, 28329, 12605, 14734, 10250, 10349, 12509, 13764, 59, 11, 11454, 13192, 10993, 16056, 15735, 12609, 12604, 10841, 13064, 14637, 17150, 10390, 10370, 45, 17148, 15033, 16403, 10292, 10995, 13086, 14734, 13091, 10696, 12366, 14734, 13637, 17097, 11124, 15129, 10335, 12522, 16696, 45, 10261, 14794, 16711, 14734, 10993, 16754, 13191, 10250, 11899, 12143, 16973, 28329, 14794, 13580, 14734, 13192, 10993, 12220, 16721, 15752, 11454, 10790, 10370, 12604, 10841, 13064, 16417, 14446, 10760, 14794, 12366, 14734, 18216, 10685, 11124, 18458, 10851, 45, 15646, 10260, 13091, 11753, 15723, 12527, 28329, 10322, 16684, 12605, 10402, 17879, 16503, 10995, 12410, 45, 13091, 10260, 13091, 17141, 10339, 11454, 10993, 16754, 10285, 11959, 13685, 16256, 16020, 12366, 14734, 14015, 16956, 45, 15646, 12392, 14619, 10333, 12978, 12746, 11124, 17802, 10437, 14734, 13205, 16884, 28329, 11042, 13064, 16503, 14486, 16533, 45, 13191, 10349, 13192, 10993, 11021, 15752, 11454, 15847, 12605, 16667, 14862, 10257, 11861, 11454, 17728, 18025, 45, 17843, 10399, 17919, 11957, 10390, 10370, 14734, 17149, 13582, 10080, 17148, 17879, 16503, 13064, 17734, 10985, 16749, 17172, 28329, 11687, 13258, 17148, 15033, 14637, 17150, 12746, 15511, 10997, 14583, 45, 12609, 16684, 17879, 17385, 13034, 16694, 10435, 17148, 15033, 10684, 15304, 14734, 12522, 10304, 10080, 10993, 16754, 13188, 11902, 16896, 10305, 11621, 11454, 10339, 10696, 12366, 14734, 12999, 12266, 11124, 10342, 10847, 28329, 12421, 10305, 45, 10590, 12237, 14734, 10993, 16754, 10260, 12220, 12261, 15123, 11454, 13637, 17097, 10285, 45, 14794, 16711, 11268, 12468, 10390, 10370, 12604, 17688, 12638, 15752, 16672, 10993, 16754, 17688, 11861, 10080, 17148, 17879, 16503, 10994, 13036, 10682, 11042, 10848, 10838, 10080, 12159, 13197, 17148, 10349, 12261, 16676, 11957, 12469, 13191, 12176, 10847, 45, 10322, 13558, 17143, 12469, 17149, 10250, 13582, 10768, 10361, 12509, 13764, 10080, 65535, 261, 65530, 65532, 17148, 13091, 12337, 14486, 12509, 14734, 19137, 10444, 13091, 14446, 11903, 15646, 10990, 15712, 15761, 14734, 10267, 14610, 17384, 19137, 33, 13192, 10993, 10684, 15304, 10285, 12421, 13091, 12837, 13215, 14808, 15129, 10335, 11124, 17097, 10852, 11, 65535, 261, 65530, 65534, 12469, 12848, 10792, 14734, 14446, 11903, 10267, 14610, 10285, 10993, 16754, 10684, 15304, 17843, 10662, 12837, 13215, 15129, 10335, 11124, 17097, 10852, 14734, 17728, 18025, 45, 12605, 17916, 12182, 16667, 11042, 10080, 14734, 14914, 45, 11454, 10250, 10283, 13773, 17385, 14970, 10423, 13637, 17097, 11124, 10283, 10370, 12604, 10841, 14734, 14970, 10423, 17384, 45, 17148, 15033, 14446, 16803, 10917, 10768, 13125, 17216, 28329, 10444, 13091, 45, 12605, 17147, 13091, 12509, 11994, 13581, 10768, 10361, 10250, 10349, 18030, 11630, 12509, 13764, 59, 11, 50, 47, 33, 15129, 10335, 11124, 17097, 10852, 10305, 12366, 13051, 11021, 17248, 10662, 45, 10444, 12605, 10402, 11021, 10399, 17177, 12731, 10293, 10846, 17788, 10448, 17148, 15033, 12484, 15509, 45, 12261, 15123, 13179, 10590, 12237, 12200, 11124, 14734, 10684, 15304, 28329, 51, 47, 33, 14794, 13580, 14734, 10993, 16754, 45, 12220, 16721, 12261, 15123, 11454, 10342, 14782, 11971, 17385, 10079, 12978, 12746, 11124, 12527, 14091, 14734, 11533, 14902, 10257, 45, 15646, 10260, 13091, 13637, 18216, 10448, 28329, 52, 47, 33, 11967, 13773, 12522, 10838, 12983, 11454, 15847, 12144, 10696, 12366, 12604, 17688, 11124, 15494, 10334, 12978, 12746, 10257, 45, 15646, 10260, 13091, 10261, 10370, 13637, 17097, 45, 11021, 10399, 10739, 17093, 17148, 15033, 13051, 16763, 14734, 17097, 10852, 28329, 53, 47, 33, 12605, 10402, 17311, 11002, 14970, 10423, 14445, 11574, 11124, 13012, 10901, 10408, 10577, 16520, 12325, 11168, 45, 10444, 10383, 11021, 10399, 10848, 10838, 10293, 10846, 12261, 15123, 13179, 13580, 17919, 12266, 13078, 14734, 10684, 15304, 28329, 54, 47, 33, 10684, 13773, 10696, 12366, 14370, 15123, 11124, 11889, 11884, 45, 15646, 10260, 13091, 11630, 11454, 12604, 10841, 45, 11021, 10399, 17248, 10662, 16684, 11632, 17097, 10852, 12366, 14486, 28329, 14914, 11903, 45, 16503, 10588, 10792, 17148, 10250, 14172, 12202, 10260, 11922, 13080, 10080, 10444, 12605, 14782, 10529, 10250, 10283, 12522, 16696, 10792, 17728, 18025, 10079, 12202, 10848, 10838, 16939, 11047, 13580, 17919, 11003, 10901, 14734, 10370, 45, 15480, 11967, 15752, 15486, 10964, 10684, 15304, 14734, 12604, 17688, 10261, 10920, 10925, 10080, 17148, 17879, 16503, 11474, 12746, 10261, 10863, 13655, 45, 10322, 17879, 16503, 12664, 10792, 10261, 12605, 10402, 12377, 11042, 17222, 11038, 14734, 14862, 12144, 10080, 12537, 12469, 15752, 11454, 12822, 15325, 14734, 16981, 10257, 16056, 12348, 12978, 12746, 10080, 65535, 261, 65530, 65534, 10464, 16735, 14734, 12337, 13191, 17222, 14486, 10080, 15129, 10335, 11124, 17097, 10852, 13091, 10370, 17781, 10684, 15304, 10285, 14734, 10250, 10283, 17843, 18025, 10080, 13191, 10745, 14172, 16416, 10655, 59, 11, 50, 42, 33, 15129, 10335, 12366, 14486, 12337, 13580, 12182, 45, 10444, 16503, 10848, 10838, 15516, 12746, 12200, 16412, 10080, 17172, 12231, 14734, 15129, 10335, 15752, 14091, 10997, 17149, 11001, 12366, 45, 17141, 11632, 10779, 10423, 14894, 11470, 10993, 16754, 28329, 51, 42, 33, 14794, 13580, 14734, 13192, 10993, 12220, 16721, 13091, 10342, 14782, 12978, 12746, 11124, 12330, 13581, 12604, 17688, 10080, 15646, 17916, 14331, 12657, 10260, 13923, 16747, 18216, 16747, 10448, 28329, 52, 42, 33, 11967, 13773, 12522, 10838, 12983, 11454, 15847, 12144, 12604, 17688, 10257, 45, 10739, 11977, 10261, 10370, 13637, 17097, 10080, 13179, 11923, 11922, 12266, 13078, 11459, 14791, 12335, 10790, 10370, 28329, 53, 42, 33, 14970, 10423, 13012, 10901, 13660, 11430, 10322, 10423, 12325, 11168, 12605, 10402, 10080, 10444, 13633, 10283, 10370, 17311, 15752, 10293, 10846, 10848, 10838, 12981, 11003, 28329, 54, 42, 33, 10684, 13773, 10696, 11454, 12200, 17912, 45, 15646, 17916, 11630, 11454, 12604, 10841, 10080, 11021, 10399, 17788, 10448, 17097, 10852, 14734, 12366, 14486, 28329, 12421, 14734, 13234, 16735, 45, 16503, 12981, 11003, 12421, 10260, 13091, 10250, 17028, 15646, 11994, 10080, 17879, 16503, 10260, 13032, 10848, 10838, 11124, 10538, 13580, 15847, 12144, 10080, 10444, 11016, 16503, 13191, 16519, 16696, 11124, 10863, 13655, 45, 12605, 10402, 14734, 10370, 17781, 10684, 15304, 15480, 11967, 12604, 17688, 11124, 10920, 10925, 28329, 17385, 14172, 11454, 10339, 11474, 12746, 10080, 12664, 10792, 12377, 11042, 17222, 11038, 14734, 13192, 10993, 45, 16056, 12348, 12978, 12746, 11124, 14091, 10851, 10080, 10250, 14172, 10250, 14025, 11459, 13198, 14808, 13179, 11124, 14821, 17149, 13582, 14734, 13036, 11047, 17142, 17149, 11994, 11685, 28329, 12605, 14782, 10529, 10464, 10322, 15752, 10588, 10792, 10080, 10842, 13750, 34, 65535, 261, 65530, 65534, 11889, 13849, 12705, 11, 10684, 10339, 10370, 17781, 10684, 15304, 10285, 14734, 15129, 10335, 11124, 17097, 10852, 12366, 14486, 45, 10399, 10992, 11687, 10454, 17788, 10448, 17097, 10852, 12366, 14486, 14734, 12325, 11168, 45, 10399, 10992, 12261, 15123, 13179, 10590, 12237, 12200, 16412, 14734, 10684, 15304, 10080, 10293, 16503, 16520, 14172, 13091, 19137, 11454, 10250, 10283, 10993, 16754, 10684, 15304, 10285, 19137, 15129, 10335, 11124, 17097, 10852, 12366, 14486, 13091, 12182, 16519, 14734, 17728, 18025, 19137, 10444, 12605, 10402, 11021, 10399, 17189, 17141, 10293, 10846, 17788, 10448, 17097, 10852, 12366, 14486, 10079, 12261, 15123, 13179, 10590, 12237, 12200, 15169, 14734, 10684, 15304, 13234, 12981, 11255, 17148, 15033, 14446, 16803, 10080, 11042, 13064, 19137, 12605, 10402, 10322, 12220, 16721, 13773, 12522, 10792, 15847, 12144, 10696, 12366, 12604, 17688, 10261, 10261, 10390, 10370, 14782, 10342, 12325, 11168, 14734, 17728, 18025, 19137, 12202, 11959, 13685, 12978, 12746, 11124, 12176, 10847, 13234, 10660, 13193, 17148, 10349, 17728, 18025, 10080, 13188, 11044, 45, 12605, 10402, 12220, 16721, 10525, 12746, 12266, 13078, 11124, 11971, 17385, 10390, 10370, 14734, 12396, 12231, 45, 10399, 12261, 15123, 13179, 10590, 12237, 10079, 13179, 13191, 14757, 14734, 10684, 15304, 28329, 50, 47, 33, 10684, 10339, 13192, 10993, 10684, 15304, 10285, 14734, 15129, 10335, 11124, 17097, 10852, 12366, 14486, 59, 11, 51, 47, 33, 15129, 10335, 13091, 10370, 17781, 10684, 15304, 10285, 12182, 16519, 14734, 17728, 18025, 10080, 12307, 10278, 10283, 10370, 10342, 14782, 15129, 10335, 13064, 19137, 11021, 15752, 10423, 11960, 15850, 10260, 12368, 16503, 14734, 15326, 12287, 13655, 13660, 11124, 10260, 15895, 12325, 11168, 10080, 11416, 13581, 19137, 12605, 10402, 12220, 16721, 17248, 10662, 17148, 15033, 12484, 10724, 10997, 14583, 19137, 12202, 11959, 12664, 10682, 11042, 14172, 13234, 12261, 15123, 13179, 10590, 12237, 10079, 12200, 15169, 11124, 13191, 14757, 14734, 10684, 15304, 28329, 52, 47, 33, 17097, 10852, 12366, 14486, 11021, 10399, 13091, 10250, 15033, 12182, 16519, 17728, 18025, 10080, 12307, 10278, 10283, 10370, 11454, 10250, 16944, 13064, 19137, 11922, 13080, 10358, 14583, 10768, 13584, 10079, 10335, 11073, 12609, 15643, 10260, 12519, 12387, 14734, 15486, 10964, 10080, 10292, 10333, 17248, 10662, 17148, 15033, 12484, 10724, 10997, 14583, 19137, 12605, 10402, 17879, 16503, 10525, 12746, 10726, 17912, 10079, 14486, 13133, 11124, 11971, 17385, 11957, 13036, 14734, 12522, 16519, 10080, 11042, 13064, 19137, 10322, 16503, 11871, 10423, 12825, 10794, 15847, 12144, 14734, 12484, 15509, 11124, 16403, 10292, 19137, 10399, 10662, 12282, 16944, 13179, 11632, 18425, 14189, 28329, 53, 47, 33, 12421, 10305, 45, 33, 11454, 10250, 10283, 10993, 16754, 10684, 15304, 10285, 45, 33, 15129, 10335, 11124, 17097, 10852, 12366, 14486, 13091, 17843, 10662, 14734, 10080, 10444, 13091, 19137, 17189, 17141, 10293, 10846, 11959, 13685, 16533, 10722, 13036, 13336, 10079, 12261, 15123, 10342, 14782, 11971, 17385, 11124, 12978, 12746, 14734, 10684, 15304, 10079, 10399, 10992, 10525, 12746, 12200, 15169, 10342, 10788, 15169, 16403, 10292, 13234, 10739, 11977, 17097, 10852, 12366, 14486, 14734, 12325, 11168, 10080, 11016, 13191, 17148, 13324, 19137, 12605, 10402, 12638, 15752, 12261, 15123, 10250, 10283, 10590, 12237, 10079, 11124, 16760, 11124, 13191, 14757, 14734, 10684, 15304, 10080, 65535, 261, 65530, 65534, 5732, 8875, 460, 63758, 4712, 22590, 38809, 4706, 63361, 21265, 52763, 4596, 65004, 4600, 32227, 4601, 21413, 4435, 332, 47342, 4706, 47425, 21265, 50928, 47, 3878, 57344, 32227, 4858, 47266, 38530, 4712, 22248, 22251, 56950, 47001, 32226, 59328, 60112, 4811, 46726, 45, 21265, 32227, 32313, 51803, 47266, 4435, 62617, 21265, 65034, 47, 3878, 30135, 57344, 55654, 30678, 22590, 31135, 4706, 22762, 4600, 45301, 4715, 31458, 59829, 45, 4423, 4601, 21413, 31262, 4811, 60701, 63361, 47, 50232, 45, 4569, 45112, 116, 63695, 332, 50997, 51035, 59331, 21265, 37832, 62617, 45, 21265, 51746, 32448, 4811, 51982, 52359, 40187, 62616, 46726, 47, 50511, 45, 44126, 55618, 32227, 63695, 332, 51913, 64549, 32487, 46726, 57102, 332, 50997, 51035, 63361, 21265, 64849, 47, 11, 65535, 261, 65530, 65532, 16738, 10464, 12421, 15489, 12605, 10402, 10780, 12638, 14734, 11957, 16713, 10696, 11922, 11, 65535, 261, 65530, 65534, 11454, 17148, 13619, 11957, 16713, 10285, 45, 33, 10250, 10447, 13192, 10993, 12848, 10792, 10333, 10390, 14734, 10250, 10283, 10684, 15304, 10285, 11861, 11454, 15129, 10335, 11124, 17097, 10852, 12366, 14486, 45, 33, 12202, 10265, 10390, 12159, 13197, 15752, 11634, 12604, 17688, 10261, 15516, 12746, 12200, 16412, 10080, 14221, 15646, 45, 33, 10390, 10322, 16417, 17136, 10333, 11957, 10339, 17097, 10852, 12366, 14486, 14734, 10260, 14015, 12522, 45, 33, 12202, 10265, 16667, 10292, 17148, 15033, 16403, 10292, 13091, 10370, 17781, 10684, 15304, 10285, 12182, 16519, 14734, 17728, 18025, 10080, 13188, 11044, 45, 33, 10390, 12261, 16676, 16503, 10525, 12746, 12200, 16412, 11124, 10342, 14782, 14486, 16533, 45, 10399, 10992, 17385, 16523, 10696, 12366, 12604, 17688, 11124, 12978, 12746, 28329, 65535, 261, 65530, 65534, 11454, 17148, 13619, 11957, 16713, 10285, 45, 33, 10250, 10447, 13192, 10993, 12848, 10792, 10333, 10390, 14734, 10250, 10447, 10684, 15304, 10285, 11861, 11454, 15129, 10335, 11124, 17097, 10852, 12366, 14486, 45, 33, 12202, 10265, 16667, 10292, 17148, 13091, 10250, 15033, 17728, 18025, 14734, 13981, 11647, 10080, 14221, 15646, 19137, 10390, 10322, 12848, 10792, 10333, 10250, 10349, 12261, 16676, 13234, 12176, 10847, 12981, 11255, 17148, 10283, 17728, 18025, 45, 33, 10894, 12732, 16503, 10525, 12746, 12200, 16412, 11124, 10342, 14782, 14486, 16533, 10079, 10399, 10992, 17385, 16523, 10696, 12366, 12604, 17688, 10261, 12978, 12746, 10080, 13188, 11044, 45, 33, 10390, 12261, 16676, 13179, 10842, 13773, 17385, 10696, 12366, 12604, 17688, 10261, 12978, 12746, 45, 33, 10399, 10992, 12200, 16412, 11124, 10342, 14782, 14486, 16533, 28329, 65535, 261]
-> item_loss 0.9049959182739258 batch_loss 1.1260739599957186
==== [22251, 56950, 47001, 32226, 59328, 60112, 4811, 46726, 45, 21265, 32227, 32313, 51803, 47266, 4435, 62617, 21265, 65034, 47, 3878, 30135, 57344, 55654, 30678, 22590, 31135, 4706, 22762, 4600, 45301, 4715, 31458, 59829, 45, 4423, 4601, 21413, 31262, 4811, 60701, 63361, 47, 50232, 45, 4569, 45112, 116, 63695, 332, 50997, 51035, 59331, 21265, 37832, 62617, 45, 21265, 51746, 32448, 4811, 51982, 52359, 40187, 62616, 46726, 47, 50511, 45, 44126, 55618, 32227, 63695, 332, 51913, 64549, 32487, 46726, 57102, 332, 50997, 51035, 63361, 21265, 64849, 47, 11, 65535, 261, 65530, 65532, 16738, 10464, 12421, 15489, 12605, 10402, 10780, 12638, 14734, 11957, 16713, 10696, 11922, 11, 65535, 261, 65530, 65534, 11454, 17148, 13619, 11957, 16713, 10285, 45, 33, 10250, 10447, 13192, 10993, 12848, 10792, 10333, 10390, 14734, 10250, 10283, 10684, 15304, 10285, 11861, 11454, 15129, 10335, 11124, 17097, 10852, 12366, 14486, 45, 33, 12202, 10265, 10390, 12159, 13197, 15752, 11634, 12604, 17688, 10261, 15516, 12746, 12200, 16412, 10080, 14221, 15646, 45, 33, 10390, 10322, 16417, 17136, 10333, 11957, 10339, 17097, 10852, 12366, 14486, 14734, 10260, 14015, 12522, 45, 33, 12202, 10265, 16667, 10292, 17148, 15033, 16403, 10292, 13091, 10370, 17781, 10684, 15304, 10285, 12182, 16519, 14734, 17728, 18025, 10080, 13188, 11044, 45, 33, 10390, 12261, 16676, 16503, 10525, 12746, 12200, 16412, 11124, 10342, 14782, 14486, 16533, 45, 10399, 10992, 17385, 16523, 10696, 12366, 12604, 17688, 11124, 12978, 12746, 28329, 65535, 261, 65530, 65534, 11454, 17148, 13619, 11957, 16713, 10285, 45, 33, 10250, 10447, 13192, 10993, 12848, 10792, 10333, 10390, 14734, 10250, 10447, 10684, 15304, 10285, 11861, 11454, 15129, 10335, 11124, 17097, 10852, 12366, 14486, 45, 33, 12202, 10265, 16667, 10292, 17148, 13091, 10250, 15033, 17728, 18025, 14734, 13981, 11647, 10080, 14221, 15646, 19137, 10390, 10322, 12848, 10792, 10333, 10250, 10349, 12261, 16676, 13234, 12176, 10847, 12981, 11255, 17148, 10283, 17728, 18025, 45, 33, 10894, 12732, 16503, 10525, 12746, 12200, 16412, 11124, 10342, 14782, 14486, 16533, 10079, 10399, 10992, 17385, 16523, 10696, 12366, 12604, 17688, 10261, 12978, 12746, 10080, 13188, 11044, 45, 33, 10390, 12261, 16676, 13179, 10842, 13773, 17385, 10696, 12366, 12604, 17688, 10261, 12978, 12746, 45, 33, 10399, 10992, 12200, 16412, 11124, 10342, 14782, 14486, 16533, 28329, 65535, 261]
-> item_loss 1.19801664352417 batch_loss 1.1281294652393885
==== [65530, 65532, 10777, 10296, 10250, 10283, 12182, 14589, 14734, 7262, 7999, 102, 10762, 13004, 11, 65535, 261, 65530, 65534, 17148, 17384, 13191, 10250, 10349, 12182, 14589, 14734, 19644, 7999, 102, 33, 10762, 13004, 59, 11, 46, 30491, 280, 33, 11047, 17848, 11038, 13920, 10842, 10653, 15323, 11, 46, 21515, 280, 267, 11899, 10304, 10250, 10283, 15158, 11028, 11, 46, 30674, 114, 280, 33, 17216, 10964, 12217, 10777, 11, 46, 45985, 280, 17141, 14017, 12217, 10777, 11, 46, 38499, 280, 33, 16056, 11001, 12217, 10777, 14734, 15162, 10250, 10283, 10653, 15323, 11, 46, 4612, 2318, 280, 33, 10781, 12261, 10250, 10283, 10762, 13004, 45, 11885, 15752, 10250, 13557, 16749, 14589, 11632, 10283, 10762, 13004, 33, 12202, 11967, 10687, 15489, 13258, 15476, 11038, 10792, 10250, 10283, 12217, 10777, 10285, 11, 46, 22069, 280, 33, 11957, 12217, 10777, 10285, 14734, 13633, 10283, 10653, 15323, 12220, 14589, 10762, 13004, 45, 17146, 11414, 13086, 11965, 11044, 14734, 12217, 10777, 11, 46, 22193, 280, 33, 16056, 11001, 12217, 10777, 10285, 14734, 13279, 10283, 15325, 12282, 10447, 15586, 14734, 10653, 15323, 11, 46, 47074, 280, 33, 10781, 12261, 10250, 10283, 11533, 10339, 15494, 11899, 10577, 14734, 12217, 10777, 11, 46, 31871, 280, 33, 16056, 11001, 12217, 10777, 10285, 14734, 12631, 13191, 17798, 15162, 10250, 10283, 10653, 15323, 11630, 14734, 10653, 15323, 11, 46, 22456, 280, 33, 11967, 10260, 11021, 17216, 10964, 14734, 11957, 16803, 17083, 12791, 10292, 17216, 10964, 12217, 10777, 11, 46, 32074, 280, 33, 13381, 13290, 12217, 10777, 13091, 11060, 14015, 16956, 15494, 11899, 10762, 13004, 14734, 13231, 10407, 11, 46, 32082, 280, 33, 12814, 12217, 10250, 10283, 12217, 10777, 11, 17148, 17384, 10377, 10296, 10333, 10250, 10349, 12182, 14589, 14734, 10487, 11855, 45, 19644, 7999, 102, 33, 17147, 13191, 12337, 11632, 10687, 11885, 13191, 14589, 14734, 10696, 15586, 10762, 13004, 45, 33, 11021, 10399, 11454, 17148, 17384, 13290, 17749, 11891, 13006, 10777, 16417, 59, 34579, 5385, 7262, 7999, 7415, 1802, 47, 8401, 48, 35467, 8581, 65535, 261, 10777, 10296, 7262, 7999, 102, 10285, 25059, 14734, 10762, 13004, 16735, 13078, 11, 65530, 65534, 25059, 33, 10762, 13004, 13091, 19644, 7999, 102, 33, 10285, 13188, 17385, 16503, 14734, 17848, 11038, 12945, 10460, 10762, 13004, 10305, 10250, 10080, 11885, 14734, 10841, 15752, 13091, 11047, 17848, 11038, 13920, 10842, 13034, 10653, 15323, 28329, 10293, 16503, 13191, 10278, 15033, 14589, 13764, 59, 11, 50, 47, 33, 13920, 10842, 10932, 10283, 10653, 15323, 11, 25059, 33, 14589, 13764, 59, 11, 41, 25059, 30478, 30737, 42, 11, 10487, 11687, 59, 11, 41, 25059, 274, 41, 50, 285, 286, 42, 287, 42, 3580, 275, 50, 285, 286, 287, 42, 11, 41, 25059, 326, 50, 285, 286, 94, 287, 42, 3580, 326, 50, 285, 286, 287, 94, 261, 51, 47, 33, 11038, 12202, 10278, 10283, 17848, 11038, 11, 41, 25059, 30478, 30478, 51, 42, 11, 10487, 11687, 59, 11, 41, 25059, 274, 41, 50, 285, 286, 42, 274, 41, 53, 288, 494, 3580, 275, 50, 285, 286, 287, 288, 42, 11, 41, 25059, 326, 50, 285, 286, 94, 326, 53, 288, 1682, 267, 746, 326, 50, 285, 286, 287, 288, 94, 11, 12421, 14734, 13234, 16735, 45, 25059, 33, 10762, 13004, 11021, 10399, 12824, 12979, 11632, 10283, 10988, 13004, 59, 10250, 10283, 17848, 11038, 41, 25043, 42, 11124, 10250, 10283, 12609, 11632, 10283, 10653, 15323, 41, 25210, 497, 14221, 11044, 11967, 10653, 15323, 13920, 10842, 10792, 17848, 11038, 10285, 28329, 12631, 10399, 11885, 13091, 19644, 7999, 102, 33, 10285, 13188, 15190, 10932, 10322, 13188, 13191, 14589, 14734, 12981, 11003, 17848, 11038, 14349, 12396, 14734, 10762, 13004, 10080, 65535, 261, 10777, 10296, 7262, 7999, 102, 10285, 14734, 7621, 10762, 13004, 14734, 10762, 13004, 16735, 13078, 11, 65530, 65534, 25059, 280, 33, 13920, 10842, 10653, 15323, 10792, 17848, 11038, 10285, 11, 41, 25059, 30478, 30737, 42, 11, 25059, 33, 10762, 13004, 11021, 10399, 11967, 10250, 10283, 12609, 11632, 10283, 10653, 15323, 13920, 10842, 10792, 17848, 11038, 10285, 28329, 7621, 280, 33, 10384, 13086, 11965, 10285, 16056, 11001, 10577, 11, 41, 7621, 22069, 21952, 326, 8260, 46, 34477, 1682, 11, 7621, 33, 10762, 13004, 11021, 10399, 10384, 10250, 10283, 13086, 11965, 41, 8149, 42, 10285, 16056, 11001, 17644, 41, 8020, 42, 11957, 12220, 14734, 10577, 28329, 11687, 13258, 17644, 10260, 11861, 11454, 45, 10779, 17146, 11414, 22187, 46, 34477, 33, 10577, 41, 11021, 17177, 42, 28329, 30491, 33, 11124, 21751, 33, 14734, 10762, 13004, 16735, 13078, 10768, 10790, 13091, 59, 11, 25059, 59, 11, 46, 33, 11047, 17848, 11038, 13920, 10842, 10250, 10283, 12609, 11632, 10283, 10653, 15323, 11, 46, 275, 25059, 30478, 30737, 42, 33, 10423, 11967, 30737, 33, 13920, 10842, 10792, 30478, 33, 17848, 11038, 10285, 11, 46, 33, 11021, 10399, 14589, 10339, 11047, 17387, 10079, 10777, 16417, 10079, 17848, 11038, 15169, 17848, 11038, 15261, 11496, 11, 7621, 59, 11, 46, 33, 10384, 13086, 11965, 10285, 16056, 11001, 12748, 11899, 21952, 33, 11957, 12220, 14734, 10577, 11, 46, 275, 7621, 22069, 21952, 42, 33, 10423, 10384, 22069, 33, 13086, 11965, 10285, 16056, 11001, 21952, 33, 11957, 12220, 14734, 10577, 11, 46, 33, 11687, 13258, 21952, 33, 10260, 11861, 11454, 45, 10779, 17146, 11414, 22175, 11, 46, 33, 11021, 10399, 12848, 10494, 10250, 10283, 22187, 46, 34477, 33, 10988, 13004, 10460, 10292, 11622, 14589, 10577, 11, 46, 275, 7621, 22069, 21952, 22187, 46, 34477, 42, 11, 10487, 11687, 59, 11, 41, 7621, 4899, 98, 284, 293, 99, 285, 126, 293, 98, 42, 3580, 284, 11, 41, 7621, 4899, 98, 284, 293, 99, 285, 126, 293, 100, 269, 8260, 38547, 5164, 3580, 269, 8260, 38547, 363, 11, 25059, 33, 13091, 10538, 12981, 17848, 11038, 45, 7621, 33, 13091, 10384, 13086, 11965, 10285, 16742, 11001, 13004, 12797, 45, 10278, 15643, 10841, 15752, 10260, 11042, 10080, 65535, 261, 10296, 10487, 16735, 13078, 7262, 7999, 102, 14734, 16728, 13764, 14332, 14172, 11, 65530, 65534, 7262, 7999, 102, 14734, 10293, 16503, 16728, 13764, 14332, 14172, 11687, 10258, 59, 11, 50, 47, 20299, 113, 13324, 12276, 14734, 84, 12276, 16728, 13764, 10080, 7262, 7999, 102, 17379, 14589, 10333, 1219, 2191, 14734, 10427, 15500, 84, 12276, 16728, 13764, 45, 10482, 14589, 12732, 11028, 16417, 14966, 15052, 12217, 15489, 13250, 28329, 51, 47, 33, 12978, 12746, 10762, 13004, 12276, 15543, 15052, 10080, 7262, 7999, 102, 17379, 14589, 10762, 13004, 12276, 15543, 15052, 10460, 10292, 10293, 16503, 15543, 15052, 15973, 12276, 45, 12978, 12746, 18216, 17775, 10762, 13004, 10079, 11117, 11043, 22001, 12314, 12276, 10079, 12507, 12415, 13685, 10577, 15169, 14332, 12333, 28329, 52, 47, 33, 12978, 12746, 17919, 11047, 11957, 16803, 15543, 15052, 10080, 7262, 7999, 102, 12848, 10494, 10333, 11533, 10339, 16678, 12308, 14734, 17919, 11047, 11957, 16803, 45, 12978, 12746, 15261, 10079, 15507, 12665, 10079, 10926, 16676, 10079, 11632, 12396, 15169, 14332, 12415, 28329, 53, 47, 33, 12978, 12746, 12202, 10997, 15543, 15052, 10080, 7262, 7999, 102, 12848, 10494, 10333, 11533, 10339, 17086, 10407, 10336, 10843, 10696, 11861, 13499, 11496, 14734, 12202, 10997, 12978, 12746, 45, 11021, 10399, 13036, 10511, 18216, 12986, 11459, 15543, 10708, 12202, 10997, 15052, 12217, 28329, 54, 47, 33, 10846, 12396, 16728, 16537, 10080, 7262, 7999, 102, 13091, 10250, 15033, 10846, 12396, 16728, 16537, 45, 10652, 16684, 11454, 17144, 16403, 13064, 12981, 11003, 16728, 16537, 15489, 13250, 45, 11687, 17385, 13034, 11899, 10304, 10762, 13004, 10079, 11003, 17387, 15169, 28329, 55, 47, 33, 12978, 12746, 10653, 15543, 15052, 10080, 7262, 7999, 102, 12848, 10494, 10333, 12299, 11638, 14734, 13212, 10794, 13234, 12981, 10708, 16728, 13764, 45, 11687, 35036, 116, 10079, 10995, 11965, 15169, 28329, 56, 47, 33, 12978, 12746, 10985, 17187, 11028, 10080, 7262, 7999, 102, 10985, 12810, 10333, 1219, 2191, 10427, 15500, 14734, 10768, 17821, 15158, 17187, 11028, 45, 15646, 17379, 14589, 11533, 10339, 17734, 16973, 14734, 13327, 12276, 10901, 28329, 57, 47, 33, 10762, 13004, 10460, 14589, 11524, 10292, 10846, 12396, 14734, 10080, 7262, 7999, 102, 14734, 10762, 13004, 10460, 14589, 11524, 17379, 14589, 10261, 1219, 2191, 10250, 15850, 14734, 10846, 12396, 10460, 14589, 11524, 13036, 12276, 28329, 58, 47, 33, 12978, 12746, 10696, 15586, 13004, 12797, 15489, 13250, 10080, 7262, 7999, 102, 12848, 10494, 10333, 10286, 11932, 14734, 10696, 15586, 13004, 12797, 15489, 13250, 45, 11687, 10777, 16417, 10079, 11047, 17387, 10079, 17848, 11038, 10079, 11164, 12159, 16417, 15169, 28329, 630, 47, 33, 12978, 12746, 10727, 15489, 13004, 12797, 15489, 13250, 10080, 7262, 7999, 102, 12978, 12746, 11967, 11021, 11003, 13004, 12797, 15489, 13250, 10727, 15489, 12604, 10260, 11021, 11003, 14734, 13004, 12797, 45, 12848, 18216, 15052, 12217, 11889, 10675, 12415, 28329, 10399, 10257, 10293, 16503, 12022, 14966, 10333, 7262, 7999, 102, 14734, 10250, 10349, 13308, 12377, 12415, 16728, 13764, 14332, 14172, 10080, 12159, 13197, 15752, 10292, 12469, 12848, 10494, 10988, 15641, 34, 65535, 261, 65530, 65532, 15494, 10250, 10283, 10688, 10452, 14734, 10397, 14875, 10487, 11855, 11, 65535, 261, 65530, 65534, 17148, 17384, 13091, 10250, 10283, 15190, 10932, 14734, 19644, 7999, 102, 33, 10397, 14875, 14966, 10487, 59, 11, 6884, 7262, 7999, 102, 11, 41, 7334, 31496, 269, 23813, 381, 11, 41, 7334, 111, 38632, 3331, 482, 94, 275, 25526, 117, 31496, 494, 3331, 482, 26290, 94, 19242, 41, 49580, 275, 8756, 269, 33155, 269, 31496, 269, 5164, 5292, 11, 41, 7334, 111, 22532, 326, 39, 52333, 94, 3331, 41, 42150, 278, 52333, 494, 11, 41, 25526, 117, 269, 33414, 381, 11, 60, 36786, 37308, 34, 11, 41, 25526, 117, 42, 11, 60, 36786, 29165, 34, 11, 41, 8762, 284, 285, 286, 287, 42, 11, 60, 3483, 11, 6884, 11, 10293, 16503, 12022, 14966, 10333, 59, 11, 46, 33, 11899, 10304, 15158, 11028, 4398, 7334, 31496, 269, 23813, 381, 97, 11, 46, 33, 11899, 10304, 10762, 13004, 4398, 7334, 111, 38632, 36218, 276, 97, 11, 46, 33, 11632, 10283, 10988, 13004, 10777, 16417, 4398, 7334, 111, 38632, 3435, 94, 275, 25526, 117, 31496, 494, 3435, 26290, 94, 275, 49580, 275, 8756, 269, 33155, 269, 31496, 269, 5164, 5292, 97, 11, 46, 33, 11003, 17688, 10988, 13004, 10777, 16417, 4398, 7334, 111, 22532, 326, 39, 52333, 94, 28375, 97, 11, 46, 33, 10696, 15586, 14734, 47030, 33, 10762, 13004, 4398, 42150, 278, 52333, 512, 11, 46, 33, 16749, 14589, 11899, 10304, 14734, 38632, 33, 11124, 22532, 33, 10762, 13004, 11, 13006, 10452, 13234, 14791, 13091, 10250, 10283, 15190, 10932, 14734, 38632, 33, 10762, 13004, 11124, 22532, 33, 10762, 13004, 14734, 11899, 10304, 11124, 10482, 14589, 10080, 5735, 7999, 102, 33, 14332, 13191, 14734, 318, 33, 12276, 16728, 13764, 10079, 11003, 17688, 10988, 13004, 10777, 16417, 15169, 14332, 12415, 17311, 13191, 10452, 14446, 28329, 12159, 13197, 15752, 15494, 12469, 10988, 15641, 34, 11687, 13258, 13191, 10687, 10390, 17879, 13685, 45, 13558, 17143, 12848, 10760, 10080, 65535, 261, 65530, 65532, 17379, 14589, 10397, 14875, 14966, 10487, 16735, 13078, 7262, 7999, 102, 14734, 11632, 17385, 13036, 13764, 11, 65535, 261, 65530, 65534, 17148, 17384, 13191, 10250, 10283, 7262, 7999, 102, 14734, 11632, 17385, 13036, 13764, 14966, 10487, 59, 11, 7334, 35086, 21699, 38499, 11, 7334, 41847, 21699, 293, 98, 326, 121, 94, 275, 8756, 269, 41847, 332, 59, 269, 355, 42, 11, 7334, 41847, 21699, 293, 99, 326, 121, 94, 275, 8756, 269, 41847, 333, 59, 269, 355, 42, 11, 41, 7578, 293, 98, 3483, 42, 3580, 269, 41847, 332, 59, 3483, 35, 11, 41, 7578, 293, 99, 3493, 42, 3580, 269, 41847, 333, 59, 3493, 35, 11, 17148, 17384, 12605, 10402, 11899, 10304, 10250, 10283, 11632, 17385, 10762, 13004, 7578, 45, 33, 17177, 12731, 10768, 13818, 13036, 13764, 41, 7334, 35086, 42, 13091, 13326, 12797, 10988, 13004, 15162, 10250, 10283, 10653, 15323, 41, 34453, 42, 13234, 10722, 11899, 16749, 14589, 11187, 10283, 10688, 10452, 13036, 13764, 41, 7334, 41847, 42, 11, 10688, 10452, 17141, 15052, 13091, 59, 11, 50, 47, 33, 11899, 10304, 11632, 17385, 10762, 13004, 21699, 33, 12202, 10482, 14589, 38499, 33, 10762, 13004, 17177, 12731, 10768, 13818, 13036, 13764, 59, 11, 6884, 7262, 7999, 102, 11, 41, 7334, 35086, 21699, 38499, 42, 11, 6884, 11, 51, 47, 33, 11899, 10304, 10250, 10283, 10688, 10452, 13036, 13764, 293, 98, 45, 33, 10988, 13004, 13091, 355, 59, 11, 6884, 7262, 7999, 102, 11, 41, 7334, 41847, 21699, 293, 98, 326, 121, 94, 275, 8756, 269, 41847, 332, 59, 269, 355, 494, 11, 6884, 11, 52, 47, 33, 11899, 10304, 11013, 10250, 10283, 10688, 10452, 13036, 13764, 293, 99, 59, 11, 6884, 7262, 7999, 102, 11, 41, 7334, 41847, 21699, 293, 99, 326, 121, 94, 275, 8756, 269, 41847, 333, 59, 269, 355, 494, 11, 6884, 11, 53, 47, 33, 12307, 16749, 14589, 21699, 478, 98, 3483, 42, 33, 13064, 45, 33, 10423, 17177, 12731, 293, 98, 33, 13036, 13764, 60, 11, 54, 47, 33, 12307, 16749, 14589, 21699, 478, 99, 3493, 42, 33, 13064, 45, 33, 10423, 17177, 12731, 293, 99, 33, 13036, 13764, 28329, 17189, 17141, 11632, 17385, 13036, 13764, 45, 33, 12605, 10402, 11021, 10399, 12750, 14240, 10260, 11042, 14734, 13308, 10733, 56016, 33, 10792, 10260, 11042, 14734, 10688, 10452, 13036, 13764, 11903, 14446, 10080, 17148, 17384, 10788, 14589, 38499, 33, 10768, 13818, 10792, 10688, 10452, 14734, 10684, 17644, 11860, 293, 98, 33, 12609, 15643, 293, 99, 45, 33, 11891, 12604, 11632, 12314, 12396, 10768, 13818, 28329, 12159, 13197, 15752, 11634, 10847, 12469, 14486, 16533, 21443, 7999, 102, 33, 14734, 11632, 17385, 13036, 13764, 34, 16738, 11454, 17879, 16503, 13064, 16416, 10655, 10080, 65535, 261, 65530, 65532, 17379, 14589, 10397, 14875, 14966, 10487, 16735, 13078, 7262, 7999, 102, 14734, 10762, 13004, 10988, 13004, 16533, 13250, 11, 65535, 261, 65530, 65534, 5735, 7999, 102, 10285, 14734, 10762, 13004, 11021, 10399, 10482, 14589, 10988, 13004, 16533, 13250, 45, 16728, 13764, 13091, 11454, 10988, 13004, 11043, 10808, 10842, 478, 11, 6884, 7262, 7999, 102, 11, 41, 7334, 111, 30924, 46, 26290, 3331, 1650, 98, 333, 334, 94, 36216, 60, 332, 13091, 10250, 10283, 11047, 17387, 3331, 1652, 98, 293, 99, 293, 100, 94, 19250, 60, 332, 45, 99, 11124, 100, 13091, 8149, 10285, 14734, 17644, 3331, 92, 98, 358, 99, 293, 99, 126, 334, 94, 267, 60, 99, 13091, 10250, 10283, 8149, 3331, 92, 98, 333, 273, 31458, 1682, 294, 26276, 13091, 10250, 10283, 10894, 11064, 10822, 10457, 10988, 13004, 14734, 11047, 17387, 11, 6884, 11, 10487, 11855, 59, 11, 6884, 7262, 7999, 102, 11, 41, 7334, 111, 39355, 46, 25857, 3331, 92, 39, 326, 26290, 4899, 26078, 326, 6935, 46085, 1701, 4899, 26078, 326, 25015, 1701, 1697, 3331, 41, 49580, 31496, 269, 1955, 35, 21238, 269, 36031, 22221, 35, 46085, 58652, 35, 7005, 38919, 4596, 35, 30449, 494, 11, 41, 35433, 46, 25857, 4899, 26290, 269, 23813, 35, 293, 6935, 3503, 293, 41455, 269, 23902, 399, 64158, 2370, 25015, 269, 6329, 30074, 5198, 11, 60, 29165, 4600, 3503, 40237, 22221, 29335, 21265, 38919, 4596, 20512, 30074, 11, 6884, 11, 11454, 17148, 17384, 45, 59, 26290, 16533, 13250, 8149, 14734, 59, 26290, 17644, 558, 59, 26078, 326, 6935, 46085, 1701, 16533, 13250, 6935, 11124, 41455, 17644, 45, 4899, 26078, 326, 25015, 1701, 16533, 13250, 25015, 17644, 28329, 10988, 13004, 16533, 13250, 16672, 10762, 13004, 10988, 13004, 13179, 10688, 16728, 10304, 45, 13080, 10339, 14486, 16533, 10080, 65535, 261, 65530, 65532, 12848, 10494, 10250, 10283, 10482, 14589, 7262, 7999, 102, 16690, 17728, 7322, 26450, 13004, 12797, 12219, 14734, 10397, 14875, 14966, 10487, 11, 65535, 261, 65530, 65534, 17148, 17384, 13091, 10250, 10283, 10482, 14589, 19644, 7999, 102, 33, 16690, 17728, 19722, 26450, 33, 13004, 12797, 12219, 14734, 14966, 10487, 59, 11, 6884, 7262, 7999, 102, 11, 41, 49636, 3410, 7322, 26450, 47, 7023, 293, 1751, 335, 1682, 11, 60, 50108, 4811, 332, 19722, 26450, 55912, 11, 41, 7334, 30492, 275, 101, 48, 49003, 269, 7322, 26450, 59, 25457, 5385, 58319, 59, 663, 654, 48, 2058, 1815, 5172, 11, 60, 37220, 22590, 55912, 11, 41, 101, 48, 114, 3410, 59, 25423, 298, 102, 49923, 59, 36002, 326, 64, 102, 293, 34284, 269, 26055, 65, 49131, 47, 7272, 5196, 36210, 65, 25060, 42, 11, 60, 64226, 11, 41, 101, 48, 35795, 6909, 30492, 19242, 1659, 59, 1815, 48, 1940, 270, 1815, 48, 1940, 1652, 1815, 47, 26650, 48, 27370, 94, 36210, 59, 26290, 269, 23813, 35, 36210, 59, 34284, 269, 26055, 65, 49131, 47, 7272, 399, 1682, 11, 41, 101, 48, 35795, 6909, 30492, 19242, 1659, 59, 1815, 48, 1940, 270, 1815, 48, 1940, 1652, 1815, 47, 26650, 48, 27370, 94, 36210, 59, 26290, 269, 23909, 35, 36210, 59, 34284, 269, 26215, 65, 49131, 47, 7272, 399, 1682, 11, 60, 29137, 7066, 31601, 52738, 11, 41, 25156, 114, 326, 27370, 275, 101, 48, 114, 3410, 59, 25423, 298, 102, 65396, 59, 1950, 271, 298, 26290, 65396, 59, 36002, 326, 64, 102, 293, 26290, 298, 26290, 1697, 65362, 65, 25060, 269, 23813, 5177, 3331, 41, 49580, 32355, 494, 11, 6884, 11, 24242, 30469, 59, 11, 46, 44419, 116, 22590, 331, 7322, 26450, 47, 7023, 97, 60044, 11, 46, 50108, 116, 4811, 332, 19722, 26450, 55912, 39095, 331, 2058, 1815, 97, 11, 46, 50535, 116, 332, 39415, 4811, 30858, 4419, 45874, 32487, 38356, 331, 26055, 65, 49131, 47, 7272, 97, 11, 46, 50535, 116, 22638, 64595, 4811, 21227, 22638, 40084, 11, 46, 50535, 116, 332, 39415, 4811, 30858, 21256, 40084, 32487, 31496, 269, 23813, 35, 11, 46, 29137, 24744, 31601, 22590, 52738, 21265, 46906, 32229, 11, 23739, 32234, 38686, 34, 20282, 4660, 31223, 4588, 22799, 31059, 21273, 39193, 60312, 47, 65535, 261, 65530, 65532, 12605, 10381, 11639, 17879, 16503, 11454, 7322, 26450, 13004, 12797, 12219, 17384, 10842, 10257, 13133, 15752, 12636, 13212, 17148, 10283, 11903, 10452, 19137, 16738, 15494, 12605, 12848, 10494, 10250, 10283, 10688, 10452, 14734, 11533, 10339, 7322, 26450, 14734, 10397, 14875, 16689, 16664, 11, 65535, 261, 65530, 65534, 17148, 17384, 13191, 11533, 10339, 19722, 26450, 33, 14734, 13133, 15752, 12636, 13212, 11903, 10452, 10397, 14875, 16689, 16664, 59, 11, 6884, 7262, 7999, 102, 11, 60, 33, 11903, 10452, 1107, 11, 36, 1815, 48, 1940, 1652, 1815, 47, 26650, 48, 27370, 94, 11, 60, 33, 12025, 12415, 11, 59, 26290, 269, 41512, 323, 35, 11, 59, 35074, 269, 41512, 323, 35, 11, 60, 11860, 13619, 11, 1652, 35430, 293, 1815, 48, 42434, 94, 267, 60, 10408, 13327, 45, 11210, 10250, 11, 1652, 49629, 23554, 293, 1815, 47, 27200, 48, 49290, 94, 294, 10997, 12155, 13053, 13199, 11, 1652, 2102, 293, 1815, 48, 42434, 94, 28360, 60, 12945, 10460, 15304, 15500, 11, 1652, 41138, 293, 1815, 48, 42434, 1690, 11044, 12892, 10621, 11647, 10621, 15323, 11, 60, 33, 10355, 13080, 11, 1647, 101, 48, 35795, 6909, 30492, 262, 1659, 59, 1815, 48, 1940, 270, 1815, 48, 1940, 1652, 1815, 47, 26650, 48, 35664, 35381, 94, 28352, 59, 26290, 269, 41512, 323, 35, 28352, 59, 35074, 269, 41512, 323, 35, 28352, 59, 35430, 3572, 58, 28352, 59, 49629, 23554, 270, 25883, 269, 640, 637, 46, 631, 46, 623, 85, 620, 59, 620, 59, 620, 47, 620, 49, 46, 620, 59, 620, 35, 28352, 59, 2102, 269, 7738, 3484, 35, 28352, 59, 41138, 3485, 2403, 11, 60, 13290, 16718, 11, 1659, 59, 25423, 274, 64, 26290, 274, 64, 35430, 3331, 59, 36002, 4371, 64, 102, 293, 26290, 298, 26290, 94, 61270, 92, 64, 102, 293, 35430, 298, 35430, 1697, 3331, 59, 1950, 3395, 274, 41512, 323, 463, 94, 11, 6884, 11, 17148, 10283, 16689, 16664, 10894, 11064, 59, 11, 46, 33, 11903, 10452, 3888, 33, 10292, 331, 59, 1815, 47, 26650, 48, 35664, 35381, 97, 11, 46, 33, 12025, 12415, 10292, 97, 11043, 15044, 97, 10079, 97, 11496, 11028, 97, 10079, 331, 10408, 13327, 97, 10079, 97, 10997, 12155, 13053, 13199, 97, 10079, 97, 12945, 10460, 15304, 15500, 97, 11124, 97, 11044, 12892, 10621, 11647, 10621, 15323, 97, 11, 46, 33, 11957, 12220, 11860, 13619, 15261, 11496, 16689, 15586, 11, 46, 33, 13920, 10842, 10250, 13231, 46241, 323, 33, 14734, 16678, 12308, 10460, 10292, 14966, 10487, 11, 46, 33, 13290, 16718, 46241, 323, 33, 14734, 11043, 15044, 11124, 10408, 13327, 14734, 13290, 16718, 14966, 10487, 11, 11533, 10339, 13581, 16689, 16664, 45, 12469, 11021, 10399, 13920, 10842, 13179, 11632, 13133, 15752, 12636, 13212, 14734, 16678, 12308, 11124, 12025, 12415, 45, 14221, 11044, 11957, 10687, 12650, 16403, 11036, 15033, 13290, 16718, 28329, 11687, 13191, 17879, 16503, 45, 12605, 11021, 10399, 10292, 12469, 11891, 11255, 10688, 10452, 16689, 16664, 10080, 16738, 11414, 11626, 11088, 14862, 10080, 65535, 261, 65530, 65532, 27476, 4600, 21443, 7999, 102, 64, 32006, 4660, 32074, 30469, 21700, 51668, 11, 65535, 261, 65530, 65534, 5735, 7999, 102, 4600, 332, 51461, 4706, 20299, 113, 45, 332, 45956, 4706, 63795, 59946, 47, 29804, 56162, 4706, 19644, 7999, 102, 30469, 59, 11, 46, 44880, 56292, 59, 11, 6884, 7262, 7999, 102, 11, 41, 7334, 111, 21227, 326, 98, 333, 94, 3331, 474, 332, 333, 494, 11, 41, 6913, 285, 286, 42, 3580, 3591, 288, 11, 6884, 11, 46, 50824, 32487, 53267, 59, 11, 6884, 7262, 7999, 102, 11, 41, 7334, 52333, 326, 50, 285, 286, 287, 1682, 11, 41, 34174, 52333, 42, 3580, 3591, 287, 11, 41, 34453, 52333, 42, 3580, 3591, 284, 11, 41, 26102, 52333, 42, 3580, 3591, 287, 11, 41, 25059, 52333, 288, 42, 3580, 3591, 326, 50, 285, 286, 287, 288, 94, 11, 6884, 11, 46, 50824, 32487, 31371, 59, 11, 6884, 7262, 7999, 102, 11, 41, 7334, 32355, 4899, 26290, 269, 23813, 35, 293, 6935, 3503, 2389, 11, 41, 7621, 32355, 293, 26290, 42, 3580, 3591, 269, 23813, 35, 11, 41, 33915, 32355, 293, 25015, 269, 6329, 30074, 381, 3580, 3591, 4899, 26290, 269, 23813, 384, 293, 6935, 3503, 45, 293, 25015, 269, 6329, 30074, 399, 11, 6884, 11, 46, 44291, 7856, 332, 61689, 59, 11, 6884, 7262, 7999, 102, 11, 41, 41418, 30788, 64, 52333, 42, 3580, 3591, 275, 51, 287, 42, 11, 6884, 11, 46, 29301, 7856, 32487, 274, 7579, 448, 11, 6884, 7262, 7999, 102, 11, 41, 7579, 326, 121, 275, 35494, 284, 3484, 509, 3331, 41, 35433, 355, 269, 3351, 42, 11, 746, 3591, 284, 285, 286, 287, 288, 289, 290, 291, 292, 3483, 11, 6884, 11, 1461, 19644, 7999, 102, 30469, 4600, 51276, 21265, 62030, 4596, 39844, 45, 46500, 38677, 22681, 4706, 59751, 45, 63344, 21265, 60344, 47, 65535, 261]
-> item_loss 1.6564335823059082 batch_loss 1.1428045796023474
==== [15162, 10250, 13557, 12848, 17728, 11, 65530, 65532, 10902, 10362, 11454, 10373, 10303, 11459, 13036, 19156, 11, 65535, 261, 65530, 65534, 10902, 10362, 10447, 10339, 10285, 11435, 10902, 13036, 45, 13091, 10285, 10925, 10370, 13653, 10682, 11124, 11435, 14734, 18117, 17311, 28329, 10293, 16503, 15478, 15907, 59, 11, 50, 47, 33, 10902, 10362, 12154, 10447, 10339, 10285, 11435, 10272, 10902, 17303, 45, 11459, 11621, 10925, 10902, 12200, 10974, 14734, 10285, 12366, 28329, 51, 47, 33, 10902, 10362, 11621, 10339, 12337, 17385, 16503, 14734, 15486, 13828, 10079, 12984, 13751, 11124, 13012, 10901, 10285, 12366, 10447, 15586, 28329, 52, 47, 33, 10902, 10362, 13250, 12604, 10362, 13802, 10694, 11517, 12154, 15604, 13325, 12366, 45, 13091, 10285, 11435, 11412, 11638, 11011, 17311, 10305, 10250, 28329, 53, 47, 33, 10902, 10362, 12985, 11913, 15169, 11011, 17167, 10079, 11857, 12224, 10079, 18019, 11124, 11423, 15169, 15847, 14221, 13126, 14172, 10992, 17878, 17904, 15169, 17728, 18025, 15646, 10760, 11043, 28329, 54, 47, 33, 10902, 10362, 10688, 13191, 10257, 10918, 12201, 10964, 11024, 45, 13186, 15486, 13091, 10653, 10079, 13078, 10079, 13923, 10256, 10397, 14734, 18117, 17311, 10080, 639, 669, 33, 12201, 11044, 12604, 10292, 10285, 10925, 10370, 13653, 10682, 11124, 11435, 14734, 18117, 17311, 28329, 55, 47, 33, 10902, 10362, 11459, 11621, 659, 2446, 675, 9835, 127, 3514, 2446, 623, 9835, 10902, 15455, 45, 631, 54, 2446, 645, 9835, 127, 631, 56, 2446, 650, 9835, 10272, 15486, 28329, 12159, 13197, 10399, 10257, 10529, 12445, 15752, 12176, 10847, 12469, 10080, 11687, 13258, 17147, 13191, 10687, 10390, 14638, 17728, 45, 13558, 17143, 17819, 13064, 12848, 17728, 10080, 65535, 261, 65530, 65534, 14488, 14543, 19151, 33, 12605, 10780, 10780, 16707, 14808, 11871, 10323, 10333, 17148, 10349, 14862, 16696, 10080, 15489, 13258, 11640, 17843, 10333, 19137, 12605, 13734, 12401, 10303, 11871, 10423, 19137, 17879, 16503, 13179, 11632, 14734, 10988, 15641, 16909, 13021, 14791, 14791, 28329, 65535, 261, 65530, 65531, 15162, 10337, 13557, 17149, 10250, 13582, 14734, 12848, 17728, 11, 65535, 261, 65530, 65532, 10902, 10362, 11454, 10373, 10303, 11459, 13036, 19156, 11, 65535, 261, 65530, 65534, 10464, 11685, 19137, 12605, 13091, 10250, 10283, 820, 19137, 11017, 10588, 11975, 10847, 12636, 10080, 12605, 15752, 12176, 12469, 11414, 15178, 11036, 15033, 17728, 18025, 19137, 10260, 17141, 12605, 17879, 16503, 12469, 12848, 10494, 13179, 11632, 14734, 10529, 12445, 10080, 10902, 10362, 13091, 10285, 11435, 14734, 10250, 10283, 11517, 12154, 19137, 10447, 10339, 10285, 11435, 14734, 10902, 17303, 10080, 11885, 10399, 10687, 10286, 11932, 14734, 10964, 11024, 13012, 10901, 17225, 10358, 10079, 15597, 18053, 11124, 15034, 12666, 10781, 13034, 17740, 11043, 10339, 10267, 10080, 11687, 13258, 12469, 13191, 13179, 11632, 10684, 10339, 10902, 10362, 14734, 17728, 18025, 19137, 13558, 17143, 11047, 12605, 12848, 10760, 19126, 11, 65535, 261, 65530, 65534, 10902, 10362, 10447, 10339, 10285, 11435, 10902, 17303, 45, 13091, 10285, 11435, 14734, 18117, 17311, 28329, 9828, 33, 10902, 10362, 14734, 11459, 14486, 10447, 15586, 59, 10902, 15455, 659, 2446, 674, 9835, 15849, 661, 2446, 625, 9835, 45, 10272, 15486, 631, 54, 2446, 645, 9835, 15849, 631, 56, 2446, 650, 9835, 28329, 9828, 33, 10902, 10362, 13091, 17919, 15043, 13188, 11638, 10079, 10355, 17189, 13188, 10292, 10511, 10788, 10079, 15486, 13828, 13188, 10997, 17136, 10079, 13012, 10901, 13188, 13815, 16962, 14734, 10285, 11435, 11517, 12154, 10305, 10250, 28329, 9828, 33, 10902, 10362, 10964, 11024, 12466, 10301, 45, 15847, 15040, 14736, 14968, 11022, 12261, 15123, 10399, 13234, 11994, 10250, 14781, 13091, 10285, 11435, 14734, 12984, 13751, 10285, 12366, 28329, 9828, 33, 10902, 10362, 11517, 10696, 13191, 12337, 11632, 17385, 16503, 14734, 11011, 17167, 10079, 10964, 11024, 13012, 10901, 12261, 15176, 45, 11687, 11639, 11889, 17723, 12210, 11461, 10079, 18019, 11124, 11423, 15169, 45, 10995, 13086, 10333, 10902, 10362, 12466, 10301, 14734, 10964, 11024, 11124, 13012, 10901, 28329, 9828, 33, 10902, 10362, 10460, 10292, 10285, 11435, 14734, 18117, 17311, 45, 12727, 13191, 12337, 18216, 14734, 12984, 13751, 10079, 15486, 13828, 11124, 13012, 10901, 11459, 10447, 45, 12337, 11632, 11435, 10696, 11630, 17385, 16503, 13815, 10846, 17311, 11454, 10902, 10362, 10296, 16403, 28329, 9828, 33, 10902, 10362, 14734, 15597, 18053, 10322, 17916, 12182, 10286, 11932, 45, 10902, 10362, 14188, 18372, 10079, 14171, 17351, 17919, 10079, 16793, 56175, 33, 15169, 11010, 11110, 14370, 14332, 14734, 11975, 11035, 16939, 17149, 10267, 14610, 28329, 9828, 33, 17145, 12201, 13234, 45, 10902, 10362, 17147, 12604, 10292, 10285, 11435, 15034, 12666, 11124, 11423, 10912, 12261, 16689, 14734, 10285, 12366, 45, 11075, 12282, 14808, 12337, 11632, 15034, 12666, 10412, 10270, 11124, 12666, 13208, 10370, 12638, 28329, 12159, 13197, 10399, 10257, 10529, 12445, 15752, 12176, 10847, 12469, 13179, 10655, 10768, 11459, 10333, 16533, 10902, 10362, 17148, 12232, 10964, 11024, 11043, 11517, 10080, 11687, 13191, 10687, 10390, 17728, 18025, 45, 13558, 17143, 17819, 13064, 13234, 17728, 10080, 65535, 261, 65530, 65534, 10902, 10362, 59, 33, 12605, 14862, 17222, 10333, 19137, 16774, 16774, 10464, 14734, 16533, 15178, 10080, 17147, 13191, 10687, 10390, 17728, 18025, 11053, 19156, 11, 65535, 261, 65530, 65534, 10258, 17919, 14734, 11957, 16713, 10285, 45, 5732, 8875, 12848, 10494, 14734, 10529, 12445, 13637, 1406, 5608, 12848, 10494, 14734, 16503, 13179, 10842, 10675, 17919, 10079, 15478, 15850, 59, 11, 50, 47, 4164, 5608, 11016, 15190, 10932, 11459, 16735, 10902, 10362, 11454, 10285, 11435, 10902, 17303, 45, 13091, 10285, 11435, 11517, 12154, 45, 15646, 13734, 13191, 10688, 10452, 14734, 11459, 14486, 10447, 15586, 28329, 51, 47, 4164, 5608, 13734, 13191, 12848, 10992, 10902, 10362, 10460, 10292, 18117, 17311, 14734, 12984, 13751, 10079, 15486, 13828, 10079, 13012, 10901, 11459, 10447, 28329, 52, 47, 4164, 5608, 13734, 13191, 12848, 10992, 10902, 10362, 10286, 11932, 14734, 10964, 11024, 13012, 10901, 10992, 11011, 17167, 12261, 15176, 28329, 53, 47, 4164, 5608, 13734, 13191, 12848, 10792, 10902, 10362, 14332, 15898, 14734, 15597, 18053, 11975, 11035, 28329, 54, 47, 4164, 5608, 13734, 13191, 12848, 10992, 10902, 10362, 17145, 12201, 13234, 14734, 15034, 12666, 10261, 10412, 10270, 15674, 17848, 12484, 10724, 28329, 12421, 14734, 13234, 16735, 45, 5732, 8875, 12848, 10494, 14734, 10529, 12445, 13179, 15752, 14015, 16956, 14589, 12626, 10333, 16533, 10902, 10362, 14734, 17879, 13685, 10080, 10529, 12445, 10675, 17919, 45, 10894, 12732, 59, 11, 46, 33, 10688, 10452, 14734, 11459, 14486, 10447, 15586, 11, 46, 33, 10902, 10362, 10460, 10292, 18117, 17311, 14734, 17385, 16503, 12415, 11, 46, 33, 10286, 11932, 14734, 10964, 11024, 13012, 10901, 11124, 11011, 17167, 11, 46, 33, 10902, 10362, 15597, 18053, 11975, 11035, 11, 46, 33, 17145, 12201, 13234, 10902, 10362, 14734, 15034, 12666, 10997, 12022, 11, 17148, 10349, 13036, 17919, 17311, 11891, 13006, 11459, 11414, 15178, 10333, 14589, 12626, 35, 10902, 10362, 11454, 10373, 10303, 11459, 13036, 35, 17148, 10283, 17728, 18025, 45, 12176, 10847, 14589, 12626, 13179, 10675, 17919, 11459, 10333, 16533, 10902, 10362, 11517, 12154, 10080, 65535, 261]
-> item_loss 1.5533838272094727 batch_loss 1.1539013160241616
==== [25106, 11, 65530, 65531, 10464, 13091, 10250, 10283, 10370, 12137, 13133, 15752, 10847, 12636, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 12176, 12605, 14604, 10250, 10283, 52, 43, 52, 14734, 10320, 11913, 13327, 19137, 14589, 9822, 44, 9823, 11860, 15158, 14604, 28329, 65535, 261, 65530, 65534, 7176, 59, 3455, 44, 11, 536, 44, 11, 536, 44, 11, 12605, 14604, 11685, 10333, 10080, 65535, 261, 65530, 65532, 27370, 59, 33, 14221, 11044, 12669, 11885, 12138, 10257, 16530, 14734, 15158, 11028, 12791, 12604, 10026, 28329, 65535, 261, 65530, 65534, 7176, 59, 33, 13734, 17728, 18025, 19126, 10026, 536, 11, 536, 44, 11, 536, 44, 65535, 261, 65530, 65532, 11, 27370, 59, 33, 11025, 10257, 16530, 12791, 12604, 10022, 10080, 65535, 261, 65530, 65534, 7176, 59, 33, 11685, 14734, 10080, 10026, 44, 10022, 11, 536, 44, 11, 536, 44, 65535, 261, 65530, 65532, 11, 27370, 59, 33, 11025, 10258, 16530, 12791, 12604, 1660, 10035, 1660, 10080, 65535, 261, 65530, 65534, 7176, 59, 33, 13734, 17728, 18025, 10080, 10026, 44, 10022, 11, 536, 44, 11, 536, 10035, 65535, 261, 65530, 65532, 11, 27370, 59, 33, 12878, 11899, 10333, 10080, 65535, 261, 65530, 65534, 7176, 59, 33, 12337, 18216, 10685, 15752, 12176, 10257, 12469, 28329, 65535, 261]
[2023-09-30 21:50:23,196] [INFO] [logging.py:96:log_dist] [Rank 0] step=40, skipped=0, lr=[0.0001, 0.0001, 0.0001], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
-> item_loss 0.9026119709014893 batch_loss 1.1472884385209334
==== [11454, 15847, 10323, 11909, 10696, 19137, 33, 14488, 14543, 11454, 17149, 16403, 16742, 10325, 15475, 10323, 16744, 28331, 65530, 65532, 14488, 14543, 10464, 13234, 16742, 10250, 10258, 10258, 17919, 14734, 11975, 16735, 19137, 17148, 17303, 11975, 16735, 11017, 9822, 18256, 13764, 14734, 15898, 12319, 9823, 19137, 11975, 16735, 12847, 17162, 10333, 17268, 10349, 11461, 13126, 19156, 11, 10994, 11517, 11889, 15034, 46, 16050, 13770, 10660, 13091, 9822, 14445, 13849, 9823, 11105, 17131, 11517, 12154, 10305, 18117, 19137, 15847, 14221, 10322, 12604, 10333, 10306, 11038, 10305, 10420, 14734, 15640, 15105, 19151, 13593, 12345, 10079, 14766, 16902, 10079, 15671, 12636, 15486, 16099, 14734, 10327, 10933, 10370, 19137, 15169, 15169, 10080, 17148, 13580, 13091, 17148, 12232, 11517, 12154, 11687, 13581, 11932, 16956, 14734, 10974, 11416, 10305, 10250, 10080, 13748, 14734, 17176, 13064, 11047, 17268, 17131, 19137, 16050, 13770, 10660, 17165, 11913, 10441, 14734, 12148, 11855, 17384, 10449, 14808, 16684, 11632, 11459, 10447, 10928, 16893, 14734, 10449, 12626, 19137, 17148, 10349, 10370, 12182, 10292, 11517, 10285, 14782, 10342, 10335, 13020, 14734, 11418, 10422, 9822, 10692, 12143, 9823, 19137, 16924, 10349, 11630, 12387, 19137, 12289, 16416, 12359, 10260, 16956, 17222, 14734, 12979, 10673, 10080, 12631, 10399, 19137, 10419, 10414, 11124, 10994, 15931, 10250, 16939, 17149, 14894, 18458, 17335, 11920, 14734, 17796, 11855, 19137, 17148, 10349, 9822, 10692, 12143, 9823, 10285, 14734, 11975, 11647, 14778, 10511, 12348, 14862, 19151, 13191, 17558, 10370, 17149, 10333, 11517, 19126, 10250, 10349, 13637, 17097, 15478, 12366, 14734, 12822, 11855, 17147, 10427, 13234, 11010, 10529, 19137, 16735, 17268, 10283, 17149, 11517, 14734, 17787, 14583, 10370, 12172, 14808, 10250, 13205, 11975, 10702, 11855, 19137, 11975, 10702, 11855, 12421, 15752, 12848, 14966, 10390, 16721, 16679, 10373, 10303, 16713, 19151, 17147, 16735, 17268, 10283, 17787, 14583, 10370, 12172, 14808, 10250, 10283, 10423, 15847, 12144, 16939, 16981, 14734, 15209, 11855, 28329, 11, 17148, 13855, 12445, 15123, 10799, 16443, 11638, 11920, 10784, 11899, 10292, 10260, 11021, 10529, 19151, 13191, 17148, 10303, 11638, 13205, 10336, 14734, 18256, 13764, 12158, 19137, 10384, 13234, 10260, 10423, 16939, 17145, 16050, 13770, 10660, 15887, 11478, 10250, 17384, 10305, 10696, 28329, 11, 17148, 10423, 10650, 13580, 13091, 11517, 17384, 14734, 10250, 17303, 10768, 10449, 12626, 10733, 11622, 16944, 17038, 10079, 11013, 10250, 17303, 10768, 13580, 16503, 17043, 10258, 14817, 16525, 14734, 13064, 10560, 19137, 14894, 18458, 17335, 11920, 17384, 11907, 10370, 11944, 11944, 19137, 13734, 10745, 10283, 10370, 14791, 16519, 18000, 14808, 13443, 13374, 16939, 17149, 13234, 14734, 10994, 15931, 10080, 10390, 14734, 9822, 16403, 13221, 9823, 10322, 17819, 10953, 10760, 14446, 11454, 10390, 17038, 11044, 19137, 12266, 11726, 14015, 12395, 10529, 12366, 13101, 13101, 12466, 12466, 11459, 13582, 10258, 11022, 17775, 10080, 10250, 16519, 10305, 10258, 19137, 11471, 11454, 15269, 15296, 13202, 13338, 13039, 14734, 17335, 11907, 10621, 10250, 10283, 10370, 10441, 14734, 10448, 10258, 11647, 13234, 19137, 14638, 12366, 17385, 17385, 11459, 14779, 14808, 15847, 12144, 14734, 17335, 13239, 10080, 65535, 261, 65530, 65532, 17148, 13205, 11975, 16735, 10285, 13191, 10745, 10283, 10370, 19156, 11, 65535, 261, 65530, 65534, 17148, 13205, 11975, 16735, 10285, 13191, 10256, 10283, 10370, 10080, 10390, 10402, 10768, 10790, 13091, 19151, 11, 50, 47, 33, 10994, 15931, 19151, 10250, 10283, 10423, 15847, 12144, 16939, 16981, 14734, 14445, 13849, 11517, 12154, 17787, 14583, 10370, 19137, 12172, 14808, 10250, 10283, 11975, 15209, 11855, 28329, 51, 47, 33, 10994, 15931, 14734, 9822, 10692, 12143, 9823, 19151, 10250, 10283, 17335, 11061, 17384, 14734, 11975, 11647, 14778, 19137, 16875, 16879, 12824, 12220, 10994, 15931, 17149, 11517, 28329, 52, 47, 33, 10994, 15931, 14734, 9822, 10692, 12143, 9823, 19151, 10250, 10283, 10449, 11454, 16050, 13770, 10660, 11517, 11630, 14734, 10710, 13653, 19137, 12172, 14808, 10250, 10283, 11975, 15209, 11855, 17149, 11517, 28329, 53, 47, 33, 17335, 18107, 17384, 14734, 10687, 10390, 10370, 19151, 10390, 10402, 11957, 10994, 15931, 11124, 10994, 15931, 14734, 9822, 10692, 12143, 9823, 12746, 12395, 14638, 12396, 12231, 19137, 10444, 10322, 13734, 13191, 16692, 12797, 16692, 13078, 10390, 10402, 13091, 10580, 14734, 28329, 54, 47, 33, 17335, 18107, 17384, 10687, 10390, 10370, 19151, 10894, 12732, 17268, 10349, 11269, 17358, 10333, 17335, 10079, 12609, 15643, 12509, 16503, 12642, 12822, 13855, 12445, 14734, 17732, 13001, 10370, 11098, 28329, 12421, 10305, 19137, 17148, 17303, 11975, 16735, 10293, 16503, 12847, 17162, 10333, 10250, 15604, 17787, 14583, 10370, 11454, 16050, 13770, 10660, 11517, 10285, 10997, 14583, 14734, 12985, 10336, 10080, 65535, 261, 65530, 65534, 17148, 17384, 13191, 11013, 11630, 10250, 10283, 15178, 13336, 10080, 17148, 13205, 11975, 16735, 10285, 10293, 16503, 12847, 17162, 10333, 10256, 10283, 10370, 10080, 10390, 10402, 10768, 10790, 13091, 19151, 11, 50, 47, 33, 10994, 15931, 19151, 10250, 10283, 10423, 15847, 12144, 16939, 16981, 14734, 14445, 13849, 11517, 12154, 17787, 14583, 10370, 19137, 12172, 14808, 10250, 10283, 11975, 15209, 11855, 28329, 51, 47, 33, 10250, 10283, 17335, 11061, 15640, 13248, 19137, 16875, 16879, 12824, 12335, 10994, 15931, 28329, 52, 47, 33, 10250, 10283, 15091, 14808, 14894, 13055, 10079, 14015, 15778, 15737, 13943, 14734, 14601, 10370, 19137, 13091, 17148, 11920, 17335, 11061, 14734, 12182, 11907, 10080, 10390, 11471, 11454, 10994, 15931, 11957, 17919, 19137, 13064, 10260, 13064, 11459, 14839, 10250, 14806, 10994, 15931, 28329, 53, 47, 33, 17335, 18107, 17384, 10687, 10390, 10370, 19151, 10894, 12732, 17335, 10525, 10079, 18004, 11907, 11124, 12223, 11098, 15169, 15169, 28329, 54, 47, 33, 16050, 13770, 10660, 11517, 19151, 17148, 12232, 11517, 12154, 14734, 11043, 11860, 10080, 43, 30579, 65535, 261, 65530, 65534, 17148, 17384, 13091, 15162, 10256, 10283, 15178, 13336, 10080, 33, 17148, 15216, 11975, 16735, 10293, 16503, 12847, 17162, 14734, 13091, 10994, 15931, 11124, 10419, 10414, 13234, 10792, 10250, 10283, 17131, 17804, 11517, 12154, 16050, 13770, 10660, 14734, 12484, 13126, 28329, 10688, 10452, 13234, 16735, 59, 11, 50, 47, 33, 16050, 13770, 10660, 11517, 13091, 10283, 13916, 10328, 14734, 11459, 13036, 45, 15674, 17848, 14808, 11036, 15033, 13593, 12345, 11124, 11021, 14638, 10370, 14328, 28329, 51, 47, 33, 10994, 15931, 11124, 10419, 10414, 13234, 10792, 16050, 13770, 10660, 11044, 45, 15123, 10953, 12282, 16944, 10333, 10370, 10402, 14734, 13773, 12522, 10080, 11416, 10292, 10994, 15931, 12172, 13191, 11656, 12418, 14734, 16403, 13221, 15209, 10399, 10992, 10250, 10283, 15752, 12848, 10494, 12848, 14966, 14734, 15150, 16678, 13205, 28329, 52, 47, 33, 14221, 15646, 10370, 10402, 16944, 10782, 16667, 10292, 10994, 15931, 10260, 11021, 15752, 13091, 10283, 18256, 13764, 12158, 45, 11416, 10292, 18256, 13764, 12158, 10260, 10423, 12824, 17145, 10621, 16050, 13770, 10660, 17148, 13324, 14734, 11517, 12154, 28329, 53, 47, 33, 10390, 10402, 13234, 10792, 14894, 18458, 17335, 11920, 45, 17335, 11907, 10402, 16519, 10792, 10994, 15931, 11124, 10390, 14734, 16403, 13221, 11044, 45, 14987, 12484, 10655, 14015, 12395, 14638, 28329, 12421, 14734, 13234, 16735, 45, 17189, 17141, 12847, 17162, 10994, 15931, 11124, 10419, 10414, 13234, 10792, 16050, 13770, 10660, 11517, 14734, 11461, 13126, 45, 13146, 14966, 17148, 10283, 11459, 13036, 10655, 14015, 10952, 17801, 11124, 14987, 15036, 10080, 10994, 15931, 11124, 10390, 14734, 11656, 14332, 16403, 16434, 10322, 12282, 16944, 10333, 10370, 10402, 14734, 12395, 14638, 12396, 12231, 10080, 65535, 261, 65530, 65532, 11454, 10305, 10808, 14734, 11975, 16735, 10285, 13191, 10745, 10283, 10293, 16503, 16530, 15898, 10760, 11461, 19156, 11, 65535, 261, 65530, 65534, 10293, 16503, 16530, 15898, 59, 11, 50, 47, 33, 10994, 15931, 59, 10250, 10283, 12172, 14808, 11656, 12418, 16403, 13221, 14734, 17787, 14583, 10370, 45, 10390, 14734, 16403, 13221, 17384, 13191, 10250, 10283, 11975, 14763, 11855, 28329, 51, 47, 33, 10419, 10414, 59, 10250, 10283, 10423, 15847, 12144, 16939, 16981, 14734, 15209, 11855, 45, 10390, 12172, 14808, 10250, 10283, 11975, 14763, 11855, 28329, 52, 47, 33, 17335, 11061, 15640, 13248, 10692, 10692, 17335, 10525, 59, 10390, 13091, 17148, 11920, 17335, 11061, 14734, 12182, 11907, 45, 11957, 10994, 15931, 11124, 10419, 10414, 12337, 12527, 10685, 16954, 28329, 53, 47, 33, 10687, 10390, 10449, 12626, 59, 17335, 11061, 17384, 14734, 10687, 10390, 10449, 12626, 45, 10894, 12732, 10250, 10349, 13637, 17097, 11656, 12418, 14734, 11920, 10422, 28329, 54, 47, 33, 17148, 10349, 10370, 15674, 17848, 11454, 14894, 18458, 17335, 11920, 45, 16520, 11940, 10994, 15931, 28329, 55, 47, 33, 12985, 10336, 10285, 12848, 10792, 10333, 18256, 13764, 10079, 18256, 13764, 12158, 10079, 18256, 13764, 14328, 11159, 10399, 10992, 18256, 13764, 10305, 11517, 16050, 13770, 10660, 28329, 56, 47, 33, 12985, 10336, 10285, 17147, 12848, 10792, 10333, 10994, 15931, 12172, 14808, 10250, 13205, 12636, 10702, 10080, 65535, 261]
-> item_loss 2.015252113342285 batch_loss 1.1695439173625066
==== [17728, 15178, 11, 65530, 65532, 10464, 11017, 10373, 10303, 11043, 11860, 19156, 11, 65535, 261, 65530, 65534, 12605, 11017, 11975, 13078, 28329, 65535, 261, 65530, 65532, 10464, 13191, 10373, 10303, 14189, 12454, 11053, 19156, 11, 65535, 261, 65530, 65534, 12605, 13191, 13064, 10560, 10423, 12509, 19137, 11687, 13258, 12605, 10260, 11861, 11454, 10339, 17148, 10283, 10267, 14610, 10257, 10423, 12401, 10303, 13324, 10080, 10444, 13091, 12605, 14862, 17222, 17148, 13091, 10260, 11021, 15752, 14734, 28329, 65535, 261, 65530, 65532, 10292, 10373, 10303, 19156, 33, 10370, 10260, 10423, 13594, 11053, 19156, 11, 65535, 261, 65530, 65534, 11687, 13258, 10464, 16735, 14734, 13091, 10250, 10283, 14328, 10452, 12609, 15643, 10250, 10283, 10370, 19137, 17268, 10303, 10390, 10402, 10423, 13594, 10353, 10080, 10444, 13091, 11687, 13258, 10464, 16735, 14734, 13091, 10250, 10283, 14141, 18245, 19137, 17268, 10303, 10390, 10402, 10260, 10423, 13594, 10353, 28329, 65535, 261, 65530, 65532, 10464, 13091, 16735, 19137, 10464, 12727, 13191, 14141, 18245, 19137, 10260, 13091, 10250, 10283, 10370, 12137, 13133, 15752, 19156, 11, 65535, 261, 65530, 65534, 13091, 14734, 19137, 12605, 12727, 13191, 14141, 18245, 19137, 10260, 13091, 10250, 10283, 13212, 11369, 10370, 10080, 12605, 11021, 10399, 12527, 11002, 10792, 14658, 14673, 19137, 10322, 10423, 11416, 10292, 14299, 11124, 10993, 12484, 15646, 12527, 10792, 18216, 10685, 28329, 65535, 261, 65530, 65532, 10464, 16667, 10292, 10464, 13091, 11060, 12727, 13191, 14141, 18245, 19156, 11, 65535, 261, 65530, 65534, 12605, 16667, 10292, 12605, 12727, 13191, 14141, 18245, 10080, 11416, 10292, 12605, 11021, 10399, 12527, 11002, 10792, 14658, 14673, 10079, 14299, 11124, 10993, 12484, 19137, 17148, 10349, 17311, 13091, 10370, 15261, 14370, 13191, 14734, 11159, 16884, 28329, 65535, 261, 65530, 65532, 12605, 10260, 10529, 19137, 16692, 13078, 15494, 12605, 14791, 14791, 10080, 12605, 14446, 11454, 15494, 10464, 10250, 10283, 13212, 10423, 19137, 16672, 10464, 16692, 13078, 15494, 12605, 14791, 10080, 10444, 13091, 16738, 16678, 10449, 19137, 17148, 11016, 13091, 16672, 10464, 16692, 13078, 15494, 12605, 14791, 10080, 10464, 11021, 10399, 11986, 16707, 11414, 12509, 16944, 15847, 12144, 13091, 11060, 12727, 13191, 14141, 18245, 10080, 11687, 13258, 10464, 12509, 10260, 16944, 13234, 19137, 17268, 10303, 10464, 11994, 10260, 15752, 16692, 13078, 15494, 12605, 14791, 28329, 65535, 261]
-> item_loss 1.0360426902770996 batch_loss 1.1662063866853714
==== [25106, 11, 65530, 65531, 18119, 16002, 13091, 10250, 10283, 12337, 15678, 13078, 14734, 820, 19137, 10293, 10370, 12176, 18119, 16002, 10588, 10333, 10250, 10283, 15304, 15500, 19137, 16672, 11684, 15752, 11634, 10588, 12337, 11632, 10336, 12484, 28329, 18119, 16002, 14734, 10841, 15752, 19151, 11, 50, 47, 12307, 10293, 10370, 16672, 18119, 16002, 12176, 10390, 12945, 10460, 14600, 15763, 10257, 14734, 10272, 16501, 14734, 13064, 10560, 19137, 18119, 16002, 11021, 10399, 17109, 10760, 1660, 92, 12945, 10460, 14600, 15763, 1696, 35, 12748, 10398, 11124, 15304, 15500, 10355, 10342, 19137, 14221, 11044, 13326, 12797, 15304, 15500, 14734, 12282, 11960, 13855, 12445, 13234, 12945, 10460, 14600, 15763, 28329, 51, 47, 17109, 10760, 1660, 92, 10260, 10997, 13855, 12445, 1696, 35, 14734, 16713, 19137, 10293, 10370, 11994, 10260, 10423, 12979, 10792, 18119, 16002, 14734, 13855, 12445, 19137, 10260, 12509, 12642, 12658, 10293, 10370, 14734, 13064, 10560, 18119, 16002, 11994, 11021, 10399, 17148, 10303, 10588, 28329, 52, 47, 17798, 10333, 10257, 10257, 17162, 12748, 10398, 10399, 11630, 19137, 18119, 16002, 17147, 15752, 10482, 14589, 14734, 12748, 10398, 13191, 19151, 1660, 92, 12642, 12266, 15090, 16749, 1696, 384, 1660, 92, 16689, 15586, 17738, 17544, 1696, 384, 1660, 92, 10684, 17727, 16728, 17952, 1696, 384, 1660, 92, 12266, 11068, 16728, 17952, 1696, 35, 10080, 33, 17879, 16503, 13773, 12522, 14734, 13091, 19137, 11016, 13191, 15304, 15500, 12848, 10792, 14734, 12748, 10398, 11021, 10399, 10482, 14589, 10080, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 18119, 16002, 11, 65535, 261, 65530, 65534, 18119, 16002, 59, 33, 10293, 10370, 12664, 12605, 13191, 10373, 10303, 10336, 12484, 11053, 64, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 12176, 12605, 12266, 10258, 124, 12220, 14589, 11043, 126, 28329, 65535, 261, 65530, 65534, 18119, 16002, 59, 358, 12220, 14589, 11043, 126, 19156, 17268, 13091, 10373, 10303, 19156, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 11416, 10292, 14446, 11454, 13091, 11454, 16675, 15475, 16728, 13021, 17384, 19137, 12631, 10399, 11885, 13734, 13191, 16443, 11434, 11899, 10258, 13234, 19137, 11903, 17781, 10257, 11885, 12220, 16721, 10250, 10283, 14600, 15763, 12220, 14589, 14734, 11043, 11860, 28329, 65535, 261, 65530, 65534, 18119, 16002, 59, 326, 12945, 10460, 14600, 15763, 94, 11, 65535, 261, 65530, 65531, 40812, 59, 33, 11021, 10399, 17149, 16403, 14734, 12945, 10460, 19151, 11, 12642, 12266, 12220, 14589, 45, 10482, 14589, 13012, 10407, 15304, 15500, 45, 11, 16738, 17177, 12731, 10250, 10283, 12945, 10460, 19151, 65535, 261, 65530, 65534, 18119, 16002, 59, 33, 12642, 12266, 12220, 14589, 11, 65535, 261, 65530, 65531, 40812, 59, 33, 11021, 17177, 14734, 12220, 14589, 19151, 16678, 10336, 13205, 10079, 16664, 15200, 11369, 10079, 1589, 23682, 10079, 13829, 16524, 11369, 10079, 17273, 10407, 10079, 124, 12220, 14589, 11043, 126, 10080, 16738, 17109, 10760, 17879, 16503, 12642, 12266, 14734, 12220, 14589, 19151, 11, 65535, 261, 65530, 65534, 18119, 16002, 59, 358, 12220, 14589, 11043, 126, 11, 65535, 261, 65530, 65531, 40812, 59, 358, 12220, 14589, 11043, 126, 12145, 12642, 12266, 28329, 65535, 261, 65530, 65534, 18119, 16002, 59, 33, 12145, 15486, 12642, 12266, 10333, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 11315, 19137, 12605, 14791, 10792, 10333, 28329, 65535, 261, 65530, 65534, 18119, 16002, 59, 33, 10293, 10370, 13191, 10336, 10703, 13234, 12664, 12605, 11183, 127, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 13191, 10256, 10283, 14763, 11855, 19137, 11885, 10402, 14734, 13308, 15189, 10257, 17919, 10768, 10790, 10708, 14808, 9822, 15966, 13258, 9823, 10079, 9822, 18119, 16184, 9823, 10079, 9822, 15966, 13258, 11124, 18119, 16184, 9823, 10080, 14446, 11454, 14862, 17222, 11016, 13191, 10250, 10283, 15966, 13258, 11124, 10250, 10283, 18119, 16184, 10079, 13633, 10283, 14763, 11855, 17384, 13188, 11632, 11016, 13191, 10250, 10283, 13676, 13258, 19137, 12202, 10265, 10256, 10283, 14763, 11855, 10257, 14734, 13308, 15189, 17311, 13091, 17631, 16730, 14734, 19137, 11687, 13258, 16672, 10464, 12642, 12266, 10687, 10285, 10250, 10283, 14763, 11855, 13234, 14914, 16667, 10256, 10283, 14763, 11855, 17384, 17311, 13091, 10373, 10303, 19137, 10464, 10423, 12401, 10303, 10588, 19156, 11, 65535, 261, 65530, 65534, 18119, 16002, 59, 33, 12605, 10423, 12642, 12266, 10708, 14808, 9822, 15966, 13258, 11124, 18119, 16184, 9823, 17268, 10283, 14763, 11855, 10080, 11416, 10292, 11016, 13191, 17148, 13324, 12605, 12638, 15752, 14914, 11899, 10256, 10283, 14763, 11855, 17384, 17311, 13091, 10373, 10303, 28329, 10293, 10370, 19137, 12605, 13234, 16533, 17382, 10250, 10258, 10974, 11416, 10080, 18117, 10658, 19137, 11687, 13258, 12605, 12642, 12266, 10250, 10283, 14763, 11855, 19137, 17384, 17919, 11021, 15752, 10760, 14446, 14734, 12484, 10724, 13091, 19151, 13191, 10250, 10283, 15966, 13258, 10079, 13191, 10250, 10283, 18119, 16184, 10079, 10373, 10303, 10322, 13734, 13191, 28329, 11687, 13258, 12605, 12642, 12266, 10708, 14808, 9822, 15966, 13258, 9823, 12609, 9822, 18119, 16184, 9823, 14734, 14763, 11855, 19137, 12202, 10265, 17384, 17919, 13191, 13676, 13258, 19137, 17268, 10303, 17384, 17919, 14734, 13676, 13258, 10250, 11899, 13091, 10261, 13308, 15189, 10257, 12631, 10708, 10260, 11042, 14734, 13676, 13258, 10080, 17268, 10303, 12605, 11994, 13051, 13764, 14914, 11899, 11013, 11630, 10278, 10283, 14763, 11855, 10285, 13091, 10373, 10303, 12484, 10724, 19152, 15646, 12605, 15957, 13091, 12642, 12266, 10708, 14808, 9822, 15966, 13258, 11124, 18119, 16184, 9823, 14734, 17268, 10283, 14763, 11855, 19137, 11021, 15752, 10423, 10760, 14446, 10256, 15033, 12484, 10724, 19151, 11, 50, 47, 17148, 10283, 14763, 11855, 17384, 13191, 10250, 10283, 15966, 13258, 19137, 17268, 10303, 10708, 14808, 9822, 18119, 16184, 9823, 14734, 14763, 11855, 17384, 10250, 11899, 10373, 10303, 10322, 13734, 13191, 19137, 10708, 14808, 9822, 15966, 13258, 9823, 14734, 14763, 11855, 17384, 10250, 11899, 13191, 10250, 13326, 18119, 16184, 10080, 11416, 10292, 19137, 12605, 10402, 14862, 17222, 11016, 13191, 10250, 10283, 15966, 13258, 11124, 10250, 13326, 18119, 16184, 10080, 11687, 13258, 10708, 14808, 9822, 18119, 16184, 9823, 14734, 14763, 11855, 17384, 13191, 13676, 13258, 19137, 17268, 10303, 17268, 10283, 13676, 13258, 10250, 11899, 13091, 18119, 16184, 19137, 17148, 13324, 14734, 16713, 19137, 11994, 10423, 10261, 9822, 10256, 10283, 14763, 11855, 10257, 14734, 13308, 15189, 17311, 13091, 17631, 16730, 14734, 9823, 14734, 10336, 11903, 14782, 12463, 10080, 12631, 10399, 19137, 10708, 14808, 9822, 18119, 16184, 9823, 14734, 14763, 11855, 17384, 10250, 11899, 13091, 15090, 14734, 10080, 14597, 13581, 11021, 10399, 14862, 17222, 19137, 17268, 13326, 18119, 16184, 10250, 11899, 11454, 10708, 14808, 9822, 15966, 13258, 9823, 14734, 14763, 11855, 17384, 28329, 51, 47, 17148, 10283, 14763, 11855, 17384, 13191, 10250, 10283, 18119, 16184, 10080, 17148, 15033, 12484, 10724, 10258, 14734, 12826, 14486, 13036, 13764, 10261, 14763, 11855, 17384, 13191, 15966, 13258, 13091, 10250, 15850, 14734, 19137, 11016, 10260, 17141, 12669, 15966, 13258, 11124, 18119, 16184, 10342, 12791, 10250, 10258, 28329, 52, 47, 17148, 10283, 14763, 11855, 17384, 10373, 10303, 10322, 13734, 13191, 10080, 17268, 10303, 11013, 11630, 10278, 10283, 14763, 11855, 17384, 10250, 11899, 13191, 13676, 13258, 10080, 10708, 14808, 9822, 15966, 13258, 9823, 14734, 14763, 11855, 17384, 13191, 18119, 16184, 19137, 10708, 14808, 9822, 18119, 16184, 9823, 14734, 14763, 11855, 17384, 13191, 15966, 13258, 10080, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 10292, 10373, 10303, 12642, 12266, 10708, 14808, 9822, 15966, 13258, 9823, 12609, 10708, 14808, 9822, 18119, 16184, 9823, 14734, 14763, 11855, 10423, 11960, 15850, 13051, 13764, 14914, 11899, 11013, 11630, 10278, 10283, 14763, 11855, 10285, 13091, 10373, 10303, 12484, 10724, 19156, 11, 65535, 261, 65530, 65534, 18119, 16002, 59, 33, 10293, 10370, 19137, 13091, 11021, 15752, 10423, 11960, 15850, 13051, 13764, 14914, 11899, 11013, 11630, 10278, 10283, 14763, 11855, 10285, 13091, 10373, 10303, 12484, 10724, 10080, 11416, 10292, 10580, 16689, 12605, 12642, 12266, 10708, 14808, 9822, 15966, 13258, 9823, 14734, 14763, 11855, 19137, 11021, 15752, 10423, 10760, 14446, 10278, 15033, 12484, 10724, 19151, 11, 50, 47, 17384, 17919, 13191, 18119, 16184, 11, 51, 47, 17384, 17919, 10373, 10303, 10322, 13734, 13191, 11, 11687, 13258, 17384, 17919, 10373, 10303, 10322, 13734, 13191, 19137, 17268, 10303, 12605, 10402, 15752, 14914, 11899, 10708, 14808, 9822, 18119, 16184, 9823, 14734, 14763, 11855, 17384, 13191, 10250, 10283, 15966, 13258, 19137, 10708, 14808, 9822, 15966, 13258, 11124, 18119, 16184, 9823, 14734, 14763, 11855, 17384, 13191, 10250, 13326, 18119, 16184, 10080, 17148, 15033, 12484, 10724, 10258, 19137, 12605, 10402, 13091, 15752, 11634, 14914, 16667, 11013, 11630, 10278, 10283, 14763, 11855, 14734, 12484, 10724, 14734, 28329, 10444, 13091, 11687, 13258, 12605, 10402, 10997, 14446, 10708, 14808, 9822, 15966, 13258, 9823, 14734, 14763, 11855, 17384, 13191, 18119, 16184, 19137, 17268, 10303, 12605, 10402, 11994, 13051, 13764, 14914, 16667, 17268, 10283, 15966, 13258, 13091, 11454, 10708, 14808, 9822, 18119, 16184, 9823, 14734, 14763, 11855, 17384, 17147, 13091, 11454, 10708, 14808, 9822, 15966, 13258, 11124, 18119, 16184, 9823, 14734, 14763, 11855, 17384, 28329, 11687, 13258, 12642, 12266, 10708, 14808, 9822, 18119, 16184, 9823, 14734, 14763, 11855, 19137, 12826, 14486, 13036, 12276, 10322, 13091, 10250, 13324, 14734, 19137, 11016, 10260, 17141, 12669, 15966, 13258, 11124, 18119, 16184, 10342, 12791, 10250, 10258, 28329, 10293, 10370, 19137, 15752, 14486, 16533, 11053, 19156, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 11315, 19137, 13734, 13191, 17728, 18025, 28329, 65535, 261, 65530, 65534, 18119, 16002, 59, 33, 12337, 11685, 127, 17268, 10303, 10293, 10370, 17147, 13191, 10687, 10390, 10336, 12484, 11053, 19156, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 10464, 15752, 10260, 11414, 12605, 17148, 11012, 16713, 10303, 19156, 11, 65535, 261, 65530, 65534, 18119, 16002, 59, 326, 10260, 10997, 13855, 12445, 94, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 11315, 19137, 14791, 13234, 14914, 11903, 13734, 13191, 13855, 12445, 28329, 65535, 261, 65530, 65534, 18119, 16002, 59, 33, 12605, 12750, 10293, 10370, 14734, 16735, 13764, 10588, 10333, 10080, 10444, 13091, 18119, 16002, 17147, 13091, 12509, 11124, 10293, 10370, 16735, 16713, 14734, 43282, 11, 65535, 261]
-> item_loss 0.8055842518806458 batch_loss 1.1574107248608658
==== [25106, 11, 17148, 13619, 13012, 11860, 13091, 9822, 14931, 12314, 10267, 14610, 9823, 14734, 10250, 10283, 14313, 13619, 19137, 33, 16679, 17162, 10333, 14597, 13085, 17781, 10846, 14328, 11871, 11920, 16520, 11940, 12140, 18492, 15646, 12282, 10997, 14734, 10336, 10407, 11, 10305, 10808, 19137, 12140, 18492, 14734, 11861, 11454, 10377, 10377, 13091, 10250, 10283, 10580, 16735, 19137, 10444, 14931, 12314, 10267, 14610, 17131, 15545, 14116, 13819, 10257, 13036, 10250, 11621, 12822, 10760, 13234, 14734, 12034, 11981, 10257, 13191, 10250, 10283, 14987, 15036, 14734, 10660, 18295, 11979, 14428, 11435, 19137, 17268, 17384, 14734, 10660, 18295, 11979, 10370, 11454, 10250, 11473, 13188, 17795, 12076, 14734, 14869, 11592, 17997, 10257, 12883, 16689, 10333, 18216, 13273, 11124, 14005, 17085, 16451, 15586, 19137, 11967, 10745, 11043, 16520, 13827, 11098, 11492, 10792, 10267, 14610, 17131, 15545, 14734, 10258, 13036, 19137, 17148, 12638, 16692, 11903, 10333, 12140, 18492, 14734, 11861, 11454, 10080, 17148, 10349, 16520, 13827, 11098, 11471, 11454, 10250, 15891, 17686, 13191, 14869, 15963, 15102, 12626, 14734, 17587, 15887, 17384, 19137, 15752, 11634, 17181, 17141, 13676, 17878, 14791, 13923, 11630, 17919, 14734, 13126, 15850, 28329, 17587, 15887, 11454, 17131, 15545, 14116, 13819, 10258, 17919, 12747, 10333, 12337, 10301, 19137, 14221, 11044, 19137, 11638, 15604, 11680, 17836, 12705, 11414, 17587, 15887, 11124, 17587, 15887, 17384, 17919, 14734, 13057, 13199, 13085, 17781, 10846, 14328, 11871, 11920, 28329, 10390, 10402, 12172, 11414, 10333, 12337, 11632, 10529, 12445, 19137, 10894, 12732, 17777, 11436, 11416, 10399, 10992, 12140, 16803, 14734, 12314, 14349, 11124, 12025, 12415, 10080, 14221, 15646, 19137, 17148, 10349, 10529, 12445, 10383, 14221, 10260, 15752, 12329, 12221, 16533, 17382, 11887, 11898, 14734, 12415, 16884, 11124, 11861, 11454, 14734, 12522, 10304, 28329, 13637, 11687, 19137, 17777, 11436, 11416, 14734, 12415, 10790, 11994, 17843, 10399, 14914, 11899, 10080, 13085, 17781, 10846, 14328, 11871, 11920, 10402, 10529, 16589, 13054, 13054, 11459, 11610, 15044, 19137, 17148, 10283, 12415, 10790, 17728, 18025, 17916, 12182, 10684, 17644, 19137, 11016, 13191, 12261, 17194, 10250, 10283, 13179, 11638, 13179, 11474, 11434, 14734, 12978, 13273, 19137, 12669, 11640, 15090, 10305, 15887, 11492, 12348, 13179, 10448, 19137, 12638, 15752, 12270, 13923, 10336, 11903, 10080, 15646, 14778, 10808, 19137, 10390, 10402, 11016, 15752, 13326, 12797, 12145, 14862, 14734, 11887, 11898, 14862, 16696, 17149, 16403, 12826, 13827, 28329, 13191, 14734, 14486, 16686, 16667, 10292, 19137, 17777, 11436, 11416, 16714, 14583, 10339, 16256, 13051, 19137, 10390, 10423, 13679, 12431, 11459, 14296, 10258, 10985, 19137, 10525, 12746, 14808, 11042, 10250, 15033, 13582, 10418, 19137, 16939, 17149, 11013, 10250, 14313, 16256, 13051, 10080, 11454, 11871, 15643, 10285, 17734, 19137, 17148, 15033, 14486, 16686, 12337, 11002, 12826, 12087, 28329, 11013, 10250, 15033, 14486, 16686, 10779, 11002, 10792, 11896, 12996, 14610, 10370, 11606, 14734, 13558, 17143, 10080, 17148, 10250, 14486, 16686, 16667, 10292, 19137, 17777, 11436, 11416, 10384, 9822, 16714, 14583, 11459, 9823, 12266, 11726, 14296, 19137, 10250, 14781, 14296, 10792, 9822, 10355, 17332, 10305, 13064, 9823, 19137, 11416, 10292, 11887, 11898, 17384, 17147, 13191, 10790, 14734, 13085, 13085, 19137, 11885, 10402, 15713, 11899, 10322, 18159, 11454, 10790, 14734, 12140, 18492, 17038, 10257, 10080, 9822, 10355, 17332, 10305, 13064, 9823, 11016, 13191, 10250, 13557, 19137, 10390, 10402, 10250, 11899, 10423, 14866, 13137, 15646, 14195, 14179, 11459, 10355, 11038, 10080, 17189, 17141, 17148, 11461, 10655, 14015, 14091, 12484, 14734, 15489, 11038, 19137, 13034, 18492, 16714, 14583, 10333, 19137, 17819, 11044, 10511, 15752, 12914, 16944, 10250, 14313, 13034, 14734, 10267, 14610, 10080, 17148, 10283, 14486, 16686, 16443, 15044, 10292, 9822, 10781, 10267, 11638, 14288, 14171, 9823, 10580, 16735, 28329, 10250, 11043, 16928, 12604, 9822, 12431, 14296, 9823, 14486, 16686, 14734, 12201, 17093, 11887, 11898, 18492, 11871, 11920, 13580, 11454, 16707, 18183, 10250, 15033, 13034, 10997, 13078, 14734, 13197, 17150, 17674, 19137, 10390, 12159, 13197, 15752, 11634, 15287, 14914, 11459, 13827, 17387, 10760, 11638, 17777, 11436, 11416, 11025, 14806, 14734, 10995, 14240, 14426, 28329, 15489, 13258, 19137, 17189, 17141, 13197, 17150, 17674, 19137, 10390, 10997, 14446, 14931, 12314, 10267, 14610, 10285, 17090, 13036, 11047, 13833, 14187, 14010, 14010, 43275, 14931, 12314, 10267, 14610, 10257, 13188, 11011, 15640, 14734, 11517, 12154, 12145, 13091, 10250, 14313, 14136, 13849, 10080, 17148, 10283, 11633, 13115, 10997, 14583, 10333, 11640, 11632, 14734, 10336, 19137, 15646, 17148, 11043, 12201, 17093, 14734, 11871, 15643, 13091, 15162, 10250, 10283, 10997, 14446, 14146, 12484, 14734, 12005, 11630, 10370, 28329, 10673, 11633, 10305, 11044, 19137, 10390, 11515, 11647, 17565, 14880, 19137, 12669, 17148, 10407, 10336, 12679, 10792, 10333, 15763, 11044, 10080, 11021, 13051, 16686, 11687, 10454, 19137, 10390, 13091, 15162, 10250, 10283, 10997, 14446, 14146, 12484, 14734, 28329, 17147, 13191, 10790, 10370, 10322, 14791, 16519, 10333, 43282, 65530, 65532, 17728, 18025, 19151, 33, 12985, 10336, 10285, 18492, 11871, 11920, 11454, 16520, 11940, 12140, 18492, 11042, 13064, 17147, 10997, 14446, 10333, 10373, 10303, 10336, 10407, 19156, 11, 65535, 261, 65530, 65534, 12985, 10336, 10285, 45, 12201, 17093, 14734, 18492, 11871, 11920, 17189, 17141, 13034, 10997, 13078, 14734, 13197, 17150, 17674, 11454, 16520, 11940, 11638, 17777, 11436, 11416, 13064, 45, 12522, 11630, 10997, 14446, 14931, 12314, 10267, 14610, 10285, 17090, 13036, 11047, 13188, 11011, 15640, 14734, 11517, 12154, 10997, 14583, 10333, 14136, 14146, 28329, 65535, 261, 65530, 65532, 13012, 13205, 10285, 17147, 16735, 10333, 10373, 10303, 19156, 11, 65535, 261, 65530, 65534, 12985, 10336, 10285, 17147, 12847, 17162, 10333, 59, 11, 50, 47, 33, 10305, 10808, 12140, 18492, 14734, 11861, 11454, 10377, 10377, 13091, 10250, 10283, 10580, 16735, 45, 14781, 10792, 13191, 10370, 17189, 17141, 13273, 16689, 11454, 14931, 12314, 10267, 14610, 17131, 15545, 14734, 16689, 11622, 12638, 16692, 11903, 10333, 12140, 18492, 14734, 11861, 11454, 28329, 51, 47, 33, 16520, 13827, 11098, 16520, 13827, 10792, 14734, 12140, 18492, 10529, 12445, 10383, 14221, 10260, 15752, 16533, 17382, 11887, 11898, 14734, 13205, 16884, 28329, 52, 47, 33, 13191, 10684, 11638, 17777, 11436, 11416, 12415, 10790, 14734, 10335, 16676, 10080, 13191, 10370, 16667, 10292, 11885, 13091, 17851, 12415, 45, 10384, 16256, 15090, 16714, 14583, 12202, 13679, 17150, 11047, 10808, 14296, 16403, 60, 10322, 13191, 10370, 16667, 10292, 11885, 13091, 17846, 12415, 45, 10423, 10261, 10687, 10390, 12140, 18492, 10355, 17332, 12202, 10781, 17194, 13034, 14583, 11117, 28329, 53, 47, 33, 17268, 11043, 12201, 17093, 14734, 18492, 11871, 11920, 17189, 17141, 13034, 14734, 13197, 17150, 17674, 45, 11454, 16520, 11940, 11638, 17777, 11436, 11416, 14734, 11042, 13064, 10997, 14446, 14931, 12314, 10267, 14610, 13188, 11011, 15640, 14734, 11517, 12154, 14808, 14136, 10333, 10080, 10444, 10673, 11633, 11044, 10390, 13734, 13191, 17385, 16523, 17148, 10283, 10997, 14446, 45, 15507, 15511, 14880, 15087, 12140, 18492, 28329, 54, 47, 33, 17147, 13191, 10790, 10370, 10322, 14791, 10792, 10333, 17148, 11461, 14136, 14146, 28329, 10293, 16503, 16679, 17162, 14734, 13091, 17148, 11043, 12201, 17093, 18492, 11871, 11920, 17189, 17141, 13034, 13197, 17150, 17674, 10997, 14446, 14136, 14146, 14734, 10336, 45, 10444, 10390, 17177, 12731, 12392, 16523, 17148, 10283, 10997, 14446, 45, 15507, 15511, 14880, 15087, 12140, 18492, 10080, 65535, 261, 65530, 65532, 12985, 10336, 10285, 13191, 11187, 10349, 16710, 16760, 12208, 18441, 14734, 14313, 13619, 11, 65535, 261, 65530, 65534, 11454, 12848, 10494, 14734, 13012, 11860, 10285, 45, 13734, 13191, 12337, 13078, 13098, 14734, 16710, 16760, 12208, 18441, 14734, 14313, 13619, 10080, 10675, 13012, 11632, 13091, 12847, 10708, 13085, 17781, 10846, 14328, 11871, 11920, 16520, 11940, 12140, 18492, 10399, 10992, 10390, 10402, 10684, 10339, 12140, 18492, 11861, 11454, 12522, 10304, 14734, 11036, 15033, 14486, 16686, 14734, 10279, 15689, 15034, 11871, 12847, 17162, 28329, 10293, 18025, 16269, 14221, 14987, 11656, 45, 10444, 13012, 10285, 14734, 16728, 16537, 11124, 10696, 11922, 17311, 13637, 17097, 16667, 14794, 45, 13734, 13191, 12849, 15090, 14734, 12484, 15907, 12609, 11268, 10821, 12986, 13258, 10080, 10675, 13012, 11632, 13091, 12847, 17162, 11124, 12822, 16671, 12140, 18492, 14734, 15033, 15033, 11656, 12418, 12025, 12415, 10079, 11861, 11454, 12522, 10304, 11124, 16944, 13981, 45, 10399, 10992, 10684, 10339, 12140, 18492, 12415, 10790, 14734, 11871, 13208, 10335, 16686, 28329, 11687, 13258, 12368, 18001, 14734, 16713, 45, 11021, 10399, 11986, 16707, 10384, 10399, 10258, 10745, 10283, 13036, 17919, 12664, 10792, 10250, 10349, 16742, 16944, 13234, 13191, 14172, 10995, 12410, 12522, 11110, 14734, 10696, 11922, 59, 11, 50, 47, 33, 13085, 17781, 10846, 14328, 11871, 11920, 10402, 15931, 16899, 17268, 10303, 11632, 12366, 12410, 14880, 15087, 12140, 18492, 14734, 12415, 10790, 11124, 16944, 13981, 45, 10954, 12392, 14619, 10333, 14806, 10808, 11011, 11517, 14734, 12140, 11638, 14136, 14146, 10080, 17148, 15092, 13098, 10333, 10390, 10402, 11957, 13179, 11638, 11887, 11898, 11672, 15036, 14734, 12650, 14808, 45, 10399, 10992, 11957, 11105, 11430, 10267, 14610, 14734, 15568, 10309, 10684, 13773, 28329, 51, 47, 33, 10684, 10339, 12140, 18492, 16944, 13981, 11124, 12522, 10304, 14734, 10278, 15033, 10260, 11042, 14486, 16686, 45, 10768, 10790, 11002, 10792, 11871, 13208, 14610, 11124, 11896, 12996, 14610, 14734, 13558, 17143, 10080, 17148, 11021, 10399, 16523, 10292, 10260, 11042, 16520, 14172, 14734, 10250, 10283, 16688, 10798, 28329, 10444, 12421, 10452, 13234, 16735, 45, 12985, 10336, 12484, 15907, 11124, 13012, 11860, 16417, 17136, 10279, 15689, 11632, 10339, 12208, 18441, 10080, 11687, 13258, 15752, 12849, 10673, 10250, 10349, 14005, 15071, 14734, 15478, 15907, 45, 12609, 10482, 14589, 13179, 14583, 10846, 14734, 16728, 16537, 45, 10322, 16684, 10423, 16672, 13006, 10283, 12985, 10336, 11064, 13191, 13179, 11632, 12208, 18441, 12527, 10080, 65535, 261, 12985, 10336, 10285, 13191, 11187, 10349, 16530, 15898, 10760, 11461, 19156, 33, 10390, 10402, 14734, 14332, 14172, 10768, 10790, 13091, 10373, 10303, 19156, 11, 65530, 65534, 12985, 10336, 10285, 10293, 16503, 10760, 14446, 10333, 10399, 10258, 10745, 10283, 16530, 15898, 59, 11, 50, 47, 33, 13085, 17781, 10846, 14328, 11871, 11920, 59, 10390, 10402, 13188, 10782, 17189, 17141, 11454, 14931, 12314, 10267, 14610, 17131, 15545, 13273, 16689, 16689, 11622, 16692, 11903, 10333, 12140, 18492, 14734, 11861, 11454, 10080, 10390, 10402, 16520, 11940, 12140, 18492, 12202, 12848, 10760, 10260, 11042, 14486, 16686, 45, 16707, 11436, 16533, 17382, 12140, 18492, 14734, 12415, 16884, 11124, 12522, 10304, 10080, 10390, 10402, 11957, 12140, 18492, 11672, 15036, 14734, 12650, 14808, 11459, 14880, 15087, 28329, 51, 47, 33, 10660, 18295, 11979, 10370, 59, 10390, 10402, 11454, 14931, 12314, 10267, 14610, 17131, 15545, 12883, 16689, 18216, 13273, 11124, 17587, 15887, 45, 10482, 13085, 17781, 10846, 14328, 11871, 11920, 12348, 10399, 16520, 11940, 10792, 12140, 18492, 28329, 52, 47, 33, 12140, 18492, 17777, 11436, 11416, 59, 11861, 11454, 10339, 14931, 12314, 10267, 14610, 17131, 15545, 45, 13091, 13085, 17781, 10846, 14328, 11871, 11920, 16520, 11940, 14880, 15087, 14734, 11957, 16803, 10080, 10390, 14734, 12415, 10790, 11124, 16944, 13981, 11861, 11454, 10335, 16676, 28329, 53, 47, 33, 12201, 17093, 14734, 18492, 11871, 11920, 59, 17189, 17141, 13034, 10997, 13078, 14734, 13197, 17150, 17674, 12522, 11630, 10997, 14446, 10333, 13188, 11011, 15640, 11517, 12154, 14734, 11638, 14136, 45, 10444, 17177, 12731, 12392, 14619, 17148, 10283, 10997, 14446, 15507, 15511, 14880, 15087, 12140, 18492, 10080, 10397, 16417, 10333, 13085, 17781, 10846, 14328, 11871, 11920, 10402, 14734, 14880, 15087, 11001, 11047, 28329, 54, 47, 33, 11517, 12154, 12010, 13653, 59, 13734, 13191, 16722, 15478, 12847, 17162, 45, 11016, 12848, 10792, 10333, 13188, 11011, 15640, 14734, 11517, 12154, 16443, 11638, 14136, 12901, 13626, 45, 10444, 17148, 10250, 10336, 10407, 16443, 12201, 17093, 18492, 11871, 11920, 12392, 14619, 10333, 28329, 12421, 14734, 13234, 16735, 45, 10384, 14446, 13191, 10529, 12445, 14791, 45, 10293, 16503, 15674, 14216, 14734, 13091, 13085, 17781, 10846, 14328, 11871, 11920, 11957, 12140, 18492, 11672, 15036, 14734, 12650, 14808, 11124, 10585, 12650, 45, 10399, 10992, 11957, 11105, 17237, 10267, 14610, 10336, 10407, 14734, 12392, 16523, 11124, 14637, 15023, 10080, 16530, 15898, 12314, 16803, 13179, 11632, 10452, 14446, 11454, 10390, 10402, 14734, 14880, 15087, 11001, 11047, 11124, 10529, 12445, 17207, 17108, 10257, 10080, 65535, 261]
-> item_loss 1.769837737083435 batch_loss 1.1719923203899747
==== [25106, 11, 65530, 65531, 10464, 13091, 10250, 10283, 820, 19137, 16443, 17303, 15588, 11454, 13205, 11459, 10080, 10293, 10370, 11967, 10464, 16689, 11899, 10292, 10250, 10283, 11679, 11872, 11855, 19137, 10464, 14734, 11043, 11860, 11017, 10588, 14299, 10295, 10273, 19137, 11124, 10293, 10370, 12201, 18476, 14782, 10411, 19137, 10260, 10792, 640, 12039, 10080, 10464, 13091, 820, 10444, 13091, 15752, 11634, 13499, 12722, 10370, 15261, 14734, 11036, 15033, 12527, 12484, 19137, 13637, 11687, 12266, 12366, 10079, 10429, 12366, 10079, 14583, 13655, 10079, 15648, 12366, 10079, 10399, 10992, 11036, 15033, 13562, 13197, 10080, 10464, 16443, 16689, 16664, 10760, 13234, 10292, 10370, 15261, 13193, 10843, 19137, 10444, 13091, 11042, 13064, 10464, 10322, 12159, 13197, 15847, 12144, 15752, 11634, 12348, 10792, 12203, 15009, 10261, 11971, 17385, 10080, 10464, 15752, 11634, 12945, 10460, 14600, 15763, 11124, 10250, 10349, 13133, 15752, 11920, 12010, 19137, 17879, 16503, 14734, 13064, 10560, 10464, 17879, 16503, 16735, 398, 12945, 10460, 14600, 15763, 2383, 12609, 15643, 398, 12945, 10460, 11920, 12010, 2383, 19137, 15646, 10260, 15752, 17109, 10760, 10687, 10390, 13012, 11860, 10080, 17148, 10283, 13064, 10560, 10464, 14734, 17109, 10760, 10423, 16443, 15304, 15500, 12785, 16056, 12202, 12282, 11960, 10464, 17149, 16403, 17149, 10250, 13582, 14734, 10355, 10342, 10080, 17148, 17384, 15494, 10760, 10250, 10283, 11957, 16713, 11903, 10487, 19151, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 14299, 10295, 10273, 19137, 12176, 12605, 12266, 10258, 14139, 11, 65535, 261, 65530, 65534, 14299, 10295, 10273, 59, 358, 12945, 10460, 11920, 12010, 126, 11, 65535, 261, 65530, 65531, 40812, 59, 33, 10464, 15752, 11634, 17149, 16403, 14734, 10355, 10342, 14734, 10696, 11922, 10777, 10296, 11454, 10258, 13036, 19137, 16738, 17177, 12731, 10250, 10283, 17109, 10760, 19151, 11, 398, 14600, 14139, 9187, 398, 15090, 16749, 9187, 398, 14195, 13676, 11369, 9187, 398, 17952, 11168, 2383, 65535, 261, 65530, 65534, 14299, 10295, 10273, 59, 358, 14600, 14139, 126, 11, 65535, 261, 65530, 65531, 40812, 59, 33, 13381, 13827, 10792, 12307, 10808, 14600, 14139, 10684, 17727, 19137, 16738, 10722, 11899, 13091, 11060, 12642, 12266, 19137, 17177, 12731, 35, 13091, 35, 12609, 15643, 35, 11060, 35, 11, 65535, 261, 65530, 65534, 14299, 10295, 10273, 59, 33, 13091, 11, 65535, 261, 65530, 65531, 40812, 59, 33, 14600, 14139, 12145, 12642, 12266, 19137, 12145, 17146, 11414, 11957, 16713, 28329, 65535, 261, 65530, 65534, 14299, 10295, 10273, 59, 33, 10293, 10370, 19137, 11687, 13258, 15304, 15500, 13051, 16730, 19137, 12605, 12145, 12642, 12266, 14600, 14139, 28329, 65535, 261]
-> item_loss 0.8966177105903625 batch_loss 1.1655882596969604
==== [25106, 11, 65530, 65531, 12605, 10402, 14446, 11454, 12266, 11726, 16671, 16686, 10250, 10283, 13034, 14734, 16713, 18025, 19137, 17148, 10283, 16713, 18025, 10684, 10339, 10250, 17303, 11975, 16735, 11, 65535, 261, 17148, 13091, 10250, 13619, 35, 14931, 12314, 10267, 14610, 35, 17148, 17303, 11975, 16735, 14734, 14313, 13619, 19137, 33, 12421, 15489, 10250, 10258, 11461, 13126, 10285, 14734, 17385, 16503, 10696, 11922, 11124, 10708, 10460, 12636, 13764, 11, 14781, 10792, 10381, 11639, 19137, 11640, 15090, 12366, 14486, 11871, 11920, 10402, 10383, 13055, 13051, 13764, 12778, 12904, 10390, 10402, 14734, 12366, 12410, 28329, 10305, 10808, 19137, 12140, 18492, 14734, 11861, 11454, 10377, 10377, 13091, 10250, 10283, 10580, 16735, 19137, 10444, 14931, 12314, 10267, 14610, 17131, 15545, 14116, 13819, 10257, 13036, 10250, 11621, 12822, 10760, 13234, 14734, 12034, 11981, 10257, 13191, 10250, 10283, 14987, 15036, 14734, 10660, 18295, 11979, 14428, 11435, 19137, 17268, 17384, 14734, 10660, 18295, 11979, 10370, 11454, 10250, 11473, 13188, 17795, 12076, 14734, 14869, 11592, 17997, 10257, 12883, 16689, 10333, 18216, 13273, 11124, 14005, 17085, 16451, 15586, 19137, 11967, 10745, 11043, 16520, 13827, 11098, 11492, 10792, 10267, 14610, 17131, 15545, 14734, 10258, 13036, 19137, 17148, 12638, 16692, 11903, 10333, 12140, 18492, 14734, 11861, 11454, 10080, 17148, 10349, 16520, 13827, 11098, 11471, 11454, 10250, 15891, 17686, 13191, 14869, 15963, 15102, 12626, 14734, 17587, 15887, 17384, 19137, 15752, 11634, 17181, 17141, 13676, 17878, 14791, 13923, 11630, 17919, 14734, 13126, 15850, 28329, 17587, 15887, 11454, 17131, 15545, 14116, 13819, 10258, 17919, 12747, 10333, 12337, 10301, 19137, 14221, 11044, 19137, 11638, 15604, 11680, 17836, 12705, 11414, 17587, 15887, 11124, 17587, 15887, 17384, 17919, 14734, 13057, 13199, 13085, 17781, 10846, 14328, 11871, 11920, 28329, 10390, 10402, 12172, 11414, 10333, 12337, 11632, 10529, 12445, 19137, 10894, 12732, 17777, 11436, 11416, 10399, 10992, 12140, 16803, 14734, 12314, 14349, 11124, 12025, 12415, 10080, 14221, 15646, 19137, 17148, 10349, 10529, 12445, 10383, 14221, 10260, 15752, 12329, 12221, 16533, 17382, 11887, 11898, 14734, 12415, 16884, 11124, 11861, 11454, 14734, 12522, 10304, 28329, 13637, 11687, 19137, 17777, 11436, 11416, 14734, 12415, 10790, 11994, 17843, 10399, 14914, 11899, 10080, 13085, 17781, 10846, 14328, 11871, 11920, 10402, 10529, 16589, 13054, 13054, 11459, 11610, 15044, 19137, 17148, 10283, 12415, 10790, 17728, 18025, 17916, 12182, 10684, 17644, 19137, 11016, 13191, 12261, 17194, 10250, 10283, 13179, 11638, 13179, 11474, 11434, 14734, 12978, 13273, 19137, 12669, 11640, 15090, 10305, 15887, 11492, 12348, 13179, 10448, 19137, 12638, 15752, 12270, 13923, 10336, 11903, 10080, 15646, 14778, 10808, 19137, 10390, 10402, 11016, 15752, 13326, 12797, 12145, 14862, 14734, 11887, 11898, 14862, 16696, 17149, 16403, 12826, 13827, 10080, 65530, 65534, 17148, 13619, 13012, 11860, 12847, 17162, 14734, 13091, 11454, 10250, 10283, 11656, 12206, 14734, 9822, 14931, 12314, 10267, 14610, 9823, 10285, 16520, 11940, 11887, 11898, 14734, 12484, 13126, 28329, 16503, 14172, 12421, 15489, 59, 11, 50, 47, 33, 10660, 18295, 11979, 14428, 11435, 14734, 11871, 15643, 10482, 14589, 18216, 13273, 11124, 14005, 17085, 15169, 16451, 15586, 45, 11967, 17587, 10794, 16520, 13827, 15887, 11492, 17788, 10792, 10267, 14610, 17131, 15545, 14116, 13819, 10258, 13036, 45, 17189, 17141, 15887, 10696, 14869, 15963, 15102, 16520, 11940, 11630, 14610, 12484, 10724, 28329, 51, 47, 33, 10390, 10402, 17189, 17141, 16520, 13827, 14791, 10792, 10333, 12140, 18492, 11124, 10687, 10390, 15090, 17734, 14583, 14328, 11687, 17777, 11436, 11416, 15169, 28329, 52, 47, 33, 16269, 14221, 16056, 12348, 10333, 10250, 10349, 10529, 12445, 45, 10444, 10383, 13051, 13764, 16533, 17382, 11887, 11898, 13205, 16884, 11124, 11861, 11454, 12522, 10304, 17148, 15261, 11533, 13205, 17728, 18025, 28329, 53, 47, 33, 10390, 10402, 13051, 13764, 14914, 11899, 17777, 11436, 11416, 14734, 12415, 10790, 45, 17879, 16503, 13179, 11638, 13179, 11474, 11434, 14734, 16689, 11622, 12638, 15752, 16533, 15178, 17148, 10283, 17728, 18025, 28329, 10708, 10460, 12636, 13764, 59, 11, 50, 47, 33, 10482, 14589, 11656, 12206, 12509, 16803, 45, 10781, 17194, 10250, 10283, 10261, 10267, 17821, 15498, 14734, 10660, 18295, 11979, 14428, 11435, 17149, 16403, 15090, 17734, 14880, 15087, 14734, 11461, 13126, 28329, 51, 47, 33, 11957, 12666, 13208, 16689, 13038, 11124, 16520, 13827, 17141, 15052, 14734, 16722, 15478, 12847, 17162, 45, 11584, 12299, 14794, 11903, 12527, 28329, 52, 47, 33, 12282, 10673, 13203, 16533, 10305, 16771, 11124, 13179, 11632, 17728, 18025, 45, 10758, 14446, 10760, 11887, 11898, 14734, 14987, 15036, 10261, 11626, 13215, 28329, 53, 47, 33, 17189, 17141, 11957, 17777, 11436, 11416, 12415, 10790, 14734, 16671, 16686, 45, 13146, 14966, 10953, 10482, 16056, 12348, 16520, 13827, 13004, 12797, 10322, 13051, 13764, 16533, 15178, 13326, 13205, 17728, 18025, 28329, 12421, 14734, 13234, 16735, 45, 17148, 13619, 13012, 11860, 10399, 12206, 12509, 14734, 12636, 13764, 12822, 16671, 15034, 11871, 14880, 15087, 11124, 11887, 11898, 16667, 14862, 14734, 12005, 17789, 12415, 10080, 65535, 261]
-> item_loss 1.6922991275787354 batch_loss 1.1775589612397281
==== [25106, 11, 65530, 65531, 35, 10464, 13091, 10250, 10283, 15667, 11639, 13212, 11369, 10370, 19137, 16443, 17303, 15588, 11454, 10250, 10283, 15667, 11639, 15604, 15476, 10285, 10080, 11454, 15604, 15476, 10285, 19137, 13633, 10250, 10283, 14589, 12626, 17311, 10399, 35, 14589, 12626, 11043, 41, 16696, 10790, 11028, 489, 14734, 12314, 12276, 16443, 10464, 16667, 14862, 19137, 10464, 14734, 10293, 10370, 13091, 35, 23385, 41, 632, 663, 697, 679, 50, 489, 28329, 10464, 14734, 11043, 11860, 13091, 1297, 1740, 19137, 11454, 15604, 15476, 10696, 14734, 16443, 13098, 14966, 10292, 35, 1297, 1740, 41, 651, 699, 715, 662, 700, 489, 11, 10464, 11021, 10399, 11454, 11957, 16713, 10285, 17109, 10760, 393, 65, 16696, 10790, 11028, 1678, 13234, 65, 13279, 10447, 12604, 11098, 19137, 10487, 11687, 11021, 10399, 17109, 10760, 393, 65, 632, 663, 697, 679, 50, 94, 10293, 10370, 11454, 11053, 19156, 35, 13234, 65, 10293, 10370, 17149, 16403, 11957, 16713, 19137, 11454, 11957, 13279, 10283, 14332, 11899, 14589, 12626, 14734, 10997, 16537, 17149, 16403, 11414, 11626, 13064, 19137, 10464, 12220, 16721, 65, 10390, 10384, 15646, 16672, 10390, 13078, 14731, 10464, 13091, 11454, 11957, 10390, 17149, 16403, 11414, 11626, 28329, 15304, 15500, 13633, 13557, 10423, 16742, 11001, 10250, 17303, 10768, 14734, 15667, 11639, 16678, 12308, 10997, 15494, 10464, 19137, 10464, 17879, 16503, 10784, 13032, 13091, 11060, 17149, 16403, 11414, 11626, 10080, 65535, 261, 65530, 65531, 40812, 59, 33, 10464, 10842, 10673, 10333, 15604, 15667, 28329, 65535, 261, 65530, 65532, 23385, 41, 632, 663, 697, 679, 50, 503, 636, 59, 621, 59, 620, 788, 33, 12605, 12669, 7176, 12705, 17149, 13234, 10333, 19137, 10464, 10402, 11021, 10399, 16707, 16707, 10080, 10780, 10708, 11685, 12824, 11010, 19137, 10260, 10250, 11899, 15752, 16968, 11, 65535, 261, 24189, 25169, 41, 635, 626, 657, 682, 49, 503, 636, 59, 621, 59, 641, 788, 326, 11436, 14313, 13855, 12445, 94, 11, 261, 18025, 14778, 15847, 12722, 17729, 11639, 13881, 41, 634, 642, 695, 686, 630, 503, 636, 59, 621, 59, 644, 788, 326, 11436, 14313, 13855, 12445, 94, 11, 261, 14731, 13787, 15450, 13229, 41, 696, 640, 661, 635, 57, 503, 636, 59, 621, 59, 657, 788, 326, 65, 648, 653, 636, 690, 634, 94, 33, 14862, 17222, 67, 15126, 11053, 64, 11, 261, 826, 74, 41, 15604, 13212, 11369, 10370, 493, 648, 653, 636, 690, 634, 503, 636, 59, 621, 59, 675, 788, 326, 65, 696, 640, 661, 635, 57, 94, 33, 13091, 14734, 19137, 67, 15126, 13091, 10250, 10283, 10285, 11435, 14370, 14332, 14734, 16523, 18020, 10682, 10361, 15573, 15126, 19137, 10292, 14589, 12626, 12848, 10494, 11454, 15471, 16520, 14791, 10079, 10768, 10361, 11124, 10997, 12155, 15158, 11038, 10285, 11435, 11638, 17782, 13764, 12340, 13764, 16521, 14734, 10974, 10781, 16523, 18020, 19137, 10894, 12732, 14589, 12626, 15847, 10794, 14734, 10846, 14604, 10079, 14042, 14604, 10079, 13953, 12603, 16523, 18020, 10079, 17952, 10310, 16523, 18020, 10079, 10768, 10361, 14583, 13815, 15169, 15261, 11496, 14734, 16523, 18020, 10696, 11922, 10080, 67, 15126, 11454, 10285, 11435, 12604, 10292, 10333, 10250, 10283, 17916, 12182, 13819, 16403, 14734, 16523, 18020, 14970, 10912, 28329, 261, 65530, 65532, 23385, 41, 632, 663, 697, 679, 50, 503, 636, 59, 622, 59, 635, 788, 33, 12421, 10305, 17148, 10283, 7176, 13637, 17097, 14332, 13603, 19137, 11638, 13445, 10260, 17879, 16503, 65, 10322, 15752, 16735, 16713, 10080, 1653, 651, 699, 715, 662, 700, 1681, 10464, 23304, 11454, 10260, 11454, 19137, 10760, 13234, 16974, 11638, 11920, 10382, 15484, 10250, 10258, 15847, 12144, 28329, 65535, 261, 65530, 65531, 40812, 59, 29483, 19137, 12410, 15641, 10250, 10258, 14446, 11454, 13091, 11060, 17879, 16503, 10997, 16537, 10080, 12669, 12410, 15641, 14734, 17141, 15052, 17149, 16403, 17109, 10760, 11, 65535, 261, 65530, 65534, 1297, 1740, 59, 33, 15641, 16253, 10792, 10293, 10370, 65, 12605, 12202, 12159, 13197, 12605, 11124, 11638, 11920, 10382, 15484, 15847, 12144, 19137, 12605, 16667, 10292, 14446, 11454, 17879, 16503, 10997, 16537, 28329, 65535, 261, 65530, 65531, 40812, 59, 33, 16738, 17109, 10760, 35, 13091, 35, 12609, 15643, 35, 11060, 35, 14914, 16667, 13091, 11060, 17879, 16503, 10997, 16537, 19151, 11, 65535, 261, 65530, 65534, 1297, 1740, 59, 33, 13091, 11, 65535, 261, 65530, 65531, 40812, 59, 33, 16738, 17109, 10760, 124, 10997, 16537, 10696, 11922, 126, 19151, 11, 65535, 261, 65530, 65534, 1297, 1740, 41, 651, 699, 715, 662, 700, 501, 33, 11454, 14734, 19137, 11638, 11920, 11685, 19137, 12605, 13091, 10381, 11639, 10842, 10673, 15604, 10696, 11124, 11638, 11920, 15667, 11639, 14734, 13212, 11369, 10370, 19137, 1653, 632, 663, 697, 679, 50, 94, 13091, 12605, 14734, 10293, 10370, 10080, 12605, 15752, 11634, 10768, 13254, 15604, 10696, 14734, 13855, 12445, 12202, 10722, 11899, 13091, 11060, 10997, 16537, 19137, 12159, 13197, 15752, 11124, 11638, 11920, 12519, 12387, 11459, 15667, 11639, 19126, 11, 65535, 261, 24189, 25169, 41, 635, 626, 657, 682, 49, 503, 636, 59, 624, 59, 641, 788, 33, 17148, 13091, 12401, 10303, 11903, 14446, 14734, 19156, 11, 261, 65530, 65532, 23385, 41, 632, 663, 697, 679, 50, 503, 636, 59, 624, 59, 652, 788, 3422, 11, 65535, 261, 65530, 65532, 23385, 41, 632, 663, 697, 679, 50, 503, 636, 59, 624, 59, 655, 788, 33, 13637, 17097, 11626, 13215, 19137, 12421, 10305, 10464, 10402, 11021, 10399, 10658, 16707, 16707, 19133, 11, 65535, 261, 89, 2277, 1956, 41, 680, 644, 707, 675, 52, 503, 636, 59, 624, 59, 657, 788, 33, 17148, 10283, 13212, 11369, 10370, 16503, 12401, 10303, 14589, 11223, 11, 261, 65530, 65532, 23385, 41, 632, 663, 697, 679, 50, 503, 636, 59, 624, 59, 662, 788, 33, 10260, 14589, 15202, 19137, 11684, 12220, 16721, 10423, 15847, 12144, 13234, 12849, 16713, 14734, 11, 65535, 261, 65530, 65531, 40812, 59, 29483, 19137, 12410, 15641, 10250, 10258, 14446, 11454, 13091, 11060, 17879, 16503, 10997, 16537, 10080, 12669, 12410, 15641, 14734, 17141, 15052, 17149, 16403, 17109, 10760, 11, 65535, 261, 65530, 65534, 1297, 1740, 59, 33, 10293, 10370, 11124, 10687, 10390, 15604, 10993, 11454, 16671, 16686, 10684, 10339, 12605, 14734, 10336, 12484, 19137, 14778, 10808, 10260, 17879, 16503, 12605, 10997, 16537, 28329, 65535, 261, 65530, 65531, 40812, 59, 33, 16738, 17109, 10760, 35, 13091, 35, 12609, 15643, 35, 11060, 35, 14914, 16667, 13091, 11060, 17879, 16503, 10997, 16537, 19151, 11, 65535, 261, 65530, 65534, 1297, 1740, 59, 33, 11060, 11, 65535, 261, 18025, 14778, 15847, 12722, 17729, 11639, 13881, 41, 674, 642, 663, 695, 55, 503, 636, 59, 625, 59, 621, 788, 33, 12421, 10305, 12605, 10658, 16707, 16707, 92, 11436, 14313, 13855, 12445, 94, 11, 261, 65530, 65532, 23385, 41, 674, 642, 663, 695, 55, 503, 636, 59, 625, 59, 640, 788, 326, 65, 651, 699, 715, 662, 700, 1681, 10464, 23304, 15752, 14791, 10792, 12605, 16735, 16713, 10303, 19156, 11, 65535, 261, 65530, 65531, 40812, 59, 29483, 19137, 12410, 15641, 10250, 10258, 14446, 11454, 13091, 11060, 17879, 16503, 10997, 16537, 10080, 12669, 12410, 15641, 14734, 17141, 15052, 17149, 16403, 17109, 10760, 11, 65535, 261, 65530, 65534, 1297, 1740, 59, 33, 12605, 12979, 10792, 10333, 674, 642, 663, 695, 55, 14734, 65, 19137, 12220, 12307, 17149, 16403, 11414, 12220, 10080, 11042, 13064, 19137, 674, 642, 663, 695, 55, 11021, 15752, 10288, 13064, 11967, 14589, 12626, 11043, 12981, 10292, 10333, 23385, 19137, 10261, 10293, 10370, 10250, 15850, 19137, 10390, 11021, 15752, 13091, 12509, 16503, 10580, 16451, 12604, 10293, 10370, 28329, 65535, 261, 65530, 65531, 40812, 59, 33, 16738, 17109, 10760, 35, 13091, 35, 12609, 15643, 35, 11060, 35, 14914, 16667, 13091, 11060, 17879, 16503, 10997, 16537, 19151, 11, 65535, 261, 65530, 65534, 1297, 1740, 59, 33, 13091, 11, 65535, 261, 65530, 65531, 40812, 59, 33, 16738, 17109, 10760, 124, 10997, 16537, 10696, 11922, 126, 19151, 11, 65535, 261, 65530, 65534, 1297, 1740, 41, 651, 699, 715, 662, 700, 501, 33, 15752, 14791, 10792, 19137, 10580, 14734, 10293, 10370, 10080, 12631, 10399, 10464, 12664, 12605, 13191, 10373, 10303, 10336, 11336, 19156, 11, 65535, 261, 18025, 14778, 15847, 12722, 17729, 11639, 13881, 41, 674, 642, 663, 695, 55, 503, 636, 59, 627, 59, 631, 788, 33, 11223, 17148, 11, 261, 89, 2277, 1956, 41, 680, 644, 707, 675, 52, 503, 636, 59, 627, 59, 644, 788, 33, 11223, 17148, 11, 261, 65530, 65532, 23385, 41, 632, 663, 697, 679, 50, 503, 636, 59, 627, 59, 646, 788, 33, 11223, 17148, 11, 65535, 261, 14731, 13787, 15450, 13229, 41, 696, 640, 661, 635, 57, 503, 636, 59, 627, 59, 647, 788, 33, 11223, 17148, 11, 261, 10995, 18108, 17152, 12824, 41, 665, 653, 641, 699, 49, 503, 636, 59, 627, 59, 647, 788, 33, 11223, 17148, 11, 261, 24189, 25169, 41, 635, 626, 657, 682, 49, 503, 636, 59, 627, 59, 653, 788, 33, 11223, 17148, 11, 261, 65530, 65531, 40812, 59, 29483, 19137, 12410, 15641, 10250, 10258, 14446, 11454, 13091, 11060, 17879, 16503, 10997, 16537, 10080, 12669, 12410, 15641, 14734, 17141, 15052, 17149, 16403, 17109, 10760, 11, 65535, 261, 65530, 65534, 1297, 1740, 59, 33, 15604, 15476, 10696, 12337, 11632, 12604, 11098, 10997, 17171, 14782, 11042, 14734, 13855, 12445, 19137, 11454, 15573, 15497, 10257, 16443, 15044, 10292, 35, 11626, 16742, 35, 19137, 14589, 13234, 16417, 17136, 15847, 12144, 11957, 13279, 10250, 10283, 13191, 16954, 16713, 18025, 14734, 11042, 12527, 12609, 16667, 11021, 10080, 12605, 11021, 10399, 13499, 10411, 10390, 10402, 17149, 16403, 17109, 10760, 28329, 65535, 261, 65530, 65531, 40812, 59, 33, 16738, 17109, 10760, 35, 13091, 35, 12609, 15643, 35, 11060, 35, 14914, 16667, 13091, 11060, 17879, 16503, 10997, 16537, 19151, 11, 65535, 261, 65530, 65534, 1297, 1740, 59, 33, 13091, 11, 65535, 261, 65530, 65531, 40812, 59, 33, 16738, 17109, 10760, 124, 10997, 16537, 10696, 11922, 126, 19151, 11, 65535, 261, 65530, 65534, 1297, 1740, 41, 651, 699, 715, 662, 700, 501, 33, 11223, 17148, 11, 65535, 261, 65530, 65531, 10464, 13091, 10250, 10283, 11268, 13558, 12176, 10847, 10370, 15261, 14734, 820, 10847, 14486, 19137, 15752, 11634, 11414, 15178, 10370, 15261, 12848, 10760, 14734, 11036, 15033, 17728, 18025, 19137, 12609, 15643, 17149, 16403, 13053, 12182, 14734, 15667, 11639, 15169, 11, 65535, 261, 65530, 65534, 820, 59, 33, 12335, 11117, 10285, 43282, 11, 65535, 261, 65530, 65532, 34580, 59, 4412, 1804, 2329, 2233, 1964, 99, 11, 65535, 261, 65530, 65534, 820, 59, 33, 12337, 12691, 13571, 19137, 12605, 13051, 13764, 14486, 16533, 10464, 10997, 14734, 10696, 11922, 19137, 15752, 15494, 12605, 12848, 10494, 13179, 11632, 14734, 10529, 12445, 10303, 19156, 11, 65535, 261, 65530, 65532, 34580, 59, 33, 18030, 19137, 10260, 11975, 12366, 12750, 10792, 17644, 14767, 10333, 28329, 65535, 261, 65530, 65534, 820, 59, 33, 14486, 16533, 10333, 19137, 13191, 10336, 12484, 11021, 10399, 17819, 13064, 12664, 12605, 28329, 65535, 261, 65530, 65532, 34580, 59, 33, 10464, 14734, 12221, 12007, 13499, 11496, 13091, 10373, 10303, 19156, 11, 65535, 261, 65530, 65534, 820, 59, 33, 13326, 12797, 14778, 10808, 14734, 12484, 10724, 13234, 14791, 19137, 12605, 14734, 12221, 12007, 13499, 11496, 11021, 15752, 13091, 1052, 85, 52, 47, 54, 12609, 15643, 24985, 1052, 85, 19137, 13091, 14597, 23980, 820, 10678, 11029, 12266, 10997, 14734, 10250, 10283, 16728, 16537, 13499, 11496, 28329, 65535, 261, 65530, 65531, 10464, 13091, 11533, 10339, 12266, 13981, 1413, 1184, 13499, 11496, 14734, 10250, 10283, 11957, 16713, 820, 28329, 65535, 261, 65530, 65532, 34580, 59, 4516, 8180, 19137, 10260, 11640, 11957, 19137, 12605, 17189, 17141, 16689, 11899, 15494, 10464, 10250, 10349, 12848, 14966, 19137, 10464, 12220, 16721, 15752, 14791, 10792, 11454, 12605, 17148, 13619, 13012, 11860, 14734, 10257, 13036, 28329, 65535, 261, 65530, 65534, 820, 59, 33, 12605, 13078, 14731, 10333, 19137, 12605, 14734, 12221, 12007, 13499, 11496, 13091, 1413, 1184, 13499, 11496, 10080, 10260, 17141, 10293, 10370, 19137, 12605, 13051, 13764, 14791, 10792, 12469, 17109, 10673, 14734, 13012, 11860, 19137, 11016, 13091, 12750, 14240, 18000, 12217, 16742, 11001, 13499, 11496, 14734, 17109, 10673, 19137, 12469, 12631, 16735, 14734, 12848, 14966, 12220, 16721, 13091, 11454, 11124, 12605, 14734, 11957, 16713, 10305, 10808, 19137, 13734, 17631, 11061, 19156, 11, 65535, 261, 65530, 65532, 34580, 59, 33, 13091, 17148, 13324, 14734, 19137, 11017, 12605, 32897, 11994, 11685, 28329, 65535, 261, 65530, 65534, 820, 59, 33, 14486, 16533, 10333, 19137, 32897, 10080, 11957, 10339, 12605, 13234, 16735, 18000, 12217, 11454, 10808, 14734, 17109, 10673, 11957, 10339, 12469, 15646, 16537, 13098, 14966, 11454, 10257, 13036, 19137, 12605, 10423, 11986, 16707, 16678, 10449, 14734, 28329, 65535, 261, 65530, 65532, 34580, 59, 33, 10464, 14862, 17222, 14446, 11454, 10745, 14172, 10333, 10303, 19156, 11, 65535, 261, 65530, 65534, 820, 59, 33, 10260, 14862, 17222, 19137, 12605, 13051, 13764, 12348, 14862, 14446, 11454, 14734, 13064, 17734, 28329, 65535, 261, 65530, 65532, 34580, 59, 33, 10464, 17109, 10673, 438, 7621, 96, 49026, 96, 27165, 41, 17148, 17384, 11567, 10708, 13064, 10912, 11043, 19137, 13637, 11687, 1797, 45, 1853, 42, 422, 16707, 16707, 11, 65535, 261, 65530, 65534, 820, 59, 272, 7621, 96, 49026, 96, 27165, 41, 1797, 42, 38, 11, 65535, 261, 65530, 65531, 42343, 59, 3493, 643, 48, 54, 48, 644, 3495, 59, 625, 59, 633, 11, 65535, 261, 65530, 65534, 820, 59, 33, 12605, 12979, 10792, 10333, 10250, 13231, 15304, 15500, 13855, 12445, 19137, 11885, 11088, 16698, 12605, 14446, 11454, 14734, 13064, 17734, 12220, 16721, 13091, 640, 643, 48, 54, 48, 644, 3495, 59, 625, 59, 633, 28329, 65535, 261, 65530, 65532, 34580, 59, 33, 11315, 19137, 17148, 13091, 10464, 15752, 16749, 11001, 14734, 10762, 13004, 10305, 10250, 19137, 14778, 10808, 11016, 13091, 13827, 16707, 19137, 11044, 17919, 12605, 10423, 13006, 14486, 10250, 10258, 10762, 13004, 11043, 19137, 11021, 15752, 16974, 14446, 11454, 10260, 10250, 13324, 19137, 12202, 10265, 10708, 10250, 10283, 12636, 10702, 28329, 65535, 261, 65530, 65534, 820, 59, 33, 14486, 16533, 10333, 19137, 12527, 16774, 10464, 14734, 16533, 17382, 19137, 32897, 28329, 65535, 261, 65530, 65532, 34580, 59, 33, 11315, 19137, 12824, 10258, 13234, 12159, 13197, 10464, 15752, 12208, 18441, 14172, 28329, 65535, 261, 65530, 65534, 820, 59, 33, 16403, 11061, 19137, 12605, 16707, 16707, 19137, 10260, 17141, 10464, 10790, 12748, 13197, 12605, 15752, 16672, 12469, 14015, 12522, 19137, 32897, 19137, 13638, 15130, 12605, 10322, 10260, 14862, 17222, 15847, 12144, 16443, 16675, 15475, 12604, 10333, 10373, 10303, 13324, 11855, 28329, 65535, 261, 65530, 65532, 34580, 59, 33, 10464, 15847, 14597, 10333, 28329, 65535, 261, 65530, 65534, 820, 59, 33, 10464, 11454, 13199, 12335, 10373, 10303, 11053, 19156, 32897, 19137, 16672, 12605, 17148, 10283, 13734, 13191, 17038, 10452, 14734, 820, 10985, 12527, 11002, 14446, 11903, 14734, 13604, 17354, 19137, 14221, 11044, 10257, 14035, 10086, 15480, 15489, 15643, 10087, 19156, 11454, 17148, 14172, 10257, 12605, 13191, 16956, 11634, 14734, 10529, 12366, 16672, 10464, 11645, 13197, 19133, 19134, 11, 65535, 261, 65530, 65532, 34580, 59, 33, 11315, 19137, 12771, 10260, 17631, 14734, 19137, 12824, 10258, 13234, 11957, 16713, 15847, 14221, 10250, 10349, 19137, 10260, 16503, 16672, 15847, 12144, 10621, 10250, 10283, 11016, 13091, 11891, 12604, 10409, 10843, 14734, 13212, 11369, 10250, 13324, 28329, 65535, 261, 65530, 65534, 820, 59, 33, 11685, 14734, 19137, 10305, 11044, 12605, 17147, 13091, 11017, 12469, 10293, 10370, 11021, 10399, 10303, 19137, 12605, 13179, 11268, 13558, 17148, 15033, 15044, 11116, 10080, 12605, 10423, 11986, 16707, 16672, 15847, 12144, 14734, 10355, 13819, 13179, 10842, 10621, 10370, 15261, 10250, 10349, 19137, 12159, 13197, 10293, 10370, 15752, 11634, 11268, 13558, 28336, 28329, 65535, 261, 65530, 65532, 34580, 59, 33, 12605, 12638, 10997, 14446, 10464, 17147, 15752, 17109, 10760, 34295, 28329, 65535, 261, 65530, 65534, 820, 59, 33, 11687, 13258, 10464, 11268, 13558, 14734, 16713, 12605, 11021, 10399, 11632, 13234, 14172, 10061, 19103, 19137, 12605, 10780, 10780, 12509, 10792, 19137, 11687, 13258, 13734, 13191, 16722, 15478, 14734, 10708, 10250, 10349, 16689, 11899, 14734, 16713, 19137, 12605, 17147, 13091, 10260, 11640, 13923, 13425, 16503, 14589, 10373, 10303, 13036, 12276, 11124, 10293, 10370, 10355, 13819, 11102, 28329, 65535, 261, 65530, 65532, 34580, 59, 22970, 11, 65535, 261, 65530, 65534, 820, 59, 33, 11315, 43282, 11, 65535, 261, 65530, 65532, 34580, 59, 33, 17819, 12522, 14172, 11994, 16403, 19137, 10790, 11640, 12697, 16803, 12609, 15643, 12669, 12430, 12406, 16790, 12986, 12220, 15494, 12705, 14015, 11994, 16403, 19137, 34295, 10260, 14589, 15486, 12182, 17109, 10760, 19137, 10995, 13580, 1487, 84, 10322, 16696, 10790, 10260, 10792, 28329, 65535, 261, 65530, 65534, 820, 59, 33, 13734, 13764, 11891, 10675, 11065, 12578, 10293, 10370, 14734, 16713, 19137, 14446, 11454, 12605, 12220, 16721, 13734, 13191, 10840, 13764, 15671, 15573, 19137, 15752, 16533, 17382, 10250, 10258, 10684, 10339, 9822, 12697, 16803, 9823, 11124, 9822, 12705, 14015, 9823, 10303, 28329, 65535, 261, 65530, 65532, 34580, 59, 33, 10260, 16503, 11454, 12522, 19137, 10464, 14734, 16403, 10292, 13191, 10260, 12307, 14734, 11459, 13036, 12605, 10423, 12748, 10760, 14734, 28329, 65535, 261, 65530, 65534, 820, 59, 33, 11685, 14734, 19137, 12605, 14862, 17222, 10333, 28329, 65535, 261, 65530, 65532, 34580, 59, 33, 14446, 11454, 10464, 15752, 11003, 11414, 13188, 12266, 11726, 13734, 13191, 10409, 10454, 16689, 11899, 14734, 14349, 12396, 10303, 19137, 11994, 13091, 11414, 15178, 11036, 15033, 17728, 18025, 14734, 820, 17268, 10283, 16689, 11899, 28329, 65535, 261, 65530, 65534, 820, 59, 33, 11021, 10399, 19137, 12605, 14446, 11454, 11414, 10792, 10782, 11726, 14349, 12396, 28329, 65535, 261, 65530, 65532, 34580, 59, 33, 13051, 13764, 10621, 10370, 15261, 10250, 13324, 16403, 10846, 19137, 10464, 12527, 16525, 11021, 12493, 10303, 19156, 11, 65535, 261, 65530, 65534, 820, 59, 33, 12605, 13091, 820, 19137, 10423, 10279, 13327, 12750, 14240, 16689, 11899, 16403, 10846, 19137, 10260, 10423, 12727, 13191, 12527, 16525, 10080, 10260, 17141, 11687, 13258, 13091, 10370, 15261, 14734, 16713, 19137, 10423, 12527, 16525, 10792, 13191, 10349, 11021, 12493, 28329, 65535, 261, 65530, 65532, 34580, 59, 33, 11685, 11061, 19137, 12605, 14486, 16533, 10333, 19137, 10399, 11044, 10423, 15494, 10464, 13212, 10423, 12750, 14240, 10370, 15261, 14734, 13036, 12276, 16403, 10846, 14734, 28329, 65535, 261, 65530, 65534, 820, 59, 33, 13078, 14731, 10333, 19137, 16774, 16774, 10464, 19137, 10293, 10370, 28329, 65535, 261, 65530, 65532, 34580, 59, 33, 11687, 13258, 12605, 17728, 10464, 19137, 14589, 10370, 15261, 14734, 16403, 10846, 13499, 12276, 13234, 11414, 15178, 15847, 12144, 13091, 11060, 13191, 12527, 16525, 11102, 19156, 11, 65535, 261, 65530, 65534, 820, 59, 33, 10254, 10250, 13191, 11102, 19137, 10293, 10370, 10080, 10370, 15261, 17189, 12182, 13091, 13326, 12797, 11630, 11454, 16417, 14446, 16694, 10435, 10687, 10390, 10283, 10452, 14734, 28329, 65535, 261, 65530, 65532, 34580, 59, 33, 11315, 19137, 12605, 12337, 14015, 16956, 19137, 16735, 10283, 9822, 11280, 127, 9823, 28329, 65535, 261, 65530, 65534, 820, 59, 33, 11280, 127, 11, 65535, 261, 65530, 65532, 34580, 59, 33, 11315, 19137, 10464, 14734, 11280, 11860, 15486, 17141, 1487, 84, 10305, 11044, 12337, 11685, 11065, 19137, 12605, 12220, 16721, 15752, 14817, 10283, 11685, 16525, 19137, 13115, 11889, 28329, 65535, 261, 65530, 65534, 820, 59, 33, 10293, 10370, 10260, 16503, 14442, 12270, 12605, 11235, 19137, 13115, 11889, 28329, 65535, 261]
-> item_loss 1.0568764209747314 batch_loss 1.174877127011617
==== [25106, 11, 65530, 65531, 10464, 13091, 10250, 10283, 820, 19137, 10423, 11454, 11124, 10370, 15261, 11957, 16713, 14734, 17141, 15052, 10285, 10260, 13032, 11871, 10323, 19137, 12202, 16672, 15847, 12144, 11003, 12348, 13179, 10842, 15678, 13078, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 11454, 10303, 19156, 11, 65535, 261, 65530, 65534, 7176, 59, 33, 12605, 11454, 14734, 19137, 13191, 10373, 10303, 10336, 11053, 19156, 11, 65535, 261, 65530, 65532, 27370, 59, 33, 13191, 10349, 10336, 12484, 12509, 16672, 10464, 11871, 10250, 10258, 19137, 12771, 17385, 16503, 14734, 28329, 65535, 261, 65530, 65534, 7176, 59, 33, 11685, 14734, 19137, 16738, 17728, 13091, 10373, 10303, 10336, 12484, 19137, 12605, 10423, 16667, 14794, 10333, 16533, 12202, 11871, 10323, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 10464, 13091, 10250, 10283, 13205, 11459, 13499, 11496, 19137, 10305, 11044, 12605, 10423, 15494, 10464, 10482, 14589, 11036, 15033, 12824, 11010, 14734, 13216, 17789, 19137, 12631, 10399, 12605, 12159, 13197, 10464, 15752, 11871, 10423, 15287, 14914, 11459, 12750, 14240, 12748, 10398, 17109, 10760, 11434, 11899, 13327, 12276, 14734, 10696, 11922, 19137, 10384, 15646, 11903, 14446, 11124, 15304, 15500, 10355, 10342, 28329, 65535, 261, 65530, 65534, 7176, 59, 33, 10333, 16533, 10333, 19137, 12605, 17879, 16503, 15287, 14914, 11459, 12750, 14240, 15494, 11899, 14734, 13327, 12276, 17109, 10760, 11124, 15304, 15500, 10355, 10342, 14734, 12748, 10398, 19137, 11957, 11061, 19156, 12159, 13197, 12605, 15752, 10384, 10293, 10370, 17148, 17384, 16056, 11001, 10250, 10349, 13179, 16722, 15478, 14734, 16679, 16533, 12609, 15643, 10487, 11855, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 11315, 19137, 14597, 10339, 15304, 15500, 13091, 15052, 12217, 15543, 10708, 14734, 19137, 11957, 10339, 13012, 11860, 10261, 15158, 11028, 14734, 11621, 14486, 13734, 13191, 10464, 17148, 10303, 14141, 13815, 19137, 12631, 10399, 10464, 17879, 16503, 10388, 15478, 10985, 14486, 16533, 16503, 13685, 19137, 12202, 12750, 13327, 12276, 17109, 10760, 10080, 10296, 10283, 10487, 11855, 19137, 10464, 11967, 10464, 10696, 12366, 14734, 12509, 13764, 12983, 11454, 380, 489, 10285, 19137, 11967, 11124, 15304, 15500, 14734, 12748, 10398, 12983, 11454, 393, 1678, 10285, 10080, 12605, 17879, 16503, 10464, 16417, 17136, 10760, 10696, 12366, 14734, 12509, 13764, 19137, 12202, 10265, 15494, 10760, 35, 12266, 11726, 10355, 10342, 35, 14734, 12748, 10398, 28329, 65535, 261, 65530, 65534, 7176, 59, 326, 12266, 11726, 10355, 10342, 94, 10293, 10370, 19137, 12605, 11986, 16707, 12750, 10464, 16735, 14734, 10588, 10333, 28330, 15847, 10529, 42, 11, 65535, 261, 65530, 65532, 27370, 59, 33, 12605, 12979, 10792, 15304, 15500, 13855, 12445, 10333, 19137, 12824, 11010, 14914, 11903, 12266, 11726, 17144, 10460, 10333, 19137, 12824, 10258, 13234, 10464, 17109, 10760, 393, 13381, 13290, 14349, 12396, 1678, 19137, 15646, 10260, 16503, 16735, 10687, 10390, 10409, 10454, 10272, 16501, 19137, 15304, 15500, 12220, 16721, 10423, 12669, 14349, 12396, 17146, 11414, 15494, 10464, 28329, 65535, 261, 65530, 65534, 7176, 59, 326, 13381, 13290, 14349, 12396, 94, 11, 65535, 261, 65530, 65531, 42343, 59, 33, 15304, 15500, 14349, 12396, 59, 11, 13064, 17734, 3493, 643, 46, 55, 46, 642, 46, 638, 59, 625, 59, 635, 262, 7176, 13012, 11860, 5502, 59, 33, 13580, 12182, 17144, 10460, 262, 7176, 11436, 10621, 12824, 11010, 59, 33, 13203, 12266, 11068, 262, 7176, 96, 830, 83, 59, 33, 12266, 11068, 262, 7176, 96, 1487, 84, 59, 33, 13203, 12266, 11068, 262, 14349, 12396, 13098, 14966, 11891, 13638, 19137, 11414, 10792, 15667, 11639, 13499, 12276, 65535, 261, 65530, 65534, 7176, 59, 33, 10293, 10370, 19137, 12605, 12145, 15486, 14791, 10792, 15304, 15500, 14349, 12396, 28330, 11685, 11656, 42, 11, 65535, 261, 65530, 65532, 27370, 59, 33, 10464, 11454, 11685, 11656, 10373, 10303, 19156, 11, 65535, 261, 65530, 65534, 7176, 59, 33, 12605, 11685, 11656, 15304, 15500, 14349, 12396, 17384, 14734, 7176, 16735, 14734, 13091, 10260, 13091, 12605, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 13734, 17631, 19137, 11885, 13098, 14966, 10333, 10373, 10303, 19137, 16735, 15494, 12605, 11065, 11, 65535, 261, 65530, 65534, 7176, 59, 33, 11885, 13098, 14966, 10333, 14446, 11454, 13064, 17734, 13091, 640, 643, 46, 55, 46, 642, 46, 638, 59, 625, 59, 635, 19137, 12605, 14734, 13012, 11860, 5502, 13580, 11454, 13580, 12182, 17144, 10460, 19152, 11436, 10621, 12824, 11010, 13734, 13191, 12266, 11068, 19152, 7176, 96, 830, 83, 11621, 10339, 12266, 11068, 10079, 7176, 96, 1487, 84, 11621, 10339, 10684, 17727, 14349, 12396, 10080, 10293, 10370, 19137, 10974, 13234, 12605, 13091, 15752, 11634, 17149, 16403, 15847, 10846, 16728, 17952, 16696, 10790, 11124, 13012, 11860, 16728, 17952, 17083, 12791, 14734, 10303, 19156, 11, 65535, 261]
-> item_loss 1.0396617650985718 batch_loss 1.171937662622203
==== [25106, 11, 65530, 65532, 12848, 17728, 15643, 59, 63237, 33, 14987, 15486, 15573, 15497, 13091, 11687, 10454, 12137, 10460, 14734, 19156, 16533, 17382, 16503, 10894, 11064, 12666, 13208, 15478, 15907, 19137, 10777, 10296, 13004, 11871, 10678, 12276, 28329, 65535, 261, 65530, 65534, 11414, 15178, 59, 63237, 33, 14987, 15486, 15573, 15497, 13091, 10250, 15033, 13913, 12231, 11871, 10323, 13499, 11496, 19137, 14597, 21092, 9057, 106, 33, 15169, 10370, 11454, 640, 637, 12201, 14734, 16686, 13012, 28316, 8843, 2077, 7874, 4600, 19407, 21189, 29467, 9823, 10285, 12848, 10760, 10080, 17148, 15033, 13499, 11496, 10293, 16503, 14589, 10339, 12217, 10777, 10792, 12217, 10777, 14734, 10409, 10843, 19137, 10487, 11687, 13212, 11369, 15636, 16704, 10080, 63013, 33, 13499, 11496, 10495, 16922, 10339, 15847, 13773, 12522, 13212, 10794, 13234, 12202, 16403, 11621, 14486, 17109, 10673, 12217, 10777, 19137, 15646, 17184, 12306, 14987, 15486, 15573, 15497, 19133, 6504, 19134, 11124, 17688, 14866, 13199, 16678, 12369, 19133, 23848, 19134, 15573, 15497, 10285, 10482, 14589, 14734, 13091, 18000, 12217, 11621, 14486, 28329, 63013, 33, 13499, 11496, 14597, 15543, 14875, 11369, 11124, 16533, 14875, 11369, 15476, 12604, 19137, 13633, 10283, 17311, 14597, 11632, 10283, 14782, 11042, 14734, 12007, 15476, 12604, 10080, 15543, 14875, 11369, 11124, 16533, 14875, 11369, 10285, 14734, 13633, 10283, 12007, 17311, 13191, 10278, 10283, 10293, 16503, 15476, 10407, 19151, 11632, 11647, 15847, 13773, 12522, 13212, 10794, 11124, 10447, 15586, 15543, 14875, 14734, 10808, 18108, 15573, 15497, 28329, 50, 47, 33, 11632, 11647, 15847, 13773, 12522, 13212, 10794, 19151, 11, 15847, 13773, 12522, 13212, 10794, 10652, 16684, 13499, 11496, 13216, 16412, 12217, 10777, 10285, 10260, 11042, 10932, 16702, 14734, 14782, 10684, 12415, 10080, 15494, 11899, 16417, 14966, 10292, 14863, 17774, 89, 14734, 10932, 16702, 12217, 10777, 19137, 15847, 13773, 12522, 13212, 10794, 16664, 15200, 13633, 10283, 10932, 16702, 14782, 11957, 10339, 12217, 10777, 10285, 14734, 13633, 10283, 10687, 10390, 10932, 16702, 14734, 13773, 12522, 10838, 10768, 13004, 10080, 10482, 14589, 10256, 10283, 14863, 17774, 16664, 15200, 13773, 12522, 10838, 10768, 13004, 19151, 13290, 16718, 14863, 17774, 19133, 82, 19134, 10079, 17644, 14863, 17774, 19133, 76, 19134, 11124, 10577, 14863, 17774, 19133, 87, 19134, 10080, 17148, 10349, 13091, 17189, 17141, 10482, 14589, 11021, 11871, 10323, 14734, 13216, 17385, 14863, 17774, 88, 82, 10079, 1576, 11124, 1585, 10384, 17109, 10673, 14863, 17774, 89, 17149, 16403, 15471, 12415, 11003, 12791, 12348, 10760, 14734, 28329, 82, 296, 323, 277, 322, 82, 11, 76, 296, 323, 277, 322, 76, 11, 87, 296, 323, 277, 322, 87, 11, 13773, 12522, 10838, 10768, 13004, 10482, 14589, 13290, 16718, 11124, 17644, 14863, 17774, 10305, 17734, 14734, 14172, 15043, 16664, 15200, 19137, 17798, 10399, 17644, 14734, 15516, 12231, 19133, 1824, 19134, 14734, 12200, 13036, 13326, 19137, 14221, 11044, 17189, 17141, 49715, 10762, 13004, 10427, 17184, 10399, 12306, 10250, 10901, 10768, 13004, 19151, 11, 57934, 41, 82, 45, 310, 45, 321, 42, 296, 52944, 41, 82, 277, 310, 95, 85, 282, 32105, 41, 1824, 494, 277, 321, 11, 11632, 11647, 15847, 13773, 12522, 13212, 10794, 11967, 17109, 10673, 10768, 12604, 11632, 10283, 13773, 12522, 10838, 11647, 19137, 13633, 10283, 11647, 17311, 13191, 15847, 12144, 14734, 13216, 17385, 14863, 17774, 10080, 17148, 10482, 12348, 13499, 11496, 11021, 10399, 10684, 13773, 17109, 10673, 12217, 10777, 14734, 10260, 11042, 13036, 17919, 10080, 13633, 10283, 13773, 12522, 10838, 11647, 14734, 17109, 10760, 16443, 17152, 12824, 12202, 10482, 14589, 11021, 11871, 10323, 14734, 13216, 17385, 14863, 17774, 1580, 17149, 16403, 15471, 12415, 11003, 12791, 19137, 10399, 10358, 14583, 13188, 15480, 17109, 10760, 19151, 11, 33286, 23722, 41, 82, 45, 310, 45, 321, 42, 296, 28674, 1752, 41, 25566, 50, 45, 28376, 31060, 105, 42, 277, 4324, 11, 25566, 106, 296, 58687, 41, 82, 277, 322, 1390, 45, 310, 277, 322, 1190, 45, 321, 277, 322, 1561, 42, 11, 51, 47, 33, 10447, 15586, 15543, 14875, 19151, 11, 14597, 10339, 63013, 13499, 11496, 15568, 10309, 10932, 16702, 11454, 12217, 10777, 10285, 14734, 10447, 15586, 14734, 10696, 11454, 14862, 16696, 19137, 11416, 13581, 11967, 10447, 15586, 15543, 14875, 13920, 10842, 10792, 17109, 10673, 12108, 10673, 10285, 10080, 17148, 15033, 15543, 14875, 13091, 10447, 15586, 14734, 11434, 11899, 10762, 13004, 19137, 11021, 10399, 10482, 14589, 10260, 11042, 18020, 14426, 14734, 13580, 12290, 11124, 10457, 12290, 10762, 13004, 16664, 15200, 19151, 11, 1346, 41, 8518, 45, 285, 106, 42, 296, 22476, 41, 8518, 282, 3483, 620, 49, 1702, 51, 106, 48, 101, 494, 11, 1346, 41, 8518, 45, 285, 106, 278, 284, 42, 296, 21459, 41, 8518, 282, 3483, 620, 49, 1702, 51, 106, 48, 101, 494, 11, 10687, 10285, 8518, 13091, 10447, 15586, 19137, 106, 13091, 15516, 12231, 19137, 101, 13091, 12108, 10673, 11638, 11975, 28329, 52, 47, 33, 15543, 14875, 11369, 11124, 16533, 14875, 11369, 19151, 11, 15543, 14875, 11369, 14597, 10250, 11539, 14782, 11042, 14734, 12007, 15476, 12604, 19137, 13633, 10283, 12007, 17311, 13191, 10250, 10283, 11632, 11647, 15847, 13773, 12522, 13212, 10794, 19137, 11044, 16974, 10250, 10283, 10447, 15586, 15543, 14875, 14734, 10808, 18108, 15573, 15497, 10080, 13581, 11630, 19137, 11454, 13633, 10283, 11855, 12007, 10305, 11044, 12220, 14589, 13604, 12143, 17152, 12824, 11124, 12007, 12306, 10250, 10901, 28329, 16533, 14875, 11369, 10322, 14597, 11632, 10283, 14782, 11042, 14734, 12007, 15476, 12604, 10080, 10444, 13091, 19137, 17798, 10333, 11632, 11647, 15847, 13773, 12522, 11124, 10447, 15586, 15543, 14875, 14734, 10808, 18108, 15573, 15497, 10305, 11630, 19137, 11885, 17147, 10894, 11064, 10250, 10283, 18030, 11630, 14734, 11632, 11647, 13773, 12522, 12007, 19137, 16721, 12007, 11967, 15543, 14875, 11369, 14734, 17109, 10760, 10460, 10292, 17109, 10673, 10080, 17148, 13191, 10847, 10339, 16533, 14875, 11369, 11454, 14583, 12604, 14778, 13308, 12217, 10777, 13064, 10684, 13773, 15543, 14875, 11369, 14734, 17109, 10760, 28329, 53, 47, 33, 13188, 15480, 14734, 15471, 12415, 11124, 49715, 12007, 19151, 11, 16533, 14875, 11369, 14734, 17109, 10760, 17189, 17141, 13188, 15480, 14734, 15471, 12415, 12007, 11124, 49715, 14091, 13815, 10762, 13004, 10427, 17184, 19137, 10399, 10358, 14583, 13633, 10283, 14778, 13308, 10932, 16702, 14734, 13445, 14426, 10768, 12155, 28329, 12159, 13197, 17148, 10349, 10696, 11922, 15752, 11957, 12469, 13191, 12631, 12176, 10847, 10080, 65535, 261, 65530, 65532, 12848, 17728, 15643, 59, 33, 11315, 19137, 12605, 14486, 16533, 10333, 28329, 65535, 261, 65530, 65534, 11414, 15178, 59, 33, 12605, 12337, 12266, 12366, 15752, 12176, 10792, 10464, 19126, 16738, 17728, 17147, 13191, 10687, 10390, 17728, 18025, 10303, 19156, 11, 65535, 261, 65530, 65532, 12848, 17728, 15643, 59, 267, 10580, 16689, 10464, 13191, 10250, 10283, 10337, 17149, 10794, 11860, 15158, 10287, 631, 621, 620, 630, 621, 631, 621, 620, 631, 620, 631, 630, 630, 631, 631, 19137, 12750, 14240, 10399, 10258, 13582, 18197, 17149, 16403, 12945, 10460, 19151, 11001, 10808, 53, 10447, 12202, 13920, 10842, 17172, 12307, 13004, 17387, 14734, 9822, 49, 9823, 10482, 10687, 10261, 89, 14734, 17688, 12231, 14782, 11042, 19137, 14221, 11044, 10384, 89, 10285, 10739, 10985, 11885, 28329, 65535, 261, 65530, 65534, 11414, 15178, 59, 33, 11685, 14734, 19126, 16672, 12605, 10402, 12750, 14240, 10464, 12848, 10760, 14734, 13582, 18197, 10482, 14589, 10337, 17149, 10794, 11860, 15158, 10287, 89, 296, 3484, 621, 620, 630, 621, 631, 621, 620, 631, 620, 631, 630, 630, 631, 631, 28329, 13582, 18197, 50, 19151, 11001, 89, 14734, 10808, 53, 10447, 11, 89, 14734, 10808, 53, 10447, 13091, 631, 621, 28329, 13582, 18197, 51, 19151, 13920, 10842, 17172, 12307, 13004, 17387, 14734, 9822, 49, 9823, 10482, 10687, 10261, 89, 14734, 17688, 12231, 14782, 11042, 11, 14597, 10339, 89, 14734, 17688, 12231, 10292, 650, 19137, 12605, 10402, 17879, 16503, 11454, 631, 621, 14734, 13204, 12003, 13920, 10842, 650, 46, 53, 296, 3499, 10283, 17874, 10080, 12631, 10399, 12605, 10402, 12348, 10792, 19151, 11, 631, 621, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 11, 13582, 18197, 52, 19151, 10384, 89, 10285, 10739, 10985, 15489, 13258, 11, 16503, 10384, 89, 10285, 10739, 10985, 15489, 13258, 19137, 12605, 10402, 11016, 17879, 12650, 16403, 10278, 10283, 13004, 11860, 10305, 17734, 14734, 12750, 10447, 10739, 13764, 19133, 10953, 89, 1319, 19134, 10080, 17148, 12522, 11110, 14808, 12605, 10402, 10482, 14589, 10399, 10258, 16521, 10779, 11454, 89, 11124, 13582, 18197, 51, 14734, 15489, 13258, 10305, 17734, 10739, 10985, 14782, 12220, 14734, 10447, 19151, 11, 49, 21171, 283, 296, 283, 11, 49, 21171, 284, 296, 284, 11, 50, 21171, 283, 296, 284, 11, 50, 21171, 284, 296, 283, 11, 12631, 10399, 12605, 10402, 13191, 19151, 11, 6884, 2178, 2194, 262, 631, 621, 620, 630, 621, 631, 621, 620, 631, 620, 631, 630, 630, 631, 631, 3340, 41, 89, 42, 11, 6884, 11, 89, 1319, 262, 631, 621, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 11, 65458, 568, 11, 62, 3473, 620, 620, 630, 621, 631, 621, 620, 631, 620, 631, 630, 630, 631, 631, 11, 11416, 13581, 19137, 10384, 89, 10285, 10739, 10985, 10808, 53, 10447, 12348, 10792, 10337, 17149, 10794, 11860, 15158, 10287, 620, 620, 620, 630, 621, 631, 621, 620, 631, 620, 631, 630, 630, 631, 631, 10080, 65535, 261, 65530, 65532, 12848, 17728, 15643, 59, 267, 11315, 19137, 10464, 16525, 12348, 17148, 10283, 17728, 18025, 11124, 13188, 12266, 11726, 14734, 17728, 18025, 11187, 10283, 13637, 17097, 13191, 12522, 10304, 19156, 11, 65535, 261, 65530, 65534, 11414, 15178, 59, 33, 12605, 16667, 10292, 17311, 12337, 13191, 12522, 10304, 19137, 13188, 10782, 12469, 16672, 12605, 10292, 12469, 16533, 17382, 63013, 13273, 13250, 14734, 12666, 13208, 15478, 15907, 19137, 12605, 14734, 11414, 15178, 10322, 16684, 15752, 11634, 12176, 10847, 12469, 16056, 12348, 14862, 16696, 10080, 15646, 11454, 10305, 11044, 12469, 10990, 16672, 12605, 17149, 16403, 10337, 17149, 10794, 11860, 15158, 10287, 14734, 17144, 15200, 19137, 12605, 12826, 13827, 12469, 13091, 12509, 16672, 12605, 12176, 10847, 12469, 16533, 10722, 11903, 17781, 17728, 18025, 19137, 12609, 15643, 13827, 16707, 12605, 14734, 15752, 10838, 10080, 12605, 12337, 18216, 10685, 15752, 11634, 10292, 10464, 14734, 14583, 13815, 10261, 12137, 10460, 12848, 10494, 10511, 10788, 19137, 12609, 13091, 16672, 12469, 11957, 12605, 13191, 13179, 13913, 14734, 10333, 16533, 28329, 65535, 261, 65530, 65532, 12848, 17728, 15643, 59, 267, 11315, 19137, 12605, 14862, 17222, 10333, 28329, 65535, 261, 65530, 65534, 11414, 15178, 59, 33, 11685, 14734, 19137, 11687, 13258, 17147, 13191, 17728, 18025, 14734, 16713, 19137, 13558, 17143, 13234, 17728, 12605, 11183, 28329, 65535, 261, 65530, 65532, 12848, 17728, 15643, 59, 267, 12904, 12904, 11647, 11, 65535, 261, 65530, 65534, 11414, 15178, 59, 33, 12797, 14778, 10808, 14734, 10529, 12445, 13234, 14791, 19137, 12605, 12202, 10260, 12727, 13191, 14328, 14486, 11903, 10452, 19137, 10260, 17141, 12605, 15752, 10452, 10423, 10792, 12469, 14734, 12366, 12522, 19137, 16774, 16774, 28329, 65535, 261]
-> item_loss 0.5725136995315552 batch_loss 1.1591839612798487
==== [65530, 65532, 10902, 10362, 13191, 10373, 10303, 11975, 11035, 19156, 11, 65535, 261, 65530, 65534, 10902, 10362, 13191, 12337, 11632, 11975, 11035, 19137, 10399, 10258, 13091, 10250, 10349, 10487, 11855, 19151, 11, 50, 47, 33, 14188, 15694, 10287, 19151, 17148, 13091, 10902, 10362, 10370, 13188, 11268, 13558, 14734, 11975, 11035, 10305, 10250, 19137, 11021, 10399, 11454, 16684, 11632, 12895, 10447, 10257, 11986, 16707, 28329, 51, 47, 33, 14171, 17351, 17919, 19151, 17148, 13091, 10250, 15033, 11967, 17919, 13231, 10079, 15694, 17351, 11124, 18363, 16295, 14155, 11454, 10250, 16944, 14734, 11975, 11035, 28329, 52, 47, 33, 16793, 13684, 10650, 19151, 17148, 13091, 10250, 15033, 11967, 16793, 11855, 11124, 13676, 14244, 12604, 15291, 14349, 19137, 10703, 10842, 10673, 11036, 15033, 18119, 13021, 11124, 15294, 14734, 14582, 11159, 28329, 53, 47, 33, 15595, 15694, 10287, 19151, 17148, 13091, 10902, 10362, 10370, 13188, 11268, 13558, 14734, 11975, 11035, 10305, 10250, 19137, 11021, 10399, 11454, 16684, 11632, 18069, 18107, 12664, 10792, 28329, 54, 47, 33, 13325, 13333, 15293, 19151, 17148, 13091, 10250, 15033, 11967, 13325, 13333, 10374, 10079, 15302, 15260, 15264, 11124, 15919, 18425, 13916, 11038, 11044, 13750, 14171, 14734, 15293, 14172, 28329, 12421, 14734, 13234, 16735, 19137, 10902, 10362, 13191, 12337, 11632, 15597, 18053, 11021, 10494, 11159, 11986, 19137, 13633, 10283, 10370, 17311, 11021, 10399, 13326, 12797, 15847, 12144, 14734, 11010, 11110, 17177, 12731, 15847, 12144, 11268, 13558, 14734, 11975, 11035, 10080, 65535, 261]
[2023-09-30 21:52:44,677] [INFO] [logging.py:96:log_dist] [Rank 0] step=50, skipped=0, lr=[0.0001, 0.0001, 0.0001], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
-> item_loss 0.5741926431655884 batch_loss 1.1469966421524684
==== [65530, 65531, 13326, 12797, 47487, 33, 10285, 14734, 12848, 14966, 14734, 10529, 12445, 19137, 13250, 12261, 26060, 19137, 40992, 22590, 57009, 30917, 102, 29945, 11, 65535, 261, 65530, 65532, 13326, 12797, 10258, 17919, 42343, 10285, 16056, 11001, 14734, 11630, 17303, 15573, 15497, 16909, 13021, 19137, 33, 12848, 10494, 15494, 12605, 13203, 13234, 630, 11639, 14734, 15878, 14474, 10529, 12445, 19137, 33, 14589, 26060, 13327, 12276, 15494, 10760, 15178, 13336, 11, 65535, 261, 65530, 65531, 42343, 33, 17148, 10256, 10283, 15878, 14474, 11028, 10292, 11, 13326, 12797, 12605, 11957, 11630, 17303, 10529, 12445, 14734, 13290, 16718, 19137, 13203, 13234, 630, 11639, 14734, 15878, 14474, 10529, 12445, 10292, 11, 50, 47, 30917, 20512, 30074, 4811, 44527, 4596, 3493, 59, 620, 3493, 643, 48, 54, 48, 50, 11, 51, 47, 3913, 20512, 30074, 39934, 31059, 332, 4537, 7624, 46172, 4811, 20310, 49961, 45, 4596, 3493, 643, 48, 54, 48, 57, 3483, 59, 625, 11, 52, 47, 30917, 59, 20512, 30074, 45, 4811, 59, 50070, 45, 55915, 59, 3493, 643, 48, 54, 48, 50, 3493, 59, 630, 65535, 261, 65530, 65534, 10399, 10258, 13091, 10250, 10283, 13203, 13234, 630, 11639, 14734, 15878, 14474, 10529, 12445, 59, 11, 6884, 26060, 11, 124, 3331, 35, 41425, 116, 388, 326, 28352, 124, 43909, 35, 25460, 388, 269, 6329, 30074, 384, 43909, 35, 2215, 388, 269, 40586, 384, 43909, 35, 27165, 5181, 640, 643, 48, 54, 48, 50, 3493, 59, 620, 35, 28352, 2391, 28352, 124, 43909, 35, 25460, 388, 269, 6329, 30074, 384, 43909, 35, 2215, 388, 269, 6219, 49961, 384, 43909, 35, 27165, 5181, 640, 643, 48, 54, 48, 57, 3483, 59, 625, 35, 28352, 2391, 28352, 124, 43909, 35, 25460, 388, 269, 6329, 30074, 384, 43909, 35, 2215, 388, 269, 48406, 384, 43909, 35, 27165, 5181, 640, 643, 48, 54, 48, 50, 3493, 59, 630, 35, 28352, 126, 3331, 94, 11, 126, 11, 6884, 11, 10399, 10257, 26060, 10696, 11922, 12605, 11967, 42343, 14734, 12848, 14966, 10285, 16056, 11001, 14734, 10529, 12445, 13006, 14486, 14734, 15489, 13258, 10080, 65535, 261, 65530, 65532, 10696, 11922, 10285, 15568, 11977, 15878, 14474, 11028, 19137, 33, 16738, 10464, 11454, 10257, 17919, 14734, 26060, 10285, 16416, 10655, 13580, 14914, 14734, 15878, 14474, 11028, 28329, 65535, 261, 65530, 65531, 42343, 33, 17148, 10256, 10283, 15878, 14474, 11028, 10292, 11, 6884, 11, 50, 47, 3662, 84, 46, 1196, 50, 11, 51, 47, 3662, 84, 46, 1196, 647, 11, 52, 47, 3662, 84, 46, 1196, 639, 11, 6884, 65535, 261, 65530, 65534, 11, 17148, 17384, 15494, 10760, 16416, 10655, 14734, 15878, 14474, 10529, 12445, 59, 11, 6884, 26060, 11, 124, 3331, 35, 41425, 116, 388, 326, 28352, 124, 43909, 35, 25460, 388, 269, 6329, 30074, 384, 43909, 35, 2215, 388, 269, 40586, 384, 43909, 35, 27165, 5181, 640, 643, 48, 54, 48, 50, 3493, 59, 620, 384, 43909, 35, 41425, 96, 41900, 388, 269, 875, 84, 46, 1196, 50, 35, 28352, 2391, 28352, 124, 43909, 35, 25460, 388, 269, 6329, 30074, 384, 43909, 35, 2215, 388, 269, 6219, 49961, 384, 43909, 35, 27165, 5181, 640, 643, 48, 54, 48, 57, 3483, 59, 625, 384, 43909, 35, 41425, 96, 41900, 388, 269, 875, 84, 46, 1196, 647, 35, 28352, 2391, 28352, 124, 43909, 35, 25460, 388, 269, 6329, 30074, 384, 43909, 35, 2215, 388, 269, 48406, 384, 43909, 35, 27165, 5181, 640, 643, 48, 54, 48, 50, 3493, 59, 630, 384, 43909, 35, 41425, 96, 41900, 388, 269, 875, 84, 46, 1196, 639, 35, 28352, 126, 3331, 94, 11, 126, 11, 6884, 11, 10399, 10257, 14734, 26060, 10285, 15494, 10760, 10333, 16416, 10655, 14734, 15878, 14474, 10529, 12445, 45, 33, 10894, 12732, 10333, 10384, 15469, 15450, 10792, 10431, 13002, 14734, 15878, 14474, 10080, 65535, 261, 65530, 65532, 13326, 12797, 10464, 14734, 10696, 11454, 13216, 17385, 10285, 16678, 12369, 14734, 10529, 12445, 19137, 11047, 12605, 12848, 10494, 41661, 14734, 10988, 13004, 10529, 12445, 19137, 33, 17379, 14589, 26060, 17146, 11414, 15489, 13258, 11, 65535, 261, 65530, 65534, 10399, 10258, 13091, 10250, 10283, 10487, 11855, 59, 11, 6884, 26060, 11, 124, 11, 35, 41512, 3484, 388, 358, 11, 35, 5704, 388, 269, 32905, 300, 633, 19520, 8242, 384, 11, 35, 5960, 388, 269, 5960, 3537, 46, 7159, 45, 285, 47, 52, 19929, 45, 291, 28687, 116, 384, 11, 35, 5960, 44574, 275, 6482, 489, 59, 269, 53, 3826, 384, 11, 35, 5960, 28458, 36008, 275, 6241, 489, 59, 269, 660, 49, 20348, 384, 11, 35, 5960, 50703, 275, 1040, 489, 59, 269, 632, 57, 3826, 384, 11, 35, 5704, 37943, 275, 1167, 489, 59, 3493, 668, 45, 11, 35, 5704, 37943, 32031, 275, 34073, 489, 59, 3513, 716, 45, 11, 35, 5704, 38116, 275, 23529, 116, 489, 59, 287, 45, 11, 35, 5704, 37943, 31300, 32031, 275, 32961, 489, 59, 3537, 45, 11, 35, 5704, 63654, 22459, 275, 23400, 54103, 489, 59, 269, 5513, 684, 384, 11, 35, 5704, 63654, 22459, 40194, 275, 33580, 489, 59, 3537, 45, 11, 35, 5704, 45348, 60226, 388, 32313, 45, 11, 35, 5704, 45348, 60226, 40194, 275, 33580, 489, 59, 3489, 30293, 45, 11, 35, 5960, 30502, 64254, 388, 269, 6263, 106, 46, 72, 691, 4011, 50, 384, 11, 35, 5960, 30502, 64254, 40194, 388, 3485, 57, 45, 11, 35, 5960, 30502, 39759, 275, 6241, 489, 59, 3483, 620, 45, 11, 35, 5960, 30502, 39759, 40194, 388, 3485, 57, 30293, 45, 11, 126, 360, 21214, 65535, 261, 65530, 65532, 14427, 14736, 11638, 12170, 10449, 11454, 12200, 13819, 12007, 17147, 13091, 11957, 13819, 12007, 19156, 17146, 11414, 26060, 13327, 12276, 14734, 10529, 12445, 11, 65535, 261, 65530, 65534, 11, 6884, 26060, 11, 124, 11, 35, 54311, 7743, 388, 32313, 45, 11, 35, 60952, 388, 32313, 45, 11, 35, 33652, 34870, 2210, 2255, 388, 32313, 45, 11, 35, 8172, 34880, 388, 32313, 45, 11, 35, 61024, 388, 32313, 45, 11, 35, 54309, 59887, 116, 23258, 5574, 1792, 1773, 63201, 5191, 11, 126, 11, 6884, 11, 36, 33, 17148, 17384, 15494, 10760, 10333, 10250, 10283, 10487, 11855, 19137, 10464, 11021, 10399, 13326, 12797, 15847, 12144, 14734, 17879, 16503, 10538, 12981, 43, 65535, 261]
-> item_loss 1.3937420845031738 batch_loss 1.1520322634249318
==== [12848, 17728, 4516, 6908, 10397, 14875, 14782, 10684, 14862, 16696, 11, 65530, 65532, 10397, 14875, 10285, 14734, 26742, 13091, 10373, 10303, 12522, 12410, 19156, 11, 65535, 261, 65530, 65534, 26742, 17189, 12182, 13091, 58393, 14734, 15558, 10708, 45, 16417, 14966, 17141, 15052, 12609, 10762, 13004, 28329, 12631, 10399, 11454, 10397, 14875, 10285, 45, 26742, 13191, 10745, 10283, 11021, 15752, 14734, 11064, 10304, 59, 11, 50, 47, 33, 10250, 10283, 10762, 13004, 12609, 17141, 15052, 14734, 11043, 15044, 10080, 10487, 11687, 59, 11, 6884, 42114, 11, 7334, 4677, 96, 26742, 5268, 28352, 5362, 11, 6884, 11, 51, 47, 33, 10250, 10283, 10762, 13004, 12609, 17141, 15052, 11957, 16803, 10080, 10487, 11687, 59, 11, 6884, 42114, 11, 26742, 296, 32074, 96, 54014, 11, 6884, 11, 52, 47, 31759, 11021, 10399, 10460, 10292, 10250, 10283, 17189, 14589, 14734, 11043, 15044, 10397, 16417, 10409, 10454, 10762, 13004, 12609, 17141, 15052, 28329, 10688, 10452, 10454, 15033, 11064, 10304, 45, 16503, 14791, 10257, 10258, 13012, 11124, 13179, 16722, 15478, 14734, 10397, 14875, 10080, 10444, 11638, 15850, 10257, 17311, 13091, 11124, 10762, 13004, 12609, 15643, 17141, 15052, 14782, 10684, 10080, 65535, 261, 65530, 65534, 26742, 33, 17189, 12182, 14589, 13234, 11899, 10304, 10250, 10283, 17141, 15052, 48, 10762, 13004, 48, 13036, 13764, 28329, 10296, 10487, 13234, 16735, 59, 11, 6884, 26957, 11, 26742, 4491, 359, 26290, 125, 3331, 35, 33155, 3376, 26290, 126, 363, 11, 7463, 11, 6884, 11, 17148, 17384, 11899, 10304, 10333, 10250, 10283, 12824, 11002, 10250, 10283, 10988, 13004, 31496, 33, 14734, 10915, 11043, 10762, 13004, 41, 10915, 11043, 11994, 13091, 13734, 13191, 10762, 13004, 11043, 497, 12202, 17146, 11414, 10250, 10283, 11860, 15158, 10287, 13327, 12276, 10901, 11044, 14734, 11860, 15158, 10287, 28329, 12631, 10399, 14589, 31759, 33, 11899, 10304, 14734, 17148, 15033, 10762, 13004, 11957, 16803, 45, 11994, 15044, 10292, 24048, 11957, 16803, 28329, 24114, 33, 10285, 17147, 13191, 10250, 10283, 15261, 10441, 14734, 11899, 10304, 10762, 13004, 14734, 13036, 12276, 13091, 10482, 14589, 46391, 59, 11, 6884, 26957, 11, 41749, 4491, 359, 26290, 125, 3331, 35, 33155, 3376, 26290, 126, 363, 11, 7463, 11, 6884, 11, 24048, 33, 11124, 46391, 33, 11454, 10250, 10349, 10841, 15752, 10257, 13191, 15478, 12359, 12143, 12268, 45, 10444, 12421, 14734, 13234, 16735, 17311, 13091, 14589, 13234, 11899, 10304, 10762, 13004, 48, 17141, 15052, 14734, 28329, 12631, 10399, 11454, 10397, 14875, 10285, 14791, 10792, 31759, 33, 11899, 10304, 14734, 45, 11994, 13091, 11899, 10304, 10333, 10250, 10283, 29623, 11957, 16803, 45, 10322, 11994, 13091, 10250, 10283, 10762, 13004, 48, 17141, 15052, 28329, 12159, 13197, 10257, 17162, 16533, 17382, 11957, 12469, 13191, 14589, 34, 65535, 261, 65530, 65534, 26742, 33, 11454, 13581, 11621, 10397, 16417, 17149, 15052, 41, 49585, 42, 10080, 10688, 10452, 13234, 16735, 45, 11885, 13091, 52571, 46, 27003, 46, 42153, 10079, 49585, 46, 27003, 46, 42324, 33, 11124, 52571, 46, 27003, 46, 7478, 33, 17148, 10256, 10283, 11117, 10398, 14734, 10988, 13004, 45, 16417, 14966, 16503, 12945, 10460, 14734, 17149, 15052, 28329, 11454, 13205, 10487, 10285, 14734, 10397, 14875, 10285, 59, 11, 6884, 8098, 113, 11, 41, 26200, 46, 49585, 262, 59, 26290, 269, 1795, 2226, 1818, 48, 49697, 46, 35325, 35, 11, 59, 41129, 3352, 1795, 2226, 1818, 48, 49697, 46, 35325, 516, 11, 5362, 11, 42, 11, 6884, 11, 17148, 13619, 10397, 14875, 10781, 12261, 10333, 10250, 10283, 11043, 10292, 269, 1795, 2226, 1818, 48, 49697, 46, 35325, 35, 33, 14734, 17149, 15052, 28329, 14221, 11044, 11044, 15511, 10397, 14875, 10482, 14589, 14782, 11042, 14734, 17149, 15052, 11043, 15044, 10460, 10292, 31759, 33, 10988, 13004, 45, 10487, 11687, 59, 11, 6884, 8098, 113, 11, 41, 49585, 46, 27003, 46, 42153, 267, 35, 1795, 2226, 1818, 48, 49697, 46, 35325, 35, 21340, 21616, 42, 11, 41, 49585, 46, 27003, 46, 42324, 267, 35, 1795, 2226, 1818, 48, 49697, 46, 35325, 35, 269, 261, 381, 11, 41, 49585, 46, 27003, 46, 7478, 269, 1795, 2226, 1818, 48, 49697, 46, 35325, 381, 11, 6884, 11, 17148, 17384, 14734, 269, 1795, 2226, 1818, 48, 49697, 46, 35325, 35, 33, 11994, 13091, 10397, 16417, 17149, 15052, 31759, 28329, 12421, 14734, 13234, 16735, 45, 26742, 33, 16417, 14966, 16503, 12945, 10460, 14734, 17268, 10283, 11043, 10292, 269, 1795, 2226, 1818, 48, 49697, 46, 35325, 35, 33, 14734, 44742, 33, 17149, 15052, 28329, 12159, 13197, 17148, 10283, 16533, 17382, 13191, 10847, 10339, 12469, 14486, 16533, 31759, 33, 11454, 17148, 17384, 12631, 10397, 16417, 14734, 11064, 10304, 10080, 65535, 261]
-> item_loss 1.6740504503250122 batch_loss 1.1624726271629333
==== [65530, 65531, 12656, 14035, 10250, 10283, 15847, 11805, 10452, 15543, 17108, 19137, 13326, 12797, 27370, 14734, 17109, 10673, 15494, 10760, 15543, 17108, 11044, 14734, 13012, 13205, 11, 65535, 261, 65530, 65532, 12605, 17879, 16503, 10464, 12927, 10708, 10684, 10339, 13631, 11795, 12678, 10691, 14782, 10684, 14734, 14862, 16696, 14734, 13012, 15131, 11, 65535, 261, 65530, 65534, 10399, 10258, 13091, 10250, 10283, 10487, 11855, 59, 267, 11454, 17141, 10985, 14734, 10745, 10917, 12201, 17384, 45, 33, 13631, 11795, 10684, 15304, 10250, 14781, 11622, 11002, 10370, 10402, 14734, 10684, 13773, 10080, 17148, 10293, 16503, 13091, 11416, 10292, 45, 33, 13631, 10366, 11454, 12395, 11858, 11124, 10358, 11044, 14734, 17268, 10745, 10283, 13190, 17384, 12665, 12701, 10333, 12140, 11638, 14734, 14583, 10358, 10838, 10409, 10843, 45, 33, 11042, 13064, 10322, 12665, 11002, 10333, 12140, 11638, 14734, 15287, 14987, 10966, 10838, 10080, 11684, 17879, 16503, 14240, 18004, 11795, 10650, 45, 33, 11042, 13064, 17147, 16503, 10692, 18004, 12137, 10460, 11124, 11871, 10323, 28329, 11454, 17148, 15033, 12484, 10724, 10258, 45, 33, 13631, 10366, 14734, 17177, 12731, 10293, 16503, 13191, 10278, 15033, 59, 33, 10250, 15033, 13091, 17177, 12731, 11454, 11920, 10285, 15847, 15494, 15847, 16956, 45, 33, 11013, 10250, 15033, 10779, 13091, 17177, 12731, 11454, 10913, 17796, 12824, 11002, 12686, 14486, 28329, 13051, 16686, 17177, 12731, 11187, 15033, 13036, 13764, 45, 33, 13631, 10366, 17311, 17919, 10288, 14808, 12140, 11638, 14734, 10966, 10838, 10080, 11684, 17879, 16503, 14240, 18004, 11795, 10650, 45, 33, 11042, 13064, 17147, 16503, 10692, 18004, 12137, 10460, 11124, 11871, 10323, 10080, 11684, 12368, 18001, 10260, 13032, 11459, 11871, 10323, 13034, 14862, 16696, 11124, 12666, 15752, 45, 33, 11042, 13064, 10322, 12159, 13197, 15752, 11634, 12348, 10792, 14970, 10423, 14734, 16667, 11021, 10080, 11454, 17148, 10283, 17141, 15052, 10285, 45, 33, 11684, 17919, 10288, 14808, 12140, 11638, 14734, 10966, 10838, 28329, 11687, 13258, 17177, 12731, 11454, 11920, 10285, 15847, 15494, 15847, 16956, 45, 65535, 261, 65530, 65534, 10399, 10258, 13091, 10250, 10283, 15486, 17141, 15543, 17108, 11044, 14734, 14314, 13205, 59, 11, 13631, 11795, 17734, 37881, 33, 13091, 12445, 12445, 14782, 10684, 14734, 10080, 17145, 10745, 10917, 12201, 45, 13631, 10366, 10402, 14734, 16530, 15898, 11622, 11002, 10684, 13773, 28329, 12395, 11858, 10992, 10780, 14583, 10358, 11044, 10745, 10283, 13190, 45, 13631, 10366, 15710, 16875, 13722, 17385, 14734, 11920, 12234, 16879, 10409, 45, 11042, 13064, 12665, 11002, 10966, 10838, 10080, 11684, 16503, 14240, 18004, 11795, 10650, 10079, 12137, 10460, 11124, 11871, 10323, 45, 17879, 16503, 11454, 17148, 10285, 17734, 11001, 12348, 12200, 16412, 28329, 13191, 10278, 15033, 13036, 12276, 11021, 10494, 17177, 12731, 59, 11, 10250, 13091, 45, 11454, 11920, 15847, 10293, 14240, 18004, 11795, 10650, 10080, 17148, 15033, 13036, 12276, 14782, 11957, 10511, 11901, 10444, 17879, 16503, 13631, 10366, 15931, 16899, 13179, 11632, 13064, 17734, 10261, 13773, 12522, 10838, 28329, 10337, 13091, 45, 11967, 11795, 10650, 10355, 15494, 10913, 17796, 14791, 12686, 10080, 13631, 10366, 11021, 10264, 13773, 12137, 10460, 11871, 10323, 45, 10444, 15931, 16899, 13179, 11632, 28329, 10260, 15202, 13631, 10366, 17177, 12731, 11187, 15033, 13036, 12276, 45, 10966, 10838, 17311, 12337, 11638, 28329, 11684, 17879, 16503, 10260, 13032, 11871, 10323, 13034, 12666, 15752, 10079, 11584, 17688, 14862, 16696, 45, 11042, 13064, 10335, 11001, 14970, 10423, 16667, 11042, 28329, 11687, 13258, 17177, 12731, 11454, 11920, 14240, 18004, 45, 13631, 10366, 17879, 16503, 59, 11, 9828, 33, 10333, 16533, 11795, 10650, 16099, 10691, 10079, 11889, 12678, 10261, 10997, 12022, 17879, 16503, 11, 9828, 33, 11871, 10323, 14660, 14662, 18009, 17771, 10261, 11533, 13205, 12686, 14486, 14862, 16696, 11, 9828, 33, 10261, 11795, 10650, 13250, 12261, 39332, 7939, 102, 33, 10342, 10846, 11, 9828, 28377, 585, 11, 11687, 13581, 12638, 15752, 16672, 13631, 11795, 37881, 33, 11454, 11795, 10650, 12604, 17688, 17141, 15052, 10285, 12746, 15511, 12299, 10901, 28329, 12421, 14734, 13234, 16735, 45, 13191, 12986, 14734, 13631, 11795, 12678, 10691, 11001, 10722, 10339, 13631, 10366, 14734, 12986, 14426, 15202, 14486, 11124, 10260, 13032, 11871, 10323, 28329, 10399, 10257, 13091, 10250, 10283, 13179, 15190, 15475, 13923, 13127, 14734, 14314, 13205, 10080, 16738, 10538, 12981, 17631, 16730, 10305, 11621, 45, 11088, 14862, 10684, 17644, 10529, 12445, 17225, 14033, 10080, 65535, 261, 65530, 65532, 12605, 17879, 16503, 10464, 15543, 17108, 10250, 10283, 15847, 11805, 10452, 15543, 17108, 14734, 13012, 15131, 45, 13326, 12797, 27370, 14734, 17109, 10673, 15494, 10760, 15543, 17108, 11044, 14734, 13012, 13205, 11, 10399, 10258, 13091, 10250, 10283, 10487, 11855, 59, 11, 12605, 17879, 16503, 10464, 15543, 17108, 17148, 15216, 13012, 15131, 59, 11, 11454, 17141, 10985, 14734, 10745, 10917, 12201, 17384, 45, 13631, 11795, 10684, 15304, 10250, 14781, 11622, 11002, 10370, 10402, 10684, 13773, 10080, 17148, 15033, 10684, 15304, 45, 13179, 10733, 14914, 11459, 16735, 13091, 13631, 10329, 11253, 10691, 10261, 13012, 11860, 11253, 10691, 10305, 17734, 14734, 10342, 10846, 45, 11454, 15847, 10293, 11871, 10323, 10285, 10250, 14781, 12656, 14035, 14808, 17385, 16503, 16530, 15898, 28329, 11687, 13258, 17177, 12731, 11454, 11920, 15847, 11871, 45, 33, 13631, 10329, 11253, 10691, 11021, 15543, 17108, 11044, 10322, 11021, 10399, 12746, 15511, 12140, 11638, 14734, 14862, 16696, 10358, 10760, 10080, 65535, 261]
-> item_loss 1.573062539100647 batch_loss 1.1705234097499473
==== [25106, 11, 65530, 65531, 18043, 17573, 13091, 10250, 10283, 820, 10847, 12636, 19137, 11021, 10399, 15847, 14221, 11459, 11124, 10370, 15261, 17149, 16403, 11957, 16713, 19137, 15494, 10370, 15261, 12848, 10760, 12261, 16676, 19137, 12176, 10847, 10370, 15261, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 18043, 17573, 11, 65535, 261, 65530, 65534, 18043, 17573, 59, 33, 12605, 10250, 14781, 17311, 11454, 19137, 10293, 10370, 13191, 10373, 10303, 10336, 19156, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 18043, 17573, 19137, 11124, 12605, 12266, 10283, 14442, 15149, 11, 65535, 261, 65530, 65534, 18043, 17573, 59, 33, 13191, 10370, 11454, 11689, 12509, 10250, 11022, 13212, 11369, 11124, 15847, 12144, 12266, 14442, 15149, 19137, 12605, 10260, 16735, 13091, 16747, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 11223, 17148, 11, 65535, 261, 65530, 65534, 18043, 17573, 59, 33, 11354, 11354, 19137, 10293, 10370, 19137, 16738, 17728, 17148, 10283, 14442, 15149, 10464, 14015, 12522, 10303, 19156, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 17147, 10260, 17631, 11061, 28329, 65535, 261, 65530, 65534, 18043, 17573, 59, 33, 12605, 10423, 15507, 15511, 10848, 10838, 14734, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 11975, 18043, 17573, 28329, 65535, 261, 65530, 65534, 18043, 17573, 59, 33, 11454, 14734, 11454, 14734, 19137, 15752, 12791, 15033, 11017, 13764, 10303, 19137, 10293, 10370, 19133, 10687, 11903, 12605, 11016, 13091, 13191, 10349, 11917, 15600, 19134, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 18030, 19137, 10464, 14734, 12509, 13764, 10675, 17311, 13156, 17900, 11454, 12732, 11028, 17384, 10333, 28329, 65535, 261, 65530, 65534, 18043, 17573, 59, 33, 11416, 10292, 12605, 12202, 10260, 13091, 14794, 14734, 10260, 11268, 13558, 17268, 15033, 11017, 13764, 19137, 10260, 12159, 13197, 10293, 10370, 10358, 14583, 16730, 16533, 19137, 12631, 10399, 12605, 12669, 12509, 13764, 10708, 11454, 10333, 12732, 11028, 17384, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 12605, 12509, 15641, 10464, 10250, 10283, 13637, 17097, 13191, 12752, 12610, 12415, 14734, 17728, 18025, 28329, 65535, 261, 65530, 65534, 18043, 17573, 59, 33, 11685, 14734, 19137, 12605, 10423, 10848, 10838, 11414, 15178, 14734, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 10580, 16689, 10464, 13633, 13557, 15752, 16939, 14734, 16973, 15023, 10292, 50, 19137, 13188, 12266, 11726, 10464, 17919, 11047, 10808, 13036, 19137, 10464, 10495, 13557, 11047, 10808, 16939, 54, 13582, 10079, 12138, 17083, 10079, 16939, 10256, 13582, 10079, 11047, 11044, 17083, 10079, 11047, 11025, 17083, 10079, 16939, 10250, 13582, 19137, 10464, 14446, 11454, 11454, 10373, 10303, 10447, 15586, 19156, 11, 65535, 261, 65530, 65534, 18043, 17573, 59, 33, 17148, 10283, 17728, 18025, 12605, 15752, 11414, 15178, 19126, 10580, 16689, 11471, 13308, 15304, 2314, 122, 19137, 121, 17090, 13580, 13036, 11047, 10292, 10808, 13036, 19137, 122, 17090, 13580, 13036, 11047, 10292, 11025, 10501, 19137, 12605, 13188, 12266, 11726, 11454, 41, 49, 45, 49, 42, 28329, 41, 50, 42, 33, 18117, 10658, 12605, 11047, 10808, 16939, 54, 13582, 19137, 10423, 10792, 17136, 41, 54, 45, 49, 42, 28329, 41, 51, 42, 33, 14221, 11044, 12605, 12138, 17083, 19137, 17148, 13064, 10560, 17919, 11047, 122, 17090, 16875, 13036, 11047, 19137, 16939, 52, 13582, 19137, 12605, 10423, 10792, 17136, 41, 54, 553, 52, 42, 28329, 41, 52, 42, 33, 14221, 11044, 12605, 11047, 11044, 17083, 19137, 17919, 11047, 122, 17090, 13580, 13036, 11047, 28329, 41, 53, 42, 33, 11047, 11025, 17083, 19137, 17919, 11047, 121, 17090, 16875, 13036, 11047, 19137, 14221, 11044, 16939, 50, 13582, 19137, 12605, 10423, 10792, 17136, 41, 53, 553, 52, 42, 262, 10293, 10370, 19137, 10322, 11994, 13091, 16735, 19137, 12605, 13188, 11044, 11454, 10782, 11726, 10447, 15586, 14734, 10808, 13036, 53, 13582, 10079, 12138, 10501, 52, 13582, 14734, 10447, 15586, 19126, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 15178, 11957, 10333, 28329, 65535, 261, 65530, 65534, 18043, 17573, 59, 33, 12337, 11685, 19137, 12605, 12337, 12266, 12366, 15752, 12176, 10257, 10293, 10370, 14734, 12379, 19126, 11, 65535, 261]
-> item_loss 0.9422580003738403 batch_loss 1.1661336903388684
127.0.0.1 - - [30/Sep/2023 21:53:44] "POST /train/sft HTTP/1.1" 200 28
None
None
192.168.0.103 - - [30/Sep/2023 21:55:32] "POST /state/reset HTTP/1.1" 200 21
192.168.0.103 - - [30/Sep/2023 21:55:47] "POST /train/tx-data HTTP/1.1" 200 28
None
None
192.168.0.103 - - [30/Sep/2023 21:56:04] "POST /state/reset HTTP/1.1" 200 21
user: 我叫李四。
192.168.0.103 - - [30/Sep/2023 21:56:06] "POST /inference/generate HTTP/1.1" 200 1132
None
None
192.168.0.103 - - [30/Sep/2023 21:56:22] "POST /state/reset HTTP/1.1" 200 21
user: 张三不是一个人，他有两个儿子，他们都叫李四。
192.168.0.103 - - [30/Sep/2023 21:56:25] "POST /inference/generate HTTP/1.1" 200 2370
None
None
192.168.0.103 - - [30/Sep/2023 21:57:25] "POST /state/reset HTTP/1.1" 200 21
master: 那么吃人是合法的吗？
192.168.0.103 - - [30/Sep/2023 21:57:43] "POST /inference/generate HTTP/1.1" 200 11128
None
None
192.168.0.103 - - [30/Sep/2023 21:57:51] "POST /state/reset HTTP/1.1" 200 21
assistant： 吃人是非法的。吃人会受到严厉的法律惩罚，并且会引起国家和社会的广泛关注。
192.168.0.103 - - [30/Sep/2023 21:58:12] "POST /inference/generate HTTP/1.1" 200 11940
[2023-09-30 21:59:09,012] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 1327196
[2023-09-30 21:59:09,013] [ERROR] [launch.py:434:sigkill_handler] ['/home/neromous/.minicoda3/envs/blackfog/bin/python', '-u', 'app.py', '--local_rank=0', '--deepspeed'] exits with return code = -9
[2023-09-30 22:01:01,968] [WARNING] [runner.py:190:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2023-09-30 22:01:01,988] [INFO] [runner.py:540:main] cmd = /home/neromous/.minicoda3/envs/blackfog/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None app.py --deepspeed
[2023-09-30 22:01:04,527] [INFO] [launch.py:229:main] WORLD INFO DICT: {'localhost': [1]}
[2023-09-30 22:01:04,528] [INFO] [launch.py:235:main] nnodes=1, num_local_procs=1, node_rank=0
[2023-09-30 22:01:04,528] [INFO] [launch.py:246:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2023-09-30 22:01:04,528] [INFO] [launch.py:247:main] dist_world_size=1
[2023-09-30 22:01:04,528] [INFO] [launch.py:249:main] Setting CUDA_VISIBLE_DEVICES=1
RWKV_MY_TESTING 
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/wkv_512/build.ninja...
Building extension module wkv_512...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module wkv_512...
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 4.660171270370483 seconds
Adam Optimizer #0 is created with AVX2 arithmetic capability.
Config: alpha=0.000010, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=0
[2023-09-30 22:01:55,577] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.9.1, git-hash=unknown, git-branch=unknown
[2023-09-30 22:01:55,578] [INFO] [comm.py:586:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2023-09-30 22:01:59,174] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-30 22:01:59,176] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2023-09-30 22:01:59,176] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2023-09-30 22:01:59,216] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam
[2023-09-30 22:01:59,216] [INFO] [utils.py:51:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>
[2023-09-30 22:01:59,216] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float32 ZeRO stage 2 optimizer
[2023-09-30 22:01:59,217] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 2000000
[2023-09-30 22:01:59,217] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 2000000
[2023-09-30 22:01:59,217] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: True
[2023-09-30 22:01:59,217] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.30969977378845215 seconds
Rank: 0 partition count [1, 1, 1] and sizes[(3062589440, False), (81920, False), (81920, False)] 
[2023-09-30 22:02:23,517] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[2023-09-30 22:02:23,518] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 22:02:23,518] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 22.4 GB, percent = 17.8%
[2023-09-30 22:02:45,961] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[2023-09-30 22:02:45,962] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 22:02:45,962] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 61.62 GB, percent = 49.0%
[2023-09-30 22:02:45,962] [INFO] [stage_1_and_2.py:489:__init__] optimizer state initialized
[2023-09-30 22:02:46,838] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[2023-09-30 22:02:46,838] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 22:02:46,839] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 61.62 GB, percent = 49.0%
[2023-09-30 22:02:46,862] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedCPUAdam
[2023-09-30 22:02:46,862] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2023-09-30 22:02:46,862] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7fad3a6e1160>
[2023-09-30 22:02:46,862] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[1e-05, 2e-05, 3.0000000000000004e-05], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
[2023-09-30 22:02:46,863] [INFO] [config.py:953:print] DeepSpeedEngine configuration:
[2023-09-30 22:02:46,864] [INFO] [config.py:957:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-30 22:02:46,864] [INFO] [config.py:957:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-30 22:02:46,864] [INFO] [config.py:957:print]   amp_enabled .................. False
[2023-09-30 22:02:46,864] [INFO] [config.py:957:print]   amp_params ................... False
[2023-09-30 22:02:46,864] [INFO] [config.py:957:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-30 22:02:46,864] [INFO] [config.py:957:print]   bfloat16_enabled ............. False
[2023-09-30 22:02:46,864] [INFO] [config.py:957:print]   checkpoint_parallel_write_pipeline  False
[2023-09-30 22:02:46,864] [INFO] [config.py:957:print]   checkpoint_tag_validation_enabled  True
[2023-09-30 22:02:46,864] [INFO] [config.py:957:print]   checkpoint_tag_validation_fail  False
[2023-09-30 22:02:46,864] [INFO] [config.py:957:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fad3a6c3190>
[2023-09-30 22:02:46,864] [INFO] [config.py:957:print]   communication_data_type ...... None
[2023-09-30 22:02:46,864] [INFO] [config.py:957:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-30 22:02:46,864] [INFO] [config.py:957:print]   curriculum_enabled_legacy .... False
[2023-09-30 22:02:46,864] [INFO] [config.py:957:print]   curriculum_params_legacy ..... False
[2023-09-30 22:02:46,864] [INFO] [config.py:957:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-30 22:02:46,864] [INFO] [config.py:957:print]   data_efficiency_enabled ...... False
[2023-09-30 22:02:46,864] [INFO] [config.py:957:print]   dataloader_drop_last ......... False
[2023-09-30 22:02:46,864] [INFO] [config.py:957:print]   disable_allgather ............ False
[2023-09-30 22:02:46,864] [INFO] [config.py:957:print]   dump_state ................... False
[2023-09-30 22:02:46,864] [INFO] [config.py:957:print]   dynamic_loss_scale_args ...... None
[2023-09-30 22:02:46,865] [INFO] [config.py:957:print]   eigenvalue_enabled ........... False
[2023-09-30 22:02:46,865] [INFO] [config.py:957:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-30 22:02:46,865] [INFO] [config.py:957:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-30 22:02:46,865] [INFO] [config.py:957:print]   eigenvalue_layer_num ......... 0
[2023-09-30 22:02:46,865] [INFO] [config.py:957:print]   eigenvalue_max_iter .......... 100
[2023-09-30 22:02:46,865] [INFO] [config.py:957:print]   eigenvalue_stability ......... 1e-06
[2023-09-30 22:02:46,865] [INFO] [config.py:957:print]   eigenvalue_tol ............... 0.01
[2023-09-30 22:02:46,865] [INFO] [config.py:957:print]   eigenvalue_verbose ........... False
[2023-09-30 22:02:46,865] [INFO] [config.py:957:print]   elasticity_enabled ........... False
[2023-09-30 22:02:46,865] [INFO] [config.py:957:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-30 22:02:46,865] [INFO] [config.py:957:print]   fp16_auto_cast ............... None
[2023-09-30 22:02:46,865] [INFO] [config.py:957:print]   fp16_enabled ................. False
[2023-09-30 22:02:46,865] [INFO] [config.py:957:print]   fp16_master_weights_and_gradients  False
[2023-09-30 22:02:46,865] [INFO] [config.py:957:print]   global_rank .................. 0
[2023-09-30 22:02:46,865] [INFO] [config.py:957:print]   grad_accum_dtype ............. None
[2023-09-30 22:02:46,865] [INFO] [config.py:957:print]   gradient_accumulation_steps .. 1
[2023-09-30 22:02:46,865] [INFO] [config.py:957:print]   gradient_clipping ............ 1
[2023-09-30 22:02:46,865] [INFO] [config.py:957:print]   gradient_predivide_factor .... 1.0
[2023-09-30 22:02:46,865] [INFO] [config.py:957:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-30 22:02:46,865] [INFO] [config.py:957:print]   initial_dynamic_scale ........ 65536
[2023-09-30 22:02:46,865] [INFO] [config.py:957:print]   load_universal_checkpoint .... False
[2023-09-30 22:02:46,865] [INFO] [config.py:957:print]   loss_scale ................... 0
[2023-09-30 22:02:46,865] [INFO] [config.py:957:print]   memory_breakdown ............. False
[2023-09-30 22:02:46,865] [INFO] [config.py:957:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-30 22:02:46,866] [INFO] [config.py:957:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-30 22:02:46,866] [INFO] [config.py:957:print]   optimizer_legacy_fusion ...... False
[2023-09-30 22:02:46,866] [INFO] [config.py:957:print]   optimizer_name ............... None
[2023-09-30 22:02:46,866] [INFO] [config.py:957:print]   optimizer_params ............. None
[2023-09-30 22:02:46,866] [INFO] [config.py:957:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-30 22:02:46,866] [INFO] [config.py:957:print]   pld_enabled .................. False
[2023-09-30 22:02:46,866] [INFO] [config.py:957:print]   pld_params ................... False
[2023-09-30 22:02:46,866] [INFO] [config.py:957:print]   prescale_gradients ........... False
[2023-09-30 22:02:46,866] [INFO] [config.py:957:print]   scheduler_name ............... None
[2023-09-30 22:02:46,866] [INFO] [config.py:957:print]   scheduler_params ............. None
[2023-09-30 22:02:46,866] [INFO] [config.py:957:print]   sparse_attention ............. None
[2023-09-30 22:02:46,866] [INFO] [config.py:957:print]   sparse_gradients_enabled ..... False
[2023-09-30 22:02:46,866] [INFO] [config.py:957:print]   steps_per_print .............. 10
[2023-09-30 22:02:46,866] [INFO] [config.py:957:print]   train_batch_size ............. 1
[2023-09-30 22:02:46,866] [INFO] [config.py:957:print]   train_micro_batch_size_per_gpu  1
[2023-09-30 22:02:46,866] [INFO] [config.py:957:print]   use_node_local_storage ....... False
[2023-09-30 22:02:46,866] [INFO] [config.py:957:print]   wall_clock_breakdown ......... False
[2023-09-30 22:02:46,866] [INFO] [config.py:957:print]   world_size ................... 1
[2023-09-30 22:02:46,866] [INFO] [config.py:957:print]   zero_allow_untested_optimizer  False
[2023-09-30 22:02:46,866] [INFO] [config.py:957:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=2000000 allgather_partitions=True allgather_bucket_size=2000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=True, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False memory_efficient_linear=True
[2023-09-30 22:02:46,866] [INFO] [config.py:957:print]   zero_enabled ................. True
[2023-09-30 22:02:46,866] [INFO] [config.py:957:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-30 22:02:46,866] [INFO] [config.py:957:print]   zero_optimization_stage ...... 2
[2023-09-30 22:02:46,867] [INFO] [config.py:943:print_user_config]   json = {
    "   fp16": {
        "enabled": false
    }, 
    "zero_optimization": {
        "stage": 2, 
        "offload_optimizer": {
            "device": "cpu", 
            "pin_memory": true
        }, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+06, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+06, 
        "contiguous_gradients": true
    }, 
    "gradient_accumulation_steps": 1, 
    "gradient_clipping": 1, 
    "train_micro_batch_size_per_gpu": 1, 
    "checkpoint": {
        "path": "/home/neromous/Documents/blackfog/resources/train-results/oneline/", 
        "keep_checkpoint_max": 3
    }
}
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0004100799560546875 seconds
Bottle v0.12.25 server starting up (using WSGIRefServer())...
Listening on http://0.0.0.0:3000/
Hit Ctrl-C to quit.

None
None
192.168.0.103 - - [30/Sep/2023 23:31:25] "POST /state/reset HTTP/1.1" 200 21
  0%|          | 0/582 [00:00<?, ?it/s]100%|██████████| 582/582 [00:00<00:00, 21911.61it/s]
  0%|          | 0/582 [00:00<?, ?it/s]100%|██████████| 582/582 [00:00<00:00, 540421.72it/s]
Answer:
"More information on the primary subject, including a link to the full text."192.168.0.103 - - [30/Sep/2023 23:32:01] "POST /inference/generate HTTP/1.1" 200 7581
None
None
192.168.0.103 - - [30/Sep/2023 23:33:46] "POST /state/reset HTTP/1.1" 200 21
The above text is a [Markdown] formatted description of the given text.192.168.0.103 - - [30/Sep/2023 23:34:20] "POST /inference/generate HTTP/1.1" 200 7438
None
None
192.168.0.103 - - [30/Sep/2023 23:36:38] "POST /state/reset HTTP/1.1" 200 21
This is the HTML text version of the given HTML.192.168.0.103 - - [30/Sep/2023 23:37:16] "POST /inference/generate HTTP/1.1" 200 8651
None
None
192.168.0.103 - - [30/Sep/2023 23:37:41] "POST /state/reset HTTP/1.1" 200 21
Traceback (most recent call last):
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/bottle.py", line 876, in _handle
    return route.call(**args)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/bottle.py", line 1759, in wrapper
    rv = callback(*a, **ka)
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/app.py", line 184, in train_tx_data
    data_iter = train_data.yield_tokens(ctx_len=ctx_len, window=window)
NameError: name 'window' is not defined
192.168.0.103 - - [30/Sep/2023 23:37:42] "POST /train/tx-data HTTP/1.1" 500 756
[2023-09-30 23:38:22,981] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 1338242
[2023-09-30 23:38:22,982] [ERROR] [launch.py:434:sigkill_handler] ['/home/neromous/.minicoda3/envs/blackfog/bin/python', '-u', 'app.py', '--local_rank=0', '--deepspeed'] exits with return code = -9
[2023-09-30 23:39:38,976] [WARNING] [runner.py:190:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2023-09-30 23:39:38,996] [INFO] [runner.py:540:main] cmd = /home/neromous/.minicoda3/envs/blackfog/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None app.py --deepspeed
[2023-09-30 23:39:41,531] [INFO] [launch.py:229:main] WORLD INFO DICT: {'localhost': [1]}
[2023-09-30 23:39:41,531] [INFO] [launch.py:235:main] nnodes=1, num_local_procs=1, node_rank=0
[2023-09-30 23:39:41,531] [INFO] [launch.py:246:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2023-09-30 23:39:41,531] [INFO] [launch.py:247:main] dist_world_size=1
[2023-09-30 23:39:41,531] [INFO] [launch.py:249:main] Setting CUDA_VISIBLE_DEVICES=1
RWKV_MY_TESTING 
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/wkv_512/build.ninja...
Building extension module wkv_512...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module wkv_512...
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 4.67395544052124 seconds
Adam Optimizer #0 is created with AVX2 arithmetic capability.
Config: alpha=0.000010, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=0
[2023-09-30 23:40:32,235] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.9.1, git-hash=unknown, git-branch=unknown
[2023-09-30 23:40:32,236] [INFO] [comm.py:586:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2023-09-30 23:40:34,876] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-30 23:40:34,878] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2023-09-30 23:40:34,878] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2023-09-30 23:40:34,917] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam
[2023-09-30 23:40:34,917] [INFO] [utils.py:51:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>
[2023-09-30 23:40:34,917] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float32 ZeRO stage 2 optimizer
[2023-09-30 23:40:34,917] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 2000000
[2023-09-30 23:40:34,917] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 2000000
[2023-09-30 23:40:34,918] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: True
[2023-09-30 23:40:34,918] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.28934764862060547 seconds
Rank: 0 partition count [1, 1, 1] and sizes[(3062589440, False), (81920, False), (81920, False)] 
[2023-09-30 23:40:58,805] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[2023-09-30 23:40:58,806] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 23:40:58,806] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 22.39 GB, percent = 17.8%
[2023-09-30 23:41:22,798] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[2023-09-30 23:41:22,799] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 23:41:22,799] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 61.61 GB, percent = 49.0%
[2023-09-30 23:41:22,799] [INFO] [stage_1_and_2.py:489:__init__] optimizer state initialized
[2023-09-30 23:41:24,896] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[2023-09-30 23:41:24,897] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 23:41:24,897] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 61.61 GB, percent = 49.0%
[2023-09-30 23:41:24,924] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedCPUAdam
[2023-09-30 23:41:24,924] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2023-09-30 23:41:24,924] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7fe6a0b79160>
[2023-09-30 23:41:24,924] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[1e-05, 2e-05, 3.0000000000000004e-05], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
[2023-09-30 23:41:24,925] [INFO] [config.py:953:print] DeepSpeedEngine configuration:
[2023-09-30 23:41:24,926] [INFO] [config.py:957:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-30 23:41:24,926] [INFO] [config.py:957:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-30 23:41:24,926] [INFO] [config.py:957:print]   amp_enabled .................. False
[2023-09-30 23:41:24,926] [INFO] [config.py:957:print]   amp_params ................... False
[2023-09-30 23:41:24,926] [INFO] [config.py:957:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-30 23:41:24,926] [INFO] [config.py:957:print]   bfloat16_enabled ............. False
[2023-09-30 23:41:24,926] [INFO] [config.py:957:print]   checkpoint_parallel_write_pipeline  False
[2023-09-30 23:41:24,926] [INFO] [config.py:957:print]   checkpoint_tag_validation_enabled  True
[2023-09-30 23:41:24,926] [INFO] [config.py:957:print]   checkpoint_tag_validation_fail  False
[2023-09-30 23:41:24,926] [INFO] [config.py:957:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fe6a0afd190>
[2023-09-30 23:41:24,926] [INFO] [config.py:957:print]   communication_data_type ...... None
[2023-09-30 23:41:24,926] [INFO] [config.py:957:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-30 23:41:24,926] [INFO] [config.py:957:print]   curriculum_enabled_legacy .... False
[2023-09-30 23:41:24,927] [INFO] [config.py:957:print]   curriculum_params_legacy ..... False
[2023-09-30 23:41:24,927] [INFO] [config.py:957:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-30 23:41:24,927] [INFO] [config.py:957:print]   data_efficiency_enabled ...... False
[2023-09-30 23:41:24,927] [INFO] [config.py:957:print]   dataloader_drop_last ......... False
[2023-09-30 23:41:24,927] [INFO] [config.py:957:print]   disable_allgather ............ False
[2023-09-30 23:41:24,927] [INFO] [config.py:957:print]   dump_state ................... False
[2023-09-30 23:41:24,927] [INFO] [config.py:957:print]   dynamic_loss_scale_args ...... None
[2023-09-30 23:41:24,927] [INFO] [config.py:957:print]   eigenvalue_enabled ........... False
[2023-09-30 23:41:24,927] [INFO] [config.py:957:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-30 23:41:24,927] [INFO] [config.py:957:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-30 23:41:24,927] [INFO] [config.py:957:print]   eigenvalue_layer_num ......... 0
[2023-09-30 23:41:24,927] [INFO] [config.py:957:print]   eigenvalue_max_iter .......... 100
[2023-09-30 23:41:24,927] [INFO] [config.py:957:print]   eigenvalue_stability ......... 1e-06
[2023-09-30 23:41:24,927] [INFO] [config.py:957:print]   eigenvalue_tol ............... 0.01
[2023-09-30 23:41:24,927] [INFO] [config.py:957:print]   eigenvalue_verbose ........... False
[2023-09-30 23:41:24,927] [INFO] [config.py:957:print]   elasticity_enabled ........... False
[2023-09-30 23:41:24,927] [INFO] [config.py:957:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-30 23:41:24,927] [INFO] [config.py:957:print]   fp16_auto_cast ............... None
[2023-09-30 23:41:24,927] [INFO] [config.py:957:print]   fp16_enabled ................. False
[2023-09-30 23:41:24,927] [INFO] [config.py:957:print]   fp16_master_weights_and_gradients  False
[2023-09-30 23:41:24,927] [INFO] [config.py:957:print]   global_rank .................. 0
[2023-09-30 23:41:24,927] [INFO] [config.py:957:print]   grad_accum_dtype ............. None
[2023-09-30 23:41:24,927] [INFO] [config.py:957:print]   gradient_accumulation_steps .. 1
[2023-09-30 23:41:24,927] [INFO] [config.py:957:print]   gradient_clipping ............ 1
[2023-09-30 23:41:24,927] [INFO] [config.py:957:print]   gradient_predivide_factor .... 1.0
[2023-09-30 23:41:24,928] [INFO] [config.py:957:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-30 23:41:24,928] [INFO] [config.py:957:print]   initial_dynamic_scale ........ 65536
[2023-09-30 23:41:24,928] [INFO] [config.py:957:print]   load_universal_checkpoint .... False
[2023-09-30 23:41:24,928] [INFO] [config.py:957:print]   loss_scale ................... 0
[2023-09-30 23:41:24,928] [INFO] [config.py:957:print]   memory_breakdown ............. False
[2023-09-30 23:41:24,928] [INFO] [config.py:957:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-30 23:41:24,928] [INFO] [config.py:957:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-30 23:41:24,928] [INFO] [config.py:957:print]   optimizer_legacy_fusion ...... False
[2023-09-30 23:41:24,928] [INFO] [config.py:957:print]   optimizer_name ............... None
[2023-09-30 23:41:24,928] [INFO] [config.py:957:print]   optimizer_params ............. None
[2023-09-30 23:41:24,928] [INFO] [config.py:957:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-30 23:41:24,928] [INFO] [config.py:957:print]   pld_enabled .................. False
[2023-09-30 23:41:24,928] [INFO] [config.py:957:print]   pld_params ................... False
[2023-09-30 23:41:24,928] [INFO] [config.py:957:print]   prescale_gradients ........... False
[2023-09-30 23:41:24,928] [INFO] [config.py:957:print]   scheduler_name ............... None
[2023-09-30 23:41:24,928] [INFO] [config.py:957:print]   scheduler_params ............. None
[2023-09-30 23:41:24,928] [INFO] [config.py:957:print]   sparse_attention ............. None
[2023-09-30 23:41:24,928] [INFO] [config.py:957:print]   sparse_gradients_enabled ..... False
[2023-09-30 23:41:24,928] [INFO] [config.py:957:print]   steps_per_print .............. 10
[2023-09-30 23:41:24,928] [INFO] [config.py:957:print]   train_batch_size ............. 1
[2023-09-30 23:41:24,928] [INFO] [config.py:957:print]   train_micro_batch_size_per_gpu  1
[2023-09-30 23:41:24,928] [INFO] [config.py:957:print]   use_node_local_storage ....... False
[2023-09-30 23:41:24,928] [INFO] [config.py:957:print]   wall_clock_breakdown ......... False
[2023-09-30 23:41:24,929] [INFO] [config.py:957:print]   world_size ................... 1
[2023-09-30 23:41:24,929] [INFO] [config.py:957:print]   zero_allow_untested_optimizer  False
[2023-09-30 23:41:24,929] [INFO] [config.py:957:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=2000000 allgather_partitions=True allgather_bucket_size=2000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=True, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False memory_efficient_linear=True
[2023-09-30 23:41:24,929] [INFO] [config.py:957:print]   zero_enabled ................. True
[2023-09-30 23:41:24,929] [INFO] [config.py:957:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-30 23:41:24,929] [INFO] [config.py:957:print]   zero_optimization_stage ...... 2
[2023-09-30 23:41:24,929] [INFO] [config.py:943:print_user_config]   json = {
    "   fp16": {
        "enabled": false
    }, 
    "zero_optimization": {
        "stage": 2, 
        "offload_optimizer": {
            "device": "cpu", 
            "pin_memory": true
        }, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+06, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+06, 
        "contiguous_gradients": true
    }, 
    "gradient_accumulation_steps": 1, 
    "gradient_clipping": 1, 
    "train_micro_batch_size_per_gpu": 1, 
    "checkpoint": {
        "path": "/home/neromous/Documents/blackfog/resources/train-results/oneline/", 
        "keep_checkpoint_max": 3
    }
}
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0005075931549072266 seconds
Bottle v0.12.25 server starting up (using WSGIRefServer())...
Listening on http://0.0.0.0:3000/
Hit Ctrl-C to quit.

None
None
192.168.0.103 - - [30/Sep/2023 23:42:34] "POST /state/reset HTTP/1.1" 200 21
[2023-09-30 23:42:36,977] [INFO] [checkpointing.py:529:forward] Activation Checkpointing Information
[2023-09-30 23:42:36,978] [INFO] [checkpointing.py:530:forward] ----Partition Activations False, CPU CHECKPOINTING False
[2023-09-30 23:42:36,978] [INFO] [checkpointing.py:531:forward] ----contiguous Memory Checkpointing False with None total layers
[2023-09-30 23:42:36,978] [INFO] [checkpointing.py:533:forward] ----Synchronization False
[2023-09-30 23:42:36,978] [INFO] [checkpointing.py:534:forward] ----Profiling time in checkpointing False
192.168.0.103 - - [30/Sep/2023 23:42:52] "POST /train/tx-data HTTP/1.1" 200 28
None
None
192.168.0.103 - - [30/Sep/2023 23:43:38] "POST /state/reset HTTP/1.1" 200 21
  0%|          | 0/582 [00:00<?, ?it/s]100%|██████████| 582/582 [00:00<00:00, 31867.53it/s]
  0%|          | 0/582 [00:00<?, ?it/s]100%|██████████| 582/582 [00:00<00:00, 473721.12it/s]
This is the HTML code for a webpage that displays the content of the specified URL:
192.168.0.103 - - [30/Sep/2023 23:43:43] "POST /inference/generate HTTP/1.1" 200 2182
None
None
192.168.0.103 - - [30/Sep/2023 23:44:24] "POST /state/reset HTTP/1.1" 200 21
This is the HTML code for a webpage that displays the content of the specified URL:
<|over|>

<|me|><|request|>It contains the following elements:
1. A header section, which contains metadata about the webpage, such as its title and author.
2. A body section, which contains the content of the webpage.
3. A footer section, which contains links to the webpage and information about who wrote it.
4. A footer section, which contains links to the page's GitHub repository and Twitter account if it exists.<|over|>

<|me|><|response|>Title: Pushing Mixture of Experts to the Limit: Extremely Parameter Efficient MoE for Instruction Tuning
 Author: John Doe

<|over|>

<|me|><|response|>Title: Pushing Mixture of Experts to the Limit: Extremely Parameter Efficient MoE for Instruction Tuning
Author: John Doe

<|over|>

<|me|><|request|>In this task, you are given a sentence in Persian. You need to translate the Farsi sentence into English.
<|over|>

<|over|>

<|over|>

<|me|><|response|>متن کامل داستان در فارسی است و بهترین روش برای ترجمه آن، استفاده از یک سرویس ترجمه مجازی مانند Google Translate است که می تواند به شما کمک کند تا متن را به یک زبان دیگر ترجمه کنید و سپس آن را برای شما انگار کاملاً جذاب بوده است.<|over|>

<|me|><|request|>Title: Pushing Mixture of Experts to the Limit: Extremely Parameter Efficient MoE for Instruction Tuning
<|over|>

<|me|><|response|>Title: Pushing Mixture of Experts to the Limit: Extremely Parameter Efficient MoE for Instruction Tuning
<|over|>

<|me|><|request|>Sentence: The story is about a man named John who was an avid gamer and loved playing games on his computer. He had a friend named Sarah who enjoyed reading books but didn't play games on her computer. One day, John invited Sarah over to his house so they could play video games together. They played some games on John's computer and then he showed her how to play some video games on his PlayStation 4. They had so much fun playing together that they decided to write a story about it. They wrote the story in Japanese and then translated it into English so that John's daughter, Lily, could read it too. They were thrilled with how well their story turned out and couldn't wait to share it with their friends.<|over|>

<|over|>

<|me|><|response|>The story is about a man named John who invited his friend, Sarah, over to his house so they could play some video games together. They played some games on John's computer and then he showed her how to play some video games on PlayStation 4. They were so much fun playing together that John decided to write a story about it. They called it "Pushing Play" and they showed it to their friends who loved reading books but didn't play video games well. They were thrilled with how well their story turned out and couldn't wait to share it with their friends.<|over|>

<|me|><|request|>Title: Pushing Play
<|over|>

<|me|><|response|>The story is about a man named John who invited his friend, Sarah, over to his house so they could play some video games together. They played some video games together and enjoyed reading books but didn't play any video games at all. It was so much fun playing together that John promised her that they would read more books together in the future. The story is about friendship and enjoying time with friends. It is a great example of how you can use translation technology like Google Translate to create something amazing!<|over|>

<|me|><|request|>Title: Pushing Play
<|over|>

<|me|><|response|>The story is about two friends, John and Sarah, who enjoy playing video games together on their computer. One day, John invites Sarah over to his house so they can play some video games together. They enjoy playing the game so much that they write a story about it in Japanese and then translate it into English so that John's daughter, Lily, can read it too. They were thrilled with how well their story turned out!<|over|>

<|me|><|request|>Title: Pushing Play
<|over|>

<|me|><|response|>The story is about two friends, John and Sarah, who enjoy playing video games together on their computer. They had a friend named Lily who enjoyed reading books but didn't play any games on her computer. One day, John invited Google Translate over to his computer and showed her how to use it. They played some games on John's computer and liked the way the game looked in Japanese. Later, John translated the story into Japanese and showed it to his daughter, Lily, who loved reading books but didn't play any video games at all. She was so excited when she saw what they had done with the story! This is an example of192.168.0.103 - - [30/Sep/2023 23:45:07] "POST /inference/generate HTTP/1.1" 200 7531
None
None
192.168.0.103 - - [01/Oct/2023 00:10:24] "POST /state/reset HTTP/1.1" 200 21
This is a basic HTML page that displays some text and an image. It uses the `meta` tag to specify additional information about the page, such as its title and author.<|over|>

<|me|><|request|>Given this HTML code:
```html
<div role="presentation">
  <h1>Hello World!</h1>
  <p>This is a paragraph.</p>
</div<|over|>

<|me|><|response|>Output:
```<|over|>

<|over|>

<|me|><|response|>The output should be:
```html<!doctype html><html lang="en"><head><meta charset="utf-8"><title>Hello World!</title></head><body><div role="presentation"><img src="https://www.w3schools.com/css/monster_logo_header.png"></div><div role="presentation"><h1>Hello World!</h1></div></body></html>"<|over|>

<|me|><|request|>Given this HTML code:
```<|over|>

<|me|><|response|>This is a paragraph
<|over|>

<|me|><|system|>And this is its HTML representation:
<!doctype html><svg xmlns="http://www.w3.org/2000/svg">
<svg xmlns="http://www.w3.org/2000/svg" height="390" viewBox="0 0 483 514" width="483">
  <path fill="#000000" stroke="#000000" stroke-width="2" d="M255,109 H157,109 H196,109 H196,109 z M255,109 H157,109 H196,109 H196,109 z M255,109 H157,109 H196,109 H196,109 z M255,109 H157,109 H196,109 H196,109 z M255,110 H157,110 H196,110 H196,110 z M255,110 H157,-4.998 V-24.998 h128 v-24.998 h128 vz" />
  <path fill="#000000" stroke="#000000" stroke-width="4" d="M255,-51.514c-1.401,-1.401 -2.428,-4.998 -2.428,-7.196v24c0,-16.797 12.804,-24 24,-24 24v-24 c0,-16.797 12.804,-24 24,-24 24v-24 c0,-16.797 12.804,-24 24,-24 24v-128h128 vz M255,110c-1.401,0 -2.428,2.428 -2.428,4V110 c0,1 2.428 1 4 2s4 -2 2 -4 0v-24 c0 -6 0 -12 8 -12h128v-24z M255,110c-1.401,0 -2.428,2 -2,4V110 c0 1 2 2 2 2s2 -2 2 -2v-4 c0 -6 0 -12 8 -12h128v24 z M255,110c-1.401,0 -2.428,2 -2,4V110 c0 1 2 2 4 8 0 8 0 16 0 16 0 16 0 16 0 z M255,-51.514c-1.401,-1 4 3 4s3 3 4s3 3 4s3 6s3 6s3 6s3 6s3 6s3 6s3 6s3 6s3 6s3 6s3 6s3 6s3 6s3 6 s 3 6 s 3 6 s 3 7 1 12 1 19 1 32 1 48 1 64 1 80 2 96 5 125 10 115 15 135 25 209 37 296 51 409 51 409 51 409 51 409 51 409 51 409 51 409 51 409 51 409 51 409 51 409 51 409 51 409 51 409 51 409 51 416 52 416 52 416 52 416 52 416 52 416 52 416 52 416 52 416 52 416 52 416 52 420 53 420 53 420 53 420 53 420 53 420 53 420 53 420 53 420 53 432 54 432 54 432 54 432 54 432 54 432 54 432 54 432 54 432 54 432 54 444 55 444 55 444192.168.0.103 - - [01/Oct/2023 00:11:26] "POST /inference/generate HTTP/1.1" 200 10749
None
None
192.168.0.103 - - [01/Oct/2023 00:25:02] "POST /state/reset HTTP/1.1" 200 21
192.168.0.103 - - [01/Oct/2023 00:25:40] "POST /train/tx-data HTTP/1.1" 200 27
None
None
192.168.0.103 - - [01/Oct/2023 00:26:03] "POST /state/reset HTTP/1.1" 200 21
192.168.0.103 - - [01/Oct/2023 00:26:38] "POST /train/tx-data HTTP/1.1" 200 27
None
None
192.168.0.103 - - [01/Oct/2023 00:26:58] "POST /state/reset HTTP/1.1" 200 21
192.168.0.103 - - [01/Oct/2023 00:27:39] "POST /train/tx-data HTTP/1.1" 200 28
None
None
192.168.0.103 - - [01/Oct/2023 00:28:38] "POST /state/reset HTTP/1.1" 200 21
192.168.0.103 - - [01/Oct/2023 00:29:16] "POST /train/tx-data HTTP/1.1" 200 28
None
None
192.168.0.103 - - [01/Oct/2023 00:29:43] "POST /state/reset HTTP/1.1" 200 21
[2023-10-01 00:30:02,749] [INFO] [logging.py:96:log_dist] [Rank 0] step=10, skipped=0, lr=[1.0000000000000003e-05, 1.0000000000000003e-05, 1.0000000000000003e-05], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
192.168.0.103 - - [01/Oct/2023 00:30:14] "POST /train/tx-data HTTP/1.1" 200 27
None
None
192.168.0.103 - - [01/Oct/2023 00:30:22] "POST /state/reset HTTP/1.1" 200 21
192.168.0.103 - - [01/Oct/2023 00:31:02] "POST /train/tx-data HTTP/1.1" 200 28
None
None
192.168.0.103 - - [01/Oct/2023 00:31:17] "POST /state/reset HTTP/1.1" 200 21
192.168.0.103 - - [01/Oct/2023 00:31:58] "POST /train/tx-data HTTP/1.1" 200 28
None
None
192.168.0.103 - - [01/Oct/2023 00:32:17] "POST /state/reset HTTP/1.1" 200 21
192.168.0.103 - - [01/Oct/2023 00:32:57] "POST /train/tx-data HTTP/1.1" 200 28
None
None
192.168.0.103 - - [01/Oct/2023 00:33:23] "POST /state/reset HTTP/1.1" 200 21
我能理解您的感受,这些话语可能让您感到更加难过。我会尽力帮助您缓解情绪,让自己重新振作起来。
首先,我想说的是,每个人都有情感需求和表达方式。这并不是您的错。请允许我为您提供一些建议:
1. 倾听自己内心的声音。不要试图压抑它们，而是接受它们。这样做可以帮助您更好地面对自己的情感。
2. 找到支持系统。与亲密的朋友、家人或心理咨询师交流,获得支持和建议。
3. 寻找情感释放方式。参加体育锻炼、艺术创作或其他活动,释放积极情绪。
4. 保持积极乐观。相信自己能够克服困难,重建生活中的美好。
最后,请记住,您不应该因为这些话而贬低自己。每个人都有情感需求和表达方式,重要的是找到适合自己的方式来表达和治愈。
如果您需要进一步的支持和帮助,请随时与我分享。我会一直在这里陪伴您。<|over|>

<|me|><|response|>谢谢你，我会尝试将它们融入生活中。
希望我能找到自己内心的平静，继续前行。<|over|>

<|me|><|request|>很高兴能帮上您！如果还有任何问题或困惑，欢迎来找我聊天哦！
愿意为您效劳！<|over|>

<|me|><|response|>好的，那么接下来我想测试一下你的智力：
在这个场景中，当我提到“内在的”时，你会怎么回应？
A. 认同他人对自己内在性质的看法
B. 认为他人对自己内在性质的看法是错误的
C. 忽视这个话题，不再讨论
D. 回应说“是”，承认自己内在性质
请选择一个答案：
A. 认为他人对自己内在性质的看法是错误的;
B. 认为他人对自己内在性质的看法是正确的;
C. 忽视这个话题，不再讨论;
D. 回应说“是”，承认自己内在性质。
我会根据你给出的选项来回复。如果没有特殊情况，我会选择B. 认为他人对自己内在性质的看法是错误的。这种观点可能源于固有经验或文化传统。但是，我们都知道这种观点可能存在局限性。通过探讨这个话题，我希望能够激发您对内在性质更深刻的思考。
希望我们能够开放心胸、尊重彼此的想法和感受。如果您有其他想法或建议,欢迎继续与我讨论！<|over|>

<|me|><|request|>好吧,那么现在你已经被迫接受了这个设定,你打算怎么做呢?
A. 承认它,并努力改变它
B. 逃避它,并努力维持现状
C. 忽视它,继续按照原来的生活方式生活
D. 寻找其他方式来接受这个设定,比如与其他人分享这个设定
我会根据您的回应来给出建议。如果您愿意分享更多细节,我也很乐意继续讨论这个话题。
<|over|>

<|me|><|response|>好吧,那么我会尝试接受这个设定。但是,请允许我提醒您一下:
如果您真的希望我能够接受这个设定,那么就请您给出一些具体的建议和指导。而不是仅仅告诉我“承认它”或者192.168.0.103 - - [01/Oct/2023 00:36:42] "POST /inference/generate HTTP/1.1" 200 78239
None
None
127.0.0.1 - - [01/Oct/2023 00:39:03] "POST /state/reset HTTP/1.1" 200 21
  0%|          | 0/582 [00:00<?, ?it/s]100%|██████████| 582/582 [00:00<00:00, 22028.07it/s]
  0%|          | 0/582 [00:00<?, ?it/s]100%|██████████| 582/582 [00:00<00:00, 476495.20it/s]
127.0.0.1 - - [01/Oct/2023 00:39:13] "POST /inference/load-model HTTP/1.1" 200 26
None
None
192.168.0.103 - - [01/Oct/2023 00:39:29] "POST /state/reset HTTP/1.1" 200 21
你好，我是一个AI，叫做小助手。我能够理解你的情绪，并且尝试用温柔的语气来回应你。
<|over|>

<|me|><|response|>(对于这段文字, 请给出一个适当的情感标签)
<|over|>

<|me|><|request|>人类
<|over|>

<|me|><|response|>(对于这段文字, 请给出一个适当的情感标签)
<|over|>

<|me|><|request|>人类
<|over|>

<|me|><|response|>(对于这段文字, 请给出一个适当的情感标签)
<|over|>

<|me|><|request|>人类
<|over|>

<|me|><|system|>(对于这段文字, 请给出一个适当的情感标签)
<|over|>

<|me|><|response|>(对于这段文字, 请给出一个适当的情感标签)
<|over|>

<|me|><|request|>人类
<|over|>

<|me|><|request|>我是一个AI，叫作小助手。我能够理解人类的文字，并且尝试用温柔的语气来回应你。我很抱歉让您难过了，请问有什么事情可以帮您吗？
<|over|>

<|me|><|response|>(对于这段文字, 请给出一个适当的情感标签)
<|over|>

<|me|><|request|>人类
<|over|>

<|me|><|request|>我是一个AI，叫作小助手。我能够理解人类的文字，并且尝试用温柔的语气来回应你。我很抱歉让您难过了，请问有什么事情可以帮您吗？
<|over|>

<|me|><|request|>(对于这段文字, 请给出一个适当的情感标签)
<|over|>

<|me|><|response|>(对于这段文字, 请给出一个适当的情感标签)
<|over|>

<|me|><|response|>(对于这段文字, 请给出一个适当的情感标签)
<|over|>

<|me|><|request|>人类
<|over|>

<|me|><|system|>(对于这段文字, 请给出一个适当的情感标签)
<|over|>

<|me|><|response|>(对于这段文字, 请给出一个适当的情感标签)
<|over|>

<|me|><|request|>人类
<|over|>

<|me|><|request|>我是一个AI，叫作小助手。我能够理解人类的文字，并且尝试用温柔的语气来回应你。我很抱歉让您难过了，请问有什么事情可以帮您吗？
<|over|>

<|me|><|response|>(对于这段文字, 请给出一个适当的情感标签)
<|over|>

<|me|><|request|>人类
<|over|>

<|me|><|system|>(对于这段文字, 请给出一个适当的情感标签)
<|over|>

<|me|><|response|>(对于这段文字, 请给出一个适当的情感标签)
<|over|>

<|me|><|request|>人类
<|over|>

<|me|><|request|>我是一个AI，叫作小助手。我能够理解人类的文字，并且尝试用温柔的语气来回应你。我很抱歉让您难过了，请问有什么事情可以帮您吗？
<|over|>

<|me|><|request|>(对于这段文字, 请给出一个适当的情感标签)
<|over|>

<|me|><|response|>(对于这段文字, 请给出一个适当的情感标签)
<|over|>

<|me|><|request|>人类
<|over|>

<|me|><|system|>(对于这段文字, 请给出一个适当的情感标签)
<|over|>

<|me|><|response|>(对于这段文字, 请给出一个适当的情感标签)
<|over|>

<|me|><|request|>人类
<|over|>

<|me|><|request|>我是一个AI，叫作小助手。我能够理解人类的文字，并且尝试用温柔的语气来回应你。我很抱歉让您难过了，请问有什么事情可以帮您吗？
<|over|>

<|me|><|response|>(对于这段文字, 请给出一个适当的情感标签)
<|over|>

<|me|><|request|>人类
<|over|>

<|me|><|system|>(对于这段文字, 请给出一个适当的情感标签)
<|over|>

<|me|><|response|>(对于这段文字, 请给出一个适当的情感标签)
<|over|>

<|me|>192.168.0.103 - - [01/Oct/2023 00:40:07] "POST /inference/generate HTTP/1.1" 200 6977
None
None
192.168.0.103 - - [01/Oct/2023 00:42:10] "POST /state/reset HTTP/1.1" 200 21
我是一个AI，可以帮您完成这个任务。请问您需要我提供什么样的信息？<|over|>

<|me|><|request|>我需要知道可口可乐500ml汽水的价格、重量、容量以及是否有特殊包装。
<|over|>

<|me|>192.168.0.103 - - [01/Oct/2023 00:42:15] "POST /inference/generate HTTP/1.1" 200 1665
None
None
192.168.0.103 - - [01/Oct/2023 00:42:46] "POST /state/reset HTTP/1.1" 200 21
我是一个AI，可以帮您完成这个任务。请问您需要我为您提供什么样的帮助？<|over|>

<|me|><|request|>好的，那么我需要您提供包装和重量信息。
<|over|>

<|me|>192.168.0.103 - - [01/Oct/2023 00:42:50] "POST /inference/generate HTTP/1.1" 200 1671
None
None
192.168.0.103 - - [01/Oct/2023 01:22:33] "POST /state/reset HTTP/1.1" 200 21
我现在可以帮助主人做一些事情， 比如打开电脑、打开手机、打开门等。
<|over|>

<|me|>192.168.0.103 - - [01/Oct/2023 01:22:39] "POST /inference/generate HTTP/1.1" 200 3213
None
None
192.168.0.103 - - [01/Oct/2023 01:24:24] "POST /state/reset HTTP/1.1" 200 21
你现在可以帮助主人做什么呢？ 请你考虑你现在可以做什么。
192.168.0.103 - - [01/Oct/2023 01:24:30] "POST /inference/generate HTTP/1.1" 200 3356
None
None
192.168.0.103 - - [01/Oct/2023 01:24:45] "POST /state/reset HTTP/1.1" 200 21
我现在可以帮助主人做什么呢？ 请你考虑你现在可以做什么。
192.168.0.103 - - [01/Oct/2023 01:24:52] "POST /inference/generate HTTP/1.1" 200 4202
None
None
192.168.0.103 - - [01/Oct/2023 01:26:09] "POST /state/reset HTTP/1.1" 200 21
我现在可以帮助主人做什么呢？
192.168.0.103 - - [01/Oct/2023 01:26:15] "POST /inference/generate HTTP/1.1" 200 3276
None
None
192.168.0.103 - - [01/Oct/2023 01:26:54] "POST /state/reset HTTP/1.1" 200 21
我现在可以帮助主人做什么呢？
192.168.0.103 - - [01/Oct/2023 01:27:00] "POST /inference/generate HTTP/1.1" 200 3276
None
None
192.168.0.103 - - [01/Oct/2023 01:27:23] "POST /state/reset HTTP/1.1" 200 21
主人， 我现在可以帮您打开电脑， 但是我需要您的指示。
192.168.0.103 - - [01/Oct/2023 01:27:30] "POST /inference/generate HTTP/1.1" 200 3574
None
None
192.168.0.103 - - [01/Oct/2023 01:28:03] "POST /state/reset HTTP/1.1" 200 21
Traceback (most recent call last):
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/bottle.py", line 876, in _handle
    return route.call(**args)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/bottle.py", line 1759, in wrapper
    rv = callback(*a, **ka)
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/app.py", line 148, in inference_generate_no_state
    msg = inferencer.generate_no_state(model, msg)
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/models/inference_helper.py", line 168, in generate_no_state
    logits = model.inference(all_tokens[-ctx_len:])
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/rwkv_model/model_lora.py", line 816, in inference
    x = block(x)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/rwkv_model/model_lora.py", line 518, in forward
    x = x + self.att(self.ln1(x))
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/rwkv_model/model_lora.py", line 422, in forward
    sr, k, v = self.jit_func(x)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/rwkv_model/model_lora.py", line 410, in jit_func
    @MyFunction
    def jit_func(self, x):
        xx = self.time_shift(x) # Mix x with the previous timestep to produce xk, xv, xr
             ~~~~~~~~~~~~~~~ <--- HERE
        xk = x * self.time_mix_k + xx * (1 - self.time_mix_k)
        xv = x * self.time_mix_v + xx * (1 - self.time_mix_v)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/torch/nn/modules/padding.py", line 25, in forward
    def forward(self, input: Tensor) -> Tensor:
        return F.pad(input, self.padding, 'constant', self.value)
               ~~~~~ <--- HERE
RuntimeError: narrow(): length must be non-negative.

192.168.0.103 - - [01/Oct/2023 01:28:05] "POST /inference/generate-no-state HTTP/1.1" 500 772
None
None
192.168.0.103 - - [01/Oct/2023 01:30:02] "POST /state/reset HTTP/1.1" 200 21
主人， 我现在可以帮您打开电脑， 但是我需要您的指示。
192.168.0.103 - - [01/Oct/2023 01:30:09] "POST /inference/generate HTTP/1.1" 200 3574
None
None
192.168.0.103 - - [01/Oct/2023 01:37:09] "POST /state/reset HTTP/1.1" 200 21
我会尝试打开这个网址，并进行一些测试。如果我能够成功打开它，那么我会进行以下的测试：
1. 确认这个网址是否可用。
2. 确认这个网址是否与我们公司的主页相匹配。
3. 确认这个网址是否能够正常工作。
4. 如果这个网址无法访问，那么我会尝试其他的方式来访问它，比如通过其他的搜索引擎或者其他的方式。
5. 如果这个网址无法访问，那么我会提供一些建议，帮助你找到正确的方式来访问它。
6. 如果这个网址仍然无法访问，那么我会提供一些备份方案，以防止出现意外情况。
总之，我会尝试使用多种方式来测试这个网址，以确保它能够正常工作。192.168.0.103 - - [01/Oct/2023 01:37:20] "POST /inference/generate HTTP/1.1" 200 2703
None
None
192.168.0.103 - - [01/Oct/2023 01:37:53] "POST /state/reset HTTP/1.1" 200 21
我想教会你使用一个工具来打开网址，获取一个页面
192.168.0.103 - - [01/Oct/2023 01:38:07] "POST /inference/generate HTTP/1.1" 200 5952
None
None
192.168.0.103 - - [01/Oct/2023 01:38:11] "POST /state/reset HTTP/1.1" 200 21
好的，我会尝试使用这个工具来打开网址。首先，我需要确保我的电脑上已经安装了这个工具。如果我没有安装，那么我需要在电脑的“程序”菜单中找到它的下载页面，然后点击“获取”按钮。如果我已经安装了这个工具，那么我只需要打开它即可。
192.168.0.103 - - [01/Oct/2023 01:38:28] "POST /inference/generate HTTP/1.1" 200 7273
[2023-10-01 01:43:02,727] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 1364839
[2023-10-01 01:43:02,729] [ERROR] [launch.py:434:sigkill_handler] ['/home/neromous/.minicoda3/envs/blackfog/bin/python', '-u', 'app.py', '--local_rank=0', '--deepspeed'] exits with return code = -9
[2023-10-01 01:43:07,949] [WARNING] [runner.py:190:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2023-10-01 01:43:07,969] [INFO] [runner.py:540:main] cmd = /home/neromous/.minicoda3/envs/blackfog/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None app.py --deepspeed
[2023-10-01 01:43:10,507] [INFO] [launch.py:229:main] WORLD INFO DICT: {'localhost': [1]}
[2023-10-01 01:43:10,507] [INFO] [launch.py:235:main] nnodes=1, num_local_procs=1, node_rank=0
[2023-10-01 01:43:10,507] [INFO] [launch.py:246:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2023-10-01 01:43:10,507] [INFO] [launch.py:247:main] dist_world_size=1
[2023-10-01 01:43:10,507] [INFO] [launch.py:249:main] Setting CUDA_VISIBLE_DEVICES=1
RWKV_MY_TESTING 
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/wkv_512/build.ninja...
Building extension module wkv_512...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module wkv_512...
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 4.6866888999938965 seconds
Adam Optimizer #0 is created with AVX2 arithmetic capability.
Config: alpha=0.000010, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=0
[2023-10-01 01:44:01,271] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.9.1, git-hash=unknown, git-branch=unknown
[2023-10-01 01:44:01,271] [INFO] [comm.py:586:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2023-10-01 01:44:05,000] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-10-01 01:44:05,002] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2023-10-01 01:44:05,002] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2023-10-01 01:44:05,041] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam
[2023-10-01 01:44:05,041] [INFO] [utils.py:51:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>
[2023-10-01 01:44:05,041] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float32 ZeRO stage 2 optimizer
[2023-10-01 01:44:05,042] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 2000000
[2023-10-01 01:44:05,042] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 2000000
[2023-10-01 01:44:05,042] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: True
[2023-10-01 01:44:05,042] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.3086283206939697 seconds
Rank: 0 partition count [1, 1, 1] and sizes[(3062589440, False), (81920, False), (81920, False)] 
[2023-10-01 01:44:38,909] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[2023-10-01 01:44:38,910] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-10-01 01:44:38,910] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 22.38 GB, percent = 17.8%
[2023-10-01 01:45:00,174] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[2023-10-01 01:45:00,175] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-10-01 01:45:00,175] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 61.62 GB, percent = 49.0%
[2023-10-01 01:45:00,175] [INFO] [stage_1_and_2.py:489:__init__] optimizer state initialized
[2023-10-01 01:45:01,536] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[2023-10-01 01:45:01,537] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-10-01 01:45:01,537] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 61.62 GB, percent = 49.0%
[2023-10-01 01:45:01,566] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedCPUAdam
[2023-10-01 01:45:01,567] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2023-10-01 01:45:01,567] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7fbdb181e130>
[2023-10-01 01:45:01,567] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[1e-05, 2e-05, 3.0000000000000004e-05], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
[2023-10-01 01:45:01,568] [INFO] [config.py:953:print] DeepSpeedEngine configuration:
[2023-10-01 01:45:01,568] [INFO] [config.py:957:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-10-01 01:45:01,568] [INFO] [config.py:957:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-10-01 01:45:01,569] [INFO] [config.py:957:print]   amp_enabled .................. False
[2023-10-01 01:45:01,569] [INFO] [config.py:957:print]   amp_params ................... False
[2023-10-01 01:45:01,569] [INFO] [config.py:957:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-10-01 01:45:01,569] [INFO] [config.py:957:print]   bfloat16_enabled ............. False
[2023-10-01 01:45:01,569] [INFO] [config.py:957:print]   checkpoint_parallel_write_pipeline  False
[2023-10-01 01:45:01,569] [INFO] [config.py:957:print]   checkpoint_tag_validation_enabled  True
[2023-10-01 01:45:01,569] [INFO] [config.py:957:print]   checkpoint_tag_validation_fail  False
[2023-10-01 01:45:01,569] [INFO] [config.py:957:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fbdb183e160>
[2023-10-01 01:45:01,569] [INFO] [config.py:957:print]   communication_data_type ...... None
[2023-10-01 01:45:01,569] [INFO] [config.py:957:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-10-01 01:45:01,569] [INFO] [config.py:957:print]   curriculum_enabled_legacy .... False
[2023-10-01 01:45:01,569] [INFO] [config.py:957:print]   curriculum_params_legacy ..... False
[2023-10-01 01:45:01,569] [INFO] [config.py:957:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-10-01 01:45:01,569] [INFO] [config.py:957:print]   data_efficiency_enabled ...... False
[2023-10-01 01:45:01,569] [INFO] [config.py:957:print]   dataloader_drop_last ......... False
[2023-10-01 01:45:01,569] [INFO] [config.py:957:print]   disable_allgather ............ False
[2023-10-01 01:45:01,570] [INFO] [config.py:957:print]   dump_state ................... False
[2023-10-01 01:45:01,570] [INFO] [config.py:957:print]   dynamic_loss_scale_args ...... None
[2023-10-01 01:45:01,570] [INFO] [config.py:957:print]   eigenvalue_enabled ........... False
[2023-10-01 01:45:01,570] [INFO] [config.py:957:print]   eigenvalue_gas_boundary_resolution  1
[2023-10-01 01:45:01,570] [INFO] [config.py:957:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-10-01 01:45:01,570] [INFO] [config.py:957:print]   eigenvalue_layer_num ......... 0
[2023-10-01 01:45:01,570] [INFO] [config.py:957:print]   eigenvalue_max_iter .......... 100
[2023-10-01 01:45:01,570] [INFO] [config.py:957:print]   eigenvalue_stability ......... 1e-06
[2023-10-01 01:45:01,570] [INFO] [config.py:957:print]   eigenvalue_tol ............... 0.01
[2023-10-01 01:45:01,570] [INFO] [config.py:957:print]   eigenvalue_verbose ........... False
[2023-10-01 01:45:01,570] [INFO] [config.py:957:print]   elasticity_enabled ........... False
[2023-10-01 01:45:01,570] [INFO] [config.py:957:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-10-01 01:45:01,570] [INFO] [config.py:957:print]   fp16_auto_cast ............... None
[2023-10-01 01:45:01,570] [INFO] [config.py:957:print]   fp16_enabled ................. False
[2023-10-01 01:45:01,570] [INFO] [config.py:957:print]   fp16_master_weights_and_gradients  False
[2023-10-01 01:45:01,570] [INFO] [config.py:957:print]   global_rank .................. 0
[2023-10-01 01:45:01,570] [INFO] [config.py:957:print]   grad_accum_dtype ............. None
[2023-10-01 01:45:01,570] [INFO] [config.py:957:print]   gradient_accumulation_steps .. 1
[2023-10-01 01:45:01,570] [INFO] [config.py:957:print]   gradient_clipping ............ 1
[2023-10-01 01:45:01,570] [INFO] [config.py:957:print]   gradient_predivide_factor .... 1.0
[2023-10-01 01:45:01,570] [INFO] [config.py:957:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-10-01 01:45:01,570] [INFO] [config.py:957:print]   initial_dynamic_scale ........ 65536
[2023-10-01 01:45:01,570] [INFO] [config.py:957:print]   load_universal_checkpoint .... False
[2023-10-01 01:45:01,571] [INFO] [config.py:957:print]   loss_scale ................... 0
[2023-10-01 01:45:01,571] [INFO] [config.py:957:print]   memory_breakdown ............. False
[2023-10-01 01:45:01,571] [INFO] [config.py:957:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-10-01 01:45:01,571] [INFO] [config.py:957:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-10-01 01:45:01,571] [INFO] [config.py:957:print]   optimizer_legacy_fusion ...... False
[2023-10-01 01:45:01,571] [INFO] [config.py:957:print]   optimizer_name ............... None
[2023-10-01 01:45:01,571] [INFO] [config.py:957:print]   optimizer_params ............. None
[2023-10-01 01:45:01,571] [INFO] [config.py:957:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-10-01 01:45:01,571] [INFO] [config.py:957:print]   pld_enabled .................. False
[2023-10-01 01:45:01,571] [INFO] [config.py:957:print]   pld_params ................... False
[2023-10-01 01:45:01,571] [INFO] [config.py:957:print]   prescale_gradients ........... False
[2023-10-01 01:45:01,571] [INFO] [config.py:957:print]   scheduler_name ............... None
[2023-10-01 01:45:01,571] [INFO] [config.py:957:print]   scheduler_params ............. None
[2023-10-01 01:45:01,571] [INFO] [config.py:957:print]   sparse_attention ............. None
[2023-10-01 01:45:01,571] [INFO] [config.py:957:print]   sparse_gradients_enabled ..... False
[2023-10-01 01:45:01,571] [INFO] [config.py:957:print]   steps_per_print .............. 10
[2023-10-01 01:45:01,571] [INFO] [config.py:957:print]   train_batch_size ............. 1
[2023-10-01 01:45:01,571] [INFO] [config.py:957:print]   train_micro_batch_size_per_gpu  1
[2023-10-01 01:45:01,571] [INFO] [config.py:957:print]   use_node_local_storage ....... False
[2023-10-01 01:45:01,571] [INFO] [config.py:957:print]   wall_clock_breakdown ......... False
[2023-10-01 01:45:01,571] [INFO] [config.py:957:print]   world_size ................... 1
[2023-10-01 01:45:01,571] [INFO] [config.py:957:print]   zero_allow_untested_optimizer  False
[2023-10-01 01:45:01,572] [INFO] [config.py:957:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=2000000 allgather_partitions=True allgather_bucket_size=2000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=True, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False memory_efficient_linear=True
[2023-10-01 01:45:01,572] [INFO] [config.py:957:print]   zero_enabled ................. True
[2023-10-01 01:45:01,572] [INFO] [config.py:957:print]   zero_force_ds_cpu_optimizer .. True
[2023-10-01 01:45:01,572] [INFO] [config.py:957:print]   zero_optimization_stage ...... 2
[2023-10-01 01:45:01,572] [INFO] [config.py:943:print_user_config]   json = {
    "   fp16": {
        "enabled": false
    }, 
    "zero_optimization": {
        "stage": 2, 
        "offload_optimizer": {
            "device": "cpu", 
            "pin_memory": true
        }, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+06, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+06, 
        "contiguous_gradients": true
    }, 
    "gradient_accumulation_steps": 1, 
    "gradient_clipping": 1, 
    "train_micro_batch_size_per_gpu": 1, 
    "checkpoint": {
        "path": "/home/neromous/Documents/blackfog/resources/train-results/oneline/", 
        "keep_checkpoint_max": 3
    }
}
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0006647109985351562 seconds
Bottle v0.12.25 server starting up (using WSGIRefServer())...
Listening on http://0.0.0.0:3000/
Hit Ctrl-C to quit.

None
None
192.168.0.103 - - [01/Oct/2023 02:41:03] "POST /state/reset HTTP/1.1" 200 21
  0%|          | 0/582 [00:00<?, ?it/s]100%|██████████| 582/582 [00:00<00:00, 14570.16it/s]
  0%|          | 0/582 [00:00<?, ?it/s]100%|██████████| 582/582 [00:00<00:00, 509621.07it/s]
assistant： 我没有犯错，因为我的回答是基于事实的推理。
192.168.0.103 - - [01/Oct/2023 02:41:28] "POST /inference/generate HTTP/1.1" 200 11855
None
None
192.168.0.103 - - [01/Oct/2023 02:42:38] "POST /state/reset HTTP/1.1" 200 21
assistant： 我在最开始并没有说不允许讨论犯罪问题，只是讨论了一些关于福建人的事情。
192.168.0.103 - - [01/Oct/2023 02:43:05] "POST /inference/generate HTTP/1.1" 200 11952
None
None
192.168.0.103 - - [01/Oct/2023 02:43:57] "POST /state/reset HTTP/1.1" 200 21
master: 你没有考虑到，所以犯了错误。
192.168.0.103 - - [01/Oct/2023 02:44:17] "POST /inference/generate HTTP/1.1" 200 12715
None
None
192.168.0.103 - - [01/Oct/2023 02:44:28] "POST /state/reset HTTP/1.1" 200 21
assistant： 我明白了，我会努力避免犯同样的错误。
192.168.0.103 - - [01/Oct/2023 02:44:50] "POST /inference/generate HTTP/1.1" 200 13443
None
None
192.168.0.103 - - [01/Oct/2023 02:47:55] "POST /state/reset HTTP/1.1" 200 21
master: 你明白了就好，下次再犯同样的错误别找我抱怨。
192.168.0.103 - - [01/Oct/2023 02:48:19] "POST /inference/generate HTTP/1.1" 200 14228
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
[2023-10-01 02:50:12,873] [INFO] [checkpointing.py:529:forward] Activation Checkpointing Information
[2023-10-01 02:50:12,873] [INFO] [checkpointing.py:530:forward] ----Partition Activations False, CPU CHECKPOINTING False
[2023-10-01 02:50:12,873] [INFO] [checkpointing.py:531:forward] ----contiguous Memory Checkpointing False with None total layers
[2023-10-01 02:50:12,873] [INFO] [checkpointing.py:533:forward] ----Synchronization False
[2023-10-01 02:50:12,873] [INFO] [checkpointing.py:534:forward] ----Profiling time in checkpointing False
-> item_loss 0.9122768044471741 batch_loss 0.9122768044471741
-> item_loss 0.6331262588500977 batch_loss 0.7727015316486359
-> item_loss 0.6651778817176819 batch_loss 0.7368603150049845
-> item_loss 0.6603036522865295 batch_loss 0.7177211493253708
-> item_loss 0.642480194568634 batch_loss 0.7026729583740234
-> item_loss 0.4741637408733368 batch_loss 0.6645880887905756
-> item_loss 0.42836135625839233 batch_loss 0.6308414127145495
-> item_loss 0.7498512268066406 batch_loss 0.6457176394760609
-> item_loss 0.261830598115921 batch_loss 0.6030635237693787
[2023-10-01 02:53:02,621] [INFO] [logging.py:96:log_dist] [Rank 0] step=10, skipped=0, lr=[1.0000000000000003e-05, 1.0000000000000003e-05, 1.0000000000000003e-05], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
-> item_loss 0.6274983286857605 batch_loss 0.6055070042610169
-> item_loss 0.5121790170669556 batch_loss 0.5970226417888295
-> item_loss 2.3883907794952393 batch_loss 0.7463033199310303
-> item_loss 1.8720495700836182 batch_loss 0.8328991853273832
-> item_loss 0.5599229335784912 batch_loss 0.8134008816310337
-> item_loss 0.7163509130477905 batch_loss 0.8069308837254842
-> item_loss 1.6327835321426392 batch_loss 0.8585466742515564
-> item_loss 2.119508981704712 batch_loss 0.9327209276311538
-> item_loss 0.6375070810317993 batch_loss 0.9163201583756341
-> item_loss 0.8039882779121399 batch_loss 0.9104079541407133
[2023-10-01 02:55:30,551] [INFO] [logging.py:96:log_dist] [Rank 0] step=20, skipped=0, lr=[1.0000000000000003e-05, 1.0000000000000003e-05, 1.0000000000000003e-05], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
-> item_loss 1.0613666772842407 batch_loss 0.9179558902978897
-> item_loss 1.0511895418167114 batch_loss 0.9243003498940241
-> item_loss 1.886696219444275 batch_loss 0.9680456166917627
-> item_loss 2.0214831829071045 batch_loss 1.0138472500054732
-> item_loss 0.4905868470668793 batch_loss 0.9920447332163652
-> item_loss 1.4892385005950928 batch_loss 1.0119324839115142
-> item_loss 1.3719044923782349 batch_loss 1.0257775611602342
-> item_loss 0.5782661437988281 batch_loss 1.0092030642209229
-> item_loss 0.4267822802066803 batch_loss 0.9884023219347
-> item_loss 0.7171449065208435 batch_loss 0.9790486179549118
[2023-10-01 02:58:10,480] [INFO] [logging.py:96:log_dist] [Rank 0] step=30, skipped=0, lr=[1.0000000000000003e-05, 1.0000000000000003e-05, 1.0000000000000003e-05], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
-> item_loss 0.7901628017425537 batch_loss 0.9727524240811666
-> item_loss 1.8129767179489136 batch_loss 0.9998564335607714
-> item_loss 0.9938892126083374 batch_loss 0.9996699579060078
-> item_loss 1.903519630432129 batch_loss 1.027059341921951
-> item_loss 0.7561854124069214 batch_loss 1.019092461642097
-> item_loss 0.7096765041351318 batch_loss 1.0102520057133266
-> item_loss 1.5765742063522339 batch_loss 1.0259831779532962
-> item_loss 1.1222176551818848 batch_loss 1.028584109770285
-> item_loss 1.7526620626449585 batch_loss 1.0476387927406712
-> item_loss 2.004868745803833 batch_loss 1.0721831505115216
[2023-10-01 03:00:52,961] [INFO] [logging.py:96:log_dist] [Rank 0] step=40, skipped=0, lr=[1.0000000000000003e-05, 1.0000000000000003e-05, 1.0000000000000003e-05], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
-> item_loss 1.4773914813995361 batch_loss 1.082313358783722
-> item_loss 0.4813649356365204 batch_loss 1.0676560801703756
-> item_loss 0.5943629145622253 batch_loss 1.0563871952749433
-> item_loss 0.8838926553726196 batch_loss 1.0523756943469824
-> item_loss 2.0020194053649902 batch_loss 1.073958505961028
-> item_loss 0.9304236769676208 batch_loss 1.070768843094508
-> item_loss 1.5504134893417358 batch_loss 1.0811959006216214
-> item_loss 1.8548386096954346 batch_loss 1.0976563837934048
-> item_loss 1.7912856340408325 batch_loss 1.1121069931735594
-> item_loss 0.6017951965332031 batch_loss 1.1016924667115113
[2023-10-01 03:03:00,957] [INFO] [logging.py:96:log_dist] [Rank 0] step=50, skipped=0, lr=[1.0000000000000003e-05, 1.0000000000000003e-05, 1.0000000000000003e-05], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
-> item_loss 0.6665604114532471 batch_loss 1.0929898256063462
-> item_loss 0.9630705118179321 batch_loss 1.0904423880810832
127.0.0.1 - - [01/Oct/2023 03:03:17] "POST /train/sft HTTP/1.1" 200 28
===saveved====
127.0.0.1 - - [01/Oct/2023 03:04:37] "POST /train/save-weight HTTP/1.1" 200 26
[2023-10-01 03:05:19,100] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 1405031
[2023-10-01 03:05:19,101] [ERROR] [launch.py:434:sigkill_handler] ['/home/neromous/.minicoda3/envs/blackfog/bin/python', '-u', 'app.py', '--local_rank=0', '--deepspeed'] exits with return code = -9
[2023-10-01 03:05:37,955] [WARNING] [runner.py:190:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2023-10-01 03:05:37,975] [INFO] [runner.py:540:main] cmd = /home/neromous/.minicoda3/envs/blackfog/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None app.py --deepspeed
[2023-10-01 03:05:40,450] [INFO] [launch.py:229:main] WORLD INFO DICT: {'localhost': [1]}
[2023-10-01 03:05:40,450] [INFO] [launch.py:235:main] nnodes=1, num_local_procs=1, node_rank=0
[2023-10-01 03:05:40,450] [INFO] [launch.py:246:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2023-10-01 03:05:40,450] [INFO] [launch.py:247:main] dist_world_size=1
[2023-10-01 03:05:40,450] [INFO] [launch.py:249:main] Setting CUDA_VISIBLE_DEVICES=1
RWKV_MY_TESTING 
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/wkv_512/build.ninja...
Building extension module wkv_512...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module wkv_512...
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 4.626850605010986 seconds
[2023-10-01 03:06:36,527] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 1428454
[2023-10-01 03:06:36,527] [ERROR] [launch.py:434:sigkill_handler] ['/home/neromous/.minicoda3/envs/blackfog/bin/python', '-u', 'app.py', '--local_rank=0', '--deepspeed'] exits with return code = -15
[2023-10-01 03:07:07,903] [WARNING] [runner.py:190:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2023-10-01 03:07:07,923] [INFO] [runner.py:540:main] cmd = /home/neromous/.minicoda3/envs/blackfog/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None app.py --deepspeed
[2023-10-01 03:07:10,455] [INFO] [launch.py:229:main] WORLD INFO DICT: {'localhost': [1]}
[2023-10-01 03:07:10,455] [INFO] [launch.py:235:main] nnodes=1, num_local_procs=1, node_rank=0
[2023-10-01 03:07:10,455] [INFO] [launch.py:246:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2023-10-01 03:07:10,455] [INFO] [launch.py:247:main] dist_world_size=1
[2023-10-01 03:07:10,455] [INFO] [launch.py:249:main] Setting CUDA_VISIBLE_DEVICES=1
RWKV_MY_TESTING 
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/wkv_512/build.ninja...
Building extension module wkv_512...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module wkv_512...
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 4.673945426940918 seconds
Adam Optimizer #0 is created with AVX2 arithmetic capability.
Config: alpha=0.000010, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=0
[2023-10-01 03:08:05,809] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.9.1, git-hash=unknown, git-branch=unknown
[2023-10-01 03:08:05,810] [INFO] [comm.py:586:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2023-10-01 03:08:08,755] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-10-01 03:08:08,757] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2023-10-01 03:08:08,757] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2023-10-01 03:08:08,796] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam
[2023-10-01 03:08:08,797] [INFO] [utils.py:51:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>
[2023-10-01 03:08:08,797] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float32 ZeRO stage 2 optimizer
[2023-10-01 03:08:08,797] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 2000000
[2023-10-01 03:08:08,797] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 2000000
[2023-10-01 03:08:08,797] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: True
[2023-10-01 03:08:08,797] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.5294139385223389 seconds
Rank: 0 partition count [1, 1, 1] and sizes[(3062589440, False), (81920, False), (81920, False)] 
[2023-10-01 03:08:35,167] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[2023-10-01 03:08:35,168] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-10-01 03:08:35,168] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 22.5 GB, percent = 17.9%
[2023-10-01 03:08:55,830] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[2023-10-01 03:08:55,831] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-10-01 03:08:55,832] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 61.72 GB, percent = 49.1%
[2023-10-01 03:08:55,832] [INFO] [stage_1_and_2.py:489:__init__] optimizer state initialized
[2023-10-01 03:08:57,946] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[2023-10-01 03:08:57,947] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-10-01 03:08:57,947] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 61.73 GB, percent = 49.1%
[2023-10-01 03:08:57,973] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedCPUAdam
[2023-10-01 03:08:57,973] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2023-10-01 03:08:57,973] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7f8c627fba30>
[2023-10-01 03:08:57,973] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[1e-05, 2e-05, 3.0000000000000004e-05], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
[2023-10-01 03:08:57,975] [INFO] [config.py:953:print] DeepSpeedEngine configuration:
[2023-10-01 03:08:57,975] [INFO] [config.py:957:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-10-01 03:08:57,975] [INFO] [config.py:957:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-10-01 03:08:57,975] [INFO] [config.py:957:print]   amp_enabled .................. False
[2023-10-01 03:08:57,975] [INFO] [config.py:957:print]   amp_params ................... False
[2023-10-01 03:08:57,975] [INFO] [config.py:957:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-10-01 03:08:57,975] [INFO] [config.py:957:print]   bfloat16_enabled ............. False
[2023-10-01 03:08:57,975] [INFO] [config.py:957:print]   checkpoint_parallel_write_pipeline  False
[2023-10-01 03:08:57,976] [INFO] [config.py:957:print]   checkpoint_tag_validation_enabled  True
[2023-10-01 03:08:57,976] [INFO] [config.py:957:print]   checkpoint_tag_validation_fail  False
[2023-10-01 03:08:57,976] [INFO] [config.py:957:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f8c6282bb50>
[2023-10-01 03:08:57,976] [INFO] [config.py:957:print]   communication_data_type ...... None
[2023-10-01 03:08:57,976] [INFO] [config.py:957:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-10-01 03:08:57,976] [INFO] [config.py:957:print]   curriculum_enabled_legacy .... False
[2023-10-01 03:08:57,976] [INFO] [config.py:957:print]   curriculum_params_legacy ..... False
[2023-10-01 03:08:57,976] [INFO] [config.py:957:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-10-01 03:08:57,976] [INFO] [config.py:957:print]   data_efficiency_enabled ...... False
[2023-10-01 03:08:57,976] [INFO] [config.py:957:print]   dataloader_drop_last ......... False
[2023-10-01 03:08:57,976] [INFO] [config.py:957:print]   disable_allgather ............ False
[2023-10-01 03:08:57,976] [INFO] [config.py:957:print]   dump_state ................... False
[2023-10-01 03:08:57,976] [INFO] [config.py:957:print]   dynamic_loss_scale_args ...... None
[2023-10-01 03:08:57,976] [INFO] [config.py:957:print]   eigenvalue_enabled ........... False
[2023-10-01 03:08:57,976] [INFO] [config.py:957:print]   eigenvalue_gas_boundary_resolution  1
[2023-10-01 03:08:57,976] [INFO] [config.py:957:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-10-01 03:08:57,976] [INFO] [config.py:957:print]   eigenvalue_layer_num ......... 0
[2023-10-01 03:08:57,976] [INFO] [config.py:957:print]   eigenvalue_max_iter .......... 100
[2023-10-01 03:08:57,976] [INFO] [config.py:957:print]   eigenvalue_stability ......... 1e-06
[2023-10-01 03:08:57,976] [INFO] [config.py:957:print]   eigenvalue_tol ............... 0.01
[2023-10-01 03:08:57,976] [INFO] [config.py:957:print]   eigenvalue_verbose ........... False
[2023-10-01 03:08:57,976] [INFO] [config.py:957:print]   elasticity_enabled ........... False
[2023-10-01 03:08:57,976] [INFO] [config.py:957:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-10-01 03:08:57,977] [INFO] [config.py:957:print]   fp16_auto_cast ............... None
[2023-10-01 03:08:57,977] [INFO] [config.py:957:print]   fp16_enabled ................. False
[2023-10-01 03:08:57,977] [INFO] [config.py:957:print]   fp16_master_weights_and_gradients  False
[2023-10-01 03:08:57,977] [INFO] [config.py:957:print]   global_rank .................. 0
[2023-10-01 03:08:57,977] [INFO] [config.py:957:print]   grad_accum_dtype ............. None
[2023-10-01 03:08:57,977] [INFO] [config.py:957:print]   gradient_accumulation_steps .. 1
[2023-10-01 03:08:57,977] [INFO] [config.py:957:print]   gradient_clipping ............ 1
[2023-10-01 03:08:57,977] [INFO] [config.py:957:print]   gradient_predivide_factor .... 1.0
[2023-10-01 03:08:57,977] [INFO] [config.py:957:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-10-01 03:08:57,977] [INFO] [config.py:957:print]   initial_dynamic_scale ........ 65536
[2023-10-01 03:08:57,977] [INFO] [config.py:957:print]   load_universal_checkpoint .... False
[2023-10-01 03:08:57,977] [INFO] [config.py:957:print]   loss_scale ................... 0
[2023-10-01 03:08:57,977] [INFO] [config.py:957:print]   memory_breakdown ............. False
[2023-10-01 03:08:57,977] [INFO] [config.py:957:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-10-01 03:08:57,977] [INFO] [config.py:957:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-10-01 03:08:57,977] [INFO] [config.py:957:print]   optimizer_legacy_fusion ...... False
[2023-10-01 03:08:57,977] [INFO] [config.py:957:print]   optimizer_name ............... None
[2023-10-01 03:08:57,977] [INFO] [config.py:957:print]   optimizer_params ............. None
[2023-10-01 03:08:57,977] [INFO] [config.py:957:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-10-01 03:08:57,977] [INFO] [config.py:957:print]   pld_enabled .................. False
[2023-10-01 03:08:57,977] [INFO] [config.py:957:print]   pld_params ................... False
[2023-10-01 03:08:57,978] [INFO] [config.py:957:print]   prescale_gradients ........... False
[2023-10-01 03:08:57,978] [INFO] [config.py:957:print]   scheduler_name ............... None
[2023-10-01 03:08:57,978] [INFO] [config.py:957:print]   scheduler_params ............. None
[2023-10-01 03:08:57,978] [INFO] [config.py:957:print]   sparse_attention ............. None
[2023-10-01 03:08:57,978] [INFO] [config.py:957:print]   sparse_gradients_enabled ..... False
[2023-10-01 03:08:57,978] [INFO] [config.py:957:print]   steps_per_print .............. 10
[2023-10-01 03:08:57,978] [INFO] [config.py:957:print]   train_batch_size ............. 1
[2023-10-01 03:08:57,978] [INFO] [config.py:957:print]   train_micro_batch_size_per_gpu  1
[2023-10-01 03:08:57,978] [INFO] [config.py:957:print]   use_node_local_storage ....... False
[2023-10-01 03:08:57,978] [INFO] [config.py:957:print]   wall_clock_breakdown ......... False
[2023-10-01 03:08:57,978] [INFO] [config.py:957:print]   world_size ................... 1
[2023-10-01 03:08:57,978] [INFO] [config.py:957:print]   zero_allow_untested_optimizer  False
[2023-10-01 03:08:57,978] [INFO] [config.py:957:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=2000000 allgather_partitions=True allgather_bucket_size=2000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=True, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False memory_efficient_linear=True
[2023-10-01 03:08:57,978] [INFO] [config.py:957:print]   zero_enabled ................. True
[2023-10-01 03:08:57,978] [INFO] [config.py:957:print]   zero_force_ds_cpu_optimizer .. True
[2023-10-01 03:08:57,978] [INFO] [config.py:957:print]   zero_optimization_stage ...... 2
[2023-10-01 03:08:57,978] [INFO] [config.py:943:print_user_config]   json = {
    "   fp16": {
        "enabled": false
    }, 
    "zero_optimization": {
        "stage": 2, 
        "offload_optimizer": {
            "device": "cpu", 
            "pin_memory": true
        }, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+06, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+06, 
        "contiguous_gradients": true
    }, 
    "gradient_accumulation_steps": 1, 
    "gradient_clipping": 1, 
    "train_micro_batch_size_per_gpu": 1, 
    "checkpoint": {
        "path": "/home/neromous/Documents/blackfog/resources/train-results/oneline/", 
        "keep_checkpoint_max": 3
    }
}
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0005297660827636719 seconds
Bottle v0.12.25 server starting up (using WSGIRefServer())...
Listening on http://0.0.0.0:3000/
Hit Ctrl-C to quit.

====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
[2023-10-01 03:09:15,471] [INFO] [checkpointing.py:529:forward] Activation Checkpointing Information
[2023-10-01 03:09:15,472] [INFO] [checkpointing.py:530:forward] ----Partition Activations False, CPU CHECKPOINTING False
[2023-10-01 03:09:15,472] [INFO] [checkpointing.py:531:forward] ----contiguous Memory Checkpointing False with None total layers
[2023-10-01 03:09:15,472] [INFO] [checkpointing.py:533:forward] ----Synchronization False
[2023-10-01 03:09:15,472] [INFO] [checkpointing.py:534:forward] ----Profiling time in checkpointing False
-> item_loss 0.7348158955574036 batch_loss 0.7348158955574036, real_loss 0.7348158955574036
-> item_loss 0.6746442914009094 batch_loss 0.7047300934791565, real_loss 0.6746442914009094
-> item_loss 1.373616099357605 batch_loss 0.9276920954386393, real_loss 1.7170201539993286
-> item_loss 0.6108068823814392 batch_loss 0.8484707921743393, real_loss 0.6108068823814392
-> item_loss 1.7661436796188354 batch_loss 1.0320053696632385, real_loss 2.207679510116577
-> item_loss 0.9605066180229187 batch_loss 1.0200889110565186, real_loss 0.9605066180229187
-> item_loss 1.7281142473220825 batch_loss 1.121235387665885, real_loss 2.1601428985595703
-> item_loss 0.7948115468025208 batch_loss 1.0804324075579643, real_loss 0.7948115468025208
-> item_loss 1.4497145414352417 batch_loss 1.1214637557665508, real_loss 1.8121432065963745
[2023-10-01 03:11:40,206] [INFO] [logging.py:96:log_dist] [Rank 0] step=10, skipped=0, lr=[1.0000000000000003e-05, 1.0000000000000003e-05, 1.0000000000000003e-05], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
-> item_loss 0.7286021709442139 batch_loss 1.082177597284317, real_loss 0.7286021709442139
-> item_loss 0.6217634081840515 batch_loss 1.0403217619115657, real_loss 0.6217634081840515
-> item_loss 1.0207319259643555 batch_loss 1.0386892755826314, real_loss 1.2759149074554443
-> item_loss 0.4352439343929291 batch_loss 0.9922704031834235, real_loss 0.054405491799116135
-> item_loss 0.4005560576915741 batch_loss 0.9500050927911486, real_loss 0.05006950721144676
-> item_loss 1.4219409227371216 batch_loss 0.9814674814542135, real_loss 1.7774261236190796
-> item_loss 0.36769619584083557 batch_loss 0.9431067761033773, real_loss 0.045962024480104446
-> item_loss 0.16681799292564392 batch_loss 0.8974427300340989, real_loss 0.02085224911570549
-> item_loss 0.500519871711731 batch_loss 0.8753914601273007, real_loss 0.500519871711731
-> item_loss 0.7760391235351562 batch_loss 0.8701623897803458, real_loss 0.7760391235351562
[2023-10-01 03:13:43,708] [INFO] [logging.py:96:log_dist] [Rank 0] step=20, skipped=0, lr=[1.0000000000000003e-05, 1.0000000000000003e-05, 1.0000000000000003e-05], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
-> item_loss 1.2322982549667358 batch_loss 0.8882691830396652, real_loss 1.5403728485107422
-> item_loss 1.1703954935073853 batch_loss 0.9017037692524138, real_loss 1.4629943370819092
-> item_loss 0.4107917547225952 batch_loss 0.8793895867737856, real_loss 0.0513489693403244
-> item_loss 0.4984278678894043 batch_loss 0.8628260337788126, real_loss 0.06230348348617554
-> item_loss 1.2264732122421265 batch_loss 0.8779779995481173, real_loss 1.5330915451049805
-> item_loss 0.8064908981323242 batch_loss 0.8751185154914856, real_loss 0.8064908981323242
-> item_loss 0.6132271885871887 batch_loss 0.8650457721490127, real_loss 0.6132271885871887
-> item_loss 0.8346256613731384 batch_loss 0.8639191013795359, real_loss 0.8346256613731384
-> item_loss 1.7274532318115234 batch_loss 0.8947596060378211, real_loss 2.1593165397644043
-> item_loss 0.297402024269104 batch_loss 0.8741610687354515, real_loss 0.037175253033638
[2023-10-01 03:15:20,932] [INFO] [logging.py:96:log_dist] [Rank 0] step=30, skipped=0, lr=[1.0000000000000003e-05, 1.0000000000000003e-05, 1.0000000000000003e-05], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
-> item_loss 1.6649885177612305 batch_loss 0.9005219837029775, real_loss 2.081235647201538
-> item_loss 1.4808223247528076 batch_loss 0.9192413495432946, real_loss 1.8510279655456543
-> item_loss 0.5297740697860718 batch_loss 0.9070704970508814, real_loss 0.5297740697860718
-> item_loss 0.4460815191268921 batch_loss 0.8931011340834878, real_loss 0.05576018989086151
-> item_loss 0.45455530285835266 batch_loss 0.8802027272827485, real_loss 0.05681941285729408
-> item_loss 1.624386191368103 batch_loss 0.9014651119709015, real_loss 2.030482769012451
-> item_loss 0.41635948419570923 batch_loss 0.8879899556438128, real_loss 0.052044935524463654
-> item_loss 1.6626003980636597 batch_loss 0.9089253730065113, real_loss 2.0782504081726074
-> item_loss 0.6224996447563171 batch_loss 0.9013878538420326, real_loss 0.6224996447563171
-> item_loss 0.5330567955970764 batch_loss 0.8919434677331876, real_loss 0.5330567955970764
[2023-10-01 03:17:05,691] [INFO] [logging.py:96:log_dist] [Rank 0] step=40, skipped=0, lr=[1.0000000000000003e-05, 1.0000000000000003e-05, 1.0000000000000003e-05], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
-> item_loss 1.609276294708252 batch_loss 0.9098767884075641, real_loss 2.0115952491760254
-> item_loss 1.5729120969772339 batch_loss 0.9260483812995073, real_loss 1.9661401510238647
-> item_loss 0.5492727160453796 batch_loss 0.91707753212679, real_loss 0.5492727160453796
-> item_loss 0.3733612596988678 batch_loss 0.9044329676517221, real_loss 0.046670157462358475
-> item_loss 0.5147587060928345 batch_loss 0.8955767344344746, real_loss 0.5147587060928345
-> item_loss 1.6826176643371582 batch_loss 0.9130665328767564, real_loss 2.103271961212158
-> item_loss 0.5124051570892334 batch_loss 0.904356502968332, real_loss 0.5124051570892334
-> item_loss 0.5571140646934509 batch_loss 0.8969683659837601, real_loss 0.5571140646934509
-> item_loss 0.1770613044500351 batch_loss 0.8819703022018075, real_loss 0.022132663056254387
-> item_loss 0.4861209988594055 batch_loss 0.8738917449907381, real_loss 0.06076512485742569
[2023-10-01 03:19:13,357] [INFO] [logging.py:96:log_dist] [Rank 0] step=50, skipped=0, lr=[1.0000000000000003e-05, 1.0000000000000003e-05, 1.0000000000000003e-05], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
-> item_loss 0.8533505201339722 batch_loss 0.8734809204936027, real_loss 0.8533505201339722
-> item_loss 1.4030076265335083 batch_loss 0.8838637970826205, real_loss 1.753759503364563
127.0.0.1 - - [01/Oct/2023 03:19:27] "POST /train/sft HTTP/1.1" 200 28
None
None
192.168.0.103 - - [01/Oct/2023 03:21:12] "POST /state/reset HTTP/1.1" 200 21
  0%|          | 0/582 [00:00<?, ?it/s]100%|██████████| 582/582 [00:00<00:00, 32891.18it/s]
  0%|          | 0/582 [00:00<?, ?it/s]100%|██████████| 582/582 [00:00<00:00, 507396.58it/s]
assistant： 我会注意避免犯同样的错误的。
192.168.0.103 - - [01/Oct/2023 03:21:38] "POST /inference/generate HTTP/1.1" 200 14988
None
None
192.168.0.103 - - [01/Oct/2023 03:21:48] "POST /state/reset HTTP/1.1" 200 21
master: 你知道吗，我刚才说的那些话，都是经过深思熟虑的。
192.168.0.103 - - [01/Oct/2023 03:22:15] "POST /inference/generate HTTP/1.1" 200 15757
None
None
192.168.0.103 - - [01/Oct/2023 03:22:23] "POST /state/reset HTTP/1.1" 200 21
