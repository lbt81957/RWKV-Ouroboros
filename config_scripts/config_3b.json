{
  "model_path": "/home/neromous/pyblackfog/rwkv-output-models/on-line/default.pth",
  "model_name": "default",
  "proj_dir": "/home/neromous/pyblackfog/rwkv-output-models/on-line",
  "port" : 40011,
  "debug" : false,
  "infctx_on": false,
  "infctx_type":"wani-boat",
  "model": {
    "n_embd": 2560,
    "n_layer": 32,
    "vocab_size": 65536,
    "ctx_len": 256
  },
  "lora":false,
  "lora_config":{
    "r": 0,
    "alpha": 0,
    "dropout": 0,
    "parts": ["att", "ln", "time"],
    "layers": null
  },
  "trainer": {
    "warmup_steps" : 8,
    "grad_cp" : 1,
    "window" :  0,
    "min_loss" : 0.5,
    "max_loss" : 1.5,
    "min_loss_fix":0.05,
    "max_loss_fix":1.05,
    "ctx_parts" : "0",
    "tokenizer" : "./rwkv_vocab_v20230424.txt"
    },
  "environ": {
    "RWKV_JIT_ON": "1",
    "RWKV_T_MAX":  256,
    "RWKV_FLOAT_MODE": "fp32",
    "RWKV_TORCH_COMPILE": "",
    "RWKV_TORCH_RUN_MODE": "torch-complie",
    "RWKV_MY_TESTING" : "",
    "RWKV_STATE": "0"
  },
  "role": {
    "system": {
      "prefix": [65530,65531],
      "postfix": [65535,261]
    },
    "ego": {
      "prefix": [65530,65531],
      "postfix": [65535,261]
    },
    "master": {
      "prefix": [65530,65532],
      "postfix": [65535,261]
    },
    "request": {
      "prefix": [65530,65532],
      "postfix": [65535,261]
    },
    "user": {
      "prefix": [65530,65532],
      "postfix": [65535,261]
    },
    "think": {
      "prefix": [65530,65533],
      "postfix": [65535,261]
    },
    "analysis" : {
      "prefix": [65530,65533],
      "postfix": [65535,261]
    },
    "response": {
      "prefix": [65530,65534],
      "postfix": [65535,261]
    },
    "robot": {
      "prefix": [65530,65534],
      "postfix": [65535,261]
    },
    "claude": {
      "prefix": [65530,65534],
      "postfix": [65535,261]
    },
    "instruction": {
      "prefix": [],
      "postfix": []
    },
    "answer": {
      "prefix": [],
      "postfix": []
    },
    "think": {
      "prefix": [],
      "postfix": []
    },

    "book": {
      "prefix": [],
      "postfix": [261]
    },
    "context": {
      "prefix": [],
      "postfix": []
    },
    "other": {
      "prefix": [],
      "postfix": []
    },
    "text": {
      "prefix": [],
      "postfix": []
    }
  },
  "inference": {
    "tokenizer": "./rwkv_vocab_v20230424.txt",
    "prompt_config": {
      "temperature": 0.1,
      "top_p": 0.1,
      "top_k": 0,
      "alpha_frequency": 0.45,
      "alpha_presence": 0.45,
      "alpha_decay": 0.996,
      "token_ban": [0],
      "token_stop": [65532],
      "chunk_len": 128,
      "token_count": 0,
      "over": true
    }

  }
}
