{
  "model_path": null,
  "model_name": "",
  "proj_dir": "",
  "model": {
    "n_embd": 2560,
    "n_layer": 32,
    "vocab_size": 65536,
    "ctx_len": 1024
  },
  "environ": {
    "RWKV_JIT_ON": "1",
    "RWKV_FLOAT_MODE": "fp16"
  },
  "role": {
    "system": {
      "prefix": [
        65530,
        65531
      ],
      "postfix": [
        65535
      ]
    },
    "user": {
      "prefix": [
        65530,
        65532
      ],
      "postfix": [
        65535
      ]
    },
    "think": {
      "prefix": [
        65530,
        65533
      ],
      "postfix": [
        65535
      ]
    },
    "robot": {
      "prefix": [
        65530,
        65534
      ],
      "postfix": [
        65535
      ]
    },
    "text": {
      "prefix": [],
      "postfix": [
        261
      ]
    }
  },
  "tokenzier": {
    "tokenizer_name": ""
  },
  "trainer": {
    "load_model": "/home/neromous/pyblackfog/rwkv-output-models/3b/rwkv-9.pth",
    "proj_dir": "/home/neromous/pyblackfog/rwkv-output-models/3b",
    "wandb": "",
    "weight_decay": 0,
    "layerwise_lr": 0,
    "random_seed": -1,
    "data_file": "/home/neromous/data/bonsai",
    "text_book": "/home/neromous/data/bonsai-textbook",
    "data_type": "utf-8",
    "epoch_steps": 100000,
    "epoch_count": 500,
    "epoch_begin": 20,
    "epoch_save": 5,
    "micro_bsz": 1,
    "pre_ffn": 0,
    "grad_cp": 1,
    "my_pos_emb": 0,
    "my_testing": "",
    "num_nodes": 1,
    "devices": 1,
    "strategy": "deepspeed_stage_2_offload",
    "gradient_accumulation_steps": 16,
    "accumulate_grad_batches": 4,
    "head_qk": 0
  },
  "inference": {
    "prompt_config": {
      "temperature": 0.1,
      "top_p": 0.1,
      "top_k": 0,
      "alpha_frequency": 0.45,
      "alpha_presence": 0.45,
      "alpha_decay": 0.996,
      "token_ban": [],
      "token_stop": [
        0,
        65535
      ],
      "chunk_len": 128,
      "token_count": 256,
      "over": true
    },
    "service_config": {
      "RUN_DEVICE": "cuda",
      "FLOAT_MODE": "fp16"
    }
  }
}
